\documentclass{book}
%\newcommand{\VolumeName}{Volume 2: Axiom Users Guide}
%\input{bookheader.tex}
\pagenumbering{arabic}
\mainmatter
\setcounter{chapter}{0} % Chapter 1

\usepackage{makeidx}
\makeindex
\begin{document}
\begin{verbatim}
\start
Date: 01 Jun 2007 08:26:07 +0200
From: Martin Rubey
To: Tim Daly
Subject: Re: Hyperdoc on windows

Tim Daly writes:

> The following question was raised about hyperdoc on windows.
> I did some work on this years ago and got it running.
> 
> > Hae?  You have a HyperDoc port for windows? Where can I get  it?
> 
> I uploaded hyperwin.tgz. You can get it at 
> <http://daly.axiom-developer.org/hyperwin.tgz>
> 
> For instructions see:
> <http://lists.gnu.org/archive/html/axiom-developer/2005-12/msg00438.html>

Since I cannot really try it (no MS Windows here...), another question: does
this also enable graphics?  At the time you wrote that you are "now trying to
get the graphics working" -- did you succeed?

I assume that your hyperdoc patch does communicate with axiom, i.e., browse and
examples work?  Otherwise it would be quite worthless, as you know.

Waldek, do you think you could merge that into your branch -- given that my
assumption is correct?

Would be great!

\start
Date: 01 Jun 2007 10:36:45 +0200
From: Martin Rubey
To: Franz Lehner, Peter Broadbery
Subject: Re: wh-sandbox and aldor

--=-=-=

Dear Franz, Peter, 

Franz: please always copy to the list, I think it is ok to send 10kb.  Your
problems may be very useful for others :-) Furthermore, there are people more
knowledgeable about building than me.  I hope you don't mind that I send the
logs to the list.

Peter: do you think you could update your Aldor support to work "out of the
box" with wh-sandbox.  At least here in Austria there seems to be a lot of
demand.  If I understand correctly, wh-sandbox (and probably
build-improvements) do not use the $AXIOM variable anymore, and the directory
structure has changed quite a bit.  Moreover, out of source build seems to be
recommended now.  I include my personal notes at the very end of this mail, but
it seems that they don't work for everybody.

> > ## make stops with
> > #
> > # SPADSET MK: all_spadsets.mk
> > # make[1]: *** No rule to make target
> > `/home/martin/ax-build/int/aldor/all_spad_cats.mk'.  Stop.
> > # make[1]: Leaving directory `/home/martin/ax-build/src/aldor'
> > # make: *** [all] Error 2
> yes, I got this far

great.

> > touch ../../int/aldor/dep_spad.stamp
> > document Make.functions.pamphlet
> > make

I believe the problem is described by the line in the log

  /bin/sh:
  /home/lehner/usr/local/src/axiom/ax-build/src/aldor/x86_64-unknown-linux/bin/interpsys:
  Datei oder Verzeichnis nicht gefunden

interpsys is an intermediate version of the axiom interpreter.  But the path

/home/lehner/usr/local/src/axiom/ax-build/src/aldor/x86_64-unknown-linux/bin/

looks rather broken -- it seems that -

  /src/aldor should rather be /build

all the time...  Hm, maybe you could just locate interpsys in your ax-build
tree, and set the path so that it will find it.  On my system it is

ax-build/build/i686-pc-linux/bin/interpsys

However, I am a little afraid that some variable is badly set.  What's the
value of $AXIOM when you tried to build?

Good luck,

Martin


--=-=-=
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--=-=-=


# After out of source build in ax-build:

# !!! check version of make (3.81 beta 4 does not work !!!

# put or link document into ax-build/target/i686-pc-linux/bin

# extract src_aldor2.tar into ax-build/src/aldor

cd ax-build/src/aldor
document Makefile.pamphlet

export AXIOM=~/ax-build/target/i686-pc-linux/
make
## make stops with
# 
# SPADSET MK: all_spadsets.mk
# make[1]: *** No rule to make target
`/home/martin/ax-build/int/aldor/all_spad_cats.mk'.  Stop.
# make[1]: Leaving directory `/home/martin/ax-build/src/aldor'
# make: *** [all] Error 2

touch ../../int/aldor/dep_spad.stamp
document Make.functions.pamphlet
make

# if build stops complaining that "no rule to make target ... axlit ", check
  version of make again

\start
Date: Fri, 1 Jun 2007 10:44:29 +0200 (CEST)
From: Franz Lehner
To: list
Subject: Re: wh-sandbox and aldor (fwd)

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

--461446550-125466476-1180679951=:27758

Dear Martin

thanks for looking into this.
> I believe it's better to do an out of source build of wh-sandbox.  Below are
> some notes I took for myself.
tried this over night.

>> document Makefile.pamphlet
>> apparently is not enough, as the other pamphlets are not unpacked.
> 
> Hm
this time document worked automatically for the others.

> !!! check version of make (3.81 beta 4 does not work !!!
> put or link document into ax-build/target/i686-pc-linux/bin
I also had to link wh-sandbox/src/scripts into ax-build/src/scripts

> ## make stops with
> #
> # SPADSET MK: all_spadsets.mk
> # make[1]: *** No rule to make target
> `/home/martin/ax-build/int/aldor/all_spad_cats.mk'.  Stop.
> # make[1]: Leaving directory `/home/martin/ax-build/src/aldor'
> # make: *** [all] Error 2
yes, I got this far

> touch ../../int/aldor/dep_spad.stamp
> document Make.functions.pamphlet
> make
it still says
ax-build/int/aldor/sax0/spadset.mk: Datei oder Verzeichnis nicht gefunden
there is only spadset_check.mk and .dir in ax-build/int/aldor/sax0/,
no spadset.mk; same for ax-build/int/aldor/saxiom/.


> # if build stops complaining that "no rule to make target ... axlit ", check
>  version of make again
make is 3.80 (3.81 from debian/etch moved out of the way).

make logs are included.

Franz
--461446550-125466476-1180679951=:27758
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--461446550-125466476-1180679951=:27758--

\start
Date: Fri, 1 Jun 2007 12:01:34 +0200 (CEST)
From: Franz Lehner
To: Martin Rubey
Subject: Re: wh-sandbox and aldor



> /home/lehner/usr/local/src/axiom/ax-build/src/aldor/x86_64-unknown-linux/bin/
>
> looks rather broken -- it seems that -
>
>  /src/aldor should rather be /build


> However, I am a little afraid that some variable is badly set.  What's the
> value of $AXIOM when you tried to build?
/home/lehner/usr/local/src/axiom/ax-build/target/x86_64-unknown-linux

Apparently the Makefile explicitly calls
ax-build/src/aldor/x86_64-unknown-linux/bin/interpsys

thus I did
ln -s build/x86_64-unknown-linux src/aldor
now proceeds further and stops at
echo LSP->O: lang.o
make[1]: *** [/home/lehner/usr/local/src/axiom/axiom1/ax-build/target/x86_64-unk
nown-linux/aldor/lib/lang.o] Fehler 255

whatever that means (long line?)

Franz
--461446550-175242582-1180692094=:26415
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--461446550-175242582-1180692094=:26415--

\start
Date: Fri, 1 Jun 2007 17:09:12 +0200 (CEST)
From: Waldek Hebisch
To: Alfredo Portes
Subject: Re: HyperDocReplacement

Alfredo Portes wrote:
> Has anyone been able to run Martin's code in
> 
> http://wiki.axiom-developer.org/SandBoxHyperDocReplacement
> 
> While trying to test this on the latest wh-sandbox and
> build-improvements I got into some issues:
> 
> 1. In wh-sandbox I need to give a full path to the hyper.spad file and
> hyper.lisp. With build improvements it works like in the example above
> (the loading of the files).
> 
> 2. In wh-sandbox doing )co \...\hyper.spad in  I get:
>    >> System error:
>    Cannot create the file HYPER.erlib/index.KAF
>

I am affraid that wh-sandbox needs paths with slashes: /.../hyper.spad
 
> I have a rookie question if one does: )co hyper.spad twice is the
> first one overwritten by the first one, or does it damage the first
> one? I say this because I did this by mistake, and the first one
> loaded fine, but the second time I got:
> 
> >> System error:
> Cannot rename the file "p "HYPER.erlib" to #p"HYPER.NRLIB"
> 

The compile command is careful to overwrite the result only _after_
successful complilation.  In particular the compilation proper
creates HYPER.erlib and after it is created HYPER.NRLIB is removed
and HYPER.erlib renamed to HYPER.NRLIB.  

Currently HYPER.NRLIB is removed using "rm -r" command, which may
fail on Windows.

\start
Date: Fri, 1 Jun 2007 17:57:43 +0200 (CEST)
From: Waldek Hebisch
To: Martin Rubey
Subject: Re: wh-sandbox and aldor
Cc: Franz Lehner

Martin, Franz,

I looked at the build logs and at src_aldor2.tgz.  AFAICS the
very first line in the log is wrong.  Namely, the Makefile
assumes old directory structure.  Currently both in wh-sandbox
and in build-improvements OBJ directory is gone.  Supporting
programs are in build/x86_64-unknown-linux/bin (where
x86_64-unknown-linux must be replaced by system name).  wh-sandbox
still uses INT directory, but it is going to change
(to match build-improvements).

There is no fixed relation between build tree and source tree,
so one has to get souce location as an extra parameter.

Because Makefile uses combination of 'cd' and 'pwd' to compute
some directory names one quickly gets completly bogus paths.
However once a few toplevel paths are fixed other parts
should be easy.

\start
Date: Fri, 1 Jun 2007 12:23:41 -0400
From: Bill Page
To: Martin Rubey
Subject: RE: Hyperdoc on windows

On June 1, 2007 2:26 AM Martin Rubey wrote:
> 
> Tim Daly writes:
> 
> > The following question was raised about hyperdoc on windows.
> > I did some work on this years ago and got it running.
> > 
> > > Hae?  You have a HyperDoc port for windows? Where can I get
> > > it?
> > 
> > I uploaded hyperwin.tgz. You can get it at 
> > http://daly.axiom-developer.org/hyperwin.tgz
> > 
> > For instructions see:
> > 
> http://lists.gnu.org/archive/html/axiom-developer/2005-12/msg00438.html

> Since I cannot really try it (no MS Windows here...), another
> question: does this also enable graphics?

No. So far as I can see this is a stand alone version of hyperdoc
only.

> At the time you wrote that you are "now trying to get the graphics
> working" -- did you succeed?

I don't recall any email from Tim that announced this. It would
be nice but stand alone Axiom graphics is not all that useful.

> I assume that your hyperdoc patch does communicate with axiom,
> i.e., browse and examples work?  Otherwise it would be quite
> worthless, as you know.

No, this is a stand alone version of hyperdoc only. It does
not communicate with Axiom. As you say, this way of running
hyperdoc has only very limited usefulness.

To run hyperdoc and Axiom the way it is done on linux would also
require the sman program which in turn requires pty support but
since AXIOMsys is a native Windows application, this is not
possible. Also the socket interface between hyperdoc and AXIOMsys
must work. As far as I know, no one has ever tested the Axiom
socket interface for the windows version of AXIOMsys. Getting
this to work *might* be possible.

> Waldek, do you think you could merge that into your branch --
> given that my assumption is correct?
>
> Would be great!

Unfortunately I think this would be premature. :-(

Also it is important to note that building hyperdoc this way
requires the cygwin environment and running it requires as a
minimum the installation of the cygwin library.

I still think the *best* option right now for running hyperdoc
and axiom graphics on Windows is via Microsoft Virtual PC
(or VMware). You can download the liveCD based on wh-sandbox
recently created by Alfredo, install both Virtual PC, Xming
and putty, then you can run all of Axiom "virtually" under
windows.

\start
Date: Fri, 1 Jun 2007 13:18:06 -0400
From: Alfredo Portes
To: Waldek Hebisch, 
Subject: Re: Compile Error

Hi Waldek,

> I am looking at the problem but unfortunatly the reason is still
> unknown.  The problem is clearly related to memory managment.  You
> may try the following patch (which switches gcl garbage collector
> to different mode):
>
> --- /home/s/test/tt/axiom2/wh-sandbox2/src/lisp/Makefile.pamphlet       2007-05-26 23:24:29.000000000 +0200
> +++ wh-sandbox2/src/lisp/Makefile.pamphlet      2007-06-01 14:18:03.000000000 +0200
> @@ -86,7 +86,7 @@
>                                          ' (si::*load-types* ~S))' \
>                                         ' (compiler::emit-fn t))' \
>                                    ' (when (fboundp (quote si::sgc-on))' \
> -                                        ' (si::sgc-on t))' \
> +                                        ' (si::sgc-on nil))' \
>                                    ' (setq compiler::*default-system-p* t))"' \
>                        ' si::*system-directory* (quote (list ".lsp")))' \
>                 '  "$(lisp_c_objects) @axiom_c_runtime_extra@")' \

The patch worked, thanks.

\start
Date: 01 Jun 2007 12:49:53 -0500
From: Gabriel Dos Reis
To: Alfredo Portes
Subject: re: Compile Error

Alfredo Portes writes:

| Hi Waldek,
| 
| > I am looking at the problem but unfortunatly the reason is still
| > unknown.  The problem is clearly related to memory managment.  You
| > may try the following patch (which switches gcl garbage collector
| > to different mode):
| >
| > --- /home/s/test/tt/axiom2/wh-sandbox2/src/lisp/Makefile.pamphlet       2007-05-26 23:24:29.000000000 +0200
| > +++ wh-sandbox2/src/lisp/Makefile.pamphlet      2007-06-01 14:18:03.000000000 +0200
| > @@ -86,7 +86,7 @@
| >                                          ' (si::*load-types* ~S))' \
| >                                         ' (compiler::emit-fn t))' \
| >                                    ' (when (fboundp (quote si::sgc-on))' \
| > -                                        ' (si::sgc-on t))' \
| > +                                        ' (si::sgc-on nil))' \
| >                                    ' (setq compiler::*default-system-p* t))"' \
| >                        ' si::*system-directory* (quote (list ".lsp")))' \
| >                 '  "$(lisp_c_objects) @axiom_c_runtime_extra@")' \
| 
| The patch worked, thanks.

Does this also fix the problem you reported to me earlier on
build-improvements?

\start
Date: Fri, 1 Jun 2007 14:01:51 -0400
From: Alfredo Portes
To: Gabriel Dos Reis
Subject: re: Compile Error

Hi Gaby,

> Does this also fix the problem you reported to me earlier on
> build-improvements?

I was about to try it on build-improvements. I will let you know.

Also regarding the X libraries problem, I get the same problem
in wh-sandbox. Even when the headers are installed, hyperdoc...
does not build. When running config I get:

checking for X... libraries , headers in standard search path

Attached is the config.log for wh-sandbox. This is in Ubuntu 7.04.

Regards,

Alfredo

------=_Part_484_25242863.1180720911190
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------=_Part_484_25242863.1180720911190--

\start
Date: Fri, 1 Jun 2007 14:20:59 -0400
From: Alfredo Portes
To: Martin Rubey
Subject: Re: HyperDocReplacement

I recompiled wh-sandbox and it seems to work fine the first two steps.
However I get
this:

(1) -> SOCKET(8080, getDocumentation$HyperDoc)
   There are no library operations named SOCKET
      Use HyperDoc Browse or issue
                               )what op SOCKET
      to learn if there is any operation containing " SOCKET " in its
      name.

   Cannot find a definition or applicable library operation named
      SOCKET with argument type(s)
                               PositiveInteger
                             (String -> String)

      Perhaps you should use "@" to indicate the required return type,
      or "$" to specify which version of the function you need.

Of course it can be that this is not the way to run it.

\start
Date: Fri, 1 Jun 2007 20:41:10 +0200 (CEST)
From: Waldek Hebisch
To: Alfredo Portes
Subject: re: Compile Error
Cc: Gabriel Dos Reis

> Also regarding the X libraries problem, I get the same problem
> in wh-sandbox. Even when the headers are installed, hyperdoc...
> does not build. When running config I get:
> 
> checking for X... libraries , headers in standard search path
> 
> Attached is the config.log for wh-sandbox. This is in Ubuntu 7.04.
> 

In the log I see:

: configure:7521: checking for XpmReadFileToImage in -lXpm
: configure:7551: gcc -o conftest -g -O2   conftest.c -lXpm  -lX11  >&5
: /usr/bin/ld: cannot find -lXpm
: collect2: ld returned 1 exit status
: configure:7557: $? = 1

which means that configure can not find libXpm.  If you really have
libXpm can you tell us where it lives?

\start
Date: Fri, 1 Jun 2007 14:52:56 -0400
From: Alfredo Portes
To: Waldek Hebisch
Subject: re: Compile Error
Cc: Gabriel Dos Reis

Hi Waldek,

On 6/1/07, Waldek Hebisch wrote:
> > Also regarding the X libraries problem, I get the same problem
> > in wh-sandbox. Even when the headers are installed, hyperdoc...
> > does not build. When running config I get:
> >
> > checking for X... libraries , headers in standard search path
> >
> > Attached is the config.log for wh-sandbox. This is in Ubuntu 7.04.
> >
>
> In the log I see:
>
> : configure:7521: checking for XpmReadFileToImage in -lXpm
> : configure:7551: gcc -o conftest -g -O2   conftest.c -lXpm  -lX11  >&5
> : /usr/bin/ld: cannot find -lXpm
> : collect2: ld returned 1 exit status
> : configure:7557: $? = 1
>
> which means that configure can not find libXpm.  If you really have
> libXpm can you tell us where it lives?

"I see" said the blind man :-). I think in Ubuntu/Debian the packages
for the X header files are in : libx11-dev and libxt-dev.

A search in my box for libXpm yields:

/usr/lib32/libXpm.so.4
/usr/lib32/libXpm.so.4.11.0
/usr/lib/libXpm.so.4
/usr/lib/libXpm.so.4.11.0

\start
Date: Fri, 1 Jun 2007 14:52:50 -0400
From: Bill Page
To: Waldek Hebisch, Alfredo Portes
Subject: re: Compile Error
Cc: Gabriel Dos Reis

On June 1, 2007 2:41 PM Waldek Hebisch wrote:
> 
> > Also regarding the X libraries problem, I get the same problem
> > in wh-sandbox. Even when the headers are installed, hyperdoc...
> > does not build. When running config I get:
> > 
> > checking for X... libraries , headers in standard search path
> > 
> > Attached is the config.log for wh-sandbox. This is in Ubuntu
> > 7.04.
> > 
> 
> In the log I see:
> 
> : configure:7521: checking for XpmReadFileToImage in -lXpm
> : configure:7551: gcc -o conftest -g -O2   conftest.c -lXpm  
> -lX11  >&5
> : /usr/bin/ld: cannot find -lXpm
> : collect2: ld returned 1 exit status
> : configure:7557: $? = 1
> 
> which means that configure can not find libXpm.  If you really have
> libXpm can you tell us where it lives?
> 

See:

http://wiki.axiom-developer.org/306LibXpmAIsInUsrLibUnderUbuntu

Perhaps this helps?

\start
Date: Fri, 1 Jun 2007 14:57:06 -0400
From: Alfredo Portes
To: Bill Page
Subject: re: Compile Error
Cc: Gabriel Dos Reis

Thanks Bill.

Wasn't this patch committed some time ago?

>
> See:
>
> http://wiki.axiom-developer.org/306LibXpmAIsInUsrLibUnderUbuntu
>
> Perhaps this helps?
>
> Regards,
> Bill Page.

\start
Date: Fri, 1 Jun 2007 14:59:07 -0400
From: Alfredo Portes
To: Gabriel Dos Reis
Subject: re: Compile Error

> Does this also fix the problem you reported to me earlier on
> build-improvements?

build-improvements builds fine now with the patch. Thank you.

\start
Date: Fri, 1 Jun 2007 21:06:25 +0200 (CEST)
From: Waldek Hebisch
To: Alfredo Portes
Subject: re: Compile Error
Cc: Gabriel Dos Reis

> Hi Waldek,
> 
> On 6/1/07, Waldek Hebisch wrote:
> > > Also regarding the X libraries problem, I get the same problem
> > > in wh-sandbox. Even when the headers are installed, hyperdoc...
> > > does not build. When running config I get:
> > >
> > > checking for X... libraries , headers in standard search path
> > >
> > > Attached is the config.log for wh-sandbox. This is in Ubuntu 7.04.
> > >
> >
> > In the log I see:
> >
> > : configure:7521: checking for XpmReadFileToImage in -lXpm
> > : configure:7551: gcc -o conftest -g -O2   conftest.c -lXpm  -lX11  >&5
> > : /usr/bin/ld: cannot find -lXpm
> > : collect2: ld returned 1 exit status
> > : configure:7557: $? = 1
> >
> > which means that configure can not find libXpm.  If you really have
> > libXpm can you tell us where it lives?
> 
> "I see" said the blind man :-). I think in Ubuntu/Debian the packages
> for the X header files are in : libx11-dev and libxt-dev.
> 
> A search in my box for libXpm yields:
> 
> /usr/lib32/libXpm.so.4
> /usr/lib32/libXpm.so.4.11.0
> /usr/lib/libXpm.so.4
> /usr/lib/libXpm.so.4.11.0
> 

I do not see libXpm.a here -- it looks that you miss development version
of libXpm (needed for linking new programs).  Installing libxpm-dev should
fix this.

\start
Date: Fri, 1 Jun 2007 15:12:02 -0400
From: Alfredo Portes
To: Waldek Hebisch
Subject: re: Compile Error
Cc: Gabriel Dos Reis

> I do not see libXpm.a here -- it looks that you miss development version
> of libXpm (needed for linking new programs).  Installing libxpm-dev should
> fix this.

Yes indeed, I am missing that. Thank you very much Waldek.

Do you think configure should be more verbose about it?
The checking for X... libraries , headers in standard search path message made
me think that everything was ok.

\start
Date: Fri, 1 Jun 2007 14:22:17 -0500 (CDT)
From: Gabriel Dos Reis
To: Waldek Hebisch
Subject: re: Compile Error

On Fri, 1 Jun 2007, Waldek Hebisch wrote:

| > Also regarding the X libraries problem, I get the same problem
| > in wh-sandbox. Even when the headers are installed, hyperdoc...
| > does not build. When running config I get:
| > 
| > checking for X... libraries , headers in standard search path
| > 
| > Attached is the config.log for wh-sandbox. This is in Ubuntu 7.04.
| > 
| 
| In the log I see:
| 
| : configure:7521: checking for XpmReadFileToImage in -lXpm
| : configure:7551: gcc -o conftest -g -O2   conftest.c -lXpm  -lX11  >&5
| : /usr/bin/ld: cannot find -lXpm
| : collect2: ld returned 1 exit status
| : configure:7557: $? = 1
| 
| which means that configure can not find libXpm.  If you really have
| libXpm can you tell us where it lives?

I was punting on that issue.  It looks like it is time to properly solve it.
Since it works on my systems, I would need some platforms where it is
an issue.  I'll try to see whether one of the machines at SF does the job.

\start
Date: Fri, 1 Jun 2007 14:24:10 -0500 (CDT)
From: Gabriel Dos Reis
To: Alfredo Portes
Subject: re: Compile Error

On Fri, 1 Jun 2007, Alfredo Portes wrote:

| Do you think configure should be more verbose about it?

Yes, unambiguously.

\start
Date: 02 Jun 2007 08:46:04 +0200
From: Martin Rubey
To: Bill Page, Alasdair McAndrew
Subject: Re: [Axiom-mail] Defining piece-wise functions	and drawing, integrating, ...

Dear Bill,

Bill Page writes:

> http://wiki.axiom-developer.org/358VariableIsApparentlyAlwaysAssumedToBePosi
> tive
> 
> > The latter filing is more complete and correctly categorised.
> 
> Good. Thanks for submitting the report!
> 
> Normally I would add my comments directly to the report, but I think this one
> deserves a little discussion first because it is important to understand what
> Axiom is doing with your commands.

Thanks for your nice explanation.  I temporarily forgot that axiom evaluates
all the arguments before passing them to the function. :-) A feature I *really*
love about axiom, by the way.

Thus it first finds a type for f(x), then for x=-1..1, and then tries to find a
fitting signature for draw.  However, doesn't axiom sometimes try several
signatures, until it succeeds?  Here, it sticks to the very first type it can
find for f(x).  It seems that Axiom assumes that compiling a function with two
different signatures yields the same result.  Well, that's probably reasonable.

I guess we can close the issue.  Maybe we should rename it though?

\start
Date: 02 Jun 2007 10:28:33 +0200
From: Martin Rubey
To: Alasdair McAndrew
Subject: Re: [Axiom-mail] A pattern matching question
Cc: Themos Tsikas

Dear Themos, Alasdair,

trying to debug the freeOf? pattern, I discovered that Themos' pattern suffers
from the same problem:

tt:=operator 'tt; ttrules := rule tt(n/(n^a+(X | integer?(a) and (n-1)^a = n^a +X))) == 1/t^a

(100) -> ttrules tt(n/(n^6+anything))

           1
   (100)  --
           6
          t
                                                     Type: Expression Integer

The problem seems to be that the syntactic sugar for the suchThat operation "|"
only works if we have a function of a single variable.  Of course, calling
suchThat without sugar, axiom does the right thing:

(101) -> ttrules := suchThat(rule tt(n/(n^a+X)) == 1/t^a, [a, X], l +-> integer? first
 l and (n-1)^(first l) = n^(first l) + second l)

                n        1
   (101)  tt(------) == --
              a          a
             n  + X     t
                        Type: RewriteRule(Integer,Integer,Expression Integer)
(102) -> ttrules tt(n/(n^6+anything))

                   n
   (102)  tt(-------------)
              6
             n  + anything
                                                     Type: Expression Integer
(103) -> ttrules tt(n/((n-1)^6))

           1
   (103)  --
           6
          t
                                                     Type: Expression Integer

\start
Date: 02 Jun 2007 15:18:32 +0200
From: Martin Rubey
To: Waldek Hebisch, Tim Daly, Bill Page
Subject: Patches

--=-=-=

Dear Bill, Tim, Waldek,

here are some patches for bug #355.


--=-=-=

Index: special.spad.pamphlet
===================================================================
--- special.spad.pamphlet	(revision 580)
+++ special.spad.pamphlet	(working copy)
@@ -86,7 +86,7 @@
             ++ \spad{Y(v,x)}.
 	    ++ This function satisfies the differential equation:
 	    ++   \spad{x^2 w''(x) + x w'(x) + (x^2-v^2)w(x) = 0}.
-            ++ Note: The default implmentation uses the relation
+            ++ Note: The default implementation uses the relation
             ++   \spad{Y(v,x) = (J(v,x) cos(v*%pi) - J(-v,x))/sin(v*%pi)}
             ++ so is not valid for integer values of v.
 	besselY: (C, C) -> C
@@ -94,7 +94,7 @@
             ++ \spad{Y(v,x)}.
 	    ++ This function satisfies the differential equation:
 	    ++   \spad{x^2 w''(x) + x w'(x) + (x^2-v^2)w(x) = 0}.
-            ++ Note: The default implmentation uses the relation
+            ++ Note: The default implementation uses the relation
             ++   \spad{Y(v,x) = (J(v,x) cos(v*%pi) - J(-v,x))/sin(v*%pi)}
             ++ so is not valid for integer values of v.
 
@@ -110,19 +110,19 @@
 	    ++   \spad{x^2 w''(x) + x w'(x) - (x^2+v^2)w(x) = 0}.
 
 	besselK: (R, R) -> R
-	    ++ besselK(v,x) is the modified Bessel function of the first kind,
+	    ++ besselK(v,x) is the modified Bessel function of the second kind,
             ++ \spad{K(v,x)}.
 	    ++ This function satisfies the differential equation:
 	    ++   \spad{x^2 w''(x) + x w'(x) - (x^2+v^2)w(x) = 0}.
-            ++ Note: The default implmentation uses the relation
+            ++ Note: The default implementation uses the relation
             ++   \spad{K(v,x) = %pi/2*(I(-v,x) - I(v,x))/sin(v*%pi)}.
             ++ so is not valid for integer values of v.
 	besselK: (C, C) -> C
-	    ++ besselK(v,x) is the modified Bessel function of the first kind,
+	    ++ besselK(v,x) is the modified Bessel function of the second kind,
             ++ \spad{K(v,x)}.
 	    ++ This function satisfies the differential equation:
 	    ++   \spad{x^2 w''(x) + x w'(x) - (x^2+v^2)w(x) = 0}.
-            ++ Note: The default implmentation uses the relation
+            ++ Note: The default implementation uses the relation
             ++   \spad{K(v,x) = %pi/2*(I(-v,x) - I(v,x))/sin(v*%pi)}
             ++ so is not valid for integer values of v.
 

--=-=-=

Index: combfunc.spad.pamphlet
===================================================================
--- combfunc.spad.pamphlet	(revision 580)
+++ combfunc.spad.pamphlet	(working copy)
@@ -41,11 +41,6 @@
       ++ formal product;
 
 @
-The latest change allows Axiom to reduce
-\begin{verbatim}
-   sum(1/i,i=1..n)-sum(1/i,i=1..n) 
-\end{verbatim}
-to reduce to zero.
 <<package COMBF CombinatorialFunction>>=
 )abbrev package COMBF CombinatorialFunction
 ++ Provides the usual combinatorial functions
@@ -703,21 +698,33 @@
     Gamma   : F -> F
       ++ Gamma(f) returns the formal Gamma function applied to f
     Gamma   : (F,F) -> F
-      ++ Gamma(a,x) returns the incomplete Gamma function applied to a and x
+      ++ Gamma(a,x) returns the incomplete Gamma function applied to a and x.
+      ++ Concerning differentiation, it is regarded as a function in the second
+      ++ argument only.
     Beta:      (F,F) -> F
       ++ Beta(x,y) returns the beta function applied to x and y
     digamma:   F->F
       ++ digamma(x) returns the digamma function applied to x 
     polygamma: (F,F) ->F
-      ++ polygamma(x,y) returns the polygamma function applied to x and y
+      ++ polygamma(x,y) returns the polygamma function applied to x and y. 
+      ++ Concerning differentiation, it is regarded as a function in the second
+      ++ argument only.
     besselJ:   (F,F) -> F
-      ++ besselJ(x,y) returns the besselj function applied to x and y
+      ++ besselJ(x,y) returns the besselj function applied to x and y.
+      ++ Concerning differentiation, it is regarded as a function in the second
+      ++ argument only.
     besselY:   (F,F) -> F
-      ++ besselY(x,y) returns the bessely function applied to x and y
+      ++ besselY(x,y) returns the bessely function applied to x and y.
+      ++ Concerning differentiation, it is regarded as a function in the second
+      ++ argument only.
     besselI:   (F,F) -> F
-      ++ besselI(x,y) returns the besseli function applied to x and y
+      ++ besselI(x,y) returns the besseli function applied to x and y.
+      ++ Concerning differentiation, it is regarded as a function in the second
+      ++ argument only.
     besselK:   (F,F) -> F
-      ++ besselK(x,y) returns the besselk function applied to x and y
+      ++ besselK(x,y) returns the besselk function applied to x and y.
+      ++ Concerning differentiation, it is regarded as a function in the second
+      ++ argument only.
     airyAi:    F -> F
       ++ airyAi(x) returns the airyai function applied to x 
     airyBi:    F -> F
@@ -837,7 +844,16 @@
         ahalf * (besselI (n-1,x) + besselI (n+1,x))
     iBesselKGrad(l: List F): F ==
         n := first l; x := second l
-        ahalf * (besselK (n-1,x) + besselK (n+1,x))
+        - ahalf * (besselK (n-1,x) + besselK (n+1,x))
+
+@
+The formulas above for the Bessel functions can be found in Milton Abramowitz
+and Irene A. Stegun, eds.  (1965). Handbook of Mathematical Functions with
+Formulas, Graphs, and Mathematical Tables. New York: Dover. ISBN 0-486-61272-4,
+Equations~9.1.27 and 9.6.26.  Up to [[patch--50]] the formula for $K$ missed
+the minus sign.  (Issue~\#355)
+
+<<package FSPECF FunctionalSpecialFunction>>=
     ipolygammaGrad(l: List F): F ==
         n := first l; x := second l
         polygamma(n+1, x)

--=-=-=


Bill: I have been unable to upload the files to MathAction again, and could not
find the instructions.  Maybe you could provide some help on MathAction
itsself?

Tim, Waldek: would you be so kind to include these patches in the respective
distributions.  By the way, I just found the documented version of the patch to
STTAYLOR, it is on MathAction, #312, powern.patch. I include a version that
applies smoothly to wh-sandbox here, too.  Please apply this one also.


--=-=-=

Index: sttaylor.spad.pamphlet
===================================================================
--- sttaylor.spad.pamphlet	(revision 580)
+++ sttaylor.spad.pamphlet	(working copy)
@@ -401,6 +401,14 @@
        cssa(frst ststa,mapsa((rst x) * #1,comps(rst ststa,x)))
 
     if A has Algebra RN then
+@
+
+The following defines lazy integration on streams interpreted as Taylor series.
+I.e. if [[x]] is $c_0,c_1,c_2,\dots$, then [[integ x]] returns
+$c_0,\frac{1}{2}c_1,\frac{1}{3}c_2,\dots$. [[integrate]] prepends a given
+constant of integration.
+
+<<package STTAYLOR StreamTaylorSeriesOperations>>=
       integre: (ST A,I) -> ST A
       integre(x,n) == delay
         empty? x => zro()
@@ -412,6 +420,9 @@
       integrate(a,x) == concat(a,integ x)
       lazyIntegrate(s,xf) == concat(s,integ(delay xf))
 
+@
+
+<<package STTAYLOR StreamTaylorSeriesOperations>>=
       nldere:(ST ST A,ST A) -> ST A
       nldere(lslsa,c) == lazyIntegrate(0,addiag(comps(lslsa,c)))
       nlde lslsa == YS(nldere(lslsa,#1))
@@ -420,10 +431,45 @@
 
       smult: (RN,ST A) -> ST A
       smult(rn,x) == map(rn * #1,x)
+@
+
+The following helper function computes
+\begin{equation*}
+  1+\int (rn+1) c x' dz - c (x-a_0),
+\end{equation*}
+where $a_0$ is the constant term of [[x]].
+
+<<package STTAYLOR StreamTaylorSeriesOperations>>=
       powerrn:(RN,ST A,ST A) -> ST A
       powerrn(rn,x,c) == delay
         concat(1,integ(smult(rn + 1,c * deriv x)) - rst x * c)
-      powern(rn,x) ==
+@
+
+The following operation raises the power series [[x]] to a rational power
+[[rn]]. We first outline the general strategy.
+
+Suppose the constant term of [[x]] equals one. In this case, we have
+\begin{equation*}
+  x^{rn+1} = 1 + \int (rn+1) x^{rn} x' dz,  
+\end{equation*}
+since $(x^{rn+1})'= (rn+1)x^{rn} x'$.  Thus, $x^{rn}$ is the fixed point of %
+[[g +-> powerrn(rn, x, g)]]. We use [[Y$ParadoxicalCombinatorsForStreams(A)]]%$
+to compute this fixed point lazily.
+
+If the constant term of [[x]] is neither zero nor one, we use the identity
+\begin{equation*}
+  (c_0 + c_1*z + c_2 z^2\dots)^{rn} = c_0^{rn} (1 + \frac{c_1}{c_0}*z +\dots)^{rn}.
+\end{equation*}
+
+Finally, if the constant term of [[x]] is zero, we use the identity
+\begin{equation*}
+  (c_0*z^o + c_1*z^{o+1} +\dots)^{rn} = z^{o rn} (c_0 + c_1*z +\dots)^{rn}.
+\end{equation*}
+
+This implementation should be compared with [[cRationalPower$ISUPS]].%$
+
+<<package STTAYLOR StreamTaylorSeriesOperations>>=
+      powern(rn, x) ==
         order : I := 0
         for n in 0.. repeat
           empty? x => return zro()
@@ -431,17 +477,46 @@
           x := rst x
           n = 1000 =>
             error "**: series with many leading zero coefficients"
+@
+First we determine the order of [[x]], i.e., the index of the first non-zero
+coefficient.
+
+Remarks:
+\begin{itemize}
+\item Note that usually [[leave]] takes no arguments. I don't know what it does
+      here.
+\item [[empty? x]] tests whether the stream [[x]] has no elements. This is
+      mathematically the same as the corresponding power series being zero.
+\end{itemize}
+
+<<package STTAYLOR StreamTaylorSeriesOperations>>=
         (ord := (order exquo denom(rn))) case "failed" =>
           error "**: rational power does not exist"
-        co := frst x
+@
+
+[[ord*numer(rn)]] will be the order of the new power series. If it is not an
+integer, we won't get a Taylor expansion and thus raise an error.
+
+<<package STTAYLOR StreamTaylorSeriesOperations>>=
         if ord > 0 and rn < 0 then
            error "**: negative power does not exist" 
+@
+
+If [[order]] was non-zero, we may not raise to a negative power. This test
+should really be done before the previous one.
+
+<<package STTAYLOR StreamTaylorSeriesOperations>>=
+        co := frst x
         (invCo := recip co) case "failed" =>
            error "** rational power of coefficient undefined"
--- This error message is misleading, isn't it? see sups.spad/cRationalPower
+@
+
+We need to be able to invert the leading coefficient. The error message is
+slightly misleading, see [[sups.spad/cRationalPower]].
+
+<<package STTAYLOR StreamTaylorSeriesOperations>>=
         power :=
---          one? co => YS(powerrn(rn,x,#1))
-          (co = 1) => YS(powerrn(rn,x,#1))
+          one? co => YS(powerrn(rn,x,#1))
           (denom rn) = 1 =>
             not negative?(num := numer rn) => 
 -- It seems that this cannot happen, but I don't know why
@@ -450,8 +525,23 @@
 
           RATPOWERS => co**rn * YS(powerrn(rn,(invCo :: A) * x,#1))
           error "** rational power of coefficient undefined"
+@
+
+We now invoke the fixed point computation as explained above. We can do the
+computation if
+\begin{itemize}
+\item the constant term equals one, or
+\item [[rn]] is an integer, or
+\item we have rational powers in the coefficient ring.
+\end{itemize}
+
+<<package STTAYLOR StreamTaylorSeriesOperations>>=
         monom(1,(ord :: I) * numer(rn)) * power
+@
 
+Finally, we return the result with the correct order.
+
+<<package STTAYLOR StreamTaylorSeriesOperations>>=
     if A has Field then
       mapdiv(x,y) == delay
         empty? y => error "stream division by zero"

--=-=-=


Waldek: do you prefer if I commit to your branch myself, or is this form good
for you, too?


\start
Date: Sat, 02 Jun 2007 15:21:36 +0200
From: Ralf Hemmecke
To: Martin Rubey
Subject: Re: [Axiom-mail] Defining piece-wise functions and drawing, integrating, ...
Cc: Bill Page Bill Page, Alasdair McAndrew

On 06/02/2007 08:46 AM, Martin Rubey wrote:
> Dear Bill,
> 
> Bill Page writes:
> 
>> http://wiki.axiom-developer.org/358VariableIsApparentlyAlwaysAssumedToBePosi
>> tive
>>
>>> The latter filing is more complete and correctly categorised.
>> Good. Thanks for submitting the report!
>>
>> Normally I would add my comments directly to the report, but I think this one
>> deserves a little discussion first because it is important to understand what
>> Axiom is doing with your commands.
> 
> Thanks for your nice explanation.  I temporarily forgot that axiom evaluates
> all the arguments before passing them to the function. :-) A feature I *really*
> love about axiom, by the way.

Bill, that is a really nice explanation of what happens and it should 
*not* be forgotten inside the mailing lists.

> Thus it first finds a type for f(x), then for x=-1..1, and then tries to find a
> fitting signature for draw.  However, doesn't axiom sometimes try several
> signatures, until it succeeds?  Here, it sticks to the very first type it can
> find for f(x).  It seems that Axiom assumes that compiling a function with two
> different signatures yields the same result.  Well, that's probably reasonable.
> 
> I guess we can close the issue.  Maybe we should rename it though?

I would say close it, when someone has started yet another file 
"tutorial.pamphlet" (maybe even mathaction is OK) which contains exactly 
what Bill has written. There should be several such tutorial sections. 
It is good if somebody tells you what actually happens in particular if 
you don't expect Axiom's output.

Just recently I gave up on TeXmacs, since I ran into too many problems 
that I could not solve and that were not properly explained in a tutorial.

Yes, I think it is even good to show "error messages" and explain why 
they appear. If you deal with some software and often find that it 
behaves differently from what you expect, you get frustrated.

\start
Date: Sat, 2 Jun 2007 12:49:15 -0500
From: Tim Daly
To: Martin Rubey
Subject: Bug #355

Martin,

Thanks for the diff-Naur patch for bug #355.
I'll apply it today and start a new build/test cycle.
If it passes I'll push it out to silver.

\start
Date: 02 Jun 2007 21:41:01 +0200
From: Martin Rubey
To: Tim Daly
Subject: Re: Bug #355

Tim Daly writes:

> Martin,
> 
> Thanks for the diff-Naur patch for bug #355.
> I'll apply it today and start a new build/test cycle.
> If it passes I'll push it out to silver.

and how about #312?

\start
Date: Sat, 2 Jun 2007 19:44:25 -0500
From: Tim Daly
To: Martin Rubey
Subject: bug #355

Martin, 

I merged and tested your changes. I've done a commit to SVN and git.

Axiom used to say:

-> D(besselK(a,x),x)

      besselK(a + 1,x) + besselK(a - 1,x)
 (1)  -----------------------------------
                     2

and now it says:


-> D(besselK(a,x),x)

      - besselK(a + 1,x) - besselK(a - 1,x)
 (1)  -------------------------------------
                       2

Is this the expected result?

I'll attaack bug #312 next and start another build/test cycle.
I'm trying to maintain individual changesets, one per fix.


\start
Date: Sat, 2 Jun 2007 20:14:11 -0500
From: Tim Daly
To: list
Subject: Porting to windows, Services for Unix

Does anyone have any experience with Microsoft's Services for Unix (SFU)
toolkit? I don't have a native windows compiler so I'm not sure if I
can use these tools. But it does mention porting X11 applications as
well as handling networking and processes. Someone with access to a
windows-native compiler could try to compile sman, hyperdoc, and graphics
and report the results.

<http://technet.microsoft.com/en-us/interopmigration/bb380242.aspx>

\start
Date: Sun, 3 Jun 2007 00:37:33 -0400
From: Bill Page
To: list
Subject: problem plotting simple functions

After building Axiom from a recent version of wh-sandbox
(revision 580) I get the following error. The first draw
command works fine but simpler examples fail:

(1) -> draw(sin(x*y),x=-5..5,y=-5..5)
   Compiling function %H with type (DoubleFloat,DoubleFloat) ->
      DoubleFloat
   Transmitting data...

   (1)  ThreeDimensionalViewport: "sin x*y"
                                               Type:
ThreeDimensionalViewport
(2) -> draw(sin(x),x=-5..5)
   Compiling function %J with type DoubleFloat -> DoubleFloat

   >> Error detected within library code:
   Not an integer

(2) -> draw(sin(x),x=-5.0..5.0)
   Compiling function %L with type DoubleFloat -> DoubleFloat

   >> Error detected within library code:
   Not an integer

(2) -> draw(sin,-5.0..5.0)

   >> Error detected within library code:
   Not an integer

------

I can find examples of similar failures by running the
graphics examples in hyperdoc.

Can anyone else reproduce this?

\start
Date: Sun, 3 Jun 2007 00:06:52 -0500
From: Tim Daly
To: Bill Page
Subject: problem plotting simple functions

Bill,

All 4 cases work in silver.

\start
Date: Sun, 3 Jun 2007 00:55:12 -0500
From: Tim Daly
To: Martin Rubey
Subject: bug #312

Martin,

The patch you posted on sttaylor fails to patch.
Can you create a diff-Naur against silver or gold?

\start
Date: Sun, 3 Jun 2007 02:50:09 -0400
From: Bill Page
To: Tim Daly
Subject: RE: problem plotting simple functions

On June 3, 2007 1:07 AM Tim Daly wrote:
> 
> All 4 cases work in silver.
> 

Thanks.

Yes. It also works fine in an earlier revision of wh-sandbox
on another platform: Open SuSE 10.2.

The problem I am having right now is with revision 580 on
a Solaris 10 x86 system. I don't know if it is just this
platform or just this revision.

I will try revision 580 on SuSE in the next few days.

\start
Date: Sun, 03 Jun 2007 08:56:13 +0200
From: Ralf Hemmecke
To: Bill Page
Subject: Re: problem plotting simple functions

Oh, interesting,

                         AXIOM Computer Algebra System
                        Version: Axiom (September 2006)
               Timestamp: Friday September 29, 2006 at 14:21:21

I think I compiled Gold from the tla archive.

On all 4 cases I get a window with title AXIOM2D or sin x*y, but I don't 
see any plot. Maybe I should compile a newer version. (Don't care about 
my case, I switched from debian sarge to etch without recompiling Axiom. 
So maybe that is a reason.)

Ralf

On 06/03/2007 06:37 AM, Bill Page wrote:
> After building Axiom from a recent version of wh-sandbox
> (revision 580) I get the following error. The first draw
> command works fine but simpler examples fail:
> 
> (1) -> draw(sin(x*y),x=-5..5,y=-5..5)
>    Compiling function %H with type (DoubleFloat,DoubleFloat) ->
>       DoubleFloat
>    Transmitting data...
> 
>    (1)  ThreeDimensionalViewport: "sin x*y"
>                                                Type:
> ThreeDimensionalViewport
> (2) -> draw(sin(x),x=-5..5)
>    Compiling function %J with type DoubleFloat -> DoubleFloat
> 
>    >> Error detected within library code:
>    Not an integer
> 
> (2) -> draw(sin(x),x=-5.0..5.0)
>    Compiling function %L with type DoubleFloat -> DoubleFloat
> 
>    >> Error detected within library code:
>    Not an integer
> 
> (2) -> draw(sin,-5.0..5.0)
> 
>    >> Error detected within library code:
>    Not an integer
> 
> ------
> 
> I can find examples of similar failures by running the
> graphics examples in hyperdoc.
> 
> Can anyone else reproduce this?

\start
Date: 03 Jun 2007 10:56:31 +0200
From: Martin Rubey
To: Tim Daly
Subject: Re: bug #312

Tim Daly writes:

> The patch you posted on sttaylor fails to patch.  Can you create a diff-Naur
> against silver or gold?

the patch you need is on IssueTracker.  The patch I posted is for Waldek.

\start
Date: Sun, 3 Jun 2007 13:44:46 -0400
From: Bill Page
To: Ralf Hemmecke
Subject: RE: Defining piece-wise functions and drawing,	integrating, ...

Note: Continued from discussion on axiom-mail.

On June 3, 2007 6:16 AM Ralf Hemmecke wrote:
> ...
> Bill Page wrote: 
> > The result of evaluating this expression depends on the value
> > assigned to x. This is a "piece-wise" expression in the sense
> > we have been discussing *BUT* this is a part of the Axiom
> > programming language - it is not part of any mathematical
> > object currently implemented in the Axiom library. The Axiom
> > library includes things like polynomials and even the domain
> > 'Expression' containing expressions like 'x+1' or 'sin(1)'
> > but there is currently no domain in which we can find an
> > expression like 'if x>0 then 1 else 0'.
> 
> Agreed, but what about telling Axiom the following:
> 
> (1) -> g(x)==if x>0 then x else -x
>                                  Type: Void
> 

I think this is equivalent to writing:

  g(x|x>0) == x
  g(x|x<=0) == -x

As far as I know the difference is only a matter of style.

> ...
> So let us in particular look at wat happens with g(y).
> ... 
> But what about the type of > and the type of 0.
> ...
> I guess it can easily be restricted to something of the form
> 
>    >: (Polynomial Integer, Polynomial Integer) -> Boolean
>
> ... 
> OK, now everything is clear and the compilation can start.
> 

Actually I would much prefer that there be no fuction named
'<' with the signature you give above. That leads to a lot
of unnecessary confusion and will also ultimately make a
proper treatment of predicates like 'x<0' more difficult.

> ... 
> As I see it, we are a bit in a dilemma here. We need the
> function expression here and at the same time > should be
> considered as something like (Float, Float) -> Boolean.
> 

I think we really need a class of fuctions > with signatures
like:

  > : (Expression Integer, Expression Integer) ->
        Union(Expression Integer, Boolean)

Then 'x<0' can be treated as an expression of type Expression
Integer just like 'sin(x)'. Or more generally we need a domain
of predicate expressions which can interact with other domains
like Expression. I would kind of like to write:

  Expression Boolean

but the current implementation of Expression does not produce
the desired result. But see for example my related experiments
at:

http://wiki.axiom-developer.org/SandboxBooleanRing

I think this is a step in the right direction.

> Yes, Bill is right, currently, Axiom's Expression(...) domain 
> does not allow to contain an expression of the form
> "if a then b else c".
> 

If we had a domain for predicate expressions then it would not
be difficult to introduce an expression in Expression of the
form:

  piecewise(Cond:Expression Boolean,
            Then:Expression Integer,
            Else:Expression Integer):Expression Integer

\start
Date: Sun, 3 Jun 2007 21:15:22 +0200 (CEST)
From: Waldek Hebisch
To: Bill Page
Subject: Re: problem plotting simple functions

Bill Page wrote:
> After building Axiom from a recent version of wh-sandbox
> (revision 580) I get the following error. The first draw
> command works fine but simpler examples fail:
> 
> (1) -> draw(sin(x*y),x=-5..5,y=-5..5)
>    Compiling function %H with type (DoubleFloat,DoubleFloat) ->
>       DoubleFloat
>    Transmitting data...
> 
>    (1)  ThreeDimensionalViewport: "sin x*y"
>                                                Type:
> ThreeDimensionalViewport
> (2) -> draw(sin(x),x=-5..5)
>    Compiling function %J with type DoubleFloat -> DoubleFloat
> 
>    >> Error detected within library code:
>    Not an integer
> 

I can not reporduce this in my developement version (slightly different
that revision 580).  Could you try your example enabling Lisp 
debugger: 

)lisp (si::use-fast-links nil)
)set break break

Then try the drawing commands.  Insted of message you should see

BOOT>>

prompt.  Type :bt at the prompt.  Do this in a terminal which
has at least few hundreds lines of scrollback or use utility like
script to capture output.  You should see the chain of calls
which resulted in error -- this should indicate in which function
the error happended and how we got there.

To get out of debugger type '(quit)' -- that is call Lisp function
quit.

\start
Date: Sun, 3 Jun 2007 21:43:06 +0200 (CEST)
From: Franz Lehner
To: list
Subject: Re: wh-sandbox and aldor, now silver

Dear all,

thanks for all your replies.
I did some more linking and got make to proceed up to
LSP->O: Error 255
in one go. Being clueless for the rest,
I switched to axiom.silver 580.

Some notes:
make stops at libXpm.a, which is in /usr/lib/libXpm.a under
Debian etch, which someone already noted in ubuntu. Simply replacing 
all occurences of 
XLIB= /usr/X11R6/lib
with
XLIB= /usr/lib

in Makefile.linux.pamphlet fixes this.

Aldor now compiles fine as well, even without any error message
if one does

      for pp in *.pamphlet; do document $pp;done

instead of only

      document Makefile.pamphlet

Thus there is a working amd64 environment now.

Unfortunately

     --enable-checking

does not work on silver.
Being completely illiterate in lisp, I blindly applied
Waldek's method from an earlier mail

+++ wh-sandbox2/src/interp/interp-proclaims.lisp        2007-04-12 
15:39:58.0000
00000 +0200
@@ -1,4 +1,6 @@
-
+(eval-when (:execute :compile-toplevel :load-toplevel)
+  (proclaim
+    '(optimize (safety 3))))
   (IN-PACKAGE "USER")
   (PROCLAIM '(FTYPE (FUNCTION (*) (VALUES T T)) BOOT:|ReadLine|))
   (PROCLAIM


it does compile, but then leads to

     >> System error:
     The function |output| is undefined.

and consequently no results are shown.
Is there a way to fix this?

\start
Date: Sun, 03 Jun 2007 22:56:27 +0200
From: Ralf Hemmecke
To: Bill Page
Subject: Re: Defining piece-wise functions and drawing,	integrating, ...

On 06/03/2007 07:44 PM, Bill Page wrote:
> Note: Continued from discussion on axiom-mail.
> 
> On June 3, 2007 6:16 AM Ralf Hemmecke wrote:
>> ...
>> Bill Page wrote: 
>>> The result of evaluating this expression depends on the value
>>> assigned to x. This is a "piece-wise" expression in the sense
>>> we have been discussing *BUT* this is a part of the Axiom
>>> programming language - it is not part of any mathematical
>>> object currently implemented in the Axiom library. The Axiom
>>> library includes things like polynomials and even the domain
>>> 'Expression' containing expressions like 'x+1' or 'sin(1)'
>>> but there is currently no domain in which we can find an
>>> expression like 'if x>0 then 1 else 0'.
>> Agreed, but what about telling Axiom the following:
>>
>> (1) -> g(x)==if x>0 then x else -x
>>                                  Type: Void
>>
> 
> I think this is equivalent to writing:
> 
>   g(x|x>0) == x
>   g(x|x<=0) == -x
> 
> As far as I know the difference is only a matter of style.

Since that function definition is only possible in the interpreter (SPAD 
would have to figure out some reasonable types at compile time, and 
Aldor would forbid such typeless things altogether), you may be right.

But, actually, who tells you that > and <= are "opposite" things?

Assume x: MyInteger and I define

(a: MyInteger) >  (b: MyInteger): Boolean == true;
(a: MyInteger) <= (b: MyInteger): Boolean == true;

Of course, that is a stupid definition, but it proves that my and your 
definition are in general not equivalent. (Just a side remark, let's 
discuss such details at the time when we are about to redesign the Axiom 
Library.

>> So let us in particular look at wat happens with g(y).
>> ... 
>> But what about the type of > and the type of 0.
>> ...
>> I guess it can easily be restricted to something of the form
>>
>>    >: (Polynomial Integer, Polynomial Integer) -> Boolean
>>
>> ... 
>> OK, now everything is clear and the compilation can start.
>>
> 
> Actually I would much prefer that there be no fuction named
> '<' with the signature you give above. That leads to a lot
> of unnecessary confusion and will also ultimately make a
> proper treatment of predicates like 'x<0' more difficult.

I somehow agree. I must say, when I wrote this, I had problems to figure 
our without testing what x>0 actually means if one thinks of > as being 
a "lexicographical" term order. In fact, extending a term order on the 
monoid [X] of power products to the full polynomial ring P=R[X] does not 
lead to an order on P that is compatible with multiplication.

>> As I see it, we are a bit in a dilemma here. We need the
>> function expression here and at the same time > should be
>> considered as something like (Float, Float) -> Boolean.
>>
> 
> I think we really need a class of fuctions > with signatures
> like:
> 
>   > : (Expression Integer, Expression Integer) ->
>         Union(Expression Integer, Boolean)

I think that would make things more complicated.

> Then 'x<0' can be treated as an expression of type Expression
> Integer just like 'sin(x)'. Or more generally we need a domain
> of predicate expressions which can interact with other domains
> like Expression.

Yep. I like to see a true expression domain. Axiom's Expression(..) is 
rather special. It covers a lot, but its inhabitants are not expression 
trees. They are rational functions.

> I would kind of like to write:
> 
>   Expression Boolean
> 
> but the current implementation of Expression does not produce
> the desired result. But see for example my related experiments
> at:
> 
> http://wiki.axiom-developer.org/SandboxBooleanRing
> 
> I think this is a step in the right direction.

(1) -> a: BooleanRing := true()
(1) ->
    (1)  true
                         Type: BooleanRing
(2) -> b: BooleanRing := false()
(2) ->
    (2)  false
                         Type: BooleanRing
(3) -> a < b
    There are 4 exposed and 1 unexposed library operations named <
       having 2 argument(s) but none was determined to be applicable.
       Use HyperDoc Browse, or issue
                                 )display op <
       to learn more about the available operations. Perhaps
       package-calling the operation or using coercions on the arguments
       will allow you to apply the operation.

    Cannot find a definition or applicable library operation named <
       with argument type(s)
                                  BooleanRing
                                  BooleanRing

       Perhaps you should use "@" to indicate the required return type,
       or "$" to specify which version of the function you need.

(3) -> x:Polynomial(BooleanRing):=a
(3) ->
    (3)  true
                           Type: Polynomial BooleanRing
(4) -> y:Polynomial(BooleanRing):=b
(4) ->
    (4)  false
                           Type: Polynomial BooleanRing
(5) -> x<y
    There are 4 exposed and 1 unexposed library operations named <
       having 2 argument(s) but none was determined to be applicable.
       Use HyperDoc Browse, or issue
                                 )display op <
       to learn more about the available operations. Perhaps
       package-calling the operation or using coercions on the arguments
       will allow you to apply the operation.

    Cannot find a definition or applicable library operation named <
       with argument type(s)
                            Polynomial BooleanRing
                            Polynomial BooleanRing

       Perhaps you should use "@" to indicate the required return type,
       or "$" to specify which version of the function you need.

I surely must do something wrong, but I somehow have the impression that

   )show Polynomial BooleanRing

doesn't tell you the truth. It shows that there is a <: (%,%)->Boolean 
function.

But BooleanRing does not have a < function and Polynomial exports < only 
through PolynomialCategory where it says:

     if R has OrderedSet  then OrderedSet

OK, that was just a side remark.

Then writing "Expression BooleanRing" is probably also not what you 
want. At least I don't want it.

>> Yes, Bill is right, currently, Axiom's Expression(...) domain 
>> does not allow to contain an expression of the form
>> "if a then b else c".

> If we had a domain for predicate expressions then it would not
> be difficult to introduce an expression in Expression of the
> form:
> 
>   piecewise(Cond:Expression Boolean,
>             Then:Expression Integer,
>             Else:Expression Integer):Expression Integer

Well, what I would dream of is an expression domain (or several of them) 
that lets you define a general expression tree where you would have 
control over what is allowed as nodes. Maybe it would be interesting to 
be able to give a grammar G and MyExpression(G) would then describe the 
language generated by G. It would be nice to be able to encode the Aldor 
language in that way.

You all probably know that everything in Maple is an expression also "if 
a then b else c fi" and that one can compute with these things. (Yes, 
yes, looks again like the Maple language is nothing but Lisp with 
another syntax. ;-) ).

Aldor's LibAlgebra defines a domain ExpressionTree. But that is 
certainly not yet perfect.

\start
Date: Sun, 3 Jun 2007 18:05:34 -0400
From: Bill Page
To: Waldek Hebisch
Subject: re: problem plotting simple functions

On June 3, 2007 3:15 PM Waldek Hebisch wrote:
>
> Bill Page wrote:
> > After building Axiom from a recent version of wh-sandbox
> > (revision 580) I get the following error. The first draw
> > command works fine but simpler examples fail:
> >
> > (1) -> draw(sin(x*y),x=-5..5,y=-5..5)
> >    Compiling function %H with type (DoubleFloat,DoubleFloat) ->
> >       DoubleFloat
> >    Transmitting data...
> >
> >    (1)  ThreeDimensionalViewport: "sin x*y"
> >                                                Type:
> > ThreeDimensionalViewport
> > (2) -> draw(sin(x),x=-5..5)
> >    Compiling function %J with type DoubleFloat -> DoubleFloat
> >
> >    >> Error detected within library code:
> >    Not an integer
> >
>
> I can not reporduce this in my developement version (slightly
> different that revision 580).  Could you try your example enabling
> Lisp debugger:
>
> )lisp (si::use-fast-links nil)
> )set break break
>
> Then try the drawing commands.  Insted of message you should see
>
> BOOT>>
>
> prompt.  Type :bt at the prompt.  Do this in a terminal which
> has at least few hundreds lines of scrollback or use utility like
> script to capture output.  You should see the chain of calls
> which resulted in error -- this should indicate in which function
> the error happended and how we got there.
>
> To get out of debugger type '(quit)' -- that is call Lisp function
> quit.
>

Thanks.

Here's the debugger ouput.

-bash-3.00$ axiom
GCL (GNU Common Lisp)  2.6.8 CLtL1    Apr  7 2007 01:22:27
Source License: LGPL(gcl,gmp), GPL(unexec,bfd,xgcl)
Binary License:  GPL due to GPL'ed components: (XGCL BFD UNEXEC)
Modifications of this banner must retain notice of a compatible license
Dedicated to the memory of W. Schelter

Use (help) to get some basic information on how to use GCL.
Temporary directory for compiler files set to /tmp/
                        AXIOM Computer Algebra System
                 Version: Axiom wh-sandbox branch 2007-05-31
                Timestamp: Saturday June 2, 2007 at 14:14:18
-------------------------------------------------------------------------=
---
-
   Issue )copyright to view copyright notices.
   Issue )summary for a summary of useful system commands.
   Issue )quit to leave AXIOM and return to shell.
-------------------------------------------------------------------------=
---
-

(1) ->
(1) -> )lisp (si::use-fast-links nil)
)set break break

Value = NIL
(1) -> (1) -> draw(sin,-5.0..5.0)
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/FLOAT.o
      for domain Float
   Loading
      /export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/SEG.o
      for domain Segment
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/DFLOAT.o
      for domain DoubleFloat
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/DRAWCFUN.o
      for package TopLevelDrawFunctionsForCompiledFunctions
   Loading
      /export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/PLOT.o
      for domain Plot
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/POINT.o
      for domain Point
   Loading
      /export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/FPS-.o
      for domain FloatingPointSystem&
   Loading
      /export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/RNS-.o
      for domain RealNumberSystem&
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/DROPT0.o
      for package DrawOptionFunctions0
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/DROPT1.o
      for package DrawOptionFunctions1
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/DROPT.o
      for domain DrawOption
   Loading
      /export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/ANY.o
      for domain Any
   Loading
      /export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/SEX.o
      for domain SExpression
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/PTPACK.o
      for package PointPackage
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/TRANFUN-.o
      for domain TranscendentalFunctionCategory&
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/ELEMFUN-.o
      for domain ElementaryFunctionCategory&
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/HYPCAT-.o
      for domain HyperbolicFunctionCategory&
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/ATRIG-.o
      for domain ArcTrigonometricFunctionCategory&
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/TRIGCAT-.o
      for domain TrigonometricFunctionCategory&
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/RADCAT-.o
      for domain RadicalCategory&
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/BASTYPE-.o
      for domain BasicType&
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/VECTCAT-.o
      for domain VectorCategory&
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/GRDEF.o
      for package GraphicsDefaults
   Loading
      /export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/CLIP.o
      for package TwoDimensionalPlotClipping
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/LIST2.o
      for package ListFunctions2
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/FLAGG2.o
      for package FiniteLinearAggregateFunctions2
   Loading
      /export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/SEG2.o
      for package SegmentFunctions2

   >> Error detected within library code:
   Not an integer



Break.
Broken at SYSTEM::BREAK-LEVEL.  Type :H for Help.
BOOT>>:bt

#0   BREAK {loc0=nil,loc1=nil,loc2=#<synonym stream to *terminal-io*>,loc3="
",loc4=nil,loc...} [ihs=41]
#1   handleLispBreakLoop {loc0=|break|,loc1=nil,loc2=((arg (nil))),loc3=nil}
[ihs=40]
#2   errorSupervisor1 {loc0=|AlgebraError|,loc1="Not an
integer",loc2=|break|,loc3="Error detected wit...} [ihs=39]
#3   errorSupervisor {loc0=|AlgebraError|,loc1="Not an integer"} [ihs=38]
#4   error {loc0="Not an integer"} [ihs=37]
#5   DFLOAT;manexp {loc0=-5.0,loc1=#<vector 08e83560>,loc2=((|Integer|)
$),loc3=#<vector 08e83560>,...} [ihs=36]
#6   newGoGet {g104406=(-5.0 (#<vector 08e83ae0> 293 .
|mantissa|)),loc1=#<compiled-function |...} [ihs=35]
#7   newGoGet {g104406=(-5.0 (#<vector 08e83560> 63 .
|convert|)),loc1=#<compiled-function |FL...} [ihs=34]
#8   newGoGet {g104406=(-5.0 (#<vector 08e832c0> 162 .
|convert|)),loc1=#<compiled-function |D...} [ihs=33]
#9   newGoGet {g104406=((#<compiled-function |DRAWCFUN;drawPlot!0|> .
#<vector 08e832c0>) #<ve...} [ihs=32]
#10   DRAWCFUN;drawPlot {loc0=#<vector 0903d620>,loc1=nil,loc2=#<vector
08e832c0>} [ihs=31]
#11   DRAWCFUN;draw;MSTdv;7 {loc0=(#<compiled-function |DFLOAT;sin;2$;39|> .
#<vector 08e83560>),loc1=#<vect...} [ihs=30]
#12   FUNCALL {loc0=#<compiled-function
|DRAWCFUN;draw;MSTdv;7|>,loc1=(#<compiled-function |DF...} [ihs=29]
#13   FUNCALL {loc0=#<compiled-function
|DRAWCFUN;draw;MSTdv;7|>,loc1=(#<compiled-function |DF...} [ihs=28]
#14   EVAL {loc0=nil,loc1=nil,loc2=nil,loc3=(let ((#0=#:g1428 #)) (the
(values t) (funcall ...} [ihs=25]
#15   timedEvaluate {code=(spadcall (quote (#<compiled-function
|DFLOAT;sin;2$;39|> . #<vector 08e83...} [ihs=24]
#16   timedEVALFUN {loc0=(spadcall (quote (#<compiled-function
|DFLOAT;sin;2$;39|> . #<vector 08e83...} [ihs=23]
#17   evalFormMkValue {loc0=#<vector 08e836a0>,loc1=(spadcall (quote
(#<compiled-function |DFLOAT;sin;...} [ihs=22]
#18   evalForm {loc0=#<vector 08e836a0>,loc1=|draw|,loc2=(#<vector 08e836c0>
(#<vector 08e83780...} [ihs=21]
#19   bottomUpForm2 {loc0=(#<vector 08e836a0> #<vector 08e836c0> (#<vector
08e83780> (#<vector 08e83...} [ihs=20]
#20   bottomUpForm3 {loc0=(#<vector 08e836a0> #<vector 08e836c0> (#<vector
08e83780> (#<vector 08e83...} [ihs=19]
#21   bottomUpForm {loc0=(#<vector 08e836a0> #<vector 08e836c0> (#<vector
08e83780> (#<vector 08e83...} [ihs=18]
#22   bottomUp {loc0=(#<vector 08e836a0> #<vector 08e836c0> (#<vector
08e83780> (#<vector 08e83...} [ihs=17]
#23   interpret1 {loc0=(|draw| |sin| (segment (- #) (# 5 0
...))),loc1=nil,loc2=(|Application| ((...} [ihs=16]
#24   interpret {g104636=(|draw| |sin| (segment (- #) (# 5 0
...))),loc1=(|Application| ((|id| #...} [ihs=15]
#25   interpretTopLevel {loc0=(|draw| |sin| (segment (- #) (# 5 0
...))),loc1=(|Application| ((|id| #) ....} [ihs=14]
#26   processInteractive1 {loc0=(|draw| |sin| (segment (- #) (# 5 0
...))),loc1=(|Application| ((|id| #) ....} [ihs=13]
#27   processInteractive {loc0=(|draw| |sin| (segment (- #) (# 5 0
...))),loc1=(|Application| ((|id| #) ....} [ihs=12]
#28   intInterpretPform {loc0=(|Application| ((|id| #) . |draw|) (|Tuple|
(|listOf| # #)))} [ihs=11]
#29   ncConversationPhase {fn=#<compiled-function
|phInterpret|>,args=(((|carrier| # # ...))),loc2=(((# . ...} [ihs=10]
#30   intloopSpadProcess,interp {loc0=((|carrier| (|ok?| . t)
(|ptreePremacro| . #0=(|Application| # #)) ...)),l...} [ihs=9]
#31   intloopSpadProcess {loc0=1,loc1=(((# . 1) .
"draw(sin,-5.0..5.0)")),loc2=(|Application| ((|id| #) ....} [ihs=8]
#32   intloopProcess {loc0=1,loc1=t,loc2=(((#) (|Application| # #))
|nonnullstream| #<compiled-functi...} [ihs=7]
#33   intloopProcessString {loc0="draw(sin,-5.0..5.0)",loc1=1} [ihs=6]
#34   TOP-LEVEL {} [ihs=5]
#35   FUNCALL {loc0=#<compiled-function
system:top-level>,loc1=nil,loc2=0,loc3=0,loc4=nil,loc5...} [ihs=4]
NIL
BOOT>>(quit)


-bash-3.00$

\start
Date: Sun, 3 Jun 2007 18:22:59 -0400
From: Bill Page
To: Ralf Hemmecke
Subject: re: Defining piece-wise functions and drawing,	integrating, ...

On June 3, 2007 4:56 PM Ralf Hemmecke wrote:
> ... 
> >> Agreed, but what about telling Axiom the following:
> >>
> >> (1) -> g(x)==if x>0 then x else -x
> >>                                  Type: Void
> >>
> > 
> On 06/03/2007 07:44 PM, Bill Page wrote:
> > I think this is equivalent to writing:
> > 
> >   g(x|x>0) == x
> >   g(x|x<=0) == -x
> > 
> > As far as I know the difference is only a matter of style.
> 
> Since that function definition is only possible in the 
> interpreter (SPAD  would have to figure out some reasonable
> types at compile time, and Aldor would forbid such typeless
> things altogether), you may be right.
> 
> But, actually, who tells you that > and <= are "opposite"
> things?

True. I said "equivalent" but very likely the object code
generated when the functions are compiled is not identical.

> ... 
> >> As I see it, we are a bit in a dilemma here. We need the
> >> function expression here and at the same time > should be
> >> considered as something like (Float, Float) -> Boolean.
> >>
> > 
> > I think we really need a class of fuctions > with signatures
> > like:
> > 
> >   > : (Expression Integer, Expression Integer) ->
> >         Union(Expression Integer, Boolean)
> 
> I think that would make things more complicated.

You are right. That was a poor suggestion.

> 
> > Then 'x<0' can be treated as an expression of type
> > Expression Integer just like 'sin(x)'. Or more generally
> > we need a domain of predicate expressions which can interact
> > with other domains like Expression.
> 
> Yep. I like to see a true expression domain. Axiom's 
> Expression(..) is rather special. It covers a lot, but its
> inhabitants are not expression trees. They are rational
> functions.

That is true but I think that there is a good reason for
this - part of the "Axiom philosophy". The mathematical
domains that we define should always be as "algebraic" as
possible.

> ...
> 
> Then writing "Expression BooleanRing" is probably also not
> what you want. At least I don't want it.

No 'Expression BooleanRing' is definitely not what I want.
'Polynomial BooleanRing' was just an exercise in one way to
provide boolean expressions. Really of course what we want
is a conventional free boolean algebra.

> ... 
> > If we had a domain for predicate expressions then it would not
> > be difficult to introduce an expression in Expression of the
> > form:
> > 
> >   piecewise(Cond:Expression Boolean,
> >             Then:Expression Integer,
> >             Else:Expression Integer):Expression Integer
> 
> Well, what I would dream of is an expression domain (or 
> several of them) that lets you define a general expression
> tree where you would have control over what is allowed as
> nodes. Maybe it would be interesting to be able to give a
> grammar G and MyExpression(G) would then describe the 
> language generated by G. It would be nice to be able to 
> encode the Aldor language in that way.

For Axiom this does not seem sufficiently "algebraic" to me.
Axiom does not like to work with things like "general
expression trees", or rather it does already very nearly
have such things, e.g. SExpression, but they are considered
rather low-level compared to the usual mathematical objects
with which one is expected to work.

> 
> You all probably know that everything in Maple is an 
> expression also "if a then b else c fi" and that one can
> compute with these things. (Yes, yes, looks again like the
> Maple language is nothing but Lisp with another syntax. ;-) ).
>

I think it is quite deliberate that Axiom is different from
Maple in this regard.
 
> Aldor's LibAlgebra defines a domain ExpressionTree. But that
> is certainly not yet perfect.
> 

I think of this as a more sophisticated replacement for
SExpression.

\start
Date: 03 Jun 2007 18:47:35 -0400
From: Stephen Wilson
To: Martin Rubey
Subject: Re: NAG libraries
Cc: Gabriel Dos Reis


Hello Martin,

Martin Rubey writes:

> Stephen Wilson writes:
> 
> > Though not dead strictly speaking, Im looking at removing the nag fortran
> > library support, which appears quite straight forward to do.
> 
> PLEASE do the opposite!  My faculty has the libraries, and I would love to be
> able to use them, just, I do not know how.  is nagman available?

I know very little about the former integration of the NAG libraries.

> It does not make sense to drop support for such a great product, even if
> commercial and available only to few. 

It makes sense to me:

  - none but a privileged few can use the library.  It costs $2500.  

  - I know of no one who can maintain the interface with the library.

  - Assuming the library was supported, the community at large cannot
    explore a potentially large portion of Axioms numerical
    capabilities.

  - and according to others, the current interface is undesirable
    anyways.

As mentioned by others, what we need is a general solution for linking
with third party libraries.

We can only explore the options which exist in open source form.

\start
Date: 03 Jun 2007 18:55:14 -0400
From: Stephen Wilson
To: Waldek Hebisch
Subject: Re: NAG libraries

Hello Waldek,

Do you happen to have the work you did removing the NAG library
support?   I looked at wh-sandbox and it appears to me the NAG
components are still extant.  Im interested in applying similar
changes to the axisp branch.

\start
Date: Mon, 4 Jun 2007 01:42:04 +0200 (CEST)
From: Waldek Hebisch
To: Bill Page
Subject: re: problem plotting simple functions

Bill Page wrote:
> On June 3, 2007 3:15 PM Waldek Hebisch wrote:
> > 
> > Bill Page wrote:
> > > After building Axiom from a recent version of wh-sandbox
> > > (revision 580) I get the following error. The first draw
> > > command works fine but simpler examples fail:
> > > 
> > > (1) -> draw(sin(x*y),x=-5..5,y=-5..5)
> > >    Compiling function %H with type (DoubleFloat,DoubleFloat) ->
> > >       DoubleFloat
> > >    Transmitting data...
> > > 
> > >    (1)  ThreeDimensionalViewport: "sin x*y"
> > >                                                Type:
> > > ThreeDimensionalViewport
> > > (2) -> draw(sin(x),x=-5..5)
> > >    Compiling function %J with type DoubleFloat -> DoubleFloat
> > > 
> > >    >> Error detected within library code:
> > >    Not an integer
> > > 
 
> Here's the debugger ouput.
> 

> (1) ->
> (1) -> )lisp (si::use-fast-links nil)
> )set break break
> 
> Value = NIL
> (1) -> (1) -> draw(sin,-5.0..5.0)
> 
>    >> Error detected within library code:
>    Not an integer
> 
> 
> 
> Break.
> Broken at SYSTEM::BREAK-LEVEL.  Type :H for Help.
> BOOT>>:bt
> 
> #0   BREAK {loc0=nil,loc1=nil,loc2=#<synonym stream to *terminal-io*>,loc3="
> ",loc4=nil,loc...} [ihs=41]
> #1   handleLispBreakLoop {loc0=|break|,loc1=nil,loc2=((arg (nil))),loc3=nil}
> [ihs=40]
> #2   errorSupervisor1 {loc0=|AlgebraError|,loc1="Not an
> integer",loc2=|break|,loc3="Error detected wit...} [ihs=39]
> #3   errorSupervisor {loc0=|AlgebraError|,loc1="Not an integer"} [ihs=38]
> #4   error {loc0="Not an integer"} [ihs=37]
> #5   DFLOAT;manexp {loc0=-5.0,loc1=#<vector 08e83560>,loc2=((|Integer|)
> $),loc3=#<vector 08e83560>,...} [ihs=36]

It seems that error occurs in manexp function.  More preciesly, manexp
calls sign function which looks like the only place which could
signal this error.

Could you try:

exponent(-5.0)$DoubleFloat

sign(-5.0)$DoubleFloat

)lisp (float-sign -5.0 1.0)

The first line is intended to test manexp -- manexp is internal to
DoubleFloat, so we can not test it directly, but exponent just
calls manexp and extracts one of components.  

Also, it may worth checking int/algebra/DFLOAT.NRLIB/code.lsp. 
In my copy I have:

(DEFUN |DFLOAT;sign;$I;81| (|x| $)
  (SPADCALL (FLOAT-SIGN |x| 1.0) (QREFELT $ 115)))

and earlier:

(DEFUN |DFLOAT;retract;$I;79| (|x| $)
  (PROG (|n|)
    (RETURN
      (SEQ (LETT |n| (FIX |x|) |DFLOAT;retract;$I;79|)
           (EXIT (COND
                   ((= |x| (FLOAT |n| MOST-POSITIVE-DOUBLE-FLOAT)) |n|)
                   ('T (|error| "Not an integer"))))))))


\start
Date: Mon, 4 Jun 2007 02:08:24 +0200 (CEST)
From: Waldek Hebisch
To: Stephen Wilson
Subject: Re: NAG libraries

Stephen Wilson wrote:
> Do you happen to have the work you did removing the NAG library
> support?   I looked at wh-sandbox and it appears to me the NAG
> components are still extant.  Im interested in applying similar
> changes to the axisp branch.
> 

No, I erased the corresponding tree.  ATM I am not sure what to
do with NAG library support.  Large part of it is very specific
to NAG library but other part have some potential for reuse.
Also, even if we do not want to use some parts it may still
serve as a template showing how to solve some problems.

I belive that you can remove the following algebra files:

annacat.spad     d01routine.spad    d02routine.spad  e04agents.spad
compile.input    d01transform.spad  d03Package.spad  e04routine.spad
cont.spad        d01weights.spad    d03agents.spad   functions.spad
d01Package.spad  d02Package.spad    d03routine.spad  routines.spad
d01agents.spad   d02agents.spad     e04Package.spad  tools.spad

asp.spad  d01.spad  e02.spad  f04.spad      fortpak.spad
c02.spad  d02.spad  e04.spad  f07.spad      fortran.spad
c05.spad  d03.spad  f01.spad  fortcat.spad  forttyp.spad
c06.spad  e01.spad  f02.spad  fortmac.spad  s.spad

On Nag cdrom the first group is in 'anna' subdirectory the second
is in 'naglink2'.  IIRC the rest of algebra does not depend on
them.

We also have a lot of Nag support in interp subdirectory --  at least
nag* and anna.boot.pamphlet

\start
Date: Sun, 3 Jun 2007 19:28:02 -0500
From: Tim Daly
To: Stephen Wilson
Subject: NAG libraries

At some point in the future we might want to try to connect to 
the Octave libraries. 

I have a branch, not ready for release, where I've done some work
on exposing literate forms of the standard linear algebra libraries.

You're correct that we need to think about exposing libraries 
in general but I have no idea how to do that.

\start
Date: Sun, 3 Jun 2007 19:42:27 -0500
From: Tim Daly
To: Franz Lehner
Subject: NAG libraries

Franz,

I'm a little puzzled by what you mean by "axiom.silver 580".
Specifically, what SVN checkout command did you use?

I'm unaware of the file "Makefile.linux.pamphlet".

You commented that for Aldor you did:
  for pp in *.pamphlet ; do document $pp ; done
but Aldor doesn't have pamphlet files.

The --enable-checking only exists in the branches and is 
not in silver, as far as I'm aware.

Tim



\start
Date: 03 Jun 2007 20:03:48 -0500
From: Gabriel Dos Reis
To: Camm Maguire
Subject: resuming saved image and value of current package

Hi Camm,

  I noticed that GCL-2.6.8pre does not preserve *package*
across save-system and resumption.  At least both CLISP and SBCL
preserves the value of *package* when saving image to disk.

  Do you think it would be workable to have GCL preserve *package* too
when save-system?

\start
Date: Sun, 3 Jun 2007 22:17:04 -0400
From: Bill Page
To: Waldek Hebisch
Subject: re: problem plotting simple functions

On June 3, 2007 7:42 PM Waldek Hebisch wrote:
> ...
> It seems that error occurs in manexp function.  More preciesly,
> manexp calls sign function which looks like the only place which
> could signal this error.
>
> Could you try:
>
> exponent(-5.0)$DoubleFloat

Here's the results:

...

(1) -> )set break break
(1) -> )lisp (si::use-fast-links nil)

Value = NIL
(1) -> exponent(-5.0)$DoubleFloat
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/FLOAT.o
      for domain Float
   Loading

/export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/DFLOAT.o
      for domain DoubleFloat

   >> Error detected within library code:
   Not an integer


Break.
Broken at SYSTEM::BREAK-LEVEL.  Type :H for Help.
BOOT>>:bt

#0   BREAK {loc0=nil,loc1=nil,loc2=#<synonym stream to *terminal-io*>,loc3="
",loc4=nil,loc...} [ihs=38]
#1   handleLispBreakLoop {loc0=|break|,loc1=nil,loc2=((arg (nil))),loc3=nil}
[ihs=37]
#2   errorSupervisor1 {loc0=|AlgebraError|,loc1="Not an
integer",loc2=|break|,loc3="Error detected wit...} [ihs=36]
#3   errorSupervisor {loc0=|AlgebraError|,loc1="Not an integer"} [ihs=35]
#4   error {loc0="Not an integer"} [ihs=34]
#5   DFLOAT;manexp {loc0=-5.0,loc1=#<vector 08e40dc0>,loc2=((|Integer|)
$),loc3=#<vector 08e40dc0>,...} [ihs=33]
#6   DFLOAT;exponent;$I;9 {loc0=-5.0,loc1=#<vector 08e40dc0>} [ihs=32]
#7   FUNCALL {loc0=#<compiled-function
|DFLOAT;exponent;$I;9|>,loc1=-5.0,loc2=#<vector 08e40d...} [ihs=31]
#8   FUNCALL {loc0=#<compiled-function
|DFLOAT;exponent;$I;9|>,loc1=-5.0,loc2=#<vector 08e40d...} [ihs=30]
#9   EVAL {loc0=nil,loc1=nil,loc2=nil,loc3=(let ((#0=#:g1426 #)) (the
(values t) (funcall ...} [ihs=27]
#10   timedEvaluate {code=(spadcall -5.0 (quote (#<compiled-function
|DFLOAT;exponent;$I;9|> . #<vec...} [ihs=26]
#11   timedEVALFUN {loc0=(spadcall -5.0 (quote (#<compiled-function
|DFLOAT;exponent;$I;9|> . #<vec...} [ihs=25]
#12   evalFormMkValue {loc0=#<vector 08e83660>,loc1=(spadcall -5.0 (quote
(#<compiled-function |DFLOAT...} [ihs=24]
#13   evalForm {loc0=#<vector 08e83660>,loc1=|exponent|,loc2=((#<vector
08e83680> (#<vector 08e...} [ihs=23]
#14   bottomUpForm2 {loc0=(#<vector 08e83660> (#<vector 08e83680> (#<vector
08e836a0> # #))),loc1=#<...} [ihs=22]
#15   bottomUpForm3 {loc0=(#<vector 08e83660> (#<vector 08e83680> (#<vector
08e836a0> # #))),loc1=#<...} [ihs=21]
#16   bottomUpForm {loc0=(#<vector 08e83660> (#<vector 08e83680> (#<vector
08e836a0> # #))),loc1=#<...} [ihs=20]
#17   bottomUp {loc0=(#<vector 08e83660> (#<vector 08e83680> (#<vector
08e836a0> # #))),loc1=1} [ihs=19]
#18   upDollar {loc0=(#<vector 08e83640> |DoubleFloat| (#<vector 08e83660>
(#<vector 08e83680> ...} [ihs=18]
#19   bottomUp {loc0=(#<vector 08e83640> |DoubleFloat| (#<vector 08e83660>
(#<vector 08e83680> ...} [ihs=17]
#20   interpret1 {loc0=((|$elt| |DoubleFloat| |exponent|) (- (# 5 0
...))),loc1=nil,loc2=(|Applic...} [ihs=16]
#21   interpret {g104636=((|$elt| |DoubleFloat| |exponent|) (- (# 5 0
...))),loc1=(|Application|...} [ihs=15]
#22   interpretTopLevel {loc0=((|$elt| |DoubleFloat| |exponent|) (- (# 5 0
...))),loc1=(|Application| (|...} [ihs=14]
#23   processInteractive1 {loc0=((|$elt| |DoubleFloat| |exponent|) (- (# 5 0
...))),loc1=(|Application| (|...} [ihs=13]
#24   processInteractive {loc0=((|$elt| |DoubleFloat| |exponent|) (- (# 5 0
...))),loc1=(|Application| (|...} [ihs=12]
#25   intInterpretPform {loc0=(|Application| (|Fromdom| (# . |exponent|) (#
. |DoubleFloat|)) (|Applicat...} [ihs=11]
#26   ncConversationPhase {fn=#<compiled-function
|phInterpret|>,args=(((|carrier| # # ...))),loc2=(((# . ...} [ihs=10]
#27   intloopSpadProcess,interp {loc0=((|carrier| (|ok?| . t)
(|ptreePremacro| . #0=(|Application| # #)) ...)),l...} [ihs=9]
#28   intloopSpadProcess {loc0=1,loc1=(((# . 1) .
"exponent(-5.0)$DoubleFloat")),loc2=(|Application| (|Fr...} [ihs=8]
#29   intloopProcess {loc0=1,loc1=t,loc2=(((#) (|Application| # #))
|nonnullstream| #<compiled-functi...} [ihs=7]
#30   intloopProcessString {loc0="exponent(-5.0)$DoubleFloat",loc1=1}
[ihs=6]
#31   TOP-LEVEL {} [ihs=5]
#32   FUNCALL {loc0=#<compiled-function
system:top-level>,loc1=nil,loc2=0,loc3=0,loc4=nil,loc5...} [ihs=4]
NIL
BOOT>> (quit)

>
> sign(-5.0)$DoubleFloat
>

Same result.
...

   >> Error detected within library code:
   Not an integer

> )lisp (float-sign -5.0 1.0)
>

This one works.

(1) -> )lisp (float-sign -5.0 1.0)

Value = -1.0

> The first line is intended to test manexp -- manexp is internal
> to DoubleFloat, so we can not test it directly, but exponent
> just calls manexp and extracts one of components. 
>
> Also, it may worth checking int/algebra/DFLOAT.NRLIB/code.lsp.
> In my copy I have:
>
> (DEFUN |DFLOAT;sign;$I;81| (|x| $)
>   (SPADCALL (FLOAT-SIGN |x| 1.0) (QREFELT $ 115)))
>
> and earlier:
>
> (DEFUN |DFLOAT;retract;$I;79| (|x| $)
>   (PROG (|n|)
>     (RETURN
>       (SEQ (LETT |n| (FIX |x|) |DFLOAT;retract;$I;79|)
>            (EXIT (COND
>                    ((= |x| (FLOAT |n| MOST-POSITIVE-DOUBLE-FLOAT)) |n|)
>                    ('T (|error| "Not an integer"))))))))
>

In my 'int/algebra/DFLOAT.NRLIB/code.lsp' I see the same code:

(DEFUN |DFLOAT;sign;$I;81| (|x| $)
  (SPADCALL (FLOAT-SIGN |x| 1.0) (QREFELT $ 115)))

and

(DEFUN |DFLOAT;retract;$I;79| (|x| $)
  (PROG (|n|)
    (RETURN
      (SEQ (LETT |n| (FIX |x|) |DFLOAT;retract;$I;79|)
           (EXIT (COND
                   ((= |x| (FLOAT |n| MOST-POSITIVE-DOUBLE-FLOAT)) |n|)
                   ('T (|error| "Not an integer"))))))))

-----------

Did I mention earlier that I am testing this on a Solaris 10
x86 system with the Blastwave toolchain?

-bash-3.00$ gcc --version
gcc (GCC) 3.4.3 (csl-sol210-3_4-branch+sol_rpath)
Copyright (C) 2004 Free Software Foundation, Inc.

Back in April my first attempts to build Axiom on this system
failed due to a problem with gcl. But Camm Maquire was able to
solve the gcl problem and his changes are in cvs gcl-2.6.8pre.
This is the version of gcl that I am using now to build
wh-sandbox. I have not found any other errors until now but
I must admit that I did not review all of the test output.

Perhaps this is a gcl bug?

\start
Date: Mon, 4 Jun 2007 00:16:46 -0500
From: Tim Daly
To: Cliff Yapp
Subject: Interesting comment

> "Git, the Lisp of SCMs"

I read the slashdot comments on git.

Emacs, Lisp, Web, and, now git have a single feature in common for me.
Each one has completely changed the way I think once I "got it".

They each had a "before-I-got-it" disdain, and an "after-I-got-it"
exclusive adoption (some might call it religious conversion). 
They all have steep learning curves.

In this way I guess they all mirror Axiom versus other CAS.

\start
Date: Mon, 4 Jun 2007 08:07:55 +0200 (CEST)
From: Franz Lehner
To: Tim Daly
Subject: Re: NAG libraries

> I'm a little puzzled by what you mean by "axiom.silver 580".
> Specifically, what SVN checkout command did you use?

   svn co https://axiom.svn.sourceforge.net/svnroot/axiom/trunk axiom.silver

as indicated at http://wiki.axiom-developer.org/AxiomSilverBranch.
In the end it said something like "checked out revision 580".

> I'm unaware of the file "Makefile.linux.pamphlet".
that one was in
http://wiki.axiom-developer.org/src_aldor2.tgz
and I followed the instructions on 
http://wiki.axiom-developer.org/AldorForAxiom

> You commented that for Aldor you did:
>  for pp in *.pamphlet ; do document $pp ; done
> but Aldor doesn't have pamphlet files.
src_aldor2.tgz does.

> The --enable-checking only exists in the branches and is
> not in silver, as far as I'm aware.
that's what I learned so far as well.
So if I want both aldor and --enable-checking, I need to get yet another 
branch? Any suggestions?

\start
Date: Mon, 04 Jun 2007 10:02:05 +0200
From: Ralf Hemmecke
To: Franz Lehner
Subject: Re: NAG libraries

>   svn co https://axiom.svn.sourceforge.net/svnroot/axiom/trunk axiom.silver

> as indicated at http://wiki.axiom-developer.org/AxiomSilverBranch.

I also feared that.

The page http://wiki.axiom-developer.org/AxiomSilverBranch became out of 
date recently.

"trunk" is basically identical with Gold (tla: axiom--main--1--patch-50) 
and currently not maintained although build-improvements and wh-sandbox 
branched from it.

http://lists.nongnu.org/archive/html/axiom-developer/2007-05/msg00540.html

Actually, I don't know exactly, why Tim now puts everything into 
"branches/daly" instead of "trunk". Gaby, Tim, Waldek, what do you think 
the best strategy would be to ease merging later?

> In the end it said something like "checked out revision 580".

The revision number in SVN is globabl over all branches, so you must 
give the directory as well. "trunk" or "branches/wh-sandbox" should be 
enough.

\start
Date: Mon, 04 Jun 2007 10:35:39 +0200
From: Ralf Hemmecke
To: Bill Page
Subject: re: Defining piece-wise functions and drawing,	integrating, ...

>>> Then 'x<0' can be treated as an expression of type
>>> Expression Integer just like 'sin(x)'. Or more generally
>>> we need a domain of predicate expressions which can interact
>>> with other domains like Expression.
>> Yep. I like to see a true expression domain. Axiom's 
>> Expression(..) is rather special. It covers a lot, but its
>> inhabitants are not expression trees. They are rational
>> functions.

> That is true but I think that there is a good reason for
> this - part of the "Axiom philosophy". The mathematical
> domains that we define should always be as "algebraic" as
> possible.

Oh, I never said, that the current Expression(...) should be removed. If 
I see what people do here at RISC with symbolic summation, that domain 
fits very well in that area. Still, Axiom lacks a true ExpressionTree 
domain. Or have I just not found it?

>>> If we had a domain for predicate expressions then it would not
>>> be difficult to introduce an expression in Expression of the
>>> form:
>>>
>>>   piecewise(Cond:Expression Boolean,
>>>             Then:Expression Integer,
>>>             Else:Expression Integer):Expression Integer
>> Well, what I would dream of is an expression domain (or 
>> several of them) that lets you define a general expression
>> tree where you would have control over what is allowed as
>> nodes. Maybe it would be interesting to be able to give a
>> grammar G and MyExpression(G) would then describe the 
>> language generated by G. It would be nice to be able to 
>> encode the Aldor language in that way.

> For Axiom this does not seem sufficiently "algebraic" to me.

Then remove the "Set" domain. Why must everything be "algebraic". 
Actually, you could probably turn an ExpressionTree into some form of 
universal algebra (just leave the set of operations empty).

> Axiom does not like to work with things like "general
> expression trees", or rather it does already very nearly
> have such things, e.g. SExpression, but they are considered
> rather low-level compared to the usual mathematical objects
> with which one is expected to work.

Oh, maybe SExpression is near to what I want. But is somehow sounds to 
LISPish for me. ;-) Anyway, I think it would be a good thing to have a 
very general expression domain (maybe like SExpression) and yet others 
that only allow certain expression trees that correspond to a grammar.

>> You all probably know that everything in Maple is an 
>> expression also "if a then b else c fi" and that one can
>> compute with these things. (Yes, yes, looks again like the
>> Maple language is nothing but Lisp with another syntax. ;-) ).

> I think it is quite deliberate that Axiom is different from
> Maple in this regard.

Hmm, still, I guess for BNatural we need something like that + a 
connection to the compiler do actually turn the expression into a 
running program.

>> Aldor's LibAlgebra defines a domain ExpressionTree. But that
>> is certainly not yet perfect.

> I think of this as a more sophisticated replacement for
> SExpression.

Maybe. But it is written in Aldor and does not rely on an underlying LISP.

\start
Date: 04 Jun 2007 07:25:48 -0400
From: Stephen Wilson
To: Waldek Hebisch
Subject: Re: NAG libraries

Waldek Hebisch writes:

> No, I erased the corresponding tree. 

Oh well, the process appears fairly straight forward.  

> ATM I am not sure what to do with NAG library support.  Large part
> of it is very specific to NAG library but other part have some
> potential for reuse.  Also, even if we do not want to use some parts
> it may still serve as a template showing how to solve some problems.

My perspective on the issue is that as the code is basicly unused at
the moment, it can go.  The code lives in the SCM history (among other
places) and can be retrieved at any time.  Any role it might serve as
template for future work will not disappear.

> I belive that you can remove the following algebra files:
> 
> annacat.spad     d01routine.spad    d02routine.spad  e04agents.spad
> compile.input    d01transform.spad  d03Package.spad  e04routine.spad
> cont.spad        d01weights.spad    d03agents.spad   functions.spad
> d01Package.spad  d02Package.spad    d03routine.spad  routines.spad
> d01agents.spad   d02agents.spad     e04Package.spad  tools.spad
> 
> asp.spad  d01.spad  e02.spad  f04.spad      fortpak.spad
> c02.spad  d02.spad  e04.spad  f07.spad      fortran.spad
> c05.spad  d03.spad  f01.spad  fortcat.spad  forttyp.spad
> c06.spad  e01.spad  f02.spad  fortmac.spad  s.spad
> 
> On Nag cdrom the first group is in 'anna' subdirectory the second
> is in 'naglink2'.  IIRC the rest of algebra does not depend on
> them.
> 
> We also have a lot of Nag support in interp subdirectory --  at least
> nag* and anna.boot.pamphlet

Thanks for the list! It appears to be a slight super set of the list I
had written down.  I will investigate and likely remove all mentioned
files.

Ill post the result and at least make this a feature of the axisp
branch.  It would seem better to wait until a more general mechanism
is hammered out before proposing the same for silver.

\start
Date: Mon, 4 Jun 2007 14:02:09 +0200 (CEST)
From: Waldek Hebisch
To: Franz Lehner
Subject: Re: NAG libraries

Franz Lehner wrote:
> > The --enable-checking only exists in the branches and is
> > not in silver, as far as I'm aware.
> that's what I learned so far as well.
> So if I want both aldor and --enable-checking, I need to get yet another 
> branch? Any suggestions?

It depends what you really want.  --enable-checking sets Lisp safety
to 3, but only in build-improvements branch.  In wh-sandbox --enable-checking
is ignored, like other unrecognized --enable-xxx options.

If you want to build with Lisp safety set to 3 than wh-sandbox
should build OK.  AFAIK gold/silver will not build with
safety set to 3 -- one has to fix a few problems and the fixes
are not applied yet.  I am not sure about build-improvements.

OTOH safety 3 means very significant slowdown.  On the same machine
safety 0 build took about 2.5 hours while safety 3 build needed 
about 19 hours.

\start
Date: 04 Jun 2007 07:14:35 -0500
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Re: NAG libraries
Cc: Franz Lehner

Ralf Hemmecke writes:

| Actually, I don't know exactly, why Tim now puts everything into
| "branches/daly" instead of "trunk". Gaby, Tim, Waldek, what do you
| think the best strategy would be to ease merging later?

I would have highly preferred Tim put the new silver in /silver, and
keep branches/daly as his private branch; but he didn't so we must
learn to leave with that.

We should remove the current silver it just is too confusing to people.
As for merge, it is going to be more painful than it has to be
primaily because Tim picked changes by carefully not picking the
revision number or ChangeLogs.  I tried twice, but abandoned because I
had more pressing things on the fire and partly because I got
frsutrated. 
Waldek has more patience than me.

\start
Date: 04 Jun 2007 07:16:44 -0500
From: Gabriel Dos Reis
To: Tim Daly
Subject: Re: Interesting comment

Tim Daly writes:

| They each had a "before-I-got-it" disdain, and an "after-I-got-it"
| exclusive adoption (some might call it religious conversion). 

Hallowed are the Ori.

\start
Date: 04 Jun 2007 07:24:30 -0500
From: Gabriel Dos Reis
To: Waldek Hebisch
Subject: Re: NAG libraries
Cc: Franz Lehner

Waldek Hebisch writes:

| Franz Lehner wrote:
| > > The --enable-checking only exists in the branches and is
| > > not in silver, as far as I'm aware.
| > that's what I learned so far as well.
| > So if I want both aldor and --enable-checking, I need to get yet another 
| > branch? Any suggestions?
| 
| It depends what you really want.  --enable-checking sets Lisp safety
| to 3, but only in build-improvements branch.  In wh-sandbox --enable-checking
| is ignored, like other unrecognized --enable-xxx options.
| 
| If you want to build with Lisp safety set to 3 than wh-sandbox
| should build OK.  AFAIK gold/silver will not build with
| safety set to 3 -- one has to fix a few problems and the fixes
| are not applied yet.  I am not sure about build-improvements.

I build build-improvements with safety 3 at least once a week.

| OTOH safety 3 means very significant slowdown.

Indeed.
That is the case at least on all my laptops and one desktop.
On a dual core dell optiplex, it takes only 3 hours.

I can have --enable-checking take a numeral arguments if that is
needed.

\start
Date: 04 Jun 2007 07:24:59 -0500
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Re: NAG libraries
Cc: Franz Lehner

Ralf Hemmecke writes:

| The page http://wiki.axiom-developer.org/AxiomSilverBranch became out
| of date recently.

silver/ is now gone.

\start
Date: Mon, 4 Jun 2007 14:37:52 +0200 (CEST)
From: Franz Lehner
To: Waldek Hebisch
Subject: Re: NAG libraries

> It depends what you really want.
I really want
1. no damaged memory
2. aldor compiler; the error messages of the spad compiler are not
    satisfactory for me.
3. recent bugfixes
What options do I have? So far I tried wh-sandbox and the wrong silver 
branch.

> --enable-checking sets Lisp safety
> to 3, but only in build-improvements branch.  In wh-sandbox --enable-checking
> is ignored, like other unrecognized --enable-xxx options.
> If you want to build with Lisp safety set to 3 than wh-sandbox
> should build OK.
yes it did. Aldor did not due to the changed directory structure.

> AFAIK gold/silver will not build with
> safety set to 3 -- one has to fix a few problems and the fixes
> are not applied yet.  I am not sure about build-improvements.
I guess the missing |output| function is one of these problems.

> OTOH safety 3 means very significant slowdown.  On the same machine
> safety 0 build took about 2.5 hours while safety 3 build needed
> about 19 hours.
It was roughly 12 hours here.
Is runtime speed affected by this?

\start
Date: Mon, 04 Jun 2007 14:38:37 +0200
From: Ralf Hemmecke
To: Gabriel Dos Reis
Subject: Re: NAG libraries

On 06/04/2007 02:24 PM, Gabriel Dos Reis wrote:
> Ralf Hemmecke writes:
> 
> | The page http://wiki.axiom-developer.org/AxiomSilverBranch became out
> | of date recently.
> 
> silver/ is now gone.

> -- Gaby

\start
Date: 04 Jun 2007 07:46:33 -0500
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Re: NAG libraries

Ralf Hemmecke writes:

| On 06/04/2007 02:24 PM, Gabriel Dos Reis wrote:
| > Ralf Hemmecke writes:
| > | The page http://wiki.axiom-developer.org/AxiomSilverBranch became
| > out
| > | of date recently.
| > silver/ is now gone.
| 
| > -- Gaby
| 
| Thank you. What a relief.

I'm planning to attempt the following -- assuming I got time today:

  * merge branches/daly to trunk
  * create a branch gold that contains the mature Gold version

The idea is that trunk should be the development silver (and hopefully
Tim will commit there) from which people will branch from.  And
build-improvements, wh-sandbox will merge to that trunk later.

\start
Date: Mon, 04 Jun 2007 14:50:01 +0200
From: Ralf Hemmecke
To: Tim Daly
Subject: Re: NAG libraries
Cc: Gabriel Dos Reis

Tim,

What do you think about maintaining sourceforge:trunk as Silver (ehm, 
Gold-to-be) instead of branches/daly?

SVN has a big weakness of not automatically tracking merged revision 
numbers (that is why some people use SVK instead).
Tim, can you figure out the SVN-revision numbers of the patches from 
Gaby and Waldek that you applied to branches/daly? I think that would 
greatly help to put an end on the "hard to merge" front.

How do you identify diff-Naur patches anyway? Which tool do you use to 
prevent you from applying the same patch twice?

Ralf

On 06/04/2007 02:14 PM, Gabriel Dos Reis wrote:
> Ralf Hemmecke writes:
> 
> | Actually, I don't know exactly, why Tim now puts everything into
> | "branches/daly" instead of "trunk". Gaby, Tim, Waldek, what do you
> | think the best strategy would be to ease merging later?
> 
> I would have highly preferred Tim put the new silver in /silver, and
> keep branches/daly as his private branch; but he didn't so we must
> learn to leave with that.
> 
> We should remove the current silver it just is too confusing to people.
> As for merge, it is going to be more painful than it has to be
> primaily because Tim picked changes by carefully not picking the
> revision number or ChangeLogs.  I tried twice, but abandoned because I
> had more pressing things on the fire and partly because I got
> frsutrated. 
> Waldek has more patience than me.

\start
Date: 04 Jun 2007 07:54:12 -0500
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Old trunk changes

Ralf --

  Looking at the ChangeLog in trunk, I see changes dated:

   2006-09-14  Ralf Hemmecke  Ralf Hemmecke
   2006-09-13  Ralf Hemmecke  Ralf Hemmecke
   2006-07-31  Ralf Hemmecke  Ralf Hemmecke

Do you know whether they have made it to Tim's branch?

\start
Date: Mon, 4 Jun 2007 14:52:43 +0200 (CEST)
From: Waldek Hebisch
To: Martin Rubey
Subject: Re: Patches
Cc: Bill Page, Waldek Hebisch

Dear Martin,

> Dear Bill, Tim, Waldek,
> 
> here are some patches for bug #355.
> 

Thanks for the patches.

> Tim, Waldek: would you be so kind to include these patches in the respective
> distributions.  By the way, I just found the documented version of the patch to
> STTAYLOR, it is on MathAction, #312, powern.patch. I include a version that
> applies smoothly to wh-sandbox here, too.  Please apply this one also.
> 

I have a little problem with documentation parts.  In combfunc.spad.pamphlet
part you write:

+      ++ Gamma(a,x) returns the incomplete Gamma function applied to a and x.
+      ++ Concerning differentiation, it is regarded as a function in the second
+      ++ argument only.

This behaviour is clearly a bug.  We can not compute correct derivative,
but at least we should leave it unevalueated or signal error.  In general
I very much prefer to fix bugs insted of documenting them.  If you
really want to document a bug at least make clear that it is a bug.

In sttaylor.spad.pamphlet part you put explanations after corresponding
code.  I find this confusing, I think that putting explanations before
code is much clearer.

> 
> Waldek: do you prefer if I commit to your branch myself, or is this form good
> for you, too?
> 

I general it is better if author of a patch applies it.  Currently
we have low volume of patches and I can apply them myself if
needed.  Still if I think that patch needs correction (as in
this case) when I do the correction myself I may get something different
than what you indended.  So it is better that you prepare
corrected patch (or present some sting reason to keep patch
as is) and once the new patch is approved apply it.

\start
Date: Mon, 4 Jun 2007 05:58:42 -0700 (PDT)
From: Cliff Yapp
To: Waldek Hebisch, Martin Rubey
Subject: Re: Patches
Cc: Bill Page

As long as we're on the subject, how would one provide a "patch" for
adding a completely new file like the Emacs mode pamphlet?  Is there
some preferred way to do this or is just supplying the file and target
directory for inclusion enough?

\start
Date: Mon, 04 Jun 2007 15:09:49 +0200
From: Ralf Hemmecke
To: Gabriel Dos Reis
Subject: Re: NAG libraries

On 06/04/2007 02:46 PM, Gabriel Dos Reis wrote:
> Ralf Hemmecke writes:
> 
> | On 06/04/2007 02:24 PM, Gabriel Dos Reis wrote:
> | > Ralf Hemmecke writes:
> | > | The page http://wiki.axiom-developer.org/AxiomSilverBranch became
> | > out
> | > | of date recently.
> | > silver/ is now gone.
> | 
> | > -- Gaby
> | 
> | Thank you. What a relief.
> 
> I'm planning to attempt the following -- assuming I got time today:
> 
>   * merge branches/daly to trunk

I'd love to see this.

>   * create a branch gold that contains the mature Gold version

Ehm, Gold is a release version, why not great

/tags/Gold-3.0  (I hope that is the current version of Axiom.

Or use

/gold/Axiom-3.0 (or what is Axiom's current version number?)

instead of tags. We probably don't change Gold anymore only that we will 
have more and more Gold versions. Actually, you could use old /silver 
look as (svn log -r 216 -v) to produce /gold/Axiom-3.0 in order to keep 
the svn archive small.

> The idea is that trunk should be the development silver (and hopefully
> Tim will commit there) from which people will branch from.  And
> build-improvements, wh-sandbox will merge to that trunk later.

> Opinions?

This has my full support.

\start
Date: Mon, 4 Jun 2007 06:12:27 -0700 (PDT)
From: Cliff Yapp
To: list
Subject: SCMs

A question, to the list in general and more specifically to those
maintaining branches.

If someone were to take the current Silver, and work through all the
changes in the branches currently being maintained in SVN
(build-improvements and wh-sandbox in particular) in a GIT repository
(thus "recreating" the revision history in GIT) would it be possible to
switch to a broader use of GIT?

I know SCMs are a bit of a religous issue, and I won't try to go into
which is "best", but I think the development model GIT uses may be a
fairly good match to the Axiom project.  If the revision histories were
re-created in GIT for the various branches, would that overcome the
practical difficulty in switching?

I don't say I know GIT well enough to do it "correctly" yet, but if we
can work in the same system it should (hopefully) be a lot easier to
address these branching issues.  In the process of doing the conversion
perhaps some of the branches can be brought closer together and some
good GIT for Axiom tutorials could be written.

If I were to attempt this (it would be a little while before I could
start, as my PC decided to give up the ghost and I'm having to rebuild)
would the key parties be interested enough to give the results a try? 
(Assuming sufficient quality of work, of course.)

I am aware that people may be too comfortable with their current tool
to want to switch to something else, and I understand if that's the
case - I'm just looking for something practical that can be done to
help keep the current diverging situation from continuing to diverge
more than necessary.

\start
Date: 04 Jun 2007 15:19:12 +0200
From: Martin Rubey
To: Waldek Hebisch
Subject: Re: Patches
Cc: Bill Page

Waldek Hebisch writes:

> > here are some patches for bug #355.

> > By the way, I just found the documented version of the patch to STTAYLOR,
> > it is on MathAction, #312, powern.patch. I include a version that applies
> > smoothly to wh-sandbox here, too.

> I have a little problem with documentation parts.  In combfunc.spad.pamphlet
> part you write:
> 
> +      ++ Gamma(a,x) returns the incomplete Gamma function applied to a and x.
> +      ++ Concerning differentiation, it is regarded as a function in the second
> +      ++ argument only.
> 
> This behaviour is clearly a bug.

Hm, I thought this at first, too.  But the behaviour is consistent for Gamma,
Bessel and Polygamma.  It is not difficult to change this behaviour to leaving
the derivative unevaluated, but I'm not sure whether that would really be
better.  If you are absolutely sure, please let me know as soon as possible.
How about polygamma?  should D(polygamma(x, x), x) throw an error?  I guess so.
But if we follow you, Bessel* should leave the derivative with respect to the
first argument - i.e., leave it unevaluated.

> In sttaylor.spad.pamphlet part you put explanations after corresponding code.
> I find this confusing, I think that putting explanations before code is much
> clearer.

I don't, but I realise that noweb behaves so that your style is preferred. -
OK.  Do you want me to change this for these two patches already?

> > Waldek: do you prefer if I commit to your branch myself, or is this form
> > good for you, too?
> > 
> 
> I general it is better if author of a patch applies it.  Currently we have
> low volume of patches and I can apply them myself if needed.  Still if I
> think that patch needs correction (as in this case) when I do the correction
> myself I may get something different than what you indended.  So it is better
> that you prepare corrected patch (or present some sting reason to keep patch
> as is) and once the new patch is approved apply it.

Hm, if I would have applied the patch myself, there probably would not have
been any review.  So, if you don't mind, for the time being with less then 10
developers, I would like to ask you to keep things as they are now, and we
change the system as soon as we are more than 10 developers, ok?  (Of course,
if you prefer to change the system right now, I follow you.)

Many many thanks for your committment :-)

\start
Date: Mon, 4 Jun 2007 16:00:48 +0200 (CEST)
From: Waldek Hebisch
To: Martin Rubey
Subject: Re: Patches

Martin Rubey wrote:
> Waldek Hebisch writes:
 
> > > here are some patches for bug #355.  > > By the way, I just
> found the documented version of the patch to STTAYLOR, > > it is on
> MathAction, #312, powern.patch. I include a version that applies > >
> smoothly to wh-sandbox here, too.
 
> > I have a little problem with documentation parts.  In
> > combfunc.spad.pamphlet part you write: + ++ Gamma(a,x) returns the
> > incomplete Gamma function applied to a and x.  + ++ Concerning
> > differentiation, it is regarded as a function in the second + ++
> > argument only.  This behaviour is clearly a bug.
 
> Hm, I thought this at first, too.  But the behaviour is consistent
> for Gamma, Bessel and Polygamma.  It is not difficult to change this
> behaviour to leaving the derivative unevaluated, but I'm not sure
> whether that would really be better.  If you are absolutely sure,
> please let me know as soon as possible.

Yes, currently we produce mathematically incorrect result.  In principle
user may get wrong results even if input does not contain explicit
derivative.  Once we get better support for special functions this may
be very serious problem.

I supect that original author did not know how to leave one partial
derivative unevaluated, while giving value of the second one (ATM this
is not clear for me either).  If you know how to to this please go
on.

> How about polygamma?  should D(polygamma(x, x), x) throw an error?
> I guess so.  But if we follow you, Bessel* should leave the
> derivative with respect to the first argument - i.e., leave it
> unevaluated.

polygamma(a, x) has sensible definition also for non-integral a, so
just leaving D(polygamma(x, x), x) unevaluated is reasonable.  Since in
other places we support only integral a error is reasonable too.  For
Bessel* leaving derivative with respect to the first argument unevaluated
is preffered to error -- we can still do some calculations with
unevaluated derivatives.
 
> > In sttaylor.spad.pamphlet part you put explanations after
> > corresponding code.  I find this confusing, I think that putting
> > explanations before code is much clearer.
 
> I don't, but I realise that noweb behaves so that your style is
> preferred. - OK.  Do you want me to change this for these two
> patches already?

Yes, pleas do.

\start
Date: Mon, 4 Jun 2007 16:15:09 +0200 (CEST)
From: Waldek Hebisch
To: Cliff Yapp
Subject: Re: Patches

C Y wrote:
> As long as we're on the subject, how would one provide a "patch" for
> adding a completely new file like the Emacs mode pamphlet?  Is there
> some preferred way to do this or is just supplying the file and target
> directory for inclusion enough?
> 

Tim clearly wants us to use 'diff -Naur'.  The -N option to diff
means that it will include new files in the patch.

Another possibility is to artificially create an empty file in
the old tree (may be easier than cleaning trash files in the new
tree).

What is preferred depends on persons.  For me, a single file +
location is good enough, for multiple files patch is preferred.

\start
Date: 04 Jun 2007 09:22:32 -0500
From: Gabriel Dos Reis
To: Martin Rubey
Subject: Re: Patches
Cc: Bill Page

Martin Rubey writes:

[...]

| Hm, if I would have applied the patch myself, there probably would not have
| been any review.

Applying patch oneself is not exclusive of review.

The algorithms is simple:
  1. send patch for review.
  2. if approved, apply patch.

I already stated my opinions on a single individual applying everybody
else patch.  People should be responsible of applying patches -- after
review -- they have created.

\start
Date: 04 Jun 2007 09:27:51 -0500
From: Gabriel Dos Reis
To: Tim Daly
Subject: REGRESS script

Tim --

  The script REGRESS contains hardcoded information about user daly.
How is it supposed to work for non-user daly (everybody else)?

\start
Date: 04 Jun 2007 16:28:52 +0200
From: Martin Rubey
To: Waldek Hebisch
Subject: Re: Patches

Waldek Hebisch writes:

> > But the behaviour is consistent for Gamma, Bessel and Polygamma.  It is not
> > difficult to change this behaviour to leaving the derivative unevaluated,
> > but I'm not sure whether that would really be better.  If you are
> > absolutely sure, please let me know as soon as possible.
> 
> Yes, currently we produce mathematically incorrect result.  In principle user
> may get wrong results even if input does not contain explicit derivative.

Oh? How is that?

> Once we get better support for special functions this may be very serious
> problem.

Probably. By the way: most (probably all) special functions would be covered by
my favourite would-be category/domain hierarchy of differentially algebraic
functions. Then we could say something like

polygamma(a, x)$HOLO(???)

and get the corresponding differential equation.

> I supect that original author did not know how to leave one partial
> derivative unevaluated, while giving value of the second one (ATM this is not
> clear for me either).  If you know how to to this please go on.

OK, I will.

> > How about polygamma?  should D(polygamma(x, x), x) throw an error?  I guess so.
> > But if we follow you, Bessel* should leave the derivative with respect to the
> > first argument - i.e., leave it unevaluated.

> polygamma(a, x) has sensible definition also for non-integral a, so just
> leaving D(polygamma(x, x), x) unevaluated is reasonable.

I could not find such a definition.  Could you please send me such a definition
or a reference?

> Since in other places we support only integral a error is reasonable too.
> For Bessel* leaving derivative with respect to the first argument unevaluated
> is preffered to error -- we can still do some calculations with unevaluated
> derivatives.

Yes.

\start
Date: Mon, 4 Jun 2007 09:43:10 -0500 (CDT)
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Re: NAG libraries

On Mon, 4 Jun 2007, Ralf Hemmecke wrote:

[...]

| > I'm planning to attempt the following -- assuming I got time today:
| > 
| >   * merge branches/daly to trunk
| 
| I'd love to see this.

Ralf --

  Can you give it a try as of revision 584?

\start
Date: Mon, 4 Jun 2007 10:59:24 -0400
From: Bill Page
To: Gabriel Dos Reis
Subject: merge branches/daly to trunk (was: NAG libraries)

On June 4, 2007 10:43 AM Gabriel Dos Reis wrote:
> | > 
> | >   * merge branches/daly to trunk
> | 
> 
>   Can you give it a try as of revision 584?
> 

Thanks, Gaby, for doing this. (I wonder if there is any
chance we can get Tim to do this in the future?)

Thanks also, Waldek, for removing the old axiom.silver
branch.

Now ... how can we get build-improvements and wh-sandbox
back into the trunk? :-)

What Tim calls "silver" (now in trunk) still seems hopelessly
out of date to me.

\start
Date: Mon, 4 Jun 2007 17:31:46 +0200 (CEST)
From: Waldek Hebisch
To: Martin Rubey
Subject: Re: Patches

Martin Rubey wrote:
> Waldek Hebisch writes:
> 
> > > But the behaviour is consistent for Gamma, Bessel and Polygamma.  It is not
> > > difficult to change this behaviour to leaving the derivative unevaluated,
> > > but I'm not sure whether that would really be better.  If you are
> > > absolutely sure, please let me know as soon as possible.
> > 
> > Yes, currently we produce mathematically incorrect result.  In principle user
> > may get wrong results even if input does not contain explicit derivative.
> 
> Oh? How is that?
> 

Consider something like naive test for holonomic functions: compute
derivatives up to some fixed order and check for linear dependence.
Such test would immediatly conclude that besselK(a, x) is holonomic
as a function of a.  I did not check this but I think that
besselK(a, x) is not holonomic as a function of a, and certainly
we would get wrong differential equation.  Once you have differential
equation in hand you can do a lot of transformations.

Of course, currently Axiom has no support for holonomic functions.
But in few places we use derivatives: changing variables in
integrals, computing Laplace transforms.  It is quite possible that
Axiom never uses derivative of bessel function with respect to
parameter.  But checking this would be a substantial ongoing effort.

> > Once we get better support for special functions this may be very serious
> > problem.
> 
> Probably. By the way: most (probably all) special functions would be covered by
> my favourite would-be category/domain hierarchy of differentially algebraic
> functions. Then we could say something like
> 
> polygamma(a, x)$HOLO(???)
> 
> and get the corresponding differential equation.
> 

Hmm, gamma and consequently also polygamma(a, x) as a function of x
is differential transcendental.  Also handling of non-holonomic
differentially algebraic functions seem to be a research problem
-- do you have some interesting results here?

> > > How about polygamma?  should D(polygamma(x, x), x) throw an error?  I guess so.
> > > But if we follow you, Bessel* should leave the derivative with respect to the
> > > first argument - i.e., leave it unevaluated.
> 
> > polygamma(a, x) has sensible definition also for non-integral a, so just
> > leaving D(polygamma(x, x), x) unevaluated is reasonable.
> 
> I could not find such a definition.  Could you please send me such a definition
> or a reference?
>


>From http://mathworld.wolfram.com/PolygammaFunction.html:

   A special function which is given by the (n+1) st derivative of the
   logarithm of the gamma function Gamma(z)
   ....
   ....
   psi_n(z) is implemented in Mathematica as PolyGamma[n, z] for positive
   integer n . In fact, PolyGamma[nu, z] is supported for all complex nu
   (Grossman 1976; Espinosa and Moll 2004).

I do not know which definition the references use, but a derivatives
may be defined for fractional orders via convolution:

{d \over dx}^n f = f*mu_{-n-1}

where 

mu_l(x) = x^l/\Gamma(l+1)  for x > 0

and mu_l(x) = 0 for x < 0.

This definition of derivative is for non-integral n, for integral
n you get normal derivative as a limit.

The definition above will get function which is analytic in n.  Because
analytic functions have strong restictions on possible zeros other
definitions are likely to give the same value.
 
\start
Date: Mon, 4 Jun 2007 17:35:23 +0200 (CEST)
From: Waldek Hebisch
To: Bill Page
Subject: Re: merge branches/daly to trunk (was: NAG libraries)
Cc: Gabriel Dos Reis

Bill Page wrote:
> On June 4, 2007 10:43 AM Gabriel Dos Reis wrote:
> > | > 
> > | >   * merge branches/daly to trunk
> > | 
> > 
> >   Can you give it a try as of revision 584?
> > 
> 
> Thanks, Gaby, for doing this. (I wonder if there is any
> chance we can get Tim to do this in the future?)
> 
> Thanks also, Waldek, for removing the old axiom.silver
> branch.
> 

Gaby removed the old axiom.silver.

\start
Date: Mon, 4 Jun 2007 10:37:44 -0500 (CDT)
From: Gabriel Dos Reis
To: Bill Page
Subject: Re: merge branches/daly to trunk (was: NAG libraries)

On Mon, 4 Jun 2007, Bill Page wrote:

| On June 4, 2007 10:43 AM Gabriel Dos Reis wrote:
| > | > 
| > | >   * merge branches/daly to trunk
| > | 
| > 
| >   Can you give it a try as of revision 584?
| > 
| 
| Thanks, Gaby, for doing this. (I wonder if there is any
| chance we can get Tim to do this in the future?)
| 
| Thanks also, Waldek, for removing the old axiom.silver
| branch.

I thought I removed axiom.silver; Waldek did we concurrently end its life? 

| Now ... how can we get build-improvements and wh-sandbox
| back into the trunk? :-)
| 
| What Tim calls "silver" (now in trunk) still seems hopelessly
| out of date to me.

it is up to date with respect to Tim's work.

\start
Date: Mon, 4 Jun 2007 08:39:46 -0700 (PDT)
From: Cliff Yapp
To: Bill Page, Gabriel Dos Reis
Subject: Re: merge branches/daly to trunk (was: NAG libraries)

--- Bill Page wrote:

> Now ... how can we get build-improvements and wh-sandbox
> back into the trunk? :-)

That relates back to packaging the changes in those trees into
individual changesets that make conceptual sense, and applying them to
the GIT silver tree.  I was hoping that would be doable as a bi-product
of svn->git.
 
> What Tim calls "silver" (now in trunk) still seems hopelessly
> out of date to me.

silver has some things build-improvements and wh-sandbox don't, and
they have many things silver doesn't.  Merging them is a non-trivial
job - they have diverged too long :-(.

Once I have a computer again I'll take a stab at using GIT to
comprehend the revisions in those trees, but based on everyone else's
results making that attempt I'm sure it won't be easy.

\start
Date: 04 Jun 2007 17:41:32 +0200
From: Martin Rubey
To: Waldek Hebisch
Subject: Re: Patches

Waldek Hebisch writes:

> Martin Rubey wrote:

> Of course, currently Axiom has no support for holonomic functions.

Yes. :-(

> But in few places we use derivatives: changing variables in integrals,
> computing Laplace transforms.  It is quite possible that Axiom never uses
> derivative of bessel function with respect to parameter.  But checking this
> would be a substantial ongoing effort.
> 
> > > Once we get better support for special functions this may be very serious
> > > problem.
> > 
> > Probably. By the way: most (probably all) special functions would be
> > covered by my favourite would-be category/domain hierarchy of
> > differentially algebraic functions. Then we could say something like
> > 
> > polygamma(a, x)$HOLO(???)

ups, that should read

besselJ(a, x)$HOLO(???)

or some such. (And, of course, I have no idea whether it is holonomic in both
variables, although I doubt it)

> > and get the corresponding differential equation.
> > 
> 
> Hmm, gamma and consequently also polygamma(a, x) as a function of x is
> differential transcendental.  Also handling of non-holonomic differentially
> algebraic functions seem to be a research problem -- do you have some
> interesting results here?

Not me, but Joris van der Hoeven told me that there is indeed a zero test for
differentially algebraic functions (in the sense: differentially algebraic
function = function satisfying ADE = exists a polynomial p with p(f, f',
f'',...) = 0)

Furthermore, ADE's are closed under addition, multiplication, etc., and there
exist algorithms to do all that.  They are probably not extremely efficient,
but since the range of functions covered is vast, this would nevertheless be
extremely good to have.

What I have implemented in my guessing package is a reasonably fast way to
guess the differential equation for such functions.  Try 

(7) -> guessADE [1,1,2,9/2,32/3,625/24,324/5]

   (7)
   [
     [
       function          BRACKET
              n
            [x ]f(x):
                    ,          3       2             ,        ,,
                - xf (x) + f(x)  - f(x) = 0,f(0)= 1,f (0)= 1,f  (0)= 4

             ,
                 ,,,         (iv)
                f   (0)= 27,f    (0)= 256

       ,
      order= 0]
     ]
    Type: List Record(function: Expression Integer,order: NonNegativeInteger)


Thanks for the polygamma reference.

\start
Date: 04 Jun 2007 17:43:09 +0200
From: Martin Rubey
To: Cliff Yapp
Subject: Re: merge branches/daly to trunk (was: NAG libraries)
Cc: Bill Page, Gabriel Dos Reis

Cliff Yapp writes:

> silver has some things build-improvements and wh-sandbox don't, and
> they have many things silver doesn't.  

Really?

\start
Date: Mon, 4 Jun 2007 11:49:36 -0400
From: Alfredo Portes
To: Gabriel Dos Reis
Subject: Re: NAG libraries

Hi Gaby,

>
>   Can you give it a try as of revision 584?

One error I get in the both trunk and daly is that I need root
permission, if not
I get the error:
[...]
cp: cannot create regular file
`/home/alfredo/SilverAxiom/mnt/linux/bin/tex/.svn/all-wcprops':
Permission denied
make: *** [/home/alfredo/SilverAxiom/mnt/linux/bin/Makefile.pamphlet] Error 1
[...]

I need to have also installed gettext (I think it was required while
compiling gcl).
I see this was referenced in an old email with Camn, you, Bill, when
trying to compile
axiom for OS X.

After I get the error:

[...]
/bin/sh: unixport/saved_gcl: not found
[...]

I think both trunk and daly need a newer gcl. Any idea what I am
missing to continue the build.

\start
Date: Mon, 4 Jun 2007 12:32:46 -0400
From: Bill Page
To: Martin Rubey, Cliff Yapp
Subject: RE: merge branches/daly to trunk
Cc: Gabriel Dos Reis

On June 4, 2007 11:43 AM Martin Rubey wrote:
> 
> Cliff Yapp writes:
> 
> > silver has some things build-improvements and wh-sandbox don't,
> > and they have many things silver doesn't.  
> 
> Really?
> 

As far as I know, the only thing in silver (aka. axiom.daly,
aka. axiom.trunk) is a first attempt at some regression testing.
I believe that Gaby is trying to port this downstream but
currently has some problems with portability of Tim's code.

> -----Original Message-----
> On June 4, 2007 10:28 AM Gabriel Dos Reis wrote
> 
>   The script REGRESS contains hardcoded information about
> user daly. How is it supposed to work for non-user daly
> (everybody else)?

\start
Date: Mon, 04 Jun 2007 18:21:13 +0200
From: Ralf Hemmecke
To: Alfredo Portes
Subject: Re: NAG libraries
Cc: Gabriel Dos Reis

Please look at revision 75. That is a problem with .svn directories 
unnecessarily copied.

Gaby, Tim, I think that patch should go into trunk=silver.

Alfredo, use SVK, that is better anyway for tracking merges (star-merge)

-- Ralf

----------------------------------------------------------------
r74 (orig r75):  hemmecke | 2006-08-01 16:45:56 +0200
Changed paths:
   M  /axiom/branches/build-improvements/ChangeLog
   M  /axiom/branches/build-improvements/Makefile.pamphlet
   M  /axiom/branches/build-improvements/src/doc/Makefile.pamphlet
   M  /axiom/branches/build-improvements/src/scripts/Makefile.pamphlet

Fix: After checking out the trunk of Axiom Silver, a 'make' did not
succeed because the src/script and src/doc/ps directories were copied
twice. Since the .svn directory inside contains write-protected files,
it caused problems.
==============================================================


On 06/04/2007 05:49 PM, Alfredo Portes wrote:
> Hi Gaby,
> 
>>
>>   Can you give it a try as of revision 584?
> 
> One error I get in the both trunk and daly is that I need root
> permission, if not
> I get the error:
> [...]
> cp: cannot create regular file
> `/home/alfredo/SilverAxiom/mnt/linux/bin/tex/.svn/all-wcprops':
> Permission denied
> make: *** [/home/alfredo/SilverAxiom/mnt/linux/bin/Makefile.pamphlet] 
> Error 1
> [...]
> 
> I need to have also installed gettext (I think it was required while
> compiling gcl).
> I see this was referenced in an old email with Camn, you, Bill, when
> trying to compile
> axiom for OS X.
> 
> After I get the error:
> 
> [...]
> /bin/sh: unixport/saved_gcl: not found
> [...]
> 
> I think both trunk and daly need a newer gcl. Any idea what I am
> missing to continue the build.

\start
Date: Mon, 4 Jun 2007 10:09:24 -0700 (PDT)
From: Cliff Yapp
To: Martin Rubey
Subject: Re: merge branches/daly to trunk (was: NAG libraries)
Cc: Bill Page, Gabriel Dos Reis


--- Martin Rubey wrote:

> Cliff Yapp writes:
> 
> > silver has some things build-improvements and wh-sandbox don't, and
> > they have many things silver doesn't.  
> 
> Really?

Tim released some new stuff when he uploaded the first version of
silver to use GIT.  He sent an email which discussed it - it's in the
archives somewhere.  It might be that applying his changes to the other
branches wouldn't be difficult, or perhaps they have already
incorporated them - I'm not sure.

\start
Date: Mon, 4 Jun 2007 12:10:55 -0500
From: Tim Daly
To: Ralf Hemmecke
Subject: trunk
Cc: Gabriel Dos Reis

> "trunk" is basically identical with Gold (tla: axiom--main--1--patch-50)
> and currently not maintained although build-improvements and wh-sandbox
> branched from it.

> Actually, I don't know exactly, why Tim now puts everything into 
> "branches/daly" instead of "trunk".

I put the files into branches/daly so that I could make the development
that I'd been doing "public". There is still more work to be done in
terms of bug fixing and cleanup before it becomes ready to be a 
complete candidate for a new release. "branches/daly" was the first
version that passed all of my local testing but there is still work
to be done.

I tried to do the merge the other SVN branches with gold and failed.
I then tried to pick up all the changes that I understood and 
merged those changes. This must be done by hand because the branch
changesets also involve changes to the Makefiles and the branch
Makefile structures don't exist in Gold. 

> ... Gaby, Tim, Waldek, what do you think
> the best strategy would be to ease merging later?

It seemed to me that putting the files into "trunk" would have 
undercut the ability of Gaby and Waldek to do a merge, thus leaving
them no path to get back to Gold. The hope is that they will spend
some time to "lift" complete changesets from their branches against
Gold so they can be applied outside their branches. 

Each branch is basically a publicly-available private sandbox.
Private sandboxes are the best way to explore an idea (I have
dozens) but it is really up to the individual to make those 
experiments fit into the released version.

\start
Date: Mon, 4 Jun 2007 12:32:29 -0500
From: Tim Daly
To: Gabriel Dos Reis
Subject: trunk
Cc: Gabriel Dos Reis

> I would have highly preferred Tim put the new silver in /silver,
> and keep branches/daly as his private branch; but he didn't so we must
> learn to live with that.

I put the code into branches/daly because it's not ready yet.  That
code is the first version that passed all of the tests.  However there
are still many things to fix and I'm going thru the bug list now
looking for fixes. That code will change in various ways (e.g. I'm
downcasing filenames to conform to windows/mac and many files will
change in an upcoming changeset).

The code isn't "silver" yet so I put it on a private branch while
I do the work in public.




> As for merge, it is going to be more painful than it has to be
> primaily because Tim picked changes by carefully not picking the
> revision number or ChangeLogs.

When you make changes do you try to merge them with Gold and then
publish either a diff-Naur or a revision number?

The revision number selection involves changesets which almost
always include Makefile changes. But Gold does not have a matching
Makefile so the changeset merge won't work. 

Perhaps the failure is due to my lack of understanding of how SVN
merge is supposed to work. However I don't see how SVN merge can
possibly be expected to merge a BI Makefile and a Gold Makefile.




> I tried twice, but abandoned because I had more pressing things
> on the fire and partly because I got frustrated.

I understand your frustration. I started this whole merge process in
the late january time frame and have been working on it exclusively
since then. You've been doing valuable work and I tried to pick up
what I could so it could be in the next release.





It seems to me that the "responsibility" criteria is somehow reversed.
If you or anyone else develops a change to the system doesn't it seem
reasonable that you are responsible for documenting, diffing, creating
changesets, creating test cases, and packaging up the changes so they
fit into what the current Gold version is? I see good work being done
but I see no effort on your part to lift it out of your private sandbox.

\start
Date: Mon, 4 Jun 2007 13:32:33 -0400
From: Bill Page
To: Cliff Yapp
Subject: RE: merge branches/daly to trunk (was: NAG libraries)
Cc: Gabriel Dos Reis

On June 4, 2007 11:40 AM C Y wrote:
> 
> --- Bill Page wrote:
> 
> > Now ... how can we get build-improvements and wh-sandbox
> > back into the trunk? :-)
> 
> That relates back to packaging the changes in those trees into
> individual changesets that make conceptual sense, and applying
> them to the GIT silver tree.  I was hoping that would be doable
> as a bi-product of svn->git.

It is easy (in principle) to migrate svn to git via git-svn

http://git-svn.yhbt.net/git-svn.html

or even 'tailor'

http://www.darcs.net/DarcsWiki/Tailor

These tools will transfer the full history and associated changesets
from one repository into another. I did this once before and that
result might still be somewhere on the axiom-developer.org server.

But how will that help merging build-improvements and wh-sandbox
into trunk?

\start
Date: Mon, 4 Jun 2007 12:53:53 -0500
From: Tim Daly
To: Gabriel Dos Reis
Subject: trunk
Cc: Gabriel Dos Reis

> I'm planning to attempt the following -- assuming I got time today:



>  * merge branches/daly to trunk

As I understand it trunk is Gold (aka --patch-50).
branches/daly was started from --patch-50 (see CHANGELOG) by adding changes.
Thus it should be sufficient to copy branches/daly.

But I wouldn't recommend doing that yet. There are more changes in
the pipeline for branches/daly which are not fully merged and tested
(e.g. bug 312 change, file-downcasing, fixes for .input files, Martin's
guess algebra, etc). But you can do it if you like. I'd be just as
happy to patch trunk as to patch branches/daly.

I think that it would be more fruitful if you spent time creating
diff-Naur changesets between trunk and build-improvements or
branches/daly and build-improvements. Each changeset should lift 
up a single feature that I failed to merge. That way we can simply
apply the changeset and get the new feature.




>  * create a branch gold that contains the mature Gold version

Frankly, I'm not even sure what this would mean. But I am sure that
creating a "branch" named "Gold" in SVN is certain to cause confusion
and havoc. Gold lives in Arch, currently --patch-50. 





> The idea is that trunk should be the development silver (and hopefully
> Tim will commit here) from which people will branch from. 

When there is some consensus that branches/daly contains the set of
outstanding bug fixes and algebra changes it could be considered a
"silver" branch. Normally I wouldn't have released it into public
view at the current stage but we've had that discussion before. Thus
I've put it on the public stage after it "works" but before it is
really ready.

We could move it to trunk if you want. It won't cause me any pain but
I suspect it will cause the branches pain. I'm not sure how SVN handles
merging of multi-branching trees. I can't figure out the model.

I'm happy to commit to trunk rather than branches/daly.



> And build-improvements, wh-sandbox will merge to that trunk later.

NOW is the time to do the merges. Now when we are marching toward a
new silver to replace Gold. Now when we have an effort to get a new
stable release out the door. Now is the time to make sure that the
things you want pushed out onto Arch, sourceforge, and savannah as
Gold are included.

Find features you want. Make exclusive diff-Naur changesets. Make
documentation. Make test cases. Make it work. Make it fit.

\start
Date: Mon, 4 Jun 2007 12:55:55 -0500
From: Tim Daly
To: Gabriel Dos Reis
Subject: trunk
Cc: Gabriel Dos Reis

> How do you identify diff-Naur patches anyway? Which tool do you use to
> prevent you from applying the same patch twice.

My eyes.

However patch will complain if you apply the same patch twice.

\start
Date: Mon, 4 Jun 2007 12:58:53 -0500
From: Tim Daly
To: Martin Rubey
Subject: bug 312

Martin,

I sent your sstaylor changes to Clifton Williamson, the original
author of the file. I'm waiting to hear his opinion on the nature
of the changes.

\start
Date: Mon, 4 Jun 2007 13:01:27 -0500
From: Tim Daly
To: Cliff Yapp
Subject: Patches

> As long as we're on the subject, how would one provide a "patch" for
> adding a completely new file...

diff-Naur will create the file. However it would just be easier to
send the file separately. The addition of a new file implies a bunch
of SVN add, git add, Arch add, and cvs add commands.

\start
Date: Mon, 4 Jun 2007 13:06:11 -0500
From: Tim Daly
To: Cliff Yapp
Subject: SCMs

> The script REGRESS contains hardcoded information about user daly.
> How is it supposed to work for non-user daly (everybody else)?

It isn't. That's a bug. Fixed shortly.

I generally have several builds running at once on different
machines and I need to know when they complete so I can review them.
Email lets me know when they complete or fail. Of course, since it
"works for me" I didn't realize I posted it. Sorry about that.

\start
Date: Mon, 4 Jun 2007 13:09:55 -0500
From: Tim Daly
To: Gabriel Dos Reis
Subject: SVN revision 584

Gaby,

So my understanding is that you've merged branches/daly with trunk.

Thus, if I'm correct branches/daly is now defunct and all changes
I make should be made to trunk.

Is that your understanding?

\start
Date: Mon, 4 Jun 2007 13:15:51 -0500
From: Tim Daly
To: Alfredo Portes
Subject: SVN revision 584
Cc: Gabriel Dos Reis

Alfredo,

> One error I get in the both trunk and daly is that I need root
> permission, if not
> I get the error:
> [...]
> cp: cannot create regular file

    for i in `find . -name ".svn" ; do rm -rf $i ; done

This is an SVN bug. It does not happen with Arch, CVS, or git.

It is also an Axiom bug because the duplicate copy should not occur.

End users won't see the bug because we need to clean out all of the
.git, .svn, .cvs, and .arch subdirectories before packaging.

\start
Date: Mon, 4 Jun 2007 13:20:52 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: Re: trunk

On Mon, 4 Jun 2007, Tim Daly wrote:

| > I'm planning to attempt the following -- assuming I got time today:
| 
| 
| 
| >  * merge branches/daly to trunk
| 
| As I understand it trunk is Gold (aka --patch-50).

No, it wasn't.  I checked.  Many changes there were not present in
branches/daly. 

| But I wouldn't recommend doing that yet. There are more changes in
| the pipeline for branches/daly which are not fully merged and tested
| (e.g. bug 312 change, file-downcasing, fixes for .input files, Martin's
| guess algebra, etc). But you can do it if you like. I'd be just as
| happy to patch trunk as to patch branches/daly.

That is great.  What I would propose is that one you commit those changes to
branches/daly, we sync it with trunk and we continue with trunk.  That way,
you pending work is not disrupted and people are given sufficient notice of
what will happen.

| I think that it would be more fruitful if you spent time creating
| diff-Naur changesets between trunk and build-improvements or
| branches/daly and build-improvements.

I *did spend* time on that issue.  Just diffing between both branches is not
an option.  Changes I've made are buring deep into your and it just sucked a
fair amount of time (last week).  The fact that you did pick changes by
discrete diff/patch does not help.  I don't have much confience in manual
diffing. 

[...]

| >  * create a branch gold that contains the mature Gold version
| 
| Frankly, I'm not even sure what this would mean. But I am sure that
| creating a "branch" named "Gold" in SVN is certain to cause confusion
| and havoc. Gold lives in Arch, currently --patch-50. 

Having many versions of Axiom floating around causes greater confusion.
If people can get silver from one place, they should also be able to get gold
from that same place.

[...]

| I'm happy to commit to trunk rather than branches/daly.

That would be great.  Before that, please could you build trunk as of today
and run your regress script and tell me if something is wrong.
Ideally, we should be able to set the regress script so that it works for
everybody and the results sent to axiom-testresults@lists.sf.net.

\start
Date: Mon, 4 Jun 2007 13:20:30 -0500
From: Tim Daly
To: Bill Page
Subject: merge branches/daly to trunk

Bill,

See http://lists.gnu.org/archive/html/axiom-developer/2007-05/msg00320.html

for details about the contents of silver.

\start
Date: Mon, 4 Jun 2007 13:22:31 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: Re: SVN revision 584

On Mon, 4 Jun 2007, Tim Daly wrote:

| Alfredo,
| 
| > One error I get in the both trunk and daly is that I need root
| > permission, if not
| > I get the error:
| > [...]
| > cp: cannot create regular file
| 
|     for i in `find . -name ".svn" ; do rm -rf $i ; done
| 
| This is an SVN bug. It does not happen with Arch, CVS, or git.

It does not happen with SVK (an SVN client).

| It is also an Axiom bug because the duplicate copy should not occur.

It is *primarily* and Axiom bug.

I'm pretty sure, Ralf fixed that bug long time ago.

| End users won't see the bug because we need to clean out all of the
| .git, .svn, .cvs, and .arch subdirectories before packaging.

developers should not see it either.

\start
Date: Mon, 4 Jun 2007 13:24:29 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: Re: SVN revision 584

On Mon, 4 Jun 2007, Tim Daly wrote:

| Gaby,
| 
| So my understanding is that you've merged branches/daly with trunk.

Yes.  Please could you build and test it first?

| Thus, if I'm correct branches/daly is now defunct and all changes
| I make should be made to trunk.

I don't want to disrupt your pending changes to branches/daly.  So if you have
any pending work in the pipeline that would be painful to get into trunk,
please just use branches/daly and we will sync later and abandon
branches/daly. 

\start
Date: Mon, 4 Jun 2007 13:24:51 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: Re: trunk

On Mon, 4 Jun 2007, Tim Daly wrote:

| 
| > How do you identify diff-Naur patches anyway? Which tool do you use to
| > prevent you from applying the same patch twice.
| 
| My eyes.

Aie. Aie. Aie.

\start
Date: Mon, 4 Jun 2007 13:27:36 -0500 (CDT)
From: Gabriel Dos Reis
To: Alfredo Portes
Subject: Re: NAG libraries

On Mon, 4 Jun 2007, Alfredo Portes wrote:

[...]

| I need to have also installed gettext (I think it was required while
| compiling gcl).

I believe you have been through that before.  The thing is to use
--disable-nls (diable Native Language Translation).  I think that gettext
requirements come from the binutils package in GCL.  So, if you configure GCL
not to use NLS, you should be fine.

| I see this was referenced in an old email with Camn, you, Bill, when
| trying to compile
| axiom for OS X.

Indeed.

\start
Date: 04 Jun 2007 20:28:19 +0200
From: Martin Rubey
To: Bill Page
Subject: Re: merge branches/daly to trunk
Cc: Gabriel Dos Reis

Bill Page writes:

> As far as I know, the only thing in silver (aka. axiom.daly,
> aka. axiom.trunk) is a first attempt at some regression testing.  I believe
> that Gaby is trying to port this downstream [...]

I think it is a mistake to do that.  We should port Christian Aistleitner's
code to use libaxiom instead of libaldor.  It is excellent code, and extremely
user friendly.  We have used it with *great* success in our species package.
I.e., it caught many mistakes that wouldn't have been discovered otherwise.

I know, this is open source.  But I do not understand that we have to invent
the wheel so many times.  I estimate that it would take four days full time to
get his code running for axiom, for anybody who knows a little aldor and knows
OutputForm.  

As far as I remember, we would mainly need a domain TextWriter that provides
the functionality of textWriter$TextWriter, stdout$TextWriter and
stderr$TextWriter.  Other domains, like String, then should provide functions

  <<: (TextWriter, %) -> TextWriter

i.e., it takes a TextWriter and a String and "appends" the String to the given
TextWriter, thus producing a new one.

So, apart from stdout and stderr, what is needed, is an operation

  textWriter: (Character -> ()) -> %

that takes a function that writes a single character and returns a TextWriter.

The domain TextWriter can be implemented in Aldor, but using the axiom library.
I did not try, but it is quite possible that one could even use the existing
implementation from libaldor.  Hm, I should really try that.

Ralf and myself have already implemented some other Aldor domains using the
axiom library, in axcompat.as.nw and axcompat2.as.nw of our pecies project,
which you can download using

svn co svn://svn.risc.uni-linz.ac.at/hemmecke/combinat/

\start
Date: Mon, 4 Jun 2007 13:31:34 -0500 (CDT)
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Re: NAG libraries

On Mon, 4 Jun 2007, Ralf Hemmecke wrote:

| Please look at revision 75. That is a problem with .svn directories
| unnecessarily copied.
| 
| Gaby, Tim, I think that patch should go into trunk=silver.

I missed this mail you sent.

Tim, please could you pick this patch?  It is revision 75.

| Alfredo, use SVK, that is better anyway for tracking merges (star-merge)
| 
| -- Ralf

:-)

\start
Date: Mon, 4 Jun 2007 13:47:19 -0500
From: Tim Daly
To: Gabriel Dos Reis
Subject: merge branches/daly to trunk

Gaby,

I'll test the trunk version.

Then I'll diff-Naur the trunk and branches/daly and then bring my
local tree up to date as well as the git public tree. 

Once that is done I'll do all future commits to trunk.

\start
Date: Mon, 4 Jun 2007 13:50:08 -0500
From: Tim Daly
To: Gabriel Dos Reis
Subject: merge branches/daly to trunk

Gaby,

>>> cp: cannot create regular file

>> This is an SVN bug.

>It does not happen with SVK (an SVN client)

How can this be true? Does SVK delete .svn?

\start
Date: Mon, 4 Jun 2007 13:54:57 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: Re: merge branches/daly to trunk

On Mon, 4 Jun 2007, Tim Daly wrote:

| Gaby,
| 
| I'll test the trunk version.
| 
| Then I'll diff-Naur the trunk and branches/daly and then bring my
| local tree up to date as well as the git public tree. 
| 
| Once that is done I'll do all future commits to trunk.


That is great news.


As for my plans to merge things from build-improvements to trunk:

  (1) I'll go on (business) travel from next wednesday, for some time.
      The only machine I'll have is a windows-based laptop.  So that seriously
      limits what I can do.

  (2) I'll try to isolate configure.ac.pamphlet alone; but it is noe terrible
      that useful.  However, I prefer to do it that way, because the Makefile
      changes need me to do full build, which I can't during my travel.

  (3) I may need to propose some "trivial" changes that help build on
      windowns. 

The bottom-line is that the changes will be incremental as opposed to a
gigantic one-shot patch.

\start
Date: 04 Jun 2007 20:55:52 +0200
From: Martin Rubey
To: Gabriel Dos Reis
Subject: re: merge branches/daly to trunk

Gabriel Dos Reis writes:

>   (1) I'll go on (business) travel from next wednesday, for some
>       time.  The only machine I'll have is a windows-based laptop.
>       So that seriously limits what I can do.

You can always work on graphics and HyperDoc on windows ;-)

\start
Date: Mon, 4 Jun 2007 13:59:02 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: Re: merge branches/daly to trunk

On Mon, 4 Jun 2007, Tim Daly wrote:

| Gaby,
| 
| >>> cp: cannot create regular file
| 
| >> This is an SVN bug.
| 
| >It does not happen with SVK (an SVN client)
| 
| How can this be true?

No question it is true :-)

And SVK is a decentralized VCS -- not that it matters for Axiom...

| Does SVK delete .svn?

No, SVK keeps the databases somewhere else (typically ~/.svk), so as not to
interfer with versioned source code.  The result is that the working directory
just looks like an exported directory (e.g. one that the end user will see),
but SVK knows which paths are checked out paths and their states.

\start
Date: Mon, 4 Jun 2007 13:59:34 -0500 (CDT)
From: Gabriel Dos Reis
To: Martin Rubey
Subject: re: merge branches/daly to trunk

On Mon, 4 Jun 2007, Martin Rubey wrote:

| Gabriel Dos Reis writes:
| 
| >   (1) I'll go on (business) travel from next wednesday, for some time.
| >       The only machine I'll have is a windows-based laptop.  So that seriously
| >       limits what I can do.
| 
| You can always work on graphics and HyperDoc on windows ;-)

:-)

\start
Date: 04 Jun 2007 21:02:23 +0200
From: Martin Rubey
To: Christian Aistleitner
Subject: AxiomUnit
Cc: Bill Page, Gabriel Dos Reis

Dear Christian!

I just did something extremely simple minded, with the following result:

(5) -> )sh MyTextWriter
 MyTextWriter  is a domain constructor
 Abbreviation for MyTextWriter is MYTEXTW 
 This constructor is exposed in this frame.
 Issue )edit csaxcompat2.as to see algebra source code for MYTEXTW 

------------------------------- Operations --------------------------------
 flush! : % -> %                       stderr : () -> %
 stdout : () -> %                      write! : (ACCharacter,%) -> Void
 textWriter : (ACCharacter -> NIL) -> %
 textWriter : ((ACCharacter -> NIL),(() -> NIL)) -> %

(5) -> write!(char "H", stderr())
H                                                                   Type: Void

The idea I had was:

Martin Rubey writes:

> I did not try, but it is quite possible that one could even use the existing
> implementation from libaldor.  Hm, I should really try that.

I set Pointer equal to MachineInteger, I think that's OK for a hack.  And, I
hope that's not a problem, Axiom cannot distinguish between stdout and stderr.

Given that, what remains for AxiomUnit?

\start
Date: Mon, 4 Jun 2007 14:12:18 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: Re: trunk

On Mon, 4 Jun 2007, Tim Daly wrote:

| > I would have highly preferred Tim put the new silver in /silver,
| > and keep branches/daly as his private branch; but he didn't so we must
| > learn to live with that.
| 
| I put the code into branches/daly because it's not ready yet.  That
| code is the first version that passed all of the tests. 

I believe the community wants to work as a community and is happy you make
that branch public.  I believe the community also thinks since that branch is
also the closest to become stable release, it should be the trunk/silver
branch. 

[...]

| I do the work in public.

That is very much appreciated.

[...]

| > As for merge, it is going to be more painful than it has to be
| > primaily because Tim picked changes by carefully not picking the
| > revision number or ChangeLogs.
| 
| When you make changes do you try to merge them with Gold and then
| publish either a diff-Naur or a revision number?

For me it is easier to track individual changes through their revision
numbers, than to *guess* them from a huge pile of diff.

| The revision number selection involves changesets which almost
| always include Makefile changes. But Gold does not have a matching
| Makefile so the changeset merge won't work. 

Well, if I can make a first merge to trunk (which now contains your changes),
then it should be easier to make the step to Gold, since trunk will eventually
become "branched" for release.

| Perhaps the failure is due to my lack of understanding of how SVN
| merge is supposed to work. However I don't see how SVN merge can
| possibly be expected to merge a BI Makefile and a Gold Makefile.

Well, first I would like to (partially) sync build-improvements with trunk,
that is (partially) merge from trunk to build-improvements; then propose 
series of patches from build-improvements to trunk.  The reason I would like
to (partially) merge from trunk to build-improvements, is that I want the
patches from build-improvements to trunk to contain only the modifications
that build-improvements actually did.

[...]

| It seems to me that the "responsibility" criteria is somehow reversed.

I'm not expecting nor asking someone else to do the merge for me.

And I do not intent to keep the work on build-improvement "private" -- there
are my local trees and gdr-sandbox for that :-)

\start
Date: Mon, 4 Jun 2007 14:13:07 -0500 (CDT)
From: Gabriel Dos Reis
To: Bill Page
Subject: RE: merge branches/daly to trunk (was: NAG libraries)

On Mon, 4 Jun 2007, Bill Page wrote:

| But how will that help merging build-improvements and wh-sandbox
| into trunk?

I have no idea how that helps me.

\start
Date: Mon, 4 Jun 2007 14:16:01 -0500 (CDT)
From: Gabriel Dos Reis
To: Martin Rubey
Subject: Re: merge branches/daly to trunk
Cc: Bill Page

On Mon, 4 Jun 2007, Martin Rubey wrote:

| Bill Page writes:
| 
| > As far as I know, the only thing in silver (aka. axiom.daly,
| > aka. axiom.trunk) is a first attempt at some regression testing.  I believe
| > that Gaby is trying to port this downstream [...]
| 
| I think it is a mistake to do that.  We should port Christian Aistleitner's
| code to use libaxiom instead of libaldor.

Since I do not have resource to allocate for that task, should I go with
no form of regression test at all?  

\start
Date: Mon, 04 Jun 2007 21:36:21 +0200
From: Ralf Hemmecke
To: Tim Daly
Subject: Re: SVN revision 584
Cc: Gabriel Dos Reis

On 06/04/2007 08:15 PM, Tim Daly wrote:
> Alfredo,
> 
>> One error I get in the both trunk and daly is that I need root
>> permission, if not
>> I get the error:
>> [...]
>> cp: cannot create regular file
> 
>     for i in `find . -name ".svn" ; do rm -rf $i ; done
> 
> This is an SVN bug. It does not happen with Arch, CVS, or git.

Sorry to say, Tim, but it is a but in the Makefiles. SVN just happens to 
make some files inside .svn read-only (because only svn should change them).

> It is also an Axiom bug because the duplicate copy should not occur.

Right and it is

svn log -v 
https://axiom.svn.sourceforge.net/svnroot/axiom/branches/build-improvements 
-r74:75

svn diff 
https://axiom.svn.sourceforge.net/svnroot/axiom/branches/build-improvements 
-r74:75

that gives you the patch. Just redirect the output of "svn diff" to a file.

> End users won't see the bug because we need to clean out all of the
> .git, .svn, .cvs, and .arch subdirectories before packaging.

Oh, I think "end users" take precompiled things that come with 
debian/red hat etc. Most others compile from a checkout of one of the 
archives. Am I wrong?

\start
Date: Mon, 4 Jun 2007 13:11:43 -0700 (PDT)
From: Cliff Yapp
To: Gabriel Dos Reis, Bill Page
Subject: RE: merge branches/daly to trunk (was: NAG libraries)

--- Gabriel Dos Reis wrote:

> On Mon, 4 Jun 2007, Bill Page wrote:
> 
> | But how will that help merging build-improvements and wh-sandbox
> | into trunk?
> 
> I have no idea how that helps me.

It would be an opportunity to isolate the changes in the trees into
conceptual "chunks", so to speak - unless the svn history indicates
changes as lumps that aren't particularly centered around one idea.  I
am not familiar enough with the commit histories to know.

I would treat it as an opportunity to a) become familiar with all the
work being done in the various branches and b) isolate parts of the
work into conceptual bundles that map well to how GIT works.

The only reason to put it all into GIT would be to try and provide
everyone with an environment where their own development histories were
present, and thus make it easier to try GIT as a more standard tool for
development.  I suppose on reflection even that might not help much
though.

\start
Date: Mon, 04 Jun 2007 22:17:00 +0200
From: Ralf Hemmecke
To: Gabriel Dos Reis
Subject: Re: trunk

> That is great.  What I would propose is that one you commit those changes to
> branches/daly, we sync it with trunk and we continue with trunk.  That way,
> you pending work is not disrupted and people are given sufficient notice of
> what will happen.

Very good, Gaby. I was about to suggest the same.

In fact, the biggest problem is not the many SCMs we have. The problem
is that different people have different views on how Axiom should develop.

We have gold/silver/experimental branches, but seemingly not everyone
understands the same thing when he says gold or silver.

I think we all agree, that the current Gold is axiom--main--1--patch-50
(and I don't know whether this has another version number like 3.0 or so).

Silver is something that should be "reasonably stable". Maybe we require
that is should at least always compile. However, it might contain things
that do not work.

Currently, Tim decides what goes into Silver (which meanwhile became
sourceforge:trunk).

People should be able do checkout Silver and investigate whether it
compiles on their machines. Whether they find bugs, etc.

At some point in time we agree that Silver is sufficiently stable so
that it can simply be *called* "Gold". Now a snapshot of Silver will be
moved to sourceforge:gold/Axiom-4.0 and development is going on at
sourceforge:trunk.

Many people have there private or public branches (which should branch
from Silver). Development there is completely up to them. If those
people think that some idea is ready to be included to Silver, they
should announce it and provide a patch or command how to get the
changeset into Silver. (In my opinion the patch should be a diff against
the current Silver and not against Gold, but maybe I just have not
enough worked in such big projects.

Before changes go to Silver, Tim has to approve them. (Actually, to
remove a bottleneck, we should introduce some voting system, whether a
particular patch should go into Silver or not.)

Could you give your opinion on whether that development model would be
good for you? Please, I don't want to hear somebody blaming somebody
else that he is doing things wrongly. We should be pragmatic and try to
figure out a way that each of us can live with. We have not enough
manpower that we can affort to work against each other.

> | >  * create a branch gold that contains the mature Gold version
> | 
> | Frankly, I'm not even sure what this would mean. But I am sure that
> | creating a "branch" named "Gold" in SVN is certain to cause confusion
> | and havoc. Gold lives in Arch, currently --patch-50. 
> 
> Having many versions of Axiom floating around causes greater confusion.
> If people can get silver from one place, they should also be able to get gold
> from that same place.

I agree with Gaby. Let's get rid of Arch. Even Tim has replaced it by 
GIT. Why should be people bother with Arch. Make it simple and let (the 
next Gold) also live at sourceforge. It will anyway since it will be a 
snapshot of silver.

I wouldn't care much about --patch-50. Let it live in Arch, if it must. 
Copying it to sourceforge isn't worth the trouble and just makes the 
archive bigger.

\start
Date: Mon, 04 Jun 2007 22:34:35 +0200
From: Ralf Hemmecke
To: Gabriel Dos Reis
Subject: Re: merge branches/daly to trunk
Cc: Christian Aistleitner, Bill Page

On 06/04/2007 09:16 PM, Gabriel Dos Reis wrote:
> On Mon, 4 Jun 2007, Martin Rubey wrote:
> 
> | Bill Page writes:
> | 
> | > As far as I know, the only thing in silver (aka. axiom.daly,
> | > aka. axiom.trunk) is a first attempt at some regression testing.  I believe
> | > that Gaby is trying to port this downstream [...]
> | 
> | I think it is a mistake to do that.  We should port Christian Aistleitner's
> | code to use libaxiom instead of libaldor.
> 
> Since I do not have resource to allocate for that task, should I go with
> no form of regression test at all?  
> 
> -- Gaby

No, of course not. And what Christian told me, it seemed a bit more 
delicate then just providing TextWriter in Axiom. One of the bigger 
questions is, how to actually call this AxiomUnit functionality.

For Aldor that is easy, one compiles an executable and runs that. With 
Axiom that is not possible, because libaxiom cannot (at least not 
easily) be compiled into a standalone executable.

Now Martin, suppose one test fails misserably, causing memory damage and 
all bad things. You would like to go on with testing in a clean 
environment. But that basically says, you have to start Axiom for every 
single test. That's going to be heavy. But Christian might be better in 
saying something why AxiomUnit does not yet exist.

\start
Date: Mon, 4 Jun 2007 15:36:23 -0500 (CDT)
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Re: trunk

On Mon, 4 Jun 2007, Ralf Hemmecke wrote:

[...]

| I think we all agree, that the current Gold is axiom--main--1--patch-50
| (and I don't know whether this has another version number like 3.0 or so).
| 
| Silver is something that should be "reasonably stable". Maybe we require
| that is should at least always compile. However, it might contain things
| that do not work.

I agree.

| Currently, Tim decides what goes into Silver (which meanwhile became
| sourceforge:trunk).
| 
| People should be able do checkout Silver and investigate whether it
| compiles on their machines. Whether they find bugs, etc.
| 
| At some point in time we agree that Silver is sufficiently stable so
| that it can simply be *called* "Gold". Now a snapshot of Silver will be
| moved to sourceforge:gold/Axiom-4.0 and development is going on at
| sourceforge:trunk.

I agree.

| Many people have there private or public branches (which should branch
| from Silver). Development there is completely up to them. If those
| people think that some idea is ready to be included to Silver, they
| should announce it and provide a patch or command how to get the
| changeset into Silver. (In my opinion the patch should be a diff against
| the current Silver and not against Gold, but maybe I just have not
| enough worked in such big projects.

I agree on all counts.

| Before changes go to Silver, Tim has to approve them. (Actually, to
| remove a bottleneck, we should introduce some voting system, whether a
| particular patch should go into Silver or not.)

Except for the voting system, I agree.

\start
Date: Mon, 4 Jun 2007 15:42:01 -0500 (CDT)
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Re: merge branches/daly to trunk
Cc: Christian Aistleitner, Bill Page

On Mon, 4 Jun 2007, Ralf Hemmecke wrote:

[...]

| For Aldor that is easy, one compiles an executable and runs that. With Axiom
| that is not possible, because libaxiom cannot (at least not easily) be
| compiled into a standalone executable.

We should work toward modularizing the Axiom system.  More specifically:

  (1) we should have standalone bootsys, that can translate, compile
      Boot codes.  It should be able to create standalone executable from
      Boot+Lisp programs.

  (2) we should have a standalone interpreter that can work with any set
      of algebras

  (3) we should have a standalone compiler that can work with any set of
      algebras

  (4) we should have a standalone et of standard algebras can be be used
      with any "standard conformant" Axiom interpreter or compiler.

No doubt, that is work.

Currently, I have (1) plus a standalone depsys that can create executable
from Lisp+Boot programs, but my hope is that depsys will die soon.

\start
Date: Mon, 4 Jun 2007 16:51:51 -0400
From: Bill Page
To: Tim Daly
Subject: RE: merge branches/daly to trunk

On June 4, 2007 2:21 PM Tim Daly wrote:
> 
> See 
> http://lists.gnu.org/archive/html/axiom-developer/2007-05/msg00320.html
>
> for details about the contents of silver.

Besides 'regress' and a little bit of documentation I don't see
anything listed here that is not already in build-improvements
and/or wh-sandbox. Am I missing something?

\start
Date: 04 Jun 2007 22:57:55 +0200
From: Martin Rubey
To: Ralf Hemmecke
Subject: AxiomUnit, was: Re: merge branches/daly to trunk
Cc: Christian Aistleitner, Bill Page, Gabriel Dos Reis

Ralf Hemmecke writes:

> Now Martin, suppose one test fails miserably, causing memory damage and all
> bad things. You would like to go on with testing in a clean environment. But
> that basically says, you have to start Axiom for every single test. That's
> going to be heavy.

I don't think that this would be such a big problem on modern machines.  Apart
from that, I think that such a test failure should happen rather seldom, and if
it does, it will be discovered no matter how axiomunit behaves.  I just want
something more organized than the current way of running tests using diff or
some variation thereof.

I think there are two possibilities: 

* run all testcases in the same axiom, and say )cl all after each testcase.  If
  a test fails miserably, it is a show-stopper anyway.  Furthermore, currently
  we don't have sane behaviour after such a failure either, so, who cares?

* Run every testcase in a fresh axiom.

\start
Date: Mon, 04 Jun 2007 23:02:58 +0200
From: Ralf Hemmecke
To: Gabriel Dos Reis
Subject: Re: merge branches/daly to trunk
Cc: Christian Aistleitner, Bill Page

On 06/04/2007 10:42 PM, Gabriel Dos Reis wrote:
> On Mon, 4 Jun 2007, Ralf Hemmecke wrote:
> 
> [...]
> 
> | For Aldor that is easy, one compiles an executable and runs that. With Axiom
> | that is not possible, because libaxiom cannot (at least not easily) be
> | compiled into a standalone executable.
> 
> We should work toward modularizing the Axiom system.  More specifically:
> 
>   (1) we should have standalone bootsys, that can translate, compile
>       Boot codes.  It should be able to create standalone executable from
>       Boot+Lisp programs.
> 
>   (2) we should have a standalone interpreter that can work with any set
>       of algebras
> 
>   (3) we should have a standalone compiler that can work with any set of
>       algebras
> 
>   (4) we should have a standalone et of standard algebras can be be used
>       with any "standard conformant" Axiom interpreter or compiler.
> 
> No doubt, that is work.

No doubt. But I love your plan. Since long I want to have the 
interpreter decoupled from the underlying libraries.

> Currently, I have (1) plus a standalone depsys that can create executable
> from Lisp+Boot programs, but my hope is that depsys will die soon.

Would that mean that Aldor->Lisp->executable should work?

\start
Date: Mon, 4 Jun 2007 23:28:50 +0200 (CEST)
From: Waldek Hebisch
To: Gabriel Dos Reis
Subject: Re: merge branches/daly to trunk

Gabriel Dos Reis wrote:
> On Mon, 4 Jun 2007, Martin Rubey wrote:
> 
> | Bill Page writes:
> | 
> | > As far as I know, the only thing in silver (aka. axiom.daly,
> | > aka. axiom.trunk) is a first attempt at some regression testing.  I believe
> | > that Gaby is trying to port this downstream [...]
> | 
> | I think it is a mistake to do that.  We should port Christian Aistleitner's
> | code to use libaxiom instead of libaldor.
> 
> Since I do not have resource to allocate for that task, should I go with
> no form of regression test at all?  
> 

I have posted some time ago scripts which help regression testing.
I must admit that I consider technique applied in current silver as
step backwards:  AFAICS results of running input files are still
compared using text comparison, but since expected result is
embedded in .input files we have extra maintenance burden when
output changes (I use separate tree for comparison).

Concerning regress script: using md5sums is quite crude, there is
a lot of differences which give functionally identical result.
One of the scripts I posted is a Lisp comparator -- I would be
happy if somebody provied a better one, but ATM it is _way_
better then byte comparison/md5sums.

\start
Date: Mon, 4 Jun 2007 17:28:58 -0400
From: Bill Page
To: Gabriel Dos Reis
Subject: RE: Interesting comment

On June 4, 2007 8:17 AM Gabriel Dos Reis wrote:
> 
> Tim Daly writes:
> 
> | They each had a "before-I-got-it" disdain, and an "after-I-got-it"
> | exclusive adoption (some might call it religious conversion). 
> 
> Hallowed are the Ori.
> 

http://en.wikipedia.org/wiki/Ori_(Stargate)

I love it. :-) Thanks.

I propose that thitle of boolvol5.pamphlet be changed to:

   The Book of Origin

\start
Date: Mon, 4 Jun 2007 16:32:31 -0500
From: Tim Daly
To: Ralf Hemmecke
Subject: regression testing

If you build axiom trunk and check the int/input/*.regress files 
you'll see that there is now an automated mechanism for regression
testing.

Each regression test input file is run in a fresh axiom image.

\start
Date: Mon, 4 Jun 2007 16:39:47 -0500
From: Tim Daly
To: Bill Page
Subject: merge branches/daly to trunk

Bill,

The major changes are
  * regression testing which involves 
      src/interp/regress.lisp.pamphlet
      a couple hundred *.input.pamphlet files 

  * regression testing to use md5sums to spot the global effects
    of each applied patch

  * documentation of quat.spad.pamphlet (basically what I did
    between November and January).

There are other changes which are not in the branches but these are
the major ones. More changes are in the pipe but are not fully
functional. At Gaby's request I went thru the differences and listed
the reasons in the link I posted earlier. To find the actual details
do a "diff -r --brief silver thebranch".

\start
Date: Mon, 4 Jun 2007 17:36:59 -0400
From: Bill Page
To: Gabriel Dos Reis
Subject: RE: Interesting comment

Correction:

> On June 4, 2007 8:17 AM Gabriel Dos Reis wrote:
> > 
> > Tim Daly writes:
> > 
> > | They each had a "before-I-got-it" disdain, and an "after-I-got-it"
> > | exclusive adoption (some might call it religious conversion). 
> > 
> > Hallowed are the Ori.
> > 
> 
> http://en.wikipedia.org/wiki/Ori_(Stargate)
> 
> I love it. :-) Thanks.
> 
> I propose that thitle of boolvol5.pamphlet be changed to:

I propose that the title of bookvol5.pamphlet be changed to:

> 
>    The Book of Origin

\start
Date: Mon, 4 Jun 2007 16:44:03 -0500 (CDT)
From: Gabriel Dos Reis
To: Bill Page
Subject: RE: Interesting comment


| I propose that thitle of boolvol5.pamphlet be changed to:
| 
|    The Book of Origin

:-) :-) :-)

\start
Date: 04 Jun 2007 23:24:33 +0200
From: Martin Rubey
To: Waldek Hebisch
Subject: Re: Patches

Dear Tim, Waldek,

Waldek Hebisch writes:

> I supect that original author did not know how to leave one partial
> derivative unevaluated, while giving value of the second one (ATM this
> is not clear for me either).  If you know how to to this please go
> on.

below is a patch that has the behaviour as you described it, with the exception
of polygamma, which now throws an error.  If you prefer that polygamma also
allows differentiation with respect to the first argument, the change is
trivial.  I don't have time to modify sttaylor right now.

Martin


--=-=-=

Index: combfunc.spad.pamphlet
===================================================================
--- combfunc.spad.pamphlet	(revision 580)
+++ combfunc.spad.pamphlet	(working copy)
@@ -41,11 +41,6 @@
       ++ formal product;
 
 @
-The latest change allows Axiom to reduce
-\begin{verbatim}
-   sum(1/i,i=1..n)-sum(1/i,i=1..n) 
-\end{verbatim}
-to reduce to zero.
 <<package COMBF CombinatorialFunction>>=
 )abbrev package COMBF CombinatorialFunction
 ++ Provides the usual combinatorial functions
@@ -690,6 +685,7 @@
   OP  ==> BasicOperator
   K   ==> Kernel F
   SE  ==> Symbol
+  SPECIALDIFF  ==> "%specialDiff"
 
   Exports ==> with
     belong? : OP -> Boolean
@@ -818,14 +814,58 @@
     -- Default behaviour is to build a kernel
     evaluate(opGamma, iiGamma)$BasicOperatorFunctions1(F)
     evaluate(opabs, iiabs)$BasicOperatorFunctions1(F)
+@
 
+\subsection{differentiation of special functions}
+
+In the following we define the symbolic derivatives of the special functions we
+provide.  The formulas we use for the Bessel functions can be found in Milton
+Abramowitz and Irene A. Stegun, eds.  (1965). Handbook of Mathematical
+Functions with Formulas, Graphs, and Mathematical Tables. New York: Dover. ISBN
+0-486-61272-4, Equations~9.1.27 and 9.6.26.  Up to [[patch--50]] the formula
+for $K$ missed the minus sign.  (Issue~\#355)
+
+We do not attempt to provide formulas for the derivative with respect to the
+first argument currently.  Instead, we leave such derivatives unevaluated.
+
+<<package FSPECF FunctionalSpecialFunction>>=
     import Fraction Integer
     ahalf:  F    := recip(2::F)::F
     athird: F    := recip(2::F)::F
     twothirds: F := 2*recip(3::F)::F
+@
 
-    lzero(l: List F): F == 0
+We need to get hold of the differentiation operator as modified by
+[[FunctionSpace]]. Otherwise, for example, display will be ugly.  We accomplish
+that by differentiating an operator, which will certainly result in a single
+kernel only.
 
+<<package FSPECF FunctionalSpecialFunction>>=
+    dummyArg: SE := new()$SE
+    opdiff := operator first kernels D((operator(new()$SE)$BasicOperator)
+                                            (dummyArg::F), dummyArg)
+@
+
+The differentiation operator [[opdiff]] takes three arguments corresponding to
+$$
+F_{,i}(a_1,a_2,\dots,a_n):
+$$
+\begin{enumerate}
+\item $F(a_1,...,dm,...a_n)$, where the $i$\textsuperscript{th} argument is a
+  dummy variable,
+\item $dm$, the dummy variable, and
+\item $a_i$, the point at which the differential is evaluated.
+\end{enumerate}
+
+The operation [[symbolicGrad]] returns the first component of the gradient of
+[[op l]].
+
+<<package FSPECF FunctionalSpecialFunction>>=
+    dummy == new()$SE :: F
+    symbolicGrad(op: BasicOperator, l: List F): F == 
+        dm: F := dummy
+        kernel(opdiff, [op [dm, second l], dm, first l])
+
     iBesselJGrad(l: List F): F ==
         n := first l; x := second l
         ahalf * (besselJ (n-1,x) - besselJ (n+1,x))
@@ -837,10 +877,19 @@
         ahalf * (besselI (n-1,x) + besselI (n+1,x))
     iBesselKGrad(l: List F): F ==
         n := first l; x := second l
-        ahalf * (besselK (n-1,x) + besselK (n+1,x))
-    ipolygammaGrad(l: List F): F ==
-        n := first l; x := second l
-        polygamma(n+1, x)
+        - ahalf * (besselK (n-1,x) + besselK (n+1,x))
+
+@
+
+For the moment we throw an error if we try to differentiate [[polygamma]] with
+respect to the first argument.
+
+<<package FSPECF FunctionalSpecialFunction>>=
+    ipolygammaGrad(l: List F, x: SE): F ==
+        member?(x, variables first l) =>
+            error "cannot differentiate polygamma with respect to the first argument"
+        n := first l; y := second l
+        differentiate(y, x)*polygamma(n+1, y)
     iBetaGrad1(l: List F): F ==
         x := first l; y := second l
         Beta(x,y)*(digamma x - digamma(x+y))
@@ -852,18 +901,17 @@
       iGamma2Grad(l: List F):F ==
         a := first l; x := second l
         - x ** (a - 1) * exp(-x)
-      derivative(opGamma2, [lzero, iGamma2Grad])
+      derivative(opGamma2, [symbolicGrad(opGamma2, #1), iGamma2Grad])
 
     derivative(opabs,       abs(#1) * inv(#1))
     derivative(opGamma,     digamma #1 * Gamma #1)
     derivative(opBeta,      [iBetaGrad1, iBetaGrad2])
     derivative(opdigamma,   polygamma(1, #1))
-    derivative(oppolygamma, [lzero, ipolygammaGrad])
-    derivative(opBesselJ,   [lzero, iBesselJGrad])
-    derivative(opBesselY,   [lzero, iBesselYGrad])
-    derivative(opBesselI,   [lzero, iBesselIGrad])
-    derivative(opBesselK,   [lzero, iBesselKGrad])
-
+    setProperty(oppolygamma, SPECIALDIFF, ipolygammaGrad@((List F, SE)->F) pretend None)
+    derivative(opBesselJ,   [symbolicGrad(opBesselJ, #1), iBesselJGrad])
+    derivative(opBesselY,   [symbolicGrad(opBesselY, #1), iBesselYGrad])
+    derivative(opBesselI,   [symbolicGrad(opBesselI, #1), iBesselIGrad])
+    derivative(opBesselK,   [symbolicGrad(opBesselK, #1), iBesselKGrad])
 @
 \section{package SUMFS FunctionSpaceSum}
 <<package SUMFS FunctionSpaceSum>>=

\start
Date: Mon, 4 Jun 2007 16:55:50 -0500
From: Tim Daly
To: Bill Page, Gabriel Dos Reis
Subject: Interesting comment

funny. i like it. we have no maintainers, we have Priors!

all hail Stallman! all hail Torvalds! all hail Knuth! all hail McCarthy!

i guess SVN-worship falls into the category of "fables meant to fill
the soul bereft of hope with purpose" :-)

can't wait for the "Ring Transporter" though as it would greatly 
facilitate my 33 mile commute. of course, my "intertubes" are full
with spam so it is better to drive.

\start
Date: Mon, 4 Jun 2007 17:57:49 -0400
From: Bill Page
To: Ralf Hemmecke
Subject: re: Defining piece-wise functions and drawing,	integrating, ...

On June 4, 2007 4:36 AM Ralf Hemmecke wrote:
> ...
> Oh, I never said, that the current Expression(...) should be 
> removed. If I see what people do here at RISC with symbolic
> summation, that domain fits very well in that area. Still,
> Axiom lacks a true ExpressionTree domain. Or have I just not
> found it?

I think that together InputForm and SExpression play that role
except that the coercion to OutputForm is a little to Lisp-ish.
I think the result of 'expr$SExpression' should be the OutputForm.

> ...
> >> Well, what I would dream of is an expression domain (or 
> >> several of them) that lets you define a general expression
> >> tree where you would have control over what is allowed as
> >> nodes. Maybe it would be interesting to be able to give a
> >> grammar G and MyExpression(G) would then describe the 
> >> language generated by G. It would be nice to be able to 
> >> encode the Aldor language in that way.
> 
> > For Axiom this does not seem sufficiently "algebraic" to me.
> 
> Then remove the "Set" domain. Why must everything be "algebraic".

I would agree to replace "Set" with something more algebraic,
e.g. a topos.

http://en.wikipedia.org/wiki/Topos

The short answer to why everything must be algebraic is:
category theory. You can ask why try to base the Axiom library
on category theory, but that is an argument at a very different
level.

In fact I think it is quite wrong that Axiom's library places
SetCategory so near to the top of the algebra hierarchy. It
would be better to start with something more primitive like the
concept of a cartesian close category.
 
> Actually, you could probably turn an ExpressionTree into some
> form of universal algebra (just leave the set of operations
> empty).

That would not make me nearly as happy as category theory. :-(

> 
> Oh, maybe SExpression is near to what I want. But is somehow 
> sounds to LISPish for me. ;-) Anyway, I think it would be a good
> thing to have a very general expression domain (maybe like
> SExpression) and yet others that only allow certain expression
> trees that correspond to a grammar.

Yes. I think Gaby had some ideas along that line. We discussed
some aspects of that here:

http://wiki.axiom-developer.org/SandBoxInductiveType

and on this list.

> ... 
> > I think of this as a more sophisticated replacement for
> > SExpression.
> 
> Maybe. But it is written in Aldor and does not rely on an 
> underlying LISP.
> 

Lisp does not "own" the concept of SExpression

http://en.wikipedia.org/wiki/S-expression

see also

http://en.wikipedia.org/wiki/M-expression

But I do not have any objection to importing the concept
of ExpressionTree into Axiom.

\start
Date: Tue, 05 Jun 2007 00:35:55 +0200
From: Ralf Hemmecke
To: Bill Page
Subject: re: Defining piece-wise functions and drawing,	integrating, ...

> I would agree to replace "Set" with something more algebraic,
> e.g. a topos.
> 
> http://en.wikipedia.org/wiki/Topos

Cool. ;-) How many people know topoi in contrast to the number of people 
who grew up with sets?

> The short answer to why everything must be algebraic is:
> category theory. You can ask why try to base the Axiom library
> on category theory, but that is an argument at a very different
> level.

Oh, I have no problem with basing a library on category theory. But 
maybe at some point we should drop the "the" in "the Axiom library".

In fact, I would love to see a system that allows different views.
As mathematics can be based on set theory or category theory. Currently 
I think that would make two libraries. The interesting part comes when 
they should be allowed to be used at the same time.

> In fact I think it is quite wrong that Axiom's library places
> SetCategory so near to the top of the algebra hierarchy. It
> would be better to start with something more primitive like the
> concept of a cartesian close category.

I already hear people saying ... but hey, "sets" are much simpler than 
ccc's.

There are just different views and Axiom should support both of them and 
even more.

>> Actually, you could probably turn an ExpressionTree into some
>> form of universal algebra (just leave the set of operations
>> empty).
> 
> That would not make me nearly as happy as category theory. :-(

OK, you are responsible to start a library that builds on category theory.

>> Oh, maybe SExpression is near to what I want. But is somehow 
>> sounds to LISPish for me. ;-) Anyway, I think it would be a good
>> thing to have a very general expression domain (maybe like
>> SExpression) and yet others that only allow certain expression
>> trees that correspond to a grammar.

> Yes. I think Gaby had some ideas along that line. We discussed
> some aspects of that here:

> http://wiki.axiom-developer.org/SandBoxInductiveType
> 
> and on this list.

I don't think that this would allow me to transform the program (= 
inductive type) at runtime as I could do with expression trees.

\start
Date: Tue, 05 Jun 2007 01:39:39 +0200
From: Ralf Hemmecke
To: Gabriel Dos Reis
Subject: Re: Old trunk changes

On 06/04/2007 02:54 PM, Gabriel Dos Reis wrote:
> Ralf --
> 
>   Looking at the ChangeLog in trunk, I see changes dated:
> 
> 
>    2006-09-14  Ralf Hemmecke  Ralf Hemmecke
>    2006-09-13  Ralf Hemmecke  Ralf Hemmecke
>    2006-07-31  Ralf Hemmecke  Ralf Hemmecke
> 
> Do you know whether they have made it to Tim's branch?

----------------------------------------------------------------------
r70 (orig r71):  dos-reis | 2006-08-01 03:39:13 +0200
Changed paths:
   M  /axiom/trunk/axiom/src/algebra/ChangeLog
   M  /axiom/trunk/axiom/src/algebra/transsolve.spad.pamphlet

2006-07-31  Ralf Hemmecke  Ralf Hemmecke

         * transsolve.spad.pamphlet: Escape "#".

woodpecker:~/SVK/axiom>cmp
branches/daly/axiom/src/algebra/transsolve.spad.pamphlet
trunk/axiom/src/algebra/transsolve.spad.pamphlet

No differences.
===========================================================


woodpecker:~/SVK/axiom/branches>svk mirror -l |grep axiom
/mirror/axiom           https://axiom.svn.sourceforge.net/svnroot/axiom

woodpecker:~/SVK/axiom/branches>svk log -r136 /mirror/axiom/
----------------------------------------------------------------------
r136 (orig r137):  hemmecke | 2006-09-14 12:28:32 +0200

Corrected corrupted binary files by taking the corresponding files from 
from axiom--main--1--patch-50.
----------------------------------------------------------------------

I hope this is what you meant.

svk log -v -r136 /mirror/axiom/ | grep /axiom/trunk/ | sed 
's/.*\/axiom\/trunk\/axiom\//sh rhxcmp /' > aaa
echo "cmp daly/axiom/\$1 build-improvements/\$1" > rhxcmp
sh aaa
cmp: daly/axiom/ChangeLog: No such file or directory
cmp: build-improvements/zips/tla-1.1.tar.gz: No such file or directory
===========================================================


I also compared with the version of trunk before you merged 
branches/daly to trunk.

woodpecker:~/SVK/axiom/trunk>svk log -r HEAD
----------------------------------------------------------------------
r197 (orig r198):  whebisch | 2006-10-25 22:15:28 +0200

Makefile fix

----------------------------------------------------------------------
Then commands similar to the things above yielded.
woodpecker:~/SVK/axiom>sh aaa
cmp: branches/daly/axiom/ChangeLog: No such file or directory
branches/daly/axiom/src/share/algebra/libaxiom.al 
trunk/axiom/src/share/algebra/libaxiom.al differ: byte 91, line 3
cmp: trunk/axiom/zips/tla-1.1.tar.gz: No such file or directory

I wouldn't care much about libaxiom.al. In fact, I believe, that it can 
currently be removed. It will be created by Peter Broadbery's script to 
make Aldor available for Axiom 
(http://wiki.axiom-developer.org/AldorForAxiom).
===========================================================

What you mean by

 >    2006-09-13  Ralf Hemmecke  Ralf Hemmecke

is not exactly clear to me (a revision number would have been clearer).

I guess you meant
woodpecker:~/SVK/axiom/trunk>svk log -r 135
----------------------------------------------------------------------
r135 (orig r136):  hemmecke | 2006-09-14 09:54:27 +0200

Removed svn:keywords from all files and svn:eol-style from selected files.
----------------------------------------------------------------------

cd SVK/axiom
echo "svk proplist /mirror/axiom/branches/daly/\$1"> rhxpl

svk log -v -r135 /mirror/axiom/ | grep /axiom/trunk/ | sed 
's/.*\/axiom\/trunk\//sh rhxpl /' > aaa

woodpecker:~/SVK/axiom>sh aaa > bbb
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/ChangeLog'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/lsp/ChangeLog'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/algebra/ChangeLog'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/algebra/Lattice.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/boot/ChangeLog'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/doc/ChangeLog'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/doc/diagrams.tex'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/graph/include/all_2d.H1'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/graph/include/all_3d.H1'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/graph/include/all_alone.H1'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/ChangeLog'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/bitmaps/Delta.bitmap'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/bitmaps/Gamma.bitmap'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/bitmaps/Im.bitmap'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/bitmaps/Lambda.bitmap'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/bitmaps/Omega.bitmap'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/bitmaps/Phi.bitmap'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/bitmaps/Pi.bitmap'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/bitmaps/Psi.bitmap'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/bitmaps/Re.bitmap'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/bitmaps/Sigma.bitmap'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/bitmaps/Theta.bitmap'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/bitmaps/Upsilon.bitmap'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/bitmaps/Xi.bitmap'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/bitmaps/ht_icon'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/form_ext.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/parse_aux.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/parse_input.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/parse_paste.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/parse_types.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/hyper/show_types.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/include/all_hyper_proto.H1'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/include/fnct_key.H1'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/include/form_ext.H1'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/include/parse_aux.H1'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/include/parse_input.H1'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/include/parse_paste.H1'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/include/parse_types.H1'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/include/show_types.H1'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/include/useproto.h'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/input/ChangeLog'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/interp/anna.boot.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/interp/construc.lisp.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/interp/domain.lisp.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/interp/guess.boot.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/interp/interp-fix.boot.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/interp/nhyper.boot.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/interp/pf2atree.boot.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/interp/redefs.boot.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/interp/word.boot.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/interp/xrun.boot.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/interp/xruncomp.boot.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/lib/ChangeLog'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/src/lib/fnct_key.c.pamphlet'
Filesystem has no item: File not found: revision 583, path 
'/axiom/branches/daly/axiom/zips/ChangeLog'

woodpecker:~/SVK/axiom>sort bbb|uniq |head
   svn:eol-style
   svn:executable
   svn:keywords
   svn:mime-type
Properties on /mirror/axiom/branches/daly/axiom/CHANGELOG:
Properties on /mirror/axiom/branches/daly/axiom/FAQ:
Properties on /mirror/axiom/branches/daly/axiom/Makefile.pamphlet:
Properties on /mirror/axiom/branches/daly/axiom/Makefile:
Properties on /mirror/axiom/branches/daly/axiom/README:
Properties on /mirror/axiom/branches/daly/axiom/configure:

So it seems the keywords are all gone which means that the revision is 
also in branches/daly.

woodpecker:~/SVK/axiom/branches/daly>svk log -rHEAD
----------------------------------------------------------------------
r582 (orig r582):  daly | 2007-06-03 06:36:10 +0200

merge input test case branch changes
=======================================================

Hope, that helped.

\start
Date: Mon, 4 Jun 2007 18:43:50 -0500 (CDT)
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Re: Old trunk changes

On Tue, 5 Jun 2007, Ralf Hemmecke wrote:

| Hope, that helped.

Many thanks.

Sorry for the earlier imprecise messag.

\start
Date: Tue, 5 Jun 2007 00:33:35 -0400
From: Bill Page
To: Ralf Hemmecke
Subject: The Axiom Library and Category Theory 

Topic drift is a wonderful thing ... :-)

On June 4, 2007 6:36 PM Ralf Hemmecke wrote:
> Bill Page wrote: 
> > I would agree to replace "Set" with something more algebraic,
> > e.g. a topos.
> > 
> > http://en.wikipedia.org/wiki/Topos
> 
> Cool. ;-) How many people know topoi in contrast to the number
> of people who grew up with sets?

Well, I do hope that the number of people in mathematics and
computer science who have grown up with category theory is
increasing at the same or greater rate than the number of people
retiring from these professions who still think that set theory
is the proper foundation of all mathematics ... ;)

The point of category theory as a foundation for mathematics
is that a lot of mathematics can and should be done long before
it becomes necessary to define what is meant by "set".

> 
> > The short answer to why everything must be algebraic is:
> > category theory. You can ask why try to base the Axiom
> > library on category theory, but that is an argument at a
> > very different level.
> 
> Oh, I have no problem with basing a library on category
> theory. But maybe at some point we should drop the "the"
> in "the Axiom library".

I am not convinced. Do you think it makes sense to drop "the"
in reference to "the Internet"? In the same way I would hope
that the mathematics implemented in Axiom is somehow
"universal" and not merely just one of several ways of doing
things. Removing "the" from the "the Axiom library" seems to
reduce Axiom to just another (albeit rather sophisticated)
programming language.

So I think that we should at least try to define "the Axiom
library" even though this may prove impossible except perhaps
in the very long term.

> 
> In fact, I would love to see a system that allows different
> views. As mathematics can be based on set theory or category
> theory. 

Maybe it is just where I live but I think most mathematicians
since about 1975 or so have agreed that one should not try to
base mathematics on set theory.

> 
> > In fact I think it is quite wrong that Axiom's library
> > places SetCategory so near to the top of the algebra
> > hierarchy. It would be better to start with something more
> > primitive like the concept of a Cartesian close category.
> 
> I already hear people saying ... but hey, "sets" are much 
> simpler than ccc's.

I think perhaps these people simply do not know what a "set"
is.

> 
> There are just different views and Axiom should support both
> of them and even more.

Right now I do not agree. I do not want Axiom to be so "relative".
Such a point of view might be alright for a programming language
like Aldor that is trying to be many things for many different
people. But (in my view) mathematics is not like that and neither
should Axiom be.

> 
> >> Actually, you could probably turn an ExpressionTree
> >> into some form of universal algebra (just leave the set
> >> of operations empty).
> > 
> > That would not make me nearly as happy as category theory.
> > :-(
> 
> OK, you are responsible to start a library that builds on 
> category theory.
> 

Well I have been thinking about and writing about on this email
list for a few years now... I would very much like to "get my
head above water" long enough to concentrate on issues like
these. Unfortunately we are still trying to decide things like
what source code management system we should be using... :-(

> >> Oh, maybe SExpression is near to what I want. But is
> >> somehow sounds to LISPish for me. ;-) Anyway, I think it
> >> would be a good thing to have a very general expression
> >> domain (maybe like SExpression) and yet others that only
> >> allow certain expression trees that correspond to a
> >> grammar.
> 
> > Yes. I think Gaby had some ideas along that line. We
> > discussed some aspects of that here:
> 
> > http://wiki.axiom-developer.org/SandBoxInductiveType
> > 
> > and on this list.
> 
> I don't think that this would allow me to transform the
> program (= inductive type) at runtime as I could do with
> expression trees.
> 

Well I am not so sure exactly what we need to be able to do
at "run time". Certainly one of the points of Aldor is to
define a *static* type system that is strong enough to express
abstract mathematics but which can still be resolved entirely
by the compiler. Among other things this means that we have
higher-order functions and dependent types.

I do think that part of the point of the Axiom "all things
algebraic" philosophy is that things such as transforming
expression trees should not be viewed as fundamental to do
doing mathematics by computer. In other words there is a
distinction between symbolic computation and computer algebra
that I have mentioned several times before and that I think
Stephen Watt has described so well.

\start
Date: 05 Jun 2007 01:24:36 -0400
From: Stephen Wilson
To: list
Subject: Boot/SPAD package syntax

Greetings,

I stumbled upon a curious facility of Boot and SPAD this evening.  I
do not recall, nor can I find, a reference to this in the list
archives or in any documentation.  Please correct me if I am wrong.

The facility is w.r.t identifiers.  An identifier such as FOO'BAR is
interpreted as meaning the symbol BAR in the package FOO.  Other
identifiers, such as 'FOO or FOO' do not communicate such a meaning.

The code which is responsible is the function
GET-BOOT-IDENTIFIER-TOKEN defined in bootlex.lisp.pamphlet.

Preliminary examination tells me that such identifiers are _not_
currently used in the extant Boot or Spad code.  I will perform
convincing tests once a local build cycle completes.

My opinion is that this is unused cruft which has no discernible
application.  In fact, it theoretically results in the generation of
non-portable code.  For example, several popular Lisp implementations
have introduced the notion of `package locks' to prevent against
unintended alteration of package symbols.  The identifier CL'FOO
results in FOO being interned in the COMMON-LISP package, which would
violate such a lock.  There are other examples.


I am curious if anyone has noticed this facility and/or sees a potential
use for it.

\start
Date: 05 Jun 2007 00:32:41 -0500
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Boot/SPAD package syntax

Stephen Wilson writes:

| Greetings,
| 
| I stumbled upon a curious facility of Boot and SPAD this evening.  I
| do not recall, nor can I find, a reference to this in the list
| archives or in any documentation.  Please correct me if I am wrong.

Since we have at least two versions of Boot around, you need to qualify
your Boot by either "old" or "new" or variations thereof.

| The facility is w.r.t identifiers.  An identifier such as FOO'BAR is
| interpreted as meaning the symbol BAR in the package FOO.  Other
| identifiers, such as 'FOO or FOO' do not communicate such a meaning.

That is old old syntax. Newer syntax in old Boot is FOO::BAR -- but it 
may require parenthesis in most cases because of the precedence of
:: qhich does not make FOO::BAR a primary.

New Boot (in src/boot) has gotten same syntax (::) recently (added by me).

[...]

| My opinion is that this is unused cruft which has no discernible
| application.  In fact, it theoretically results in the generation of
| non-portable code.  For example, several popular Lisp implementations
| have introduced the notion of `package locks' to prevent against
| unintended alteration of package symbols.  The identifier CL'FOO
| results in FOO being interned in the COMMON-LISP package, which would
| violate such a lock.  There are other examples.

Those are *bugs in Axiom* source code -- there are plenty of those
around. Even if you remove the syntax CL'FOO, you'll find that
existing Axiom codes uses other things like restart, etc.

| I am curious if anyone has noticed this facility and/or sees a potential
| use for it.

I use the syntax FOO::BAR, but not FOO'BAR, for "package-call".
New Boot treats FOO'BAR as a "single" identifier.

\start
Date: Tue, 05 Jun 2007 08:02:31 +0200
From: Ralf Hemmecke
To: Bill Page
Subject: Re: The Axiom Library and Category Theory

> The point of category theory as a foundation for mathematics
> is that a lot of mathematics can and should be done long before
> it becomes necessary to define what is meant by "set".

You may be right. But what foundation you use for mathematics is in the 
end a very vague thing. Let's say we base mathematics on category 
theory. Then you have to explain and define a category without using 
mathematics. You have to have a lot of people agreeing on these "common 
sense". Once that is done. The rest is "easy".

I guess, you more easily get people to agree what a set is. It's not 
necessary at first to start with classes.

Anyway, what I want to say is, that mathematics can be based on category 
theory and on set theory. There is no "must" for either of them. You can 
also use higher order logic to start mathematics.

You like different views in LEO. Why do you think different views on the 
foundations of mathematics are bad. (OK, actually, you never said that, 
you just have preferences for category theory.)

>>> The short answer to why everything must be algebraic is:
>>> category theory. You can ask why try to base the Axiom
>>> library on category theory, but that is an argument at a
>>> very different level.
>> Oh, I have no problem with basing a library on category
>> theory. But maybe at some point we should drop the "the"
>> in "the Axiom library".
> 
> I am not convinced. Do you think it makes sense to drop "the"
> in reference to "the Internet"? In the same way I would hope
> that the mathematics implemented in Axiom is somehow
> "universal" and not merely just one of several ways of doing
> things. Removing "the" from the "the Axiom library" seems to
> reduce Axiom to just another (albeit rather sophisticated)
> programming language.

OK, if Axiom becomes as universal as "the" mathematics, we can leave 
"the Axiom library". ;-)

> So I think that we should at least try to define "the Axiom
> library" even though this may prove impossible except perhaps
> in the very long term.

Yes, but it should not force people to just have only *one* view on 
mathematics.

>> In fact, I would love to see a system that allows different
>> views. As mathematics can be based on set theory or category
>> theory. 
> 
> Maybe it is just where I live but I think most mathematicians
> since about 1975 or so have agreed that one should not try to
> base mathematics on set theory.

Do they also say "it cannot be based on set theory"?

>>> In fact I think it is quite wrong that Axiom's library
>>> places SetCategory so near to the top of the algebra
>>> hierarchy. It would be better to start with something more
>>> primitive like the concept of a Cartesian close category.
>> I already hear people saying ... but hey, "sets" are much 
>> simpler than ccc's.

> I think perhaps these people simply do not know what a "set"
> is.

As I said above. The other people actually do handwaiving when trying to 
explain what one should understand by a "category".

>> There are just different views and Axiom should support both
>> of them and even more.

> Right now I do not agree. I do not want Axiom to be so "relative".

Right now I don't see how one could implement different views 
consistently. And it certainly costs a lot of effort. But let me have my 
dreams.

> Such a point of view might be alright for a programming language
> like Aldor that is trying to be many things for many different
> people. But (in my view) mathematics is not like that and neither
> should Axiom be.

Maybe I should read "A new kind of science" to understand what Stephen 
Wolfram thinks about what mathematics is.

[snip]

>>>> Oh, maybe SExpression is near to what I want. But is
>>>> somehow sounds to LISPish for me. ;-) Anyway, I think it
>>>> would be a good thing to have a very general expression
>>>> domain (maybe like SExpression) and yet others that only
>>>> allow certain expression trees that correspond to a
>>>> grammar.
>>> Yes. I think Gaby had some ideas along that line. We
>>> discussed some aspects of that here:
>>> http://wiki.axiom-developer.org/SandBoxInductiveType
>>>
>>> and on this list.
>> I don't think that this would allow me to transform the
>> program (= inductive type) at runtime as I could do with
>> expression trees.

> Well I am not so sure exactly what we need to be able to do
> at "run time". Certainly one of the points of Aldor is to
> define a *static* type system that is strong enough to express
> abstract mathematics but which can still be resolved entirely
> by the compiler. Among other things this means that we have
> higher-order functions and dependent types.

In Aldor-Combinat we just are at a point where Aldor seems to be too 
weak to express the idea of multi-sorted species in a natural and 
somehow typesafe manner. Remember my wish.

http://lists.nongnu.org/archive/html/axiom-developer/2007-03/msg00151.html

> I do think that part of the point of the Axiom "all things
> algebraic" philosophy is that things such as transforming
> expression trees should not be viewed as fundamental to do
> doing mathematics by computer.

Oh, I mentioned Expression(Grammar) in my last mail. If I allow only 
transformations of expression trees that respect the Grammar, isn't that 
in some way "algebraic".

> In other words there is a
> distinction between symbolic computation and computer algebra
> that I have mentioned several times before and that I think
> Stephen Watt has described so well.

Yes, it agree with the essence of that distinction and that also means 
(at least for me) that Axiom be strong in computer algebra, but allow 
experiments using symbolic computation (which will be hopefully turned 
into proper computer algebra programs later).

\start
Date: 05 Jun 2007 02:58:09 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Boot/SPAD package syntax

Gabriel Dos Reis writes:

> Stephen Wilson writes:
> 
> | Greetings,
> | 
> | I stumbled upon a curious facility of Boot and SPAD this evening.  I
> | do not recall, nor can I find, a reference to this in the list
> | archives or in any documentation.  Please correct me if I am wrong.
> 
> Since we have at least two versions of Boot around, you need to qualify
> your Boot by either "old" or "new" or variations thereof.

When I say Boot, I mean the Boot which is used in Axiom.  In
particular, the Boot which translates the current Boot code.  Other
variations are effectively mythical to me.  I guess this is what you
qualify as "old"?

> 
> | The facility is w.r.t identifiers.  An identifier such as FOO'BAR is
> | interpreted as meaning the symbol BAR in the package FOO.  Other
> | identifiers, such as 'FOO or FOO' do not communicate such a meaning.
> 
> That is old old syntax. Newer syntax in old Boot is FOO::BAR -- but it 
> may require parenthesis in most cases because of the precedence of
> :: qhich does not make FOO::BAR a primary.

Superficial examination does not suggest that this syntax is used
anywhere in current boot or spad code.

Regardless of syntax, I am more interested in the semantics of the
construct.

> New Boot (in src/boot) has gotten same syntax (::) recently (added by me).

Ok.  This is in gdr-sandbox, no?

> | My opinion is that this is unused cruft which has no discernible
> | application.  In fact, it theoretically results in the generation of
> | non-portable code.  For example, several popular Lisp implementations
> | have introduced the notion of `package locks' to prevent against
> | unintended alteration of package symbols.  The identifier CL'FOO
> | results in FOO being interned in the COMMON-LISP package, which would
> | violate such a lock.  There are other examples.
> 
> Those are *bugs in Axiom* source code -- there are plenty of those
> around. 

Not quite following.  There is nothing to suggest to me that SPAD as a
language defines identifiers such as CL'FOO as being invalid in the
same way as, say, C++ defines identifiers which start with an
underscore to be reserved names for use by the implementation.

Given the lack of specification, and given the lack of use of such a
feature, these are not bugs in Axiom by any stretch.

> Even if you remove the syntax CL'FOO, you'll find that existing
> Axiom codes uses other things like restart, etc.

I know axiom calls Lisp from SPAD and Boot directly.  As far as Boot
goes, I dont have much interest in its semantics.  In SPAD however, I
am generally concerned with the ease with which one can bypass the
typesystem and call arbitrary Lisp code.


> | I am curious if anyone has noticed this facility and/or sees a potential
> | use for it.
> 
> I use the syntax FOO::BAR, but not FOO'BAR, for "package-call".
> New Boot treats FOO'BAR as a "single" identifier.

Ok, a "package-call" is a Lisp concept.  As far as I know neither Boot
nor SPAD admit the concept of a package.

Are there other operations in Boot which deal with packages? How can
one define a package in Boot? (by "in Boot" I mean "in Boot", not by
punting to Lisp with a MAKE_-PACKAGE('FOO)). 

I am interested in how this feature integrates with Boot, but also
lets not forget SPAD.

\start
Date: Tue, 05 Jun 2007 09:46:39 +0200
From: Ralf Hemmecke
To: Stephen Wilson
Subject: Re: Boot/SPAD package syntax
Cc: Gabriel Dos Reis

>> I use the syntax FOO::BAR, but not FOO'BAR, for "package-call".
>> New Boot treats FOO'BAR as a "single" identifier.

> Ok, a "package-call" is a Lisp concept.  As far as I know neither Boot
> nor SPAD admit the concept of a package.

I don't know much about Lisp and Boot, but Aldor defines what a package 
is (maybe it is different from what you mean here) and I always thought, 
that this is a concept that also exists in SPAD.

See src/algebra/mappkg.spad.pamphlet:

MappingPackageInternalHacks1(A: SetCategory): MPcat == MPdef where
     NNI ==> NonNegativeInteger

     MPcat == with
         iter:  ((A -> A), NNI, A) -> A
           ++\spad{iter(f,n,x)} applies \spad{f n} times to \spad{x}.
         recur: ((NNI, A)->A, NNI, A) -> A
           ++\spad{recur(n,g,x)} is \spad{g(n,g(n-1,..g(1,x)..))}.

     MPdef == add
         iter(g,n,x)  ==
             for i in 1..n repeat x := g x     -- g(g(..(x)..))
             x
         recur(g,n,x) ==
             for i in 1..n repeat x := g(i,x)  -- g(n,g(n-1,..g(1,x)..))
             x

I would call that a package.

I am not really sure about SPAD, but in Aldor I would call that as

   A ==> Integer;
   g(i: Integer): Integer == i;
   n: NNI := 10;
   a: A := 3;
   iter(g, n, a)$MappingPackageInternalHacks1(A);

or

   (iter$MappingPackageInternalHacks1(A))(g,n,a)

You probably mean something else...

\start
Date: 05 Jun 2007 11:15:07 +0200
From: Martin Rubey
To: Jay Belanger, Cliff Yapp, Francois Maltey
Subject: axiom.el problems

--=-=-=

Dear Jay, Cliff, Francois and all emacs experts!

I have the following two annoying problems with my emacs mode (private version
attached).

* after loading axiom.el, I cannot use shell mode anymore.  This is most
  annoying

* if one produces a lot of output, and presses M-p while the output is being
  written to the buffer, everything gets messed up.  In particular, point moves
  to the previous prompt and further output is written *before* that prompt
  instead of afterwards.  I don't understand this behaviour, since I defined

(defun axiom-scroll-previous-input (&optional arg)
  "Fetch the previous input."
  (interactive "p")
  (unless (axiom-output? (point))
    (axiom-previous-prompt)
    (comint-set-process-mark)
    (comint-previous-input arg)
    ;; delete the rest
    (delete-region (point) (axiom-end-of-input))))

  So, before doing anything, I check whether I am in the output region, in
  which case I do nothing.  Can anyone explain that behaviour?


Many thanks,

Martin



--=-=-=
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--=-=-=--

\start
Date: Tue, 5 Jun 2007 19:37:53 +1000
From: Alasdair McAndrew
To: list
Subject: Is anybody actually doing mathematics with Axiom?

Admittedly I'm very new to the Axiom game, but in the few months I've been
involved, the Axiom mail-lists have been almost exclusively concerned with
meta-mathematics: emacs and TeXmacs, version control systems, and just
recently sets versus topoi versus categories.

Not that these things aren't of fundamental importance, but does anybody
actually use Axiom for mathematics: teaching, research, or even fun?  Is
anybody out there adding further mathematical functionality to Axiom -
numerical routines, difference equation solvers, discrete mathematics etc
etc?

FWIW, as Martin well knows, I've been banging my head over pattern matching
and z-transforms lately. I have a file which works to about 75%; the last
bit, which involves partial fractions, is still giving me gyp.

And on the meta-mathematical side, has anybody got an emacs mode to work
with *.input files?

And on the subject of numerical routines, is anybody interested in using any
of the netlib stuff (lapack, for exmaple), in Axiom?  It's GPL, I believe.

\start
Date: 05 Jun 2007 11:53:24 +0200
From: Martin Rubey
To: Alasdair McAndrew
Subject: Re: Is anybody actually doing mathematics with	Axiom?

Alasdair McAndrew writes:

> but does anybody actually use Axiom for mathematics: teaching, research, or
> even fun?  

I am.  For example, I wrote a tiny script to spit out all set partitions in
(Coxeter-) Type B and D and counted the first few terms, then entered them into
Sloane's database, to find the reference Ruedi Suter.

I also used Axiom to check a conjecture on Jeu de Taquin.  To this end I
implemented growth diagrams by Fomin, but I am unable to pursue this project on
my own.

Last year I used the (in my opinion) formidable graphics to show students how a
saddle point and a tangential plane looks like.  Gorgeous!

> Is anybody out there adding further mathematical functionality to Axiom -
> numerical routines, difference equation solvers, discrete mathematics etc
> etc?

I added the guessing package (currently state of the art), and together with
Ralf a project to deal with combinatorial species.

Concerning difference equations, you might know that my favorite would-be
project is a hierarchy covering 

  functions satisfying algebraic diffential equations,
  holonomic functions,
  algebraic functions,
  rational functions
  polynomials

on one hand and 

  "admissible" recurrence relations
  D-finite recurrence relations
  recurrence relations with constant coefficients

on the other hand.  But I could not find a collaborator so far --
unfortunately, Antoine Hersen gave up.  (One needs to know a bit about
Ore-algebras, AKA skew-polynomial rings.)

> FWIW, as Martin well knows, I've been banging my head over pattern matching
> and z-transforms lately. I have a file which works to about 75%; the last
> bit, which involves partial fractions, is still giving me gyp.

Try to formulate a question, then I can try to answer it.

> And on the meta-mathematical side, has anybody got an emacs mode to work
> with *.input files?

Francois Maltey sent me some files, but I am unable to incorporate them into my
emacs mode (which I use myself meanwhile), for lack of time.

\start
Date: Tue, 5 Jun 2007 12:06:53 +0200 (CEST)
From: Waldek Hebisch
To: Martin Rubey
Subject: Re: Patches

> Dear Tim, Waldek,
> 
> Waldek Hebisch writes:
> 
> > I supect that original author did not know how to leave one partial
> > derivative unevaluated, while giving value of the second one (ATM this
> > is not clear for me either).  If you know how to to this please go
> > on.
> 
> below is a patch that has the behaviour as you described it, with the exception
> of polygamma, which now throws an error.  If you prefer that polygamma also
> allows differentiation with respect to the first argument, the change is
> trivial.  I don't have time to modify sttaylor right now.
> 

I tried the patch and I see a problem.  Namely, when one tries do
do something with unevaluated derivatives Axiom goes into infinite
recursion.  For example:

integrate(D(besselK(a,x),a),a)

or

limit(D(besselK(a,x),a),a=1)

shows the problem.

Backtrace show repeated pattern of smpeval and notfound calls:

#3   ES-;okkernel {loc0=#<vector 0000000001ea99f0>,loc1=(((1 #<vector 0000000002d369f0> #) . #0=(0...} [ihs=576]
#4   FSPECF;symbolicGrad {loc0=#<vector 0000000001eacf00>,loc1=(((1 #<vector 0000000002dd3de0> #) . #0=(0...} [ihs=575]
#5   FS-;notfound {loc0=(#<compiled-function |FS-;smpeval!1|> . #<vector 0000000002d39f00>),loc1=(...} [ihs=574]
#6   FS-;smpeval {loc0=(1 #<vector 0000000002d9de70> (1 0 . 1)),loc1=(#<vector 0000000002e70f90>)...} [ihs=573]
#7   FS-;notfound {loc0=(#<compiled-function |FS-;smpeval!1|> . #<vector 0000000002de0300>),loc1=(...} [ihs=572]
#8   FS-;smpeval {loc0=(1 #<vector 0000000002e460c0> (1 0 . 1)),loc1=(#<vector 0000000002f13ed0>)...} [ihs=571]

.....

#538   FS-;notfound {loc0=(#<compiled-function |FS-;smpeval!1|> . #<vector 00000000021bc9c0>),loc1=(...} [ihs=41]
#539   newGoGet {g104406=((#<compiled-function |FS-;smpeval!2|> . #<vector 00000000021bc9f0>) (#...} [ihs=40]
#540   FS-;smpeval {loc0=(1 #<vector 00000000021bce40> (1 0 . 1)),loc1=(#<vector 0000000001ed8360>)...} [ihs=39]
#541   newGoGet {g104406=(((1 #<vector 00000000021bce40> #) . #0=(0 . 1)) (#<vector 0000000001ed...} [ihs=38]
#542   newGoGet {g104406=(((1 #<vector 00000000021bce40> #) . #0=(0 . 1)) #<vector 0000000001ed8...} [ihs=37]
#543   newGoGet {g104406=(#<vector 0000000001ea99f0> ((# . #0=(0 . 1)) (# . #0#) (# . #0#)) (#<v...} [ihs=36]
#544   EFSTRUC;k2Elem {loc0=#<vector 0000000001edaf30>,loc1=(|a|),loc2=#<vector
000000000219b930>} [ihs=35]
#545   newGoGet {g104406=((#<compiled-function |EFSTRUC;smpElem!0|> . #<vector 000000000219b810>...} [ihs=34]
#546   EFSTRUC;smpElem {loc0=(1 #<vector 0000000001edaf30> (1 0 . 1)),loc1=(|a|),loc2=#<vector 00000000...} [ihs=33]
#547   EFSTRUC;realElem {loc0=((1 #<vector 0000000001edaf30> (1 . #0=(0 . 1))) . #0#),loc1=(|a|),loc2=#<...} [ihs=32]
#548   newGoGet {g104406=(((1 #<vector 0000000001edaf30> #) . #0=(0 . 1)) |a| (#<vector 00000000...} [ihs=31]
#549   FSINT;integrate;FSU;10 {loc0=((1 #<vector 0000000001edaf30> (1 . #0=(0 .
1))) . #0#),loc1=|a|,loc2=#<ve...} [ihs=30]

\start
Date: 05 Jun 2007 07:48:18 -0400
From: Stephen Wilson
To: Ralf Hemmecke
Subject: Re: Boot/SPAD package syntax
Cc: Gabriel Dos Reis

Hello Ralf,

The concept of a Lisp package does not translate into a SPAD or Aldor
package directly.  As you know, a "package-call" in the latter case is
denoted by the $ operator.  I fail to see the connection between the '
(or ::) operator in Boot/SPAD and any language concept such as SPAD
packages.

\start
Date: Tue, 5 Jun 2007 22:32:23 +1000
From: Alasdair McAndrew
To: Martin Rubey, list
Subject: Re: Is anybody actually doing mathematics with	Axiom?

Hi Martin,

Here is my ztrans.input file in its current diabolical form - all the
cleverness is yours and Themos's; the extra hack work is my own.  It does
forward transforms pretty well (of powers, exponential functions and
mixtures thereof), but inverse transforms are less well handled.  For
example,

ex:=ztrans(n^5,n,z)

produces a formidable polynomial quotient; to invert it you need to apply
partial fractions to ex/z, and apply the inverse transform to each
individual fractional term multiplied by z.  This is not happening right
now.

As well, I need to implement shifts:

ztrans(f(n-k),n,z) == z^(-b)*ztrans(f(n),n,z)

and for f(n+k).

My own thoughts for difference equations were much more modest than yours:
linear equations with constant coefficients, and equations which can be
transformed into linear equations.  I can't imagine it would be too hard?
Of course, if I get the z-ztransforms working, that can be used....

cheers,
Alasdair


On 05 Jun 2007 11:53:24 +0200, Martin Rubey
wrote:
>
> Alasdair McAndrew writes:
>
> > but does anybody actually use Axiom for mathematics: teaching, research,
> or
> > even fun?
>
> I am.  For example, I wrote a tiny script to spit out all set partitions
> in
> (Coxeter-) Type B and D and counted the first few terms, then entered them
> into
> Sloane's database, to find the reference Ruedi Suter.
>
> I also used Axiom to check a conjecture on Jeu de Taquin.  To this end I
> implemented growth diagrams by Fomin, but I am unable to pursue this
> project on
> my own.
>
> Last year I used the (in my opinion) formidable graphics to show students
> how a
> saddle point and a tangential plane looks like.  Gorgeous!
>
> > Is anybody out there adding further mathematical functionality to Axiom
> -
> > numerical routines, difference equation solvers, discrete mathematics
> etc
> > etc?
>
> I added the guessing package (currently state of the art), and together
> with
> Ralf a project to deal with combinatorial species.
>
> Concerning difference equations, you might know that my favorite would-be
> project is a hierarchy covering
>
>   functions satisfying algebraic diffential equations,
>   holonomic functions,
>   algebraic functions,
>   rational functions
>   polynomials
>
> on one hand and
>
>   "admissible" recurrence relations
>   D-finite recurrence relations
>   recurrence relations with constant coefficients
>
> on the other hand.  But I could not find a collaborator so far --
> unfortunately, Antoine Hersen gave up.  (One needs to know a bit about
> Ore-algebras, AKA skew-polynomial rings.)
>
> > FWIW, as Martin well knows, I've been banging my head over pattern
> matching
> > and z-transforms lately. I have a file which works to about 75%; the
> last
> > bit, which involves partial fractions, is still giving me gyp.
>
> Try to formulate a question, then I can try to answer it.
>
> > And on the meta-mathematical side, has anybody got an emacs mode to work
> > with *.input files?
>
> Francois Maltey sent me some files, but I am unable to incorporate them
> into my
> emacs mode (which I use myself meanwhile), for lack of time.
>
> Martin
>
>

------=_Part_18497_28790895.1181046743200

Hi Martin,<br><br>Here is my ztrans.input file in its current diabolical form - all the cleverness is yours and Themos&#39;s; the extra hack work is my own.&nbsp; It does forward transforms pretty well (of powers, exponential functions and mixtures thereof), but inverse transforms are less well handled.&nbsp; For example,
<br><br>ex:=ztrans(n^5,n,z)<br><br>produces a formidable polynomial quotient; to invert it you need to apply partial fractions to ex/z, and apply the inverse transform to each individual fractional term multiplied by z.&nbsp; This is not happening right now.
<br><br>As well, I need to implement shifts:<br><br>ztrans(f(n-k),n,z) == z^(-b)*ztrans(f(n),n,z)<br><br>and for f(n+k).<br><br>My own thoughts for difference equations were much more modest than yours: linear equations with constant coefficients, and equations which can be transformed into linear equations.&nbsp; I can&#39;t imagine it would be too hard?&nbsp; Of course, if I get the z-ztransforms working, that can be used....
<br><br>cheers,<br>Alasdair<br><br><br><div><span class="gmail_quote">On 05 Jun 2007 11:53:24 +0200, <b class="gmail_sendername">Martin Rubey</b> &lt;<a href="mailto:Martin Rubey">Martin Rubey</a>
&gt; wrote:</span><blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">&quot;Alasdair McAndrew&quot; &lt;<a href="mailto:Alasdair McAndrew">Alasdair McAndrew
</a>&gt; writes:<br><br>&gt; but does anybody actually use Axiom for mathematics: teaching, research, or<br>&gt; even fun?<br><br>I am.&nbsp;&nbsp;For example, I wrote a tiny script to spit out all set partitions in<br>(Coxeter-) Type B and D and counted the first few terms, then entered them into
<br>Sloane&#39;s database, to find the reference Ruedi Suter.<br><br>I also used Axiom to check a conjecture on Jeu de Taquin.&nbsp;&nbsp;To this end I<br>implemented growth diagrams by Fomin, but I am unable to pursue this project on
<br>my own.<br><br>Last year I used the (in my opinion) formidable graphics to show students how a<br>saddle point and a tangential plane looks like.&nbsp;&nbsp;Gorgeous!<br><br>&gt; Is anybody out there adding further mathematical functionality to Axiom -
<br>&gt; numerical routines, difference equation solvers, discrete mathematics etc<br>&gt; etc?<br><br>I added the guessing package (currently state of the art), and together with<br>Ralf a project to deal with combinatorial species.
<br><br>Concerning difference equations, you might know that my favorite would-be<br>project is a hierarchy covering<br><br>&nbsp;&nbsp;functions satisfying algebraic diffential equations,<br>&nbsp;&nbsp;holonomic functions,<br>&nbsp;&nbsp;algebraic functions,
<br>&nbsp;&nbsp;rational functions<br>&nbsp;&nbsp;polynomials<br><br>on one hand and<br><br>&nbsp;&nbsp;&quot;admissible&quot; recurrence relations<br>&nbsp;&nbsp;D-finite recurrence relations<br>&nbsp;&nbsp;recurrence relations with constant coefficients<br><br>on the other hand.&nbsp;&nbsp;But I could not find a collaborator so far --
<br>unfortunately, Antoine Hersen gave up.&nbsp;&nbsp;(One needs to know a bit about<br>Ore-algebras, AKA skew-polynomial rings.)<br><br>&gt; FWIW, as Martin well knows, I&#39;ve been banging my head over pattern matching<br>&gt; and z-transforms lately. I have a file which works to about 75%; the last
<br>&gt; bit, which involves partial fractions, is still giving me gyp.<br><br>Try to formulate a question, then I can try to answer it.<br><br>&gt; And on the meta-mathematical side, has anybody got an emacs mode to work
<br>&gt; with *.input files?<br><br>Francois Maltey sent me some files, but I am unable to incorporate them into my<br>emacs mode (which I use myself meanwhile), for lack of time.<br><br>Martin<br><br></blockquote></div><br>

------=_Part_18497_28790895.1181046743200--

------=_Part_18496_28493133.1181046743200
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------=_Part_18496_28493133.1181046743200--

\start
Date: 05 Jun 2007 07:41:44 -0500
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Boot/SPAD package syntax

Stephen Wilson writes:

| Gabriel Dos Reis writes:
| 
| > Stephen Wilson writes:
| > 
| > | Greetings,
| > | 
| > | I stumbled upon a curious facility of Boot and SPAD this evening.  I
| > | do not recall, nor can I find, a reference to this in the list
| > | archives or in any documentation.  Please correct me if I am wrong.
| > 
| > Since we have at least two versions of Boot around, you need to qualify
| > your Boot by either "old" or "new" or variations thereof.
| 
| When I say Boot, I mean the Boot which is used in Axiom. 

Why do you think I meant something else?

| In
| particular, the Boot which translates the current Boot code.  

What do you think bootsys is used for?

| Other variations are effectively mythical to me.  

I can see that.

| I guess this is what you qualify as "old"?

No.

New Boot is the one from src/boot.
Old Boot is done by depsys.

[...]

| Regardless of syntax, I am more interested in the semantics of the
| construct.

If you don't like my anseer you're out of luck.

| > New Boot (in src/boot) has gotten same syntax (::) recently (added by me).
| 
| Ok.  This is in gdr-sandbox, no?

The (::) syntax was already in Old Boot.
It was added to build-improvements.

| > | My opinion is that this is unused cruft which has no discernible
| > | application.  In fact, it theoretically results in the generation of
| > | non-portable code.  For example, several popular Lisp implementations
| > | have introduced the notion of `package locks' to prevent against
| > | unintended alteration of package symbols.  The identifier CL'FOO
| > | results in FOO being interned in the COMMON-LISP package, which would
| > | violate such a lock.  There are other examples.
| > 
| > Those are *bugs in Axiom* source code -- there are plenty of those
| > around. 
| 
| Not quite following.  There is nothing to suggest to me that SPAD as a
| language defines identifiers such as CL'FOO as being invalid in the
| same way as, say, C++ defines identifiers which start with an
| underscore to be reserved names for use by the implementation.

Axiom source code == the collection source code that makes up the
    Axiom interpreter or compiler.

| Given the lack of specification, and given the lack of use of such a
| feature, these are not bugs in Axiom by any stretch.

In this specific case, the bugs I've came across happen to be in the
manually written Lisp parts, like restart -- I believe I already
mentioned that.

[...]

| > | I am curious if anyone has noticed this facility and/or sees a potential
| > | use for it.
| > 
| > I use the syntax FOO::BAR, but not FOO'BAR, for "package-call".
| > New Boot treats FOO'BAR as a "single" identifier.
| 
| Ok, a "package-call" is a Lisp concept.  As far as I know neither Boot
| nor SPAD admit the concept of a package.

They do.

| Are there other operations in Boot which deal with packages? How can
| one define a package in Boot?

Lisp is part of New Boot through the espace (!) character.
Names in all caps are defined to correspond to their equivalent
in Lisp.  If you want to push into an existing package, you say

   )package "FOO"

\start
Date: 05 Jun 2007 14:43:35 +0200
From: Martin Rubey
To: Waldek Hebisch
Subject: Re: Patches

Waldek Hebisch writes:

> > below is a patch that has the behaviour as you described it, with
> > the exception of polygamma, which now throws an error.  If you
> > prefer that polygamma also allows differentiation with respect to
> > the first argument, the change is trivial.  I don't have time to
> > modify sttaylor right now.

> I tried the patch and I see a problem.

Wow!  I love your scrutinity!  Could you add this as a test, maybe? Here is a
better patch.


--=-=-=

Index: combfunc.spad.pamphlet
===================================================================
--- combfunc.spad.pamphlet	(revision 580)
+++ combfunc.spad.pamphlet	(working copy)
@@ -41,11 +41,6 @@
       ++ formal product;
 
 @
-The latest change allows Axiom to reduce
-\begin{verbatim}
-   sum(1/i,i=1..n)-sum(1/i,i=1..n) 
-\end{verbatim}
-to reduce to zero.
 <<package COMBF CombinatorialFunction>>=
 )abbrev package COMBF CombinatorialFunction
 ++ Provides the usual combinatorial functions
@@ -690,6 +685,7 @@
   OP  ==> BasicOperator
   K   ==> Kernel F
   SE  ==> Symbol
+  SPECIALDIFF  ==> "%specialDiff"
 
   Exports ==> with
     belong? : OP -> Boolean
@@ -818,29 +814,90 @@
     -- Default behaviour is to build a kernel
     evaluate(opGamma, iiGamma)$BasicOperatorFunctions1(F)
     evaluate(opabs, iiabs)$BasicOperatorFunctions1(F)
+@
 
+\subsection{differentiation of special functions}
+
+In the following we define the symbolic derivatives of the special functions we
+provide.  The formulas we use for the Bessel functions can be found in Milton
+Abramowitz and Irene A. Stegun, eds.  (1965). Handbook of Mathematical
+Functions with Formulas, Graphs, and Mathematical Tables. New York: Dover. ISBN
+0-486-61272-4, Equations~9.1.27 and 9.6.26.  Up to [[patch--50]] the formula
+for $K$ missed the minus sign.  (Issue~\#355)
+
+We do not attempt to provide formulas for the derivative with respect to the
+first argument currently.  Instead, we leave such derivatives unevaluated.
+
+<<package FSPECF FunctionalSpecialFunction>>=
     import Fraction Integer
     ahalf:  F    := recip(2::F)::F
     athird: F    := recip(2::F)::F
     twothirds: F := 2*recip(3::F)::F
+@
 
-    lzero(l: List F): F == 0
+We need to get hold of the differentiation operator as modified by
+[[FunctionSpace]]. Otherwise, for example, display will be ugly.  We accomplish
+that by differentiating an operator, which will certainly result in a single
+kernel only.
 
-    iBesselJGrad(l: List F): F ==
+<<package FSPECF FunctionalSpecialFunction>>=
+    dummyArg: SE := new()$SE
+    opdiff := operator first kernels D((operator(new()$SE)$BasicOperator)
+                                            (dummyArg::F), dummyArg)
+@
+
+The differentiation operator [[opdiff]] takes three arguments corresponding to
+$$
+F_{,i}(a_1,a_2,\dots,a_n):
+$$
+\begin{enumerate}
+\item $F(a_1,...,dm,...a_n)$, where the $i$\textsuperscript{th} argument is a
+  dummy variable,
+\item $dm$, the dummy variable, and
+\item $a_i$, the point at which the differential is evaluated.
+\end{enumerate}
+
+In the following, it seems to be safe to use the same dummy variable
+troughout.  At least, this is done also in [[FunctionSpace]], and did not cause
+problems.
+
+The operation [[symbolicGrad]] returns the first component of the gradient of
+[[op l]].
+
+<<package FSPECF FunctionalSpecialFunction>>=
+    dm := new()$SE :: F
+
+    iBesselJ(l: List F, t: SE): F ==
         n := first l; x := second l
-        ahalf * (besselJ (n-1,x) - besselJ (n+1,x))
-    iBesselYGrad(l: List F): F ==
+        differentiate(n, t)*kernel(opdiff, [opBesselJ [dm, x], dm, n])
+          + differentiate(x, t) * ahalf * (besselJ (n-1,x) - besselJ (n+1,x))
+
+    iBesselY(l: List F, t: SE): F ==
         n := first l; x := second l
-        ahalf * (besselY (n-1,x) - besselY (n+1,x))
-    iBesselIGrad(l: List F): F ==
+        differentiate(n, t)*kernel(opdiff, [opBesselY [dm, x], dm, n])
+          + differentiate(x, t) * ahalf * (besselY (n-1,x) - besselY (n+1,x))
+
+    iBesselI(l: List F, t: SE): F ==
         n := first l; x := second l
-        ahalf * (besselI (n-1,x) + besselI (n+1,x))
-    iBesselKGrad(l: List F): F ==
+        differentiate(n, t)*kernel(opdiff, [opBesselI [dm, x], dm, n])
+          + differentiate(x, t)* ahalf * (besselI (n-1,x) + besselI (n+1,x))
+
+    iBesselK(l: List F, t: SE): F ==
         n := first l; x := second l
-        ahalf * (besselK (n-1,x) + besselK (n+1,x))
-    ipolygammaGrad(l: List F): F ==
-        n := first l; x := second l
-        polygamma(n+1, x)
+        differentiate(n, t)*kernel(opdiff, [opBesselK [dm, x], dm, n])
+          - differentiate(x, t)* ahalf * (besselK (n-1,x) + besselK (n+1,x))
+
+@
+
+For the moment we throw an error if we try to differentiate [[polygamma]] with
+respect to the first argument.
+
+<<package FSPECF FunctionalSpecialFunction>>=
+    ipolygamma(l: List F, x: SE): F ==
+        member?(x, variables first l) =>
+            error "cannot differentiate polygamma with respect to the first argument"
+        n := first l; y := second l
+        differentiate(y, x)*polygamma(n+1, y)
     iBetaGrad1(l: List F): F ==
         x := first l; y := second l
         Beta(x,y)*(digamma x - digamma(x+y))
@@ -849,20 +906,36 @@
         Beta(x,y)*(digamma y - digamma(x+y))
 
     if F has ElementaryFunctionCategory then
-      iGamma2Grad(l: List F):F ==
+      iGamma2(l: List F, t: SE): F ==
         a := first l; x := second l
-        - x ** (a - 1) * exp(-x)
-      derivative(opGamma2, [lzero, iGamma2Grad])
+        differentiate(a, t)*kernel(opdiff, [opGamma2 [dm, x], dm, a])
+          - differentiate(x, t)* x ** (a - 1) * exp(-x)
+      setProperty(opGamma2, SPECIALDIFF, iGamma2@((List F, SE)->F) 
+                                                 pretend None)
+@
 
+Finally, we tell Axiom to use these functions for differentiation.  Note that
+up to [[patch--50]], the properties for the Bessel functions were set using
+[[derivative(oppolygamma, [lzero, ipolygammaGrad])]], where [[lzero]] returned
+zero always.  Trying to replace [[lzero]] by a function that returns the first
+component of the gradient failed, it resulted in an infinit loop for
+[[integrate(D(besselJ(a,x),a),a)]].
+
+<<package FSPECF FunctionalSpecialFunction>>=
     derivative(opabs,       abs(#1) * inv(#1))
     derivative(opGamma,     digamma #1 * Gamma #1)
     derivative(opBeta,      [iBetaGrad1, iBetaGrad2])
     derivative(opdigamma,   polygamma(1, #1))
-    derivative(oppolygamma, [lzero, ipolygammaGrad])
-    derivative(opBesselJ,   [lzero, iBesselJGrad])
-    derivative(opBesselY,   [lzero, iBesselYGrad])
-    derivative(opBesselI,   [lzero, iBesselIGrad])
-    derivative(opBesselK,   [lzero, iBesselKGrad])
+    setProperty(oppolygamma, SPECIALDIFF, ipolygamma@((List F, SE)->F)
+                                                     pretend None)
+    setProperty(opBesselJ, SPECIALDIFF, iBesselJ@((List F, SE)->F) 
+                                                 pretend None)
+    setProperty(opBesselY, SPECIALDIFF, iBesselY@((List F, SE)->F) 
+                                                 pretend None)
+    setProperty(opBesselI, SPECIALDIFF, iBesselI@((List F, SE)->F) 
+                                                 pretend None)
+    setProperty(opBesselK, SPECIALDIFF, iBesselK@((List F, SE)->F) 
+                                                 pretend None)
 
 @
 \section{package SUMFS FunctionSpaceSum}

\start
Date: 05 Jun 2007 07:46:31 -0500
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Re: Boot/SPAD package syntax

Ralf Hemmecke writes:

| >> I use the syntax FOO::BAR, but not FOO'BAR, for "package-call".
| >> New Boot treats FOO'BAR as a "single" identifier.
| 
| > Ok, a "package-call" is a Lisp concept.  As far as I know neither Boot
| > nor SPAD admit the concept of a package.
| 
| I don't know much about Lisp and Boot, but Aldor defines what a
| package is (maybe it is different from what you mean here) and I
| always thought, that this is a concept that also exists in SPAD.

There are different notions of package here.  
There is the notion of package as defined by Spad, and Axiom.
Then there is the notion of package, which really is a name space, as
defined by the assembly language Lisp.

In Spad you can do "package call", i.e. explicitly specify where
you want the symbol from, as in "x$P"; in the assembly language Lisp
you do "P:x" or "P::x".   

\start
Date: Tue, 5 Jun 2007 08:02:45 -0500
From: Tim Daly
To: Alasdair McAndrew
Subject: Is anybody actually doing mathematics with Axiom

> And on the subject of numerical routines, is anybody interested in using any
> of the netlib stuff (lapack, for example), in Axiom? It's GPL, I believe.

I'm working on making a literate version of the low level linear algebra
routines, like BLAS and LAPACK. I have permission from an author of a
related text to use his material for documentation. Eventually I want to
move up the stack and integrate things like OCTAVE.

\start
Date: Tue, 5 Jun 2007 08:12:05 -0500
From: Tim Daly
To: Martin Rubey
Subject: Is anybody actually doing mathematics with Axiom

> ... I wrote a tiny script to spit out all set partitions in 
> (Coxeter-) Type B and D ...

> Last year I used the (in my opinion) formidable graphics to show students
> how a saddle point and a tangential plane looks like. Gorgeous!

It would be useful to turn these local examples into input pamphlets
so they can be used for regression testing and as examples of what
Axiom can do. 

I'd encourage people to post example input files showing work in
their area of interest.

\start
Date: Tue, 5 Jun 2007 08:14:23 -0500 (CDT)
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Re: merge branches/daly to trunk
Cc: Christian Aistleitner, Bill Page

On Mon, 4 Jun 2007, Ralf Hemmecke wrote:

| On 06/04/2007 10:42 PM, Gabriel Dos Reis wrote:
| > On Mon, 4 Jun 2007, Ralf Hemmecke wrote:
| > 
| > [...]
| > 
| > | For Aldor that is easy, one compiles an executable and runs that. With
| > | Axiom
| > | that is not possible, because libaxiom cannot (at least not easily) be
| > | compiled into a standalone executable.
| > 
| > We should work toward modularizing the Axiom system.  More specifically:
| > 
| >   (1) we should have standalone bootsys, that can translate, compile
| >       Boot codes.  It should be able to create standalone executable from
| >       Boot+Lisp programs.
| > 
| >   (2) we should have a standalone interpreter that can work with any set
| >       of algebras
| > 
| >   (3) we should have a standalone compiler that can work with any set of
| >       algebras
| > 
| >   (4) we should have a standalone et of standard algebras can be be used
| >       with any "standard conformant" Axiom interpreter or compiler.
| > 
| > No doubt, that is work.
| 
| No doubt. But I love your plan. Since long I want to have the interpreter
| decoupled from the underlying libraries.

Looks, we have a common goal :-)

| > Currently, I have (1) plus a standalone depsys that can create executable
| > from Lisp+Boot programs, but my hope is that depsys will die soon.
| 
| Would that mean that Aldor->Lisp->executable should work?

Could you elaborate on what you mean by that phase?

\start
Date: Tue, 5 Jun 2007 08:18:06 -0500 (CDT)
From: Gabriel Dos Reis
To: Waldek Hebisch
Subject: Re: merge branches/daly to trunk

On Mon, 4 Jun 2007, Waldek Hebisch wrote:

[...]

| I must admit that I consider technique applied in current silver as
| step backwards:  AFAICS results of running input files are still
| compared using text comparison, but since expected result is
| embedded in .input files we have extra maintenance burden when
| output changes (I use separate tree for comparison).

If I were to make sure that I did not break anything already working in Tim's
tree, I have to test his regress script first -- no matter how much I don't
appreciate the methodology of the script.  At the moment, it has all sort  of
things that depend on user daly so I cannot even try. 

| Concerning regress script: using md5sums is quite crude, there is
| a lot of differences which give functionally identical result.

yes, we agree.

\start
Date: 05 Jun 2007 08:25:37 -0500
From: Gabriel Dos Reis
To: Tim Daly
Subject: Re: Is anybody actually doing mathematics with Axiom

Tim Daly writes:

[...]

| I'd encourage people to post example input files showing work in
| their area of interest.

Most of the time, my input files depend on libraries not in Axiom
distribution. 

\start
Date: Tue, 5 Jun 2007 23:36:02 +1000
From: Alasdair McAndrew
To: list
Subject: Comparison of CAS's?

------=_Part_19229_3871480.1181050562705

As far as I know, nobody has tried to compare CAS's since Michael Wester's
attempts in the 1990's.  And even then, his final test, which had over 500
problems purporting to be from "all areas of mathematics" was not in any way
comprehensive: no topology, no abstract algebra, not much logic, nothing on
graphics, and so on.  And these tests only tested the "breadth" of a system
- the number of different problems it could spit out a correct answer to.
In these tests, and in some smaller ones developed by Barry Simon, Axiom
performed very poorly.

Nobody that I know of has attempted a more modern comparison, looking a
depth as much as breadth.  It may well be that Axiom does not have the
black-box problem solving abilities of some of its rivals (put a problem in,
get an answer out), but it may be that in depth and in its fundamental
design paradigms, it outweighs others.

Does anybody know of any research in this area?  I started a while back
trying to get some material together to write a small article comparing
CAS's for teaching and learning, but never got very far with it (something
common to all my projects at the moment!)

It seems to me that this would be a worthwhile effort.

cheers,
Alasdair

\start
Date: Tue, 05 Jun 2007 15:36:05 +0200
From: Ralf Hemmecke
To: Gabriel Dos Reis
Subject: Re: merge branches/daly to trunk
Cc: Christian Aistleitner, Bill Page

> | >   (1) we should have standalone bootsys, that can translate, compile
> | >       Boot codes.  It should be able to create standalone executable from
> | >       Boot+Lisp programs.

> | > Currently, I have (1) plus a standalone depsys that can create executable
> | > from Lisp+Boot programs, but my hope is that depsys will die soon.
> | 
> | Would that mean that Aldor->Lisp->executable should work?

> Could you elaborate on what you mean by that phase?

I meant that using (1) could help to get something like the equivalent 
of AldorUnit running for the Axiom library. I don't know how much that 
makes sense, but it might help us to introduce unit testing to Axiom.

I imagine that testcases could be written in Aldor like for AldorUnit, 
but then we need to take libaxiom, libaldorunit (which was compiled 
against libaxiom) and produce an executable TestSuite program. That 
would just be similar to what is done now with aldorunit.

It basically works like that:

   1) write a couple of testcases.
   2) let a program generate a wrapper file that collects all these cases
      into a TestSuite.as file.
   3) Compile TestSuite.as (using libaxiom and libaldorunit as underlying
      libraries) and arrive at an executable.

No interpreter would be needed here. It would simply test the things in 
libaxiom.

The Aldor compiler would be used to produce LISP. (Or use the SPAD 
compiler, if that works with a well-specified (and close to Aldor) input 
language.) From there I understood you can go on via (1) to produce an 
executable.

\start
Date: Tue, 05 Jun 2007 10:13:39 -0400
From: Eugene Surowitz
To: Tim Daly
Subject: Re: Interesting comment
Cc: Bill Page, Gabriel Dos Reis

The NY Metropolitan Opera has already grabbed
a good thing for their "Romeo and Juliet" production:
There's a large vertical ring with symbols on it
on stage while the lovers are transporting themselves;
it shows Hubble telescope pix and other astronomical events.

All hallowed be SG-1: Stallman, Torvalds, Knuth, McCarthy!

Gene

Tim Daly wrote:
> funny. i like it. we have no maintainers, we have Priors!
> 
> all hail Stallman! all hail Torvalds! all hail Knuth! all hail McCarthy!
> 
> i guess SVN-worship falls into the category of "fables meant to fill
> the soul bereft of hope with purpose" :-)
> 
> can't wait for the "Ring Transporter" though as it would greatly 
> facilitate my 33 mile commute. of course, my "intertubes" are full
> with spam so it is better to drive.

\start
Date: 05 Jun 2007 10:24:58 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Boot/SPAD package syntax

Gabriel Dos Reis writes:

> Stephen Wilson writes:
> 
> | Gabriel Dos Reis writes:
> | 
> | > Stephen Wilson writes:
> | > 
> | > | Greetings,
> | > | 
> | > | I stumbled upon a curious facility of Boot and SPAD this evening.  I
> | > | do not recall, nor can I find, a reference to this in the list
> | > | archives or in any documentation.  Please correct me if I am wrong.
> | > 
> | > Since we have at least two versions of Boot around, you need to qualify
> | > your Boot by either "old" or "new" or variations thereof.
> | 
> | When I say Boot, I mean the Boot which is used in Axiom. 
> 
> Why do you think I meant something else?

The basic point is that, by the time AXIOMsys is generated, there is a
function BOOTTRAN::BOOTTOCL.  AFAIK, there are two such functions with
the same name defined in src/boot/ptyout.boot.pamphlet and
src/interp/util.lisp.pamphlet.  The latter version is the one which
lives in an Axiom image, and also depsys.  Thats the boot Im refering
to.
> 
> | In
> | particular, the Boot which translates the current Boot code.  
> 
> What do you think bootsys is used for?

To bootstrap the system.  As you know, it works with the boot flavor
in src/boot.  The majority of the code is translated by depsys.

> 
> | Other variations are effectively mythical to me.  
> 
> I can see that.
> 
> | I guess this is what you qualify as "old"?
> 
> No.
> 
> New Boot is the one from src/boot.
> Old Boot is done by depsys.

Ok. 

> 
> [...]
> 
> | Regardless of syntax, I am more interested in the semantics of the
> | construct.
> 
> If you don't like my anseer you're out of luck.

Its not that I dont like your answer, its just that I havent gotten
one yet.

> 
> | > New Boot (in src/boot) has gotten same syntax (::) recently (added by me).
> | 
> | Ok.  This is in gdr-sandbox, no?
> 
> The (::) syntax was already in Old Boot.
> It was added to build-improvements.

Ok, thanks.

> 
> | > | My opinion is that this is unused cruft which has no discernible
> | > | application.  In fact, it theoretically results in the generation of
> | > | non-portable code.  For example, several popular Lisp implementations
> | > | have introduced the notion of `package locks' to prevent against
> | > | unintended alteration of package symbols.  The identifier CL'FOO
> | > | results in FOO being interned in the COMMON-LISP package, which would
> | > | violate such a lock.  There are other examples.
> | > 
> | > Those are *bugs in Axiom* source code -- there are plenty of those
> | > around. 
> | 
> | Not quite following.  There is nothing to suggest to me that SPAD as a
> | language defines identifiers such as CL'FOO as being invalid in the
> | same way as, say, C++ defines identifiers which start with an
> | underscore to be reserved names for use by the implementation.
> 
> Axiom source code == the collection source code that makes up the
>     Axiom interpreter or compiler.
> 

Right.  Not sure I get your point. 

> | Given the lack of specification, and given the lack of use of such a
> | feature, these are not bugs in Axiom by any stretch.
> 
> In this specific case, the bugs I've came across happen to be in the
> manually written Lisp parts, like restart -- I believe I already
> mentioned that.

Ok, I asked what the package call operator ' (or ::) means, and now
your just saying that if CL'FOO has undefined behaviour its a bug in
Axiom as opposed to a bug in the language semantics of Boot (or SPAD
for that matter).

Not sure how the bug count in manually typed bootified lisp code
relates to this (I assume you are refering to the Lisp code written
directly in Boot by typing something like CONS(x, y)).  After all, we
are talking about a Boot construct primarily (that it happens to map
to a Lisp construct is beside the point).

> 
> [...]
> 
> | > | I am curious if anyone has noticed this facility and/or sees a potential
> | > | use for it.
> | > 
> | > I use the syntax FOO::BAR, but not FOO'BAR, for "package-call".
> | > New Boot treats FOO'BAR as a "single" identifier.
> | 
> | Ok, a "package-call" is a Lisp concept.  As far as I know neither Boot
> | nor SPAD admit the concept of a package.
> 
> They do.

SPAD has packages as Ralf pointed out.  These do not relate to Lisp
packages directly.  The *only* interpretation of a Boot or Spad
"package-call" via ' or :: that I can see relates to the native Lisp
notion.

>From what I can see, Boot gives you a surface syntax to interact with
the Lisp package system.

Could you give a breif example of what constitues a Boot package and
the operations defined on it?
 
> | Are there other operations in Boot which deal with packages? How can
> | one define a package in Boot?
> 
> Lisp is part of New Boot through the espace (!) character.
> Names in all caps are defined to correspond to their equivalent
> in Lisp.  If you want to push into an existing package, you say
> 
>    )package "FOO"

This appears to be surface syntax for (IN-PACKAGE "FOO").  It does not
define a package.

What is a Boot package?  How do you create one from Boot? 

I suspect boot packages are just lisp packages.


Note too, this issue is also of importance for the SPAD language.
What does FOO'BAR mean in SPAD?  How does it realate to other
constructs in the language?

I am primarily interested in the SPAD case.  I was hoping for some
illustration of how the construct is put to use in SPAD.  As I feel
direct Lisp callouts from SPAD are a dangerous thing, I need some
convincing that this construct is useful/necessary.  As I mentioned,
it would seem the construct is unused, and thus support could be
easily removed from the system.

\start
Date: 05 Jun 2007 10:36:49 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Boot/SPAD package syntax

Gabriel Dos Reis writes:

> Then there is the notion of package, which really is a name space, as
> defined by the assembly language Lisp.

Packages in Lisp are not just namespaces.  They are objects (data)
with which one can compute with and manipulate.  Of course, their
primary purpose is to provide a home for symbols, and to provide the
notion of internal/exported symbols.

All assembly languages provide access to facilities not available to
the higher level languages implemented upon them.

\start
Date: Tue, 5 Jun 2007 11:21:11 -0400
From: Bill Page
To: list
Subject: gcc mercurial repository

http://gcc.gnu.org/ml/gcc-patches/2007-05/msg01825.html

I have no wish to extend the source code repository controversy
but I just thought I would mention that gcc now has a mercurial
(hg) mirror. This seems significant to me since Gaby has so
strongly promoted SVN as the "best choice" based partly, I think,
on it's adpotion by gcc.

\start
Date: Tue, 5 Jun 2007 10:37:00 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Boot/SPAD package syntax

On Tue, 5 Jun 2007, Stephen Wilson wrote:

| Gabriel Dos Reis writes:
| 
| > Stephen Wilson writes:
| > 
| > | Gabriel Dos Reis writes:
| > | 
| > | > Stephen Wilson writes:
| > | > 
| > | > | Greetings,
| > | > | 
| > | > | I stumbled upon a curious facility of Boot and SPAD this evening.  I
| > | > | do not recall, nor can I find, a reference to this in the list
| > | > | archives or in any documentation.  Please correct me if I am wrong.
| > | > 
| > | > Since we have at least two versions of Boot around, you need to qualify
| > | > your Boot by either "old" or "new" or variations thereof.
| > | 
| > | When I say Boot, I mean the Boot which is used in Axiom. 
| > 
| > Why do you think I meant something else?
| 
| The basic point is that, by the time AXIOMsys is generated, there is a
| function BOOTTRAN::BOOTTOCL.  AFAIK, there are two such functions with
| the same name defined in src/boot/ptyout.boot.pamphlet and
| src/interp/util.lisp.pamphlet.  The latter version is the one which
| lives in an Axiom image, and also depsys.  Thats the boot Im refering
| to.

OK.
We are back to my earlier point: When you say Boot, you need to qualify it.

FYI, the boottocl defined src/interp is scheduled for death (as is depsys).  
The plan is to migrate to bootsys.  See the comment in the source codes. 

| > | In
| > | particular, the Boot which translates the current Boot code.  
| > 
| > What do you think bootsys is used for?
| 
| To bootstrap the system. 

Good.

| As you know, it works with the boot flavor in src/boot.  

And some part of src/interp too.

[...]

| Its not that I dont like your answer, its just that I havent gotten
| one yet.

Looks to me that you're not interested in one.

Because the original message had several of them.

[...]

| > | > Those are *bugs in Axiom* source code -- there are plenty of those
| > | > around. 
| > | 
| > | Not quite following.  There is nothing to suggest to me that SPAD as a
| > | language defines identifiers such as CL'FOO as being invalid in the
| > | same way as, say, C++ defines identifiers which start with an
| > | underscore to be reserved names for use by the implementation.
| > 
| > Axiom source code == the collection source code that makes up the
| >     Axiom interpreter or compiler.
| > 
| 
| Right.  Not sure I get your point. 

Time will come.

| > | Given the lack of specification, and given the lack of use of such a
| > | feature, these are not bugs in Axiom by any stretch.
| > 
| > In this specific case, the bugs I've came across happen to be in the
| > manually written Lisp parts, like restart -- I believe I already
| > mentioned that.
| 
| Ok, I asked what the package call operator ' (or ::) means, and now
| your just saying that if CL'FOO has undefined behaviour its a bug in
| Axiom as opposed to a bug in the language semantics of Boot (or SPAD
| for that matter).

That is not what I'm saying.

| 
| Not sure how the bug count in manually typed bootified lisp code
| relates to this (I assume you are refering to the Lisp code written
| directly in Boot by typing something like CONS(x, y)).  After all, we
| are talking about a Boot construct primarily (that it happens to map
| to a Lisp construct is beside the point).
| 
| > 
| > [...]
| > 
| > | > | I am curious if anyone has noticed this facility and/or sees a potential
| > | > | use for it.
| > | > 
| > | > I use the syntax FOO::BAR, but not FOO'BAR, for "package-call".
| > | > New Boot treats FOO'BAR as a "single" identifier.
| > | 
| > | Ok, a "package-call" is a Lisp concept.  As far as I know neither Boot
| > | nor SPAD admit the concept of a package.
| > 
| > They do.
| 
| SPAD has packages as Ralf pointed out. 

I know SPAD has package -- see my other mail for what I meant by
"package-call", which is not my invention but that of the inventors of both
the Spad and Boot languages.

| These do not relate to Lisp packages directly. 

No, but the notion of "package-call" is that of selecting a symbol from a
specific place.  That notion is the same in both Lisp and Spad.

| > Lisp i5As part of New Boot through the espace (!) character.
| > Names in all caps are defined to correspond to their equivalent
| > in Lisp.  If you want to push into an existing package, you say
| > 
| >    )package "FOO"
| 
| This appears to be surface syntax for (IN-PACKAGE "FOO").  It does not
| define a package.

Thanks for repeating back what I said.

| What is a Boot package?  

A Boot package is no different from Lisp package: a name space.

Old Boot assumes that everything goes into the BOOTTRAN package.

New Boot assumes that people are responsible of pushing into the package
the want.

| How do you create one from Boot? 

I believe in CLTLx, a reference to a package creates that package if it 
does not already exist.  Boot uses that semantics.

| I suspect boot packages are just lisp packages.

Boot is used to *implement Axiom*.  Yes, it is language that translates
to Lisp.  

| Note too, this issue is also of importance for the SPAD language.
| What does FOO'BAR mean in SPAD?  How does it realate to other
| constructs in the language?

The Ada-style FOO'BAR was considered obsolete, I believe, for Spad (and 
later for Old Old Boot).

| I am primarily interested in the SPAD case.

In the specific case of Spad, that specific construct can go away.

|  I was hoping for some
| illustration of how the construct is put to use in SPAD.  As I feel
| direct Lisp callouts from SPAD are a dangerous thing,

No more dangerous than pretend.

What we need is not to prevent people to call Lisp -- they will, and there 
are legitimate cases where one needs to access the assembly-language
(currently only Lisp).  What we need is an assembly-indepedent interface,

| I need some
| convincing that this construct is useful/necessary.  As I mentioned,
| it would seem the construct is unused, and thus support could be
| easily removed from the system.

Since the same parser is used to parse Old Boot, you'll also need more than
superficial examination that no Boot codes uses it.

\start
Date: Tue, 5 Jun 2007 10:39:30 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Boot/SPAD package syntax

On Tue, 5 Jun 2007, Stephen Wilson wrote:

| Gabriel Dos Reis writes:
| 
| > Then there is the notion of package, which really is a name space, as
| > defined by the assembly language Lisp.
| 
| Packages in Lisp are not just namespaces. 

Notice I said "name space", not "namespace".

| They are objects (data) with which one can compute with and manipulate.

How does that make it not a name space ?

|  Of course, their
| primary purpose is to provide a home for symbols, and to provide the
| notion of internal/exported symbols.

So? 

| All assembly languages provide access to facilities not available to
| the higher level languages implemented upon them.

And?

\start
Date: 05 Jun 2007 10:43:17 -0500
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Re: merge branches/daly to trunk
Cc: Christian Aistleitner, Bill Page

Ralf Hemmecke writes:

| > | >   (1) we should have standalone bootsys, that can translate, compile
| > | >       Boot codes.  It should be able to create standalone executable from
| > | >       Boot+Lisp programs.
| 
| > | > Currently, I have (1) plus a standalone depsys that can create executable
| > | > from Lisp+Boot programs, but my hope is that depsys will die soon.
| > | | Would that mean that Aldor->Lisp->executable should work?
| 
| > Could you elaborate on what you mean by that phase?
| 
| I meant that using (1) could help to get something like the equivalent
| of AldorUnit running for the Axiom library. I don't know how much that
| makes sense, but it might help us to introduce unit testing to Axiom.

OK, I see.  Thanks!

\start
Date: Tue, 5 Jun 2007 11:48:59 -0400
From: Bill Page
To: Alasdair McAndrew
Subject: RE: Is anybody actually doing mathematics with	Axiom?

On June 5, 2007 5:38 AM Alasdair McAndrew wrote:

> Admittedly I'm very new to the Axiom game, but in the few
> months I've been involved, the Axiom mail-lists have been
> almost exclusively concerned with meta-mathematics: emacs
> and TeXmacs, version control systems, and just recently sets
> versus topoi versus categories. 
>

In the context of Axiom I do not think that category theory
is "meta-mathematics" but I would agree that for the most part
it is related to the development of new mathematics capabilities
of Axiom and not to their application.

> Not that these things aren't of fundamental importance, but
> does anybody actually use Axiom for mathematics: teaching,
> research, or even fun?  Is anybody out there adding further
> mathematical functionality to Axiom - numerical routines,
> difference equation solvers, discrete mathematics etc etc? 

Here is one example of how I would like to have more "fun"
with Axiom, if ever I can find enough time:

http://wiki.axiom-developer.org/SandBoxCategoricalRelativity

\start
Date: Tue, 5 Jun 2007 08:51:16 -0700 (PDT)
From: Cliff Yapp
To: Bill Page, Ralf Hemmecke
Subject: Re: The Axiom Library and Category Theory 

> The point of category theory as a foundation for mathematics
> is that a lot of mathematics can and should be done long before
> it becomes necessary to define what is meant by "set".

I have seen a few comments to the fact that it should be possible, in
theory, to describe virtually all of mathematics within the framework
of category theory.  If this is true, to me that makes it not only the
obvious foundational choice for The Axiom Library but the essential
one.

> > In fact, I would love to see a system that allows different
> > views. As mathematics can be based on set theory or category
> > theory. 
> 
> Maybe it is just where I live but I think most mathematicians
> since about 1975 or so have agreed that one should not try to
> base mathematics on set theory.

I would be curious as to whether it is possible, even in theory, to
make a CAS that allows multiple foundational design principles.  I
would think it is essential to choose a framework and build within it -
I doubt the mathematics would be "portable" between different
frameworks.  Does anyone know if this "portability" between
foundational concepts is actually possible?  My assumption that it
isn't is one of the major reasons I would like to see a proper Category
Theory at the foundations of Axiom's algebra.

> > > That would not make me nearly as happy as category theory.
> > > :-(
> > 
> > OK, you are responsible to start a library that builds on 
> > category theory.
> 
> Well I have been thinking about and writing about on this email
> list for a few years now... I would very much like to "get my
> head above water" long enough to concentrate on issues like
> these. Unfortunately we are still trying to decide things like
> what source code management system we should be using... :-(

I agree.  In my opinion when we get to the stage of making the Algebra
files truely literate, we will find that the optimal time to re-set the
foundations it builds on.  At that time, I think we should provide
"proper" category theory foundations and build on them, even if it
means re-tuning some of our terminology.  Mathematicians are the target
users for Axiom, and making their "native" vocabulary and Axiom's
terminology the same seem to me to have obvious benefits.  I know that
would be a large amount of work but any proper literate treatment of
Axiom's foundations will involve a similar amount of work - whatever
foundations we build on, we must document all the code and the ideas
behind it.  When we do it, let's do it once and in such a fashion that
(as far as is possible) we won't need to do it ever again.

Unfortunately, before we can get to this (very interesting) stage we
MUST have a firm, well defined, well documented foundation - especially
in terms of Aldor/SPAD programming.  :-(

\start
Date: 05 Jun 2007 10:56:34 -0500
From: Gabriel Dos Reis
To: Alasdair McAndrew
Subject: Re: Comparison of CAS's?

Alasdair McAndrew writes:

| As far as I know, nobody has tried to compare CAS's since Michael Wester's
| attempts in the 1990's. 

Not that I know of.  I believe Wester's work date back from late
1990s.  Everywhere else in computer science, that would be an
eternity, but not in compuer algebra it seems...

I believe many of his issues with Axioms are still unresolved.

| And even then, his final test, which had over 500
| problems purporting to be from "all areas of mathematics" was not in any way
| comprehensive: no topology, no abstract algebra, not much logic, nothing on
| graphics, and so on.  And these tests only tested the "breadth" of a system
| - the number of different problems it could spit out a correct answer to.
| In these tests, and in some smaller ones developed by Barry Simon, Axiom
| performed very poorly.
| 
| Nobody that I know of has attempted a more modern comparison, looking a
| depth as much as breadth.

Maybe because the task is not so trivial.  I believe Wester did an
excellent job.

|  It may well be that Axiom does not have the
| black-box problem solving abilities of some of its rivals (put a problem in,
| get an answer out), but it may be that in depth and in its fundamental
| design paradigms, it outweighs others.

Maybe.  Most people drive a car for the service it provides.  Many
people use CASes for similar reasons.

| Does anybody know of any research in this area?  I started a while back
| trying to get some material together to write a small article comparing
| CAS's for teaching and learning, but never got very far with it (something
| common to all my projects at the moment!)
| 
| It seems to me that this would be a worthwhile effort.

Yes, but it is not a simple task.

You need to know all systems you compare in depth enough to make
a fair comparision.  Furthermore, CASes are to solve problems.  So you
have to come up with realistic problems to solve and express the
solutions in "native styles" for each of them.

\start
Date: Tue, 5 Jun 2007 17:56:10 +0200 (CEST)
From: Waldek Hebisch
To: Martin Rubey
Subject: Re: Patches

Martin Rubey wrote:
> Waldek Hebisch writes:
> 
> > > below is a patch that has the behaviour as you described it, with the exception
> > > of polygamma, which now throws an error.  If you prefer that polygamma also
> > > allows differentiation with respect to the first argument, the change is
> > > trivial.  I don't have time to modify sttaylor right now.
> > > 
> > 
> > I tried the patch and I see a problem.
> 
> Wow!  I love your scrutinity!  Could you add this as a test, maybe? Here is a
> better patch.
> 

Thanks for the patch.  Applied to wh-sandbox revision 586.

\start
Date: 05 Jun 2007 11:01:19 -0500
From: Gabriel Dos Reis
To: Bill Page
Subject: Re: gcc mercurial repository

Bill Page writes:

| http://gcc.gnu.org/ml/gcc-patches/2007-05/msg01825.html
| 
| I have no wish to extend the source code repository controversy
| but I just thought I would mention that gcc now has a mercurial
| (hg) mirror. 

It also has a GIT repo mirror -- see the continuing propaganda that
erupted this month (and note too that no key player is involved in the
debate). 

Note however that the master repo is still SVN.

| This seems significant to me since Gaby has so
| strongly promoted SVN as the "best choice" based partly, I think,
| on it's adpotion by gcc.

As a "better choice" at the time.

\start
Date: 05 Jun 2007 11:14:04 -0500
From: Gabriel Dos Reis
To: Cliff Yapp
Subject: Re: The Axiom Library and Category Theory
Cc: Bill Page

Cliff Yapp writes:

| --- Bill Page wrote:
| 
| > The point of category theory as a foundation for mathematics
| > is that a lot of mathematics can and should be done long before
| > it becomes necessary to define what is meant by "set".
| 
| I have seen a few comments to the fact that it should be possible, in
| theory, to describe virtually all of mathematics within the framework
| of category theory.  If this is true, to me that makes it not only the
| obvious foundational choice for The Axiom Library but the essential
| one.

I've been trying to stay out of this debate...

In computational mathematics, we have computation which brings in
computer science.  Basing math implementation on set theory is, in
both conceptual and practical points of view, like using OO design in
the sense that everything derives from a universal Object type.  That
has been tried many times with failure -- but that won't stop people from
trying again.

On the other hand, Category Theory (or the Theory of Empty Set), does
not require set -- you can do things with small and large categories.
It only cares about *forms and structures*.  From an implementation
point of view, it means that you don't need to require all
computational objects to derive from a single universal base.  That
gives flexibility for composition -- something much harder and clumsy
with OO paradigms (all incarnations that have been tried so fart).

You can failures of OO thinking in the current library in forms of the
curious Abelian Monoids that are not Monoids.  No undergrade in math will
get away with that.  But, Axiom apparently does :-(

So from my perspective (*Computational Math*), the question is not on
what Math is based, but on what computation is based and which
framework allows for easy of composition and extension.

\start
Date: 05 Jun 2007 13:16:55 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Boot/SPAD package syntax

Gabriel Dos Reis writes:

> On Tue, 5 Jun 2007, Stephen Wilson wrote:
> 
> | Gabriel Dos Reis writes:
> | 
> | > Stephen Wilson writes:
> | > 
> | > | Gabriel Dos Reis writes:
> | > | 
> | > | > Stephen Wilson writes:
> | > | > 
> | > | > | Greetings,
> | > | > | 
> | > | > | I stumbled upon a curious facility of Boot and SPAD this evening.  I
> | > | > | do not recall, nor can I find, a reference to this in the list
> | > | > | archives or in any documentation.  Please correct me if I am wrong.
> | > | > 
> | > | > Since we have at least two versions of Boot around, you need to qualify
> | > | > your Boot by either "old" or "new" or variations thereof.
> | > | 
> | > | When I say Boot, I mean the Boot which is used in Axiom. 
> | > 
> | > Why do you think I meant something else?
> | 
> | The basic point is that, by the time AXIOMsys is generated, there is a
> | function BOOTTRAN::BOOTTOCL.  AFAIK, there are two such functions with
> | the same name defined in src/boot/ptyout.boot.pamphlet and
> | src/interp/util.lisp.pamphlet.  The latter version is the one which
> | lives in an Axiom image, and also depsys.  Thats the boot Im refering
> | to.
> 
> OK.
> We are back to my earlier point: When you say Boot, you need to qualify it.

I think I have a picture now. I perceive there to be three boots. Old,
New, and New-New (your improved boot).

> FYI, the boottocl defined src/interp is scheduled for death (as is depsys).  
> The plan is to migrate to bootsys.  See the comment in the source codes. 

I know you want this to occur.

[...]
> | Its not that I dont like your answer, its just that I havent gotten
> | one yet.
> 
> Looks to me that you're not interested in one.
> 
> Because the original message had several of them.

I was interested in a construct which I thought might be a
little-known feature.  I wanted to know what use it had, in the
contexts of SPAD and Boot.  I was clear in indicating that it can be
interpeted is a simple callout to Lisp.  

Regardless, I now understand the function of the operator. I _do_
appreciate you lending your insight.


[...]
> | > | Given the lack of specification, and given the lack of use of such a
> | > | feature, these are not bugs in Axiom by any stretch.
> | > 
> | > In this specific case, the bugs I've came across happen to be in the
> | > manually written Lisp parts, like restart -- I believe I already
> | > mentioned that.
> | 
> | Ok, I asked what the package call operator ' (or ::) means, and now
> | your just saying that if CL'FOO has undefined behaviour its a bug in
> | Axiom as opposed to a bug in the language semantics of Boot (or SPAD
> | for that matter).
> 
> That is not what I'm saying.

The only other interpretation I can come to by rereading the
discussion is that CL'FOO (or CL::FOO) is effectively an escape syntax
into Lisp, and as such Boot does not define semantics for such
constructs.  Similar to C's asm.

If this is correct, my appologies.  I was under some misunderstanding
that Boot was going to abstract away such things.  I really did think
it was possible that Boot had its own notion of `package', not
necessarily conincident with Lisp's.

[...]
> | What is a Boot package?  
> 
> A Boot package is no different from Lisp package: a name space.
> 
> Old Boot assumes that everything goes into the BOOTTRAN package.
> 
> New Boot assumes that people are responsible of pushing into the package
> the want.
> | How do you create one from Boot? 
> 
> I believe in CLTLx, a reference to a package creates that package if it 
> does not already exist.  Boot uses that semantics.

I understand now.

If anything, I would highly recommend Boot be updated to emit ANSI
Common Lisp.

[...]
> | I am primarily interested in the SPAD case.
> 
> In the specific case of Spad, that specific construct can go away.

Ok.  I thought as much.

> |  I was hoping for some
> | illustration of how the construct is put to use in SPAD.  As I feel
> | direct Lisp callouts from SPAD are a dangerous thing,
> 
> No more dangerous than pretend.
> 
> What we need is not to prevent people to call Lisp -- they will, and there 
> are legitimate cases where one needs to access the assembly-language
> (currently only Lisp).  What we need is an assembly-indepedent interface,

Yep. I agree in principle.


> | I need some
> | convincing that this construct is useful/necessary.  As I mentioned,
> | it would seem the construct is unused, and thus support could be
> | easily removed from the system.
> 
> Since the same parser is used to parse Old Boot, you'll also need more than
> superficial examination that no Boot codes uses it.

Yes.  I will modify the parser to emit a message on encountering the
construct.

\start
Date: 05 Jun 2007 19:28:40 +0200
From: Martin Rubey
To: Gabriel Dos Reis
Subject: Re: Comparison of CAS's?

Gabriel Dos Reis writes:

> Alasdair McAndrew writes:
> 
> | As far as I know, nobody has tried to compare CAS's since Michael Wester's
> | attempts in the 1990's. 
> 
> Not that I know of.  I believe Wester's work date back from late
> 1990s.  Everywhere else in computer science, that would be an
> eternity, but not in compuer algebra it seems...
> 
> I believe many of his issues with Axioms are still unresolved.

Yes. By comparison, the MuPAD team runs the test suite with every new release
and is now doing really well.

> You need to know all systems you compare in depth enough to make a fair
> comparision.  Furthermore, CASes are to solve problems.  So you have to come
> up with realistic problems to solve and express the solutions in "native
> styles" for each of them.

Well, this is one approach.  However, I think that this setting is not as
realistic as it may seem.  Many researchers I know indeed use one tool for
this, another one for that, and they avoid general purpose CAS altogether.
(Others don't, of course.  I'd say it's a small majority that uses mainly
general purpose CAS.)

Even though Mathematica does better than Axiom on Wester's suite, I prefer
Axiom, because it provides more possibilities, and after a while, I find it
easier to use.  A good example is the demonstration of Cayley's theorem on the
characteristic polynomial, as pointed out by Francois Maltey recently.

>From a user's perspective, I believe that MuPAD is currently the best CAS
around.  However, it's programming language has some severe limitations, which
Aldor does not have.

On the other hand, Axiom is free, and MuPAD is not, not even gratis anymore.

Apart from all that, if our goal was to make Axiom pass more tests of Wester's
suite, we need Gruntz algorithm for limits and an implementation of Zeilberger
for summation, as far as I recall.  However, I think that this is not quite the
right way to go about it.

\start
Date: Tue, 05 Jun 2007 18:41:03 +0000
From: Vladimir Bondarenko
To: list
Subject: Re: Comparison of CAS's?

> Gabriel Dos Reis writes:
>
>> Alasdair McAndrew writes:
>>
>> | As far as I know, nobody has tried to compare CAS's since Michael Wester's
>> | attempts in the 1990's.
>>
>> Not that I know of.  I believe Wester's work date back from late
>> 1990s.  Everywhere else in computer science, that would be an
>> eternity, but not in compuer algebra it seems...

Unfortunately, now, computer algebra is still in a deep mire. Even its 
most powerful representative, Mathematica 6, has (at least) thousands 
of distinct defects.

>>
>> I believe many of his issues with Axioms are still unresolved.

About Windows version, I'd speak about at least 20,000 points in the 
source code to fix.

>
> Yes. By comparison, the MuPAD team runs the test suite with every new release
> and is now doing really well.

According to SciFace, I am the "best beta tester" of MuPAD.

http://groups.google.com/group/sci.math.symbolic/msg/05085553a1489bcc

"is now doing really well."

If you are speaking about MuPAD 4, I fully disagree with this.

MuPAD 4 fails at the simplest calculus examples where Derive 6,
Maple 11 and Mathematica 6 succeed.

>
>> You need to know all systems you compare in depth enough to make a fair
>> comparision.  Furthermore, CASes are to solve problems.  So you have to come
>> up with realistic problems to solve and express the solutions in "native
>> styles" for each of them.
>
> Well, this is one approach.  However, I think that this setting is not as
> realistic as it may seem.  Many researchers I know indeed use one tool for
> this, another one for that, and they avoid general purpose CAS altogether.
> (Others don't, of course.  I'd say it's a small majority that uses mainly
> general purpose CAS.)
>
> Even though Mathematica does better than Axiom on Wester's suite, I prefer
> Axiom, because it provides more possibilities, and after a while, I find it
> easier to use.  A good example is the demonstration of Cayley's 
> theorem on the
> characteristic polynomial, as pointed out by Francois Maltey recently.
>
>> From a user's perspective, I believe that MuPAD is currently the best CAS
> around.

I am upset to hear this.

For practical, applied tasks, MuPAD 4 is the weakest CAS I have ever
seen over the last 10 years, with lots of regression bugs and new howlers.

If we speak about practical computational tasks, Mathematica 6 is a
kind of tipsy grad student... MuPAD 4 is a semi-crazy froshie.

> However, it's programming language has some severe limitations, which
> Aldor does not have.
>
> On the other hand, Axiom is free, and MuPAD is not, not even gratis anymore.
>
> Apart from all that, if our goal was to make Axiom pass more tests of 
> Wester's
> suite, we need Gruntz algorithm for limits and an implementation of 
> Zeilberger
> for summation, as far as I recall.  However, I think that this is not 
> quite the
> right way to go about it.
>
>
>
> Martin
>
>

I am shocked to observe that it looks like AXIOM developers have
an idea that "there are not so many defects in AXIOM".

If you will keep thinking the same way forgetting about the quality
assurance problems, you never reach your 30-years goal of getting a 
powerful dependable AXIOM.

Frankly, a big problem I see, there is not a single practical
QA engineer within AXIOM folks.

Many of you are top-notch, amazing developers. There is a huge gap 
between a developer and a QA engineer.

Best wishes,

Vladimir Bondarenko

VM and GEMM architect Co-founder, CEO, Mathematical Director

http://www.cybertester.com/  Cyber Tester, LLC 
http://maple.bug-list.org/   Maple Bugs Encyclopaedia 
http://www.CAS-testing.org/  CAS Testing

\start
Date: Tue, 5 Jun 2007 14:47:41 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Boot/SPAD package syntax

On Tue, 5 Jun 2007, Stephen Wilson wrote:

| I think I have a picture now. I perceive there to be three boots. Old,
| New, and New-New (your improved boot).

That picture might be inaccurate -- ask Tim about all the gory details. :-)

[...]

| > | > | Given the lack of specification, and given the lack of use of such a
| > | > | feature, these are not bugs in Axiom by any stretch.
| > | > 
| > | > In this specific case, the bugs I've came across happen to be in the
| > | > manually written Lisp parts, like restart -- I believe I already
| > | > mentioned that.
| > | 
| > | Ok, I asked what the package call operator ' (or ::) means, and now
| > | your just saying that if CL'FOO has undefined behaviour its a bug in
| > | Axiom as opposed to a bug in the language semantics of Boot (or SPAD
| > | for that matter).
| > 
| > That is not what I'm saying.
| 
| The only other interpretation I can come to by rereading the
| discussion is that CL'FOO (or CL::FOO) is effectively an escape syntax
| into Lisp, and as such Boot does not define semantics for such
| constructs.  Similar to C's asm.

C does not have asm.  C++ does.

Both Boot and Spad have the translation time )lisp system command
to excute Lisp codes, but that does not include runtime codes.

New Boot (Shoe) also has the esclamation (!) character as escape to Lisp:
You can include arbitrary non-toplevel Lisp forms (as you would include
arbitrary asm in C++) through the escape character.  

In "pure" Spad, "package calling" Lisp is the only effective means of going
at the assembly language level.  It is very useful occasionally.  For example,
it is used for SExpression.  I've used it to provide a Spad domain view
on top of the s-expression abstract syntax tree produced by the old
compiler.  I'm writing a new library for the new compiler.

| If this is correct, my appologies.  I was under some misunderstanding
| that Boot was going to abstract away such things.  I really did think
| it was possible that Boot had its own notion of `package', not
| necessarily conincident with Lisp's.

The original inventor of Boot did not go that far -- and I don't consider
going that far either.  I would do otherwise only if presented with
compeling cases.  If nothing else, the translation to Lisp should be as simple
as possible, and at the same time offering a higher level view of the codes.

[...]

| If anything, I would highly recommend Boot be updated to emit ANSI
| Common Lisp.

I'm working on that.

[...]

| Yes.  I will modify the parser to emit a message on encountering the
| construct.

Exactly what I would have done.
Thanks!

\start
Date: Tue, 5 Jun 2007 14:51:54 -0500 (CDT)
From: Gabriel Dos Reis
To: Martin Rubey
Subject: Re: Comparison of CAS's?

On Tue, 5 Jun 2007, Martin Rubey wrote:

| From a user's perspective, I believe that MuPAD is currently the best CAS
| around. 

Yes, that is why I hesitated long between MuPAD an Axiom.  I was a little
unhappy with MuPAD's choice og going non-"free" for academic purposes -- but I
believe I understand the motivations.

| However, it's programming language has some severe limitations, which
| Aldor does not have.

Compared to Maple's programming language, I'd still take MuPAD.

| On the other hand, Axiom is free, and MuPAD is not, not even gratis anymore.

Yup. :-(

| Apart from all that, if our goal was to make Axiom pass more tests of Wester's
| suite, we need Gruntz algorithm for limits and an implementation of Zeilberger
| for summation, as far as I recall.  However, I think that this is not quite the
| right way to go about it.

Well, people will read Wester's book (and I hope they do!) and will wonder.
While I don't believe The Goal of Axiom is pass that testsuite, I believe
that Axiom should pass that testsuite.

\start
Date: Tue, 05 Jun 2007 21:58:41 +0200
From: Ralf Hemmecke
To: Vladimir Bondarenko
Subject: QA engineer, was: Re: Comparison of CAS's?

> Frankly, a big problem I see, there is not a single practical
> QA engineer within AXIOM folks.

If you know a QA engineer who wants to contribute to Axiom's QA send him 
to us. Our sources live in the open. Everyone is free to contribute.

If you qualify as a QA engineer, contribute yourself. Just criticizing 
that Axiom has no QA engineer does not contribute anything to make Axiom 
better.

\start
Date: Tue, 5 Jun 2007 22:08:15 +0200 (CEST)
From: Franz Lehner
To: Waldek Hebisch
Subject: Re: wh-sandbox and aldor

> I looked at the build logs and at src_aldor2.tgz.  AFAICS the
> very first line in the log is wrong.  Namely, the Makefile
> assumes old directory structure.  Currently both in wh-sandbox
> and in build-improvements OBJ directory is gone.  Supporting
> programs are in build/x86_64-unknown-linux/bin (where
> x86_64-unknown-linux must be replaced by system name).  wh-sandbox
> still uses INT directory, but it is going to change
> (to match build-improvements).
After creating OBJ and some linking here and there I eventually succeeded 
in compiling src_aldor. Still this does not seem to be enough, as it says

)co aux
     Compiling AXIOM source code from file /home/lehner/ax/lib/aux.as
        using AXIOM-XL compiler and options
-O -Fasy -Fao -Flsp -laxiom -Mno-AXL_W_WillObsolete -DAxiom -Y 
$AXIOM/algebra
        Use the system command )set compiler args to change these
        options.

     >> System error:
     The function GETENV is undefined.

\start
Date: Tue, 5 Jun 2007 13:09:35 -0700 (PDT)
From: Cliff Yapp
To: list
Subject: Re: Comparison of CAS's?

--- Vladimir Bondarenko wrote:

> I am shocked to observe that it looks like AXIOM developers have
> an idea that "there are not so many defects in AXIOM".

I don't think this is the case - rather, we feel that Axiom has the
long term potential to provide a robust environment on which to build. 
The system in its current form obviously has many defects.
 
> If you will keep thinking the same way forgetting about the quality
> assurance problems, you never reach your 30-years goal of getting a 
> powerful dependable AXIOM.

That goal requires foundational work before it can be practically
attacked.  In particular, either SPAD or Aldor (whatever is ultimately
chosen) MUST be clearly and precisely defined.  Arguably, we also need
to integrate either ACL2 or some other such system as well - eventually
we should provide the ground work for provable correctness.

Quality assurance is necessary, but it is not sufficient to have total
confidence in a system.  What IS required to have total confidence in a
system is still (as far as I can tell) a legitimate subject for
research.  Some people feel this is not a possible goal, but my hunch
is that computer produced results can achieve a level of trustability
that would compare favorably to human correctness auditing. MAKING that
system is an immense challenge, but the potential benefits are also
immense.

> Frankly, a big problem I see, there is not a single practical
> QA engineer within AXIOM folks.

To be honest, I don't think we are at that stage yet.  Attacking the
Algebra in a major way will come once we have a foundation within which
we can attack it successfully (i.e. with some confidence solutions to
problems will remain viable in the long term.)  The resolution of the
SPAD vs. Aldor decision is an obviously critical step in that process.

QA starts when there is expectation that the product you have can meet
such tests successfully - if you KNOW it can't, then there is little
point.  You fix what you already know is broken, and then when you
think you have it you hit it with QA testing.  We have a Long List of
things that we know are broken.

Paul Dietz wrote a very interesting utility which generated random
valid lisp code as a way to stress Lisp compilers and their compilance
with the ANSI standard.  Perhaps a study of that code would suggest
ways to do something similar for mathematical problems.  But I
personally have no expectation that Axiom is ready for that level of
testing - that comes later in this process.

\start
Date: 05 Jun 2007 16:44:42 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Boot/SPAD package syntax

Gabriel Dos Reis writes:

> On Tue, 5 Jun 2007, Stephen Wilson wrote:
> 
> | I think I have a picture now. I perceive there to be three boots. Old,
> | New, and New-New (your improved boot).
> 
> That picture might be inaccurate -- ask Tim about all the gory details. :-)

True, true.  In time I hope to get a complete picture.

[...]
> C does not have asm.  C++ does.

I just had to check. Geeze, details, details :)

> Both Boot and Spad have the translation time )lisp system command
> to excute Lisp codes, but that does not include runtime codes.
> 
> New Boot (Shoe) also has the esclamation (!) character as escape to Lisp:
> You can include arbitrary non-toplevel Lisp forms (as you would include
> arbitrary asm in C++) through the escape character.  

Ok. Thanks.

> In "pure" Spad, "package calling" Lisp is the only effective means of going
> at the assembly language level.  It is very useful occasionally.  For example,
> it is used for SExpression.  I've used it to provide a Spad domain view
> on top of the s-expression abstract syntax tree produced by the old
> compiler.  I'm writing a new library for the new compiler.

I would like to describe a relatively new idea (for me).  It will
likely take a long time to see a prototype.

As I sit on the Lisp side of things this does not jive with a boot
implementation directly.  Perhaps it is of some interest to you regardless.

With this comes the blatent assumption that calling out to the Lisp
level requires detailed understanding of how SPAD entities are
represented, and how the underlying Lisp image is designed. 

I am considering the mechainics involved in treating domains and
categories as well-defined lisp objects, complete with api's and
protocals to manage their runtime manipulation, among other things.

Instead of a package call to Lisp, Im considering the possibility of
defining SPAD functions in Lisp, and making them available as domain
exports `transparently'.

Given a prototype:

 (ensure-domain-export <export-name> <domain-obj> <axiom-type-specifier>
    ...)

The basic idea would be to enrich the system with a new export
(labeled with the `export-designator' <export-name>) for the domain
object <domain-obj>, satisfying a certain type represented as the
object <axiom-type-specifier>.

The consequence is that this appears as a `native' spad export.  The
<axiom-type-specifier> ensures that call sites are staticly type
checked.  Types of return values would be dynamically asserted (this
is a low-level interface. Trust the programmer).

One might find the name ENSURE-DOMAIN-EXPORT reminiscent of those
provided by the CLOS MOP.  This is intentional.

I feel that SPAD should have an (easily extensible) set of primitive
domains and categories upon which all others ultimately derive.  As in
most programming languages, there is no way to define such objects
directly.  This is one approach which I suspect alleviates the need
for escape to Lisp.

[...]
> | Yes.  I will modify the parser to emit a message on encountering the
> | construct.
> 
> Exactly what I would have done.

I will let you know if I encounter a dependence on the package-call
operator in the extant code.

\start
Date: Tue, 05 Jun 2007 20:52:10 +0000
From: Vladimir Bondarenko
To: list
Subject: Re: Comparison of CAS's?

Quoting Cliff Yapp:

> --- Vladimir Bondarenko wrote:

CY> I don't think this is the case

I know this; to an extent, it was my provocative overstatement. I'd 
rather like to hear some comments from AXIOM developers.

CY>  rather, we feel that Axiom has the long term CY>  potential to 
provide a robust environment on CY>  which to build.

An outsider, just an AXIOM userm I feel identically.
I do feel genuine potential AXIOM can reach, in a
long run.

CY>  The system in its current form obviously has CY>  many defects.

Right you are. Lots of these defect can be detected,
minimized, classified in an automated mode.

CY> That goal requires foundational work before CY> it can be 
practically attacked.

Again, I much agree with you.

CY>  my hunch is that computer produced results can CY>  achieve a 
level of trustability that would CY>  compare favorably to human 
correctness auditing.

I know that you ARE right. Even more, I know we will
see this within just 20 years.

CY>  MAKING that system is an immense challenge, but CY>  the potential 
benefits are also immense.

A wonderful and precise wording!

Cheers,

Vladimir


>
>> I am shocked to observe that it looks like AXIOM developers have
>> an idea that "there are not so many defects in AXIOM".
>
> I don't think this is the case - rather, we feel that Axiom has the
> long term potential to provide a robust environment on which to build.
> The system in its current form obviously has many defects.
>
>> If you will keep thinking the same way forgetting about the quality
>> assurance problems, you never reach your 30-years goal of getting a
>> powerful dependable AXIOM.
>
> That goal requires foundational work before it can be practically
> attacked.  In particular, either SPAD or Aldor (whatever is ultimately
> chosen) MUST be clearly and precisely defined.  Arguably, we also need
> to integrate either ACL2 or some other such system as well - eventually
> we should provide the ground work for provable correctness.
>
> Quality assurance is necessary, but it is not sufficient to have total
> confidence in a system.  What IS required to have total confidence in a
> system is still (as far as I can tell) a legitimate subject for
> research.  Some people feel this is not a possible goal, but my hunch
> is that computer produced results can achieve a level of trustability
> that would compare favorably to human correctness auditing. MAKING that
> system is an immense challenge, but the potential benefits are also
> immense.
>
>> Frankly, a big problem I see, there is not a single practical
>> QA engineer within AXIOM folks.
>
> To be honest, I don't think we are at that stage yet.  Attacking the
> Algebra in a major way will come once we have a foundation within which
> we can attack it successfully (i.e. with some confidence solutions to
> problems will remain viable in the long term.)  The resolution of the
> SPAD vs. Aldor decision is an obviously critical step in that process.
>
> QA starts when there is expectation that the product you have can meet
> such tests successfully - if you KNOW it can't, then there is little
> point.  You fix what you already know is broken, and then when you
> think you have it you hit it with QA testing.  We have a Long List of
> things that we know are broken.
>
> Paul Dietz wrote a very interesting utility which generated random
> valid lisp code as a way to stress Lisp compilers and their compilance
> with the ANSI standard.  Perhaps a study of that code would suggest
> ways to do something similar for mathematical problems.  But I
> personally have no expectation that Axiom is ready for that level of
> testing - that comes later in this process.

\start
Date: Tue, 5 Jun 2007 15:59:50 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Boot/SPAD package syntax

On Tue, 5 Jun 2007, Stephen Wilson wrote:

| Gabriel Dos Reis writes:
| 
| > On Tue, 5 Jun 2007, Stephen Wilson wrote:
| > 
| > | I think I have a picture now. I perceive there to be three boots. Old,
| > | New, and New-New (your improved boot).
| > 
| > That picture might be inaccurate -- ask Tim about all the gory details. :-)
| 
| True, true.  In time I hope to get a complete picture.
| 
| [...]
| > C does not have asm.  C++ does.
| 
| I just had to check. Geeze, details, details :)

I've been reading too many C and C++ technical details for over a decade :-)

[...]

| As I sit on the Lisp side of things this does not jive with a boot
| implementation directly.  Perhaps it is of some interest to you regardless.
| 
| With this comes the blatent assumption that calling out to the Lisp
| level requires detailed understanding of how SPAD entities are
| represented, and how the underlying Lisp image is designed. 
| 
| I am considering the mechainics involved in treating domains and
| categories as well-defined lisp objects, complete with api's and
| protocals to manage their runtime manipulation, among other things.

Yes, this is part of what I have been calling The Axiom Virtual Machine.
I have not sent a complete proposal to the list, but it is one I'm working 
on.  The specification includes things like abstract specification for 
categories, domains, packages, and Spad typed abstract syntax tree for Spad
programs, along with runtime APIs -- the Axiom Virtual Machine Instruction
Set.   It will provides specification for the layout of the 
compilation file for a Spad program -- much like the specification of a JVM
class file.

[...]

| > | Yes.  I will modify the parser to emit a message on encountering the
| > | construct.
| > 
| > Exactly what I would have done.
| 
| I will let you know if I encounter a dependence on the package-call
| operator in the extant code.

\start
Date: Tue, 05 Jun 2007 17:05:56 -0400
From: Bill Page
To: Gabriel Dos Reis
Subject: Re: The Axiom Library and Category Theory

Quoting Gabriel Dos Reis wrote:

> ... 
> On the other hand, Category Theory (or the Theory of Empty Set),
> does not require set -- you can do things with small and large
> categories. 

Just out of curiosity I did a quick web search for the phrase
"Theory of Empty Set" and only turned up your paper for LCSD'05:

   "What is Generic Programming?"
   http://www.cs.rpi.edu/research/pdf/06-12.pdf

where you and Jarvi wrote:

   Category theory - also occasionally referred to as "abstract
   nonesense" or "the theory of empty set" -- has found an
   unreasonably  effective application in Computer Science. 

The phrase "abstract nonsense" is well known, e.g. 

http://en.wikipedia.org/wiki/Abstract_nonsense

but I had not heard the phrase "theory of empty set" before. 
Can you tell where else you have seen this phrase used in
reference to category theory?

> It only cares about *forms and structures*.  From an implementation
> point of view, it means that you don't need to require all computational
> objects to derive from a single universal base.  That gives flexibility for
> composition -- something much harder and clumsy with OO paradigms
> (all incarnations that have been tried so far). 
>

I think you are right. Although the Axiom language might have the
ability to avoid this "crisis", the current Axiom library seems to at
least partly embody a more conventional OO approach. 

> You can failures of OO thinking in the current library in forms of the
> curious Abelian Monoids that are not Monoids.  No undergrade in
> math will get away with that.  But, Axiom apparently does :-(
>

Yes, this is a serious problem with the Axiom library that has been
recognized for some time. I think it is time we tried a little harder
to do something about it. 

In the thread:

http://lists.nongnu.org/archive/html/axiom-math/2007-05/msg00015.html

we were talking about the possibility of defining the monoid unit as
a higher order functional. Have you had any more thoughts about
this?

\start
Date: 05 Jun 2007 17:28:40 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Boot/SPAD package syntax

It would seem that we have similar thoughts on how Axiom can move
forward.

Though our approaches differ, I do look forward to future discussions
`over the fence'.

\start
Date: Wed, 6 Jun 2007 00:04:01 +0200 (CEST)
From: Waldek Hebisch
To: Franz Lehner
Subject: Re: wh-sandbox and aldor

Franz Lehner wrote:
> 
> > I looked at the build logs and at src_aldor2.tgz.  AFAICS the
> > very first line in the log is wrong.  Namely, the Makefile
> > assumes old directory structure.  Currently both in wh-sandbox
> > and in build-improvements OBJ directory is gone.  Supporting
> > programs are in build/x86_64-unknown-linux/bin (where
> > x86_64-unknown-linux must be replaced by system name).  wh-sandbox
> > still uses INT directory, but it is going to change
> > (to match build-improvements).
> After creating OBJ and some linking here and there I eventually succeeded 
> in compiling src_aldor. Still this does not seem to be enough, as it says
> 
> )co aux
>      Compiling AXIOM source code from file /home/lehner/ax/lib/aux.as
>         using AXIOM-XL compiler and options
> -O -Fasy -Fao -Flsp -laxiom -Mno-AXL_W_WillObsolete -DAxiom -Y 
> $AXIOM/algebra
>         Use the system command )set compiler args to change these
>         options.
> 
>      >> System error:
>      The function GETENV is undefined.
> 

This is due to recent change in wh-sandbox.  The following patch
should fix this problem:

diff -u wh-sandbox2.bb2/src/interp/i-syscmd.boot.pamphlet wh-sandbox2/src/interp/i-syscmd.boot.pamphlet
--- wh-sandbox2.bb2/src/interp/i-syscmd.boot.pamphlet	2007-06-05 23:42:04.000000000 +0200
+++ wh-sandbox2/src/interp/i-syscmd.boot.pamphlet	2007-06-05 23:49:39.000000000 +0200
@@ -657,7 +643,8 @@
     if ^beQuiet then sayKeyedMsg("S2IZ0038A",[namestring args, asharpArgs])
 
     command :=
-<<remove TRUENAME>>
+      STRCONC(STRCONC(getEnv('"ALDORROOT"),'"/bin/"),_
+                    "aldor ", asharpArgs, '" ", namestring args)
     rc := OBEY command
 
     if (rc = 0) and doCompileLisp then

\start
Date: Tue, 5 Jun 2007 20:58:27 -0500
From: Tim Daly
To: list
Subject: changes to SVN/git

I've applied and tested the changes for the SVN copy bug.

I've removed the daly-specific code from src/regress/REGRESS.

I've diffed the trunk/axiom, branches/daly, and git versions.
branches/daly is now for my own use and should be ignored.

"silver" is trunk/axiom and all further commits will go there.

\start
Date: Tue, 5 Jun 2007 19:11:40 -0700 (PDT)
From: Cliff Yapp
To: Tim Daly, list
Subject: Re: changes to SVN/git

I'll change the AxiomSources page once I get access to my machine again
unless someone beats me to it (I don't have my Zope password with me.) 
The silver SVN link needs to be switched to trunk/axiom.

Are we going to continue syncing google or is that effort no longer
ongoing?

--- Tim Daly wrote:

> I've applied and tested the changes for the SVN copy bug.
> 
> I've removed the daly-specific code from src/regress/REGRESS.
> 
> I've diffed the trunk/axiom, branches/daly, and git versions.
> branches/daly is now for my own use and should be ignored.
> 
> "silver" is trunk/axiom and all further commits will go there.

\start
Date: 05 Jun 2007 22:30:07 -0500
From: Gabriel Dos Reis
To: Cliff Yapp
Subject: Re: changes to SVN/git

Cliff Yapp writes:

| Are we going to continue syncing google or is that effort no longer
| ongoing?

People at Goolge were unhappy with our current practice of putting
tarballs in repo.  I'd suggest waiting till we find a common ground
before restarting the mirror.

\start
Date: 05 Jun 2007 22:30:17 -0500
From: Gabriel Dos Reis
To: Tim Daly
Subject: Re: changes to SVN/git

Tim Daly writes:

| I've applied and tested the changes for the SVN copy bug.
| 
| I've removed the daly-specific code from src/regress/REGRESS.
| 
| I've diffed the trunk/axiom, branches/daly, and git versions.
| branches/daly is now for my own use and should be ignored.
| 
| "silver" is trunk/axiom and all further commits will go there.

Thanks!

\start
Date: Tue, 5 Jun 2007 22:36:00 -0500
From: Tim Daly
To: Waldek Hebisch
Subject: asq change

Waldek,

To introduce your asq.c file what is required?
Do I need to rebuild all of the databases by hand?
Does it depend on your "database from scratch" method?

\start
Date: Tue, 5 Jun 2007 22:53:38 -0500 (CDT)
From: Gabriel Dos Reis
To: Waldek Hebisch
Subject: Re: clisp and sbcl

On Tue, 29 May 2007, Waldek Hebisch wrote:

| > On Mon, 28 May 2007, Waldek Hebisch wrote:
| > 
| > | (defun |evalSharpOne| (x |#1|) (declare (special |#1|))
| > |    (EVAL `(let () (declare (special |#1|) ,x))))
| > 
| > Have you tried this variant?  It looks "reasonable" to me.
| > 
| 
| There is a little problem with parentheses, it should be:
| 
| (defun |evalSharpOne| (x |#1|)
|    (declare (special |#1|))
|    (EVAL `(let () (declare (special |#1|)) ,x)))
| 
| Using version above compiler warnings go away.  But I did not
| put it trough full test cycle.

Waldek --

  How was the full test cycle?

\start
Date: Wed, 6 Jun 2007 11:22:55 +0200 (CEST)
From: Waldek Hebisch
To: Gabriel Dos Reis
Subject: Re: clisp and sbcl

Gabriel Dos Reis wrote:
> On Tue, 29 May 2007, Waldek Hebisch wrote:
> | There is a little problem with parentheses, it should be:
> | 
> | (defun |evalSharpOne| (x |#1|)
> |    (declare (special |#1|))
> |    (EVAL `(let () (declare (special |#1|)) ,x)))
> | 
> | Using version above compiler warnings go away.  But I did not
> | put it trough full test cycle.
> 
> Waldek --
> 
>   How was the full test cycle?
> 

It passed all my tests, I put it in current wh-sandbox.

\start
Date: Wed, 6 Jun 2007 11:32:28 +0200 (CEST)
From: Waldek Hebisch
To: Tim Daly
Subject: Re: asq change

> Waldek,
> 
> To introduce your asq.c file what is required?
> Do I need to rebuild all of the databases by hand?
> Does it depend on your "database from scratch" method?
> 
> Tim
> 

Version in wh-sandbox should work in all version of Axiom,
there are no dependencies.

\start
Date: Wed, 6 Jun 2007 04:42:34 -0500 (CDT)
From: Gabriel Dos Reis
To: Waldek Hebisch
Subject: Re: clisp and sbcl

On Wed, 6 Jun 2007, Waldek Hebisch wrote:

| Gabriel Dos Reis wrote:
| > On Tue, 29 May 2007, Waldek Hebisch wrote:
| > | There is a little problem with parentheses, it should be:
| > | 
| > | (defun |evalSharpOne| (x |#1|)
| > |    (declare (special |#1|))
| > |    (EVAL `(let () (declare (special |#1|)) ,x)))
| > | 
| > | Using version above compiler warnings go away.  But I did not
| > | put it trough full test cycle.
| > 
| > Waldek --
| > 
| >   How was the full test cycle?
| > 
| 
| It passed all my tests, I put it in current wh-sandbox.

Great!

\start
Date: Wed, 6 Jun 2007 11:45:48 +0200 (CEST)
From: Franz Lehner
To: Waldek Hebisch
Subject: Re: wh-sandbox and aldor

> This is due to recent change in wh-sandbox.  The following patch
> should fix this problem:
Thanks, that did it.
Below are (roughly, it took some trial and error to figure it out) the 
steps which made it work, perhaps it can be useful to others.

Franz


svn co https://axiom.svn.sourceforge.net/svnroot/axiom/branches/wh-sandbox
cd wh-sandbox
svn co https://axiom.svn.sourceforge.net/svnroot/axiom/branches/build-improvements/gcl gcl
cd zips
wget https://axiom.svn.sourceforge.net/svnroot/axiom/trunk/axiom/zips/noweb-2.10a.tgz

#
# Two patches kindly suggested by Waldek Hebisch
#
#apply patch to enable checking
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+++ wh-sandbox/src/interp/interp-proclaims.lisp
00000 +0200
@@ -1,4 +1,6 @@
-
+(eval-when (:execute :compile-toplevel :load-toplevel)
+  (proclaim
+    '(optimize (safety 3))))
  (IN-PACKAGE "USER")
  (PROCLAIM '(FTYPE (FUNCTION (*) (VALUES T T)) BOOT:|ReadLine|))
  (PROCLAIM

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

#apply patch to make ALDOR work
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+++ wh-sandbox2/src/interp/i-syscmd.boot.pamphlet
@@ -657,7 +643,8 @@
      if ^beQuiet then sayKeyedMsg("S2IZ0038A",[namestring args, asharpArgs])

      command :=
-<<remove TRUENAME>>
+      STRCONC(STRCONC(getEnv('"ALDORROOT"),'"/bin/"),_
+                    "aldor ", asharpArgs, '" ", namestring args)
      rc := OBEY command

      if (rc = 0) and doCompileLisp then
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



cd ../..
mkdir ax-build
cd ax-build
../wh-sandbox/configure 
make

#get some coffee
#the build took 12 hours on AMD Athlon(tm) 64 Processor 3000+

#Aldor
export AXIOM=$WHEREVERYOUARE/ax-build/target/x86_64-unknown-linux
export ALDORROOT=<ALDOR-directory>/linux/1.0.2

(cd $AXIOM/bin; ln -s ../../../build/scripts/document .)
mkdir -p obj/x86_64-unknown-linux
(cd obj/x86_64-unknown-linux ; ln -s ../../build/x86_64-unknown-linux/bin .)
(cd obj/x86_64-unknown-linux$; ln -s ../../src/interp/ .)

cd src
#for axiom.sty
ln -s ../../wh-sandbox/src/scripts/ .

tar xzf ../../src_aldor2.tgz
cd aldor
ln -s ../../build/x86_64-unknown-linux .

#extract the Makefiles
for pp in *.pamphlet; do document $pp;done

make
#after error Martin Rubey recommends:
# (I think it does not occur if all the pamphlets are extracted at once
# as indicated in the loop above, but you never know)

touch ../../int/aldor/dep_spad.stamp
document Make.functions.pamphlet
make

#cross your fingers

\start
Date: 06 Jun 2007 11:52:44 +0200
From: Martin Rubey
To: Franz Lehner
Subject: Re: wh-sandbox and aldor

Franz Lehner writes:

> > This is due to recent change in wh-sandbox.  The following patch
> > should fix this problem:
> Thanks, that did it.

superb! and thanks for your notes.  I'll put a link to this thread
AldorForAxiom immediately.

Mayn thanks for your patience,

\start
Date: 06 Jun 2007 05:05:26 -0500
From: Gabriel Dos Reis
To: Franz Lehner
Subject: Re: wh-sandbox and aldor

Franz Lehner writes:

[...]

| cd ../..
| mkdir ax-build
| cd ax-build
| ../wh-sandbox/configure make
| 
| #get some coffee
| #the build took 12 hours on AMD Athlon(tm) 64 Processor 3000+
| 
| #Aldor
| export AXIOM=$WHEREVERYOUARE/ax-build/target/x86_64-unknown-linux
| export ALDORROOT=<ALDOR-directory>/linux/1.0.2
| 
| (cd $AXIOM/bin; ln -s ../../../build/scripts/document .)
| mkdir -p obj/x86_64-unknown-linux
| (cd obj/x86_64-unknown-linux ; ln -s ../../build/x86_64-unknown-linux/bin .)
| (cd obj/x86_64-unknown-linux$; ln -s ../../src/interp/ .)

In the past, I have documented that you can just lndir in the ax-build
dir and have everything setup...

\start
Date: Wed, 6 Jun 2007 04:44:48 -0700
From: Mike Hansen
To: list
Subject: Problems building wh-sandbox

Hello,
I'm trying to build the wh-sandbox tree, but get the following error
when running 'make'.  I'm not familiar enough with the build process
and LISP to effectively figure out the problem.  Here is the error:

>echo '(compiler::link (quote ("axiom-package.lisp" "axiom-lisp.o")) "lisp" ' \
              ' (format nil "(progn (let ((*load-path* (cons ~S *load-path*))'\
                                        ' (si::*load-types* ~S))' \
                                       ' (compiler::emit-fn t))' \
                                  ' (when (fboundp (quote si::sgc-on))' \
                                        ' (si::sgc-on t))' \
                                  ' (setq compiler::*default-system-p* t))"' \
                      ' si::*system-directory* (quote (list ".lsp")))' \
               '
"/opt/axiom/wh-build/src/lisp/../.././src/lib/bsdsignal.o
/opt/axiom/wh-build/src/lisp/../.././src/lib/cfuns-c.o
/opt/axiom/wh-build/src/lisp/../.././src/lib/sockio-c.o  -lutil")' \
            | /usr/bin/gcl
GCL (GNU Common Lisp)  2.6.7 CLtL1    Nov 10 2006 14:25:02
Source License: LGPL(gcl,gmp), GPL(unexec,bfd,xgcl)
Binary License:  GPL due to GPL'ed components: (XGCL READLINE BFD UNEXEC)
Modifications of this banner must retain notice of a compatible license
Dedicated to the memory of W. Schelter

Use (help) to get some basic information on how to use GCL.
Temporary directory for compiler files set to /tmp/

>GCL (GNU Common Lisp)  April 1994  262144 pages
Building symbol table for /opt/axiom/wh-build/src/lisp/raw_lisp ..
I'm not an object
Lisp initialization failed.

"lisp"

>/usr/bin/install -c lisp /opt/axiom/wh-build/build/x86_64-unknown-linux/bin
/usr/bin/install: cannot stat `lisp': No such file or directory
make: *** [do_it.gcl] Error 1


How would I go about fixing this?

\start
Date: 06 Jun 2007 14:23:07 +0200
From: Martin Rubey
To: list
Subject: Bug #359

Dear Ralf,

> Why? The reason is the ::Boolean. That leads to a type mismatch. You
> effectively ask for a function with the signature

> map: (L -> Boolean, L) -> List Boolean

(where L ==> List Equation Polynomial Integer.) I think you meant to write

  map: (Equation Polynomial Integer -> Boolean, L) -> List Boolean

> but Axiom does not provide such a function.

In case the above was indeed a typo, this is not true, ListFunctions2 has such
a map:

(1) -> )sh ListFunctions2
 ListFunctions2(A: Type,B: Type)  is a package constructor
 Abbreviation for ListFunctions2 is LIST2 
 This constructor is exposed in this frame.
 Issue )edit /users/rubey/axiom/target/i686-pc-linux//../../src/algebra/LIST2.spad to see algebra source code for LIST2 

------------------------------- Operations --------------------------------
 map : ((A -> B),List A) -> List B    
 reduce : (((A,B) -> B),List A,B) -> B
 scan : (((A,B) -> B),List A,B) -> List B

\start
Date: Wed, 6 Jun 2007 14:36:51 +0200 (CEST)
From: Waldek Hebisch
To: Mike Hansen
Subject: Re: Problems building wh-sandbox

> Hello,
> I'm trying to build the wh-sandbox tree, but get the following error
> when running 'make'.  I'm not familiar enough with the build process
> and LISP to effectively figure out the problem.  Here is the error:
> 
> >echo '(compiler::link (quote ("axiom-package.lisp" "axiom-lisp.o")) "lisp" ' \
>               ' (format nil "(progn (let ((*load-path* (cons ~S *load-path*))'\
>                                         ' (si::*load-types* ~S))' \
>                                        ' (compiler::emit-fn t))' \
>                                   ' (when (fboundp (quote si::sgc-on))' \
>                                         ' (si::sgc-on t))' \
>                                   ' (setq compiler::*default-system-p* t))"' \
>                       ' si::*system-directory* (quote (list ".lsp")))' \
>                '
> "/opt/axiom/wh-build/src/lisp/../.././src/lib/bsdsignal.o
> /opt/axiom/wh-build/src/lisp/../.././src/lib/cfuns-c.o
> /opt/axiom/wh-build/src/lisp/../.././src/lib/sockio-c.o  -lutil")' \
>             | /usr/bin/gcl
> GCL (GNU Common Lisp)  2.6.7 CLtL1    Nov 10 2006 14:25:02
> Source License: LGPL(gcl,gmp), GPL(unexec,bfd,xgcl)
> Binary License:  GPL due to GPL'ed components: (XGCL READLINE BFD UNEXEC)
> Modifications of this banner must retain notice of a compatible license
> Dedicated to the memory of W. Schelter
> 
> Use (help) to get some basic information on how to use GCL.
> Temporary directory for compiler files set to /tmp/
> 
> >GCL (GNU Common Lisp)  April 1994  262144 pages
> Building symbol table for /opt/axiom/wh-build/src/lisp/raw_lisp ..
> I'm not an object
> Lisp initialization failed.
> 
> "lisp"
> 
> >/usr/bin/install -c lisp /opt/axiom/wh-build/build/x86_64-unknown-linux/bin
> /usr/bin/install: cannot stat `lisp': No such file or directory
> make: *** [do_it.gcl] Error 1
> 
> 
> How would I go about fixing this?
> 

This looks like problem with your gcl installation.  The message tells
you that the file /opt/axiom/wh-build/src/lisp/raw_lisp is not a valid
object file.  But gcl should have made a fresh
/opt/axiom/wh-build/src/lisp/raw_lisp just in previous step...

I did not see such problem before, but I have seen other problems
doing this step using gcl-2.6.7 bundled with Linux distributions.
For me the problems went away when I used gcl that I compiled myself.

So, I would suggest that you fetch gcl source from axiom repository:

cd wh-sandbox
svn co https://axiom.svn.sourceforge.net/svnroot/axiom/branches/build-improvements/gcl gcl

and start a fresh build.

BTW:  It is better to build in separate directory.

\start
Date: Wed, 06 Jun 2007 14:40:11 +0200
From: Ralf Hemmecke
To: Martin Rubey
Subject: Re: Bug #359

On 06/06/2007 02:23 PM, Martin Rubey wrote:
> Dear Ralf,
> 
>> Why? The reason is the ::Boolean. That leads to a type mismatch. You
>> effectively ask for a function with the signature
> 
>> map: (L -> Boolean, L) -> List Boolean
> 
> (where L ==> List Equation Polynomial Integer.) I think you meant to write
> 
>   map: (Equation Polynomial Integer -> Boolean, L) -> List Boolean
> 
>> but Axiom does not provide such a function.
> 
> In case the above was indeed a typo, this is not true, ListFunctions2 has such
> a map:
> 
> (1) -> )sh ListFunctions2
>  ListFunctions2(A: Type,B: Type)  is a package constructor
>  Abbreviation for ListFunctions2 is LIST2 
>  This constructor is exposed in this frame.
>  Issue )edit /users/rubey/axiom/target/i686-pc-linux//../../src/algebra/LIST2.spad to see algebra source code for LIST2 
> 
> ------------------------------- Operations --------------------------------
>  map : ((A -> B),List A) -> List B    
>  reduce : (((A,B) -> B),List A,B) -> B
>  scan : (((A,B) -> B),List A,B) -> List B

Thanks, I've reverted my comment.

The only thing I would say is that FiniteLinearAggregateFunctions2 where 
map is finally implemented looks much more complicated than just writing

[beta a for a in la]

instead of

map(beta, la).

\start
Date: Wed, 06 Jun 2007 14:44:00 +0200
From: Ralf Hemmecke
To: Waldek Hebisch
Subject: Re: Problems building wh-sandbox

> and start a fresh build.
> 
> BTW:  It is better to build in separate directory.

Why don't people say what commands one should use for "out of source build".

http://wiki.axiom-developer.org/BuildAxiom

is missing that completely. Could somebody add a bit of wisdom to that page?

\start
Date: Wed, 6 Jun 2007 06:01:45 -0700
From: Mike Hansen
To: list
Subject: Re: Problems building wh-sandbox

I'm building in a directory wh-build which is different than
wh-sandbox.  I removed my copy of gcl and tried to have it build gcl
from source.  After fixing problems with bfd.h and bfdlink.h by adding
--disable-dynsysbfd --disable-statsysbfd to GCLOPTS, I get the
following error while building GCL:

cp init_pre_gcl.lsp.in init_pre_gcl.lsp.tmp
touch raw_pre_gcl_map
gcc -o raw_pre_gcl  \
               -L.  -Wl,-Map raw_pre_gcl_map   -lpre_gcl -lm  -lgmp
-lreadline -lncurses -lc -lgclp
cat init_pre_gcl.lsp.tmp | sed \
               -e "s#@LI-VERS@#(`cat ../majvers`.`cat ../minvers`) `date`#1" \
               -e "s#@LI-EXTVERS@#`cat ../minvers | cut -f2 -d.`#1" \
               -e "s#@LI-MINVERS@#`cat ../minvers | cut -f1 -d.`#1" \
               -e "s#@LI-MAJVERS@#`cat ../majvers`#1" \
               -e "s#@LI-CC@#\"gcc -c -Wall -DVOL=volatile
-fsigned-char -pipe \"#1" \
               -e "s#@LI-LD@#\"gcc -o \"#1" \
               -e "s#@LI-LD-LIBS@#\"   -lpre_gcl -lm  -lgmp
-lreadline -lncurses -lc -lgclp \"#1" \
               -e "s#@LI-OPT-THREE@#\"-O3 -fomit-frame-pointer\"#1" \
               -e "s#@LI-OPT-TWO@#\"-O\"#1" \
               -e "s#@LI-INIT-LSP@#\"init_pre_gcl.lsp\"#1" >init_pre_gcl.lsp
cp init_pre_gcl.lsp foo
echo " (in-package \"USER\")(system:save-system \"saved_pre_gcl\")" >>foo
/opt/axiom/wh-build/gcl/unixport/raw_pre_gcl
/opt/axiom/wh-build/gcl/unixport/ -libdir /opt/axiom/wh-build/gcl/ <
foo
GCL (GNU Common Lisp)  April 1994  262144 pages
Building symbol table for /opt/axiom/wh-build/gcl/unixport/raw_pre_gcl ..
I'm not an object
Lisp initialization failed.
rm raw_pre_gcl
make[2]: Leaving directory `/opt/axiom/wh-build/gcl/unixport'
(cd lsp; touch *.lsp ; make all)
make[2]: Entering directory `/opt/axiom/wh-build/gcl/lsp'
make[2]: Leaving directory `/opt/axiom/wh-build/gcl/lsp'
(cd cmpnew; touch *.lsp ; make all)
make[2]: Entering directory `/opt/axiom/wh-build/gcl/cmpnew'
make[2]: Leaving directory `/opt/axiom/wh-build/gcl/cmpnew'
[ "" == "" ] || (cd xgcl-2 && make LISP=../unixport/saved_pre_gcl)
[: 1: ==: unexpected operator
make[2]: Entering directory `/opt/axiom/wh-build/gcl/xgcl-2'
make[2]: *** No rule to make target `../unixport/saved_pre_gcl',
needed by `objects'.  Stop.
make[2]: Leaving directory `/opt/axiom/wh-build/gcl/xgcl-2'
make[1]: *** [unixport/saved_gcl] Error 2
make[1]: Leaving directory `/opt/axiom/wh-build/gcl'
make: *** [/opt/axiom/wh-build/build/x86_64-unknown-linux/bin/gcl] Error 2


--Mike

On 6/6/07, Waldek Hebisch wrote:
> This looks like problem with your gcl installation.  The message tells
> you that the file /opt/axiom/wh-build/src/lisp/raw_lisp is not a valid
> object file.  But gcl should have made a fresh
> /opt/axiom/wh-build/src/lisp/raw_lisp just in previous step...
>
> I did not see such problem before, but I have seen other problems
> doing this step using gcl-2.6.7 bundled with Linux distributions.
> For me the problems went away when I used gcl that I compiled myself.
>
> So, I would suggest that you fetch gcl source from axiom repository:
>
> cd wh-sandbox
> svn co https://axiom.svn.sourceforge.net/svnroot/axiom/branches/build-improvements/gcl gcl
>
> and start a fresh build.
>
> BTW:  It is better to build in separate directory.

\start
Date: Wed, 06 Jun 2007 10:38:06 -0400
From: Bill Page
To: Alfredo Portes
Subject: Re: Google
Cc: Gabriel Dos Reis

Quoting Alfredo Portes:

> I was about to ask Ben to reset the repository and repopulate it
> from sourceforge. Is that ok, to then put the script to sync?
>

As far as I know if we re-populate directly from an rsync of the
SourceForge repository then I think we will be in the same state
as before - using too much space for Google - because although
the old "silver" root directory no longer appears in the repository
listing it is still in the repository history. As I understand it nothing
can really be deleted from SVN unless you have 'svnadmin' access
and you do some kind of export and re-import. 

What Gaby recommended instead, I think, was that we take a
"snapshot" of the state of the working directories as a given
point in time - say once per week - and then only commit these
snapshots to the Google repository. That way the source code
on Google code will be reasonably up to date but it will not
contain all the history from SourceForge. 

Doing this would require a completely different kind of script
to be run say as a cron job at axiom-developer.org. The old
script used 'tailor' which tries to keep the entire history in
place and I guess we don't want that any more. 

If this is agreeable to everyone I would be very happy to help
you to setup a script. Maybe we could use SVK to checkout
the sources to a working copy of the Google repository. SVK
only copies the source files and not the svn admin files. Then
we can run a commit to update Google with this "snapshot"
of the sources. Does that make sense to you?

\start
Date: Wed, 6 Jun 2007 17:43:44 +0200 (CEST)
From: Franz Lehner
To: Gabriel Dos Reis
Subject: Re: wh-sandbox and aldor

> In the past, I have documented that you can just lndir in the ax-build
> dir and have everything setup...
I understood that an out-of-source build on wh-sandbox essentially does
this (or rather copied the source); however as Waldek indicated, the OBJ 
directory is gone in wh-sandbox and appears to be essential for src_aldor
to build. I am not an expert on Makefiles and adapted the directory 
structure to the Makefile rather than the opposite.

\start
Date: Wed, 6 Jun 2007 20:05:27 +0200 (CEST)
From: Waldek Hebisch
To: Mike Hansen
Subject: Re: Problems building wh-sandbox
Cc: Camm Maguire

> Hello,
> 
> I'm building in a directory wh-build which is different than
> wh-sandbox.  I removed my copy of gcl and tried to have it build gcl
> from source.  After fixing problems with bfd.h and bfdlink.h by adding
> --disable-dynsysbfd --disable-statsysbfd to GCLOPTS, I get the
> following error while building GCL:
> 
> cp init_pre_gcl.lsp.in init_pre_gcl.lsp.tmp
> touch raw_pre_gcl_map
> gcc -o raw_pre_gcl  \
>                -L.  -Wl,-Map raw_pre_gcl_map   -lpre_gcl -lm  -lgmp
> -lreadline -lncurses -lc -lgclp
> cat init_pre_gcl.lsp.tmp | sed \
>                -e "s#@LI-VERS@#(`cat ../majvers`.`cat ../minvers`) `date`#1" \
>                -e "s#@LI-EXTVERS@#`cat ../minvers | cut -f2 -d.`#1" \
>                -e "s#@LI-MINVERS@#`cat ../minvers | cut -f1 -d.`#1" \
>                -e "s#@LI-MAJVERS@#`cat ../majvers`#1" \
>                -e "s#@LI-CC@#\"gcc -c -Wall -DVOL=volatile
> -fsigned-char -pipe \"#1" \
>                -e "s#@LI-LD@#\"gcc -o \"#1" \
>                -e "s#@LI-LD-LIBS@#\"   -lpre_gcl -lm  -lgmp
> -lreadline -lncurses -lc -lgclp \"#1" \
>                -e "s#@LI-OPT-THREE@#\"-O3 -fomit-frame-pointer\"#1" \
>                -e "s#@LI-OPT-TWO@#\"-O\"#1" \
>                -e "s#@LI-INIT-LSP@#\"init_pre_gcl.lsp\"#1" >init_pre_gcl.lsp
> cp init_pre_gcl.lsp foo
> echo " (in-package \"USER\")(system:save-system \"saved_pre_gcl\")" >>foo
> /opt/axiom/wh-build/gcl/unixport/raw_pre_gcl
> /opt/axiom/wh-build/gcl/unixport/ -libdir /opt/axiom/wh-build/gcl/ <
> foo
> GCL (GNU Common Lisp)  April 1994  262144 pages
> Building symbol table for /opt/axiom/wh-build/gcl/unixport/raw_pre_gcl ..
> I'm not an object
> Lisp initialization failed.
> rm raw_pre_gcl
> make[2]: Leaving directory `/opt/axiom/wh-build/gcl/unixport'
> (cd lsp; touch *.lsp ; make all)
> make[2]: Entering directory `/opt/axiom/wh-build/gcl/lsp'
> make[2]: Leaving directory `/opt/axiom/wh-build/gcl/lsp'
> (cd cmpnew; touch *.lsp ; make all)
> make[2]: Entering directory `/opt/axiom/wh-build/gcl/cmpnew'
> make[2]: Leaving directory `/opt/axiom/wh-build/gcl/cmpnew'
> [ "" == "" ] || (cd xgcl-2 && make LISP=../unixport/saved_pre_gcl)
> [: 1: ==: unexpected operator
> make[2]: Entering directory `/opt/axiom/wh-build/gcl/xgcl-2'
> make[2]: *** No rule to make target `../unixport/saved_pre_gcl',
> needed by `objects'.  Stop.
> make[2]: Leaving directory `/opt/axiom/wh-build/gcl/xgcl-2'
> make[1]: *** [unixport/saved_gcl] Error 2
> make[1]: Leaving directory `/opt/axiom/wh-build/gcl'
> make: *** [/opt/axiom/wh-build/build/x86_64-unknown-linux/bin/gcl] Error 2
> 
> 

It looks that BFD library included with gcl is incompatible with
your operating system.  Or maybe you use header files from included
BFD library, but the system version of BFD library (which is
clearly incompatible with version included with gcl).

I am affraid I will not be able to help, but anybody trying to
help will need more information: in particular version of
software involved: OS (Linux version), BFD library, gcc.

CC-ing Camm Maguire, gcl maintainer.

\start
Date: Wed, 6 Jun 2007 15:15:28 -0400
From: Alfredo Portes
To: Bill Page
Subject: Re: Google
Cc: Gabriel Dos Reis

> If this is agreeable to everyone I would be very happy to help
> you to setup a script. Maybe we could use SVK to checkout
> the sources to a working copy of the Google repository. SVK
> only copies the source files and not the svn admin files. Then
> we can run a commit to update Google with this "snapshot"
> of the sources. Does that make sense to you?

Yeah I forgot about the size of the history. I am not sure how Tim
keeps git/svn in sync. If he uses git-svn maybe the same can be
done with it.

The google repository is now clean again.

\start
Date: 06 Jun 2007 21:18:15 +0200
From: Martin Rubey
To: list
Subject: Re: Bug #359

I investigated a little further bug #359.  Thanks to a helpful anonymous, we
can now trigger it simply by saying

(1) -> eq := 1=1

   (1)  1= 1
                                               Type: Equation PositiveInteger

(2) -> )se bre bre
(2) -> [eq::Boolean]

   (2)  [true]
                                                           Type: List Boolean
(3) -> [eq::Boolean for i in 1..1]
   Internal Error
   Generated code is incorrect for equation 

 

Break.
Broken at |UPCOLLECT|.  Type :H for Help.
BOOT>>:bt

#0   upCOLLECT {loc0=(#<vector 08d0d4ec> (step |i| #<vector 08d0d578> ...)
 (#<vector 08d0d604> ...} [ihs=8]
#1   upconstruct {loc0=(#<vector 08d0d4d0> (#<vector 08d0d4ec> (step |i|
 #<vector 08d0d578> ...) ...} [ihs=7]
#2   RESTART
 {loc0="/tmp/.d",loc1=0,loc2=nil,loc3=0,loc4=0,loc5=nil,loc6=nil,loc7=nil,loc8=ni...}
 [ihs=6]
#3   TOP-LEVEL
 {loc0=nil,loc1=0,loc2=0,loc3=nil,loc4=nil,loc5=nil,loc6=nil,loc7="/usr/local/lib...}
 [ihs=5]
#4   FUNCALL {loc0=#<compiled-function system:top-level>} [ihs=4]
NIL
BOOT>>

[coerce(eq)@Boolean for i in 1..1] works, by the way, [(1=1)::Boolean for i in
1..1], too.  upCollect and upconstruct are defined in i-spec1.boot.pamphlet.
The only location where this error message is thrown is in coerceByFunction in
i-coerce.boot.pamphlet, the error code is S2IC0015.

I tried to read upconstruct, upCOLLECT and coerceByFunction, but I have no idea
what they are doing.  In fact, I don't even see how upconstruct calls upCOLLECT
and coerceByFunction.

\start
Date: Wed, 6 Jun 2007 21:57:23 +0200 (CEST)
From: Waldek Hebisch
To: Martin Rubey
Subject: re: Bug #359

> I investigated a little further bug #359.  Thanks to a helpful anonymous, we
> can now trigger it simply by saying
> 
> (1) -> eq := 1=1
> 
>    (1)  1= 1
>                                                Type: Equation PositiveInteger
> 
> (2) -> )se bre bre
> (2) -> [eq::Boolean]
> 
>    (2)  [true]
>                                                            Type: List Boolean
> (3) -> [eq::Boolean for i in 1..1]
>    Internal Error
>    Generated code is incorrect for equation 
> 
>  
> 
> Break.
> Broken at |UPCOLLECT|.  Type :H for Help.
> BOOT>>:bt
> 
> #0   upCOLLECT {loc0=(#<vector 08d0d4ec> (step |i| #<vector 08d0d578> ...)
>  (#<vector 08d0d604> ...} [ihs=8]
> #1   upconstruct {loc0=(#<vector 08d0d4d0> (#<vector 08d0d4ec> (step |i|
>  #<vector 08d0d578> ...) ...} [ihs=7]
> #2   RESTART
>  {loc0="/tmp/.d",loc1=0,loc2=nil,loc3=0,loc4=0,loc5=nil,loc6=nil,loc7=nil,loc8=ni...}
>  [ihs=6]
> #3   TOP-LEVEL
>  {loc0=nil,loc1=0,loc2=0,loc3=nil,loc4=nil,loc5=nil,loc6=nil,loc7="/usr/local/lib...}
>  [ihs=5]
> #4   FUNCALL {loc0=#<compiled-function system:top-level>} [ihs=4]
> NIL
> BOOT>>
> 
> [coerce(eq)@Boolean for i in 1..1] works, by the way, [(1=1)::Boolean for i in
> 1..1], too.  upCollect and upconstruct are defined in i-spec1.boot.pamphlet.
> The only location where this error message is thrown is in coerceByFunction in
> i-coerce.boot.pamphlet, the error code is S2IC0015.
> 
> I tried to read upconstruct, upCOLLECT and coerceByFunction, but I have no idea
> what they are doing.  In fact, I don't even see how upconstruct calls upCOLLECT
> and coerceByFunction.
> 

Martin, when you debug with gcl do first

)lisp (si:use-fast-links nil)

that gives more informative backtrace, in particular what looks like
the real way from upCOLLECT to coerceByFunction:

#5   coerceByFunction {loc0=(#0=(|Equation| (|PositiveInteger|)) |getValueFromEnvironment| (quote |eq|...} [ihs=33]
#6   intCodeGenCOERCE {loc0=(#0=(|Equation| (|PositiveInteger|)) |getValueFromEnvironment| (quote |eq|...} [ihs=32]
#7   coerceInt0 {loc0=(#0=(|Equation| (|PositiveInteger|)) |getValueFromEnvironment| (quote |eq|...} [ihs=31]
#8   coerceInteractive {loc0=(#0=(|Equation| (|PositiveInteger|)) |getValueFromEnvironment| (quote |eq|...} [ihs=30]
#9   coerceOrRetract {loc0=(#0=(|Equation| (|PositiveInteger|)) |getValueFromEnvironment| (quote |eq|...} [ihs=29]
#10   getArgValue1 {loc0=#<vector 0000000001c01db0>,loc1=(|Boolean|)} [ihs=28]
#11   getArgValue {loc0=#<vector 0000000001c01db0>,loc1=(|Boolean|),loc2=t} [ihs=27]
#12   evalCOERCE {loc0=#<vector 0000000001c01de0>,loc1=#<vector 0000000001c01db0>,loc2=(|Boolean|...} [ihs=26]
#13   upCOERCE {loc0=(#<vector 0000000001c01de0> #<vector 0000000001c01db0> |Boolean|),loc1=|up...} [ihs=25]
#14   bottomUp {loc0=(#<vector 0000000001c01de0> #<vector 0000000001c01db0> |Boolean|),loc1=(((...} [ihs=24]
#15   bottomUpCompile {loc0=(#<vector 0000000001c01de0> #<vector 0000000001c01db0> |Boolean|),loc1=nil} [ihs=23]
#16   upCOLLECT1 {loc0=(#<vector 0000000001c01ea0> (step |i| #<vector 0000000001c01e70> ...) (#<v...} [ihs=22]
#17   upCOLLECT0 {loc0=(#<vector 0000000001c01ea0> (step |i| #<vector 0000000001c01e70> ...) (#<v...} [ihs=21]
#18   upCOLLECT {loc0=(#<vector 0000000001c01ea0> (step |i| #<vector 0000000001c01e70> ...) (#<v...} [ihs]
#19   bottomUp {loc0=(#<vector 0000000001c01ea0> (step |i| #<vector 0000000001c01e70> ...) (#<v...} [ihs=19]
#20   upconstruct {loc0=(#<vector 0000000001c01ed0> (#<vector 0000000001c01ea0>
(step |i| #<vector...} [ihs=18]
#21   bottomUp {loc0=(#<vector 0000000001c01ed0> (#<vector 0000000001c01ea0> (step |i| #<vector...} [ihs=17]


sbcl gives sligthly more informative backtrace:

2: (|coerceByFunction|
    ((|Equation| (|PositiveInteger|)) |getValueFromEnvironment| '|eq|
     '(|Equation| (|PositiveInteger|)))
    (|Boolean|))
3: (|coerceInteractive|
    ((|Equation| (|PositiveInteger|)) |getValueFromEnvironment| '|eq|
     '(|Equation| (|PositiveInteger|)))
    #<unavailable argument>)
4: (|coerceOrRetract|
    ((|Equation| (|PositiveInteger|)) |getValueFromEnvironment| '|eq|
     '(|Equation| (|PositiveInteger|)))
    (|Boolean|))
5: (|getArgValue1|
    #(|eq| NIL
      ((|Equation| (|PositiveInteger|)) |getValueFromEnvironment| '|eq|
       '(|Equation| (|PositiveInteger|)))
      ((|Equation| (|PositiveInteger|))) NIL)
    (|Boolean|))
6: (|getArgValue|
    #(|eq| NIL
      ((|Equation| (|PositiveInteger|)) |getValueFromEnvironment| '|eq|
       '(|Equation| (|PositiveInteger|)))
      ((|Equation| (|PositiveInteger|))) NIL)
    (|Boolean|))
7: (|evalCOERCE|
    #(COERCE NIL NIL NIL NIL)
    #(|eq| NIL
      ((|Equation| (|PositiveInteger|)) |getValueFromEnvironment| '|eq|
       '(|Equation| (|PositiveInteger|)))
      ((|Equation| (|PositiveInteger|))) NIL)
    (|Boolean|))
8: (|upCOERCE|
    (#(COERCE NIL NIL NIL NIL)
     #(|eq| NIL
       ((|Equation| (|PositiveInteger|)) |getValueFromEnvironment| '|eq|
        '(|Equation| (|PositiveInteger|)))
       ((|Equation| (|PositiveInteger|))) NIL)
     |Boolean|))
9: (|bottomUp|
    (#(COERCE NIL NIL NIL NIL)
     #(|eq| NIL
       ((|Equation| (|PositiveInteger|)) |getValueFromEnvironment| '|eq|
        '(|Equation| (|PositiveInteger|)))
       ((|Equation| (|PositiveInteger|))) NIL)
     |Boolean|))
10: (|bottomUpCompile|
     (#(COERCE NIL NIL NIL NIL)
      #(|eq| NIL
        ((|Equation| (|PositiveInteger|)) |getValueFromEnvironment| '|eq|
         '(|Equation| (|PositiveInteger|)))
        ((|Equation| (|PositiveInteger|))) NIL)
      |Boolean|))
11: (|upCOLLECT1|
     (#(COLLECT NIL NIL NIL NIL)
      (STEP
       |i|
       #(|--immediateData--| NIL ((|PositiveInteger|) . 1)
         ((|PositiveInteger|)) NIL)
       #(|--immediateData--| NIL ((|PositiveInteger|) . 1)
         ((|PositiveInteger|)) NIL)
       #(|--immediateData--| NIL ((|PositiveInteger|) . 1)
         ((|PositiveInteger|)) NIL))
      (#(COERCE NIL NIL NIL NIL)
       #(|eq| NIL
         ((|Equation| #) |getValueFromEnvironment| '|eq| '(|Equation| #))
         ((|Equation| #)) NIL)
       |Boolean|)))
12: (|upCOLLECT0|
     (#(COLLECT NIL NIL NIL NIL)
      (STEP
       |i|
       #(|--immediateData--| NIL ((|PositiveInteger|) . 1)
         ((|PositiveInteger|)) NIL)
       #(|--immediateData--| NIL ((|PositiveInteger|) . 1)
         ((|PositiveInteger|)) NIL)
       #(|--immediateData--| NIL ((|PositiveInteger|) . 1)
         ((|PositiveInteger|)) NIL))
      (#(COERCE NIL NIL NIL NIL)
       #(|eq| NIL
         ((|Equation| #) |getValueFromEnvironment| '|eq| '(|Equation| #))
         ((|Equation| #)) NIL)
       |Boolean|)))
13: (|bottomUp|
     (#(COLLECT NIL NIL NIL NIL)
      (STEP
       |i|
       #(|--immediateData--| NIL ((|PositiveInteger|) . 1)
         ((|PositiveInteger|)) NIL)
       #(|--immediateData--| NIL ((|PositiveInteger|) . 1)
         ((|PositiveInteger|)) NIL)
       #(|--immediateData--| NIL ((|PositiveInteger|) . 1)
         ((|PositiveInteger|)) NIL))
      (#(COERCE NIL NIL NIL NIL)
       #(|eq| NIL
         ((|Equation| #) |getValueFromEnvironment| '|eq| '(|Equation| #))
         ((|Equation| #)) NIL)
       |Boolean|)))
14: (|upconstruct|
     (#(|construct| NIL NIL NIL NIL)
      (#(COLLECT NIL NIL NIL NIL)
       (STEP
        |i|
        #(|--immediateData--| NIL (# . 1) (#) NIL)
        #(|--immediateData--| NIL (# . 1) (#) NIL)
        #(|--immediateData--| NIL (# . 1) (#) NIL))
       (#(COERCE NIL NIL NIL NIL)
        #(|eq| NIL (# |getValueFromEnvironment| '|eq| '#) (#) NIL) |Boolean|))))
15: (|bottomUp|
     (#(|construct| NIL NIL NIL NIL)
      (#(COLLECT NIL NIL NIL NIL)
       (STEP
        |i|
        #(|--immediateData--| NIL (# . 1) (#) NIL)
        #(|--immediateData--| NIL (# . 1) (#) NIL)
        #(|--immediateData--| NIL (# . 1) (#) NIL))
       (#(COERCE NIL NIL NIL NIL)
        #(|eq| NIL (# |getValueFromEnvironment| '|eq| '#) (#) NIL) |Boolean|))))


\start
Date: 06 Jun 2007 22:15:41 +0200
From: Martin Rubey
To: Waldek Hebisch
Subject: re: Bug #359

Waldek Hebisch writes:

> Martin, when you debug with gcl do first
> 
> )lisp (si:use-fast-links nil)
> 
> that gives more informative backtrace, in particular what looks like
> the real way from upCOLLECT to coerceByFunction:

thanks for this hint!  In fact, I got similar information by fiddling around
with )tr meanwhile, but your hint renders this a lot easier.  Many thanks!

Somehow it seems to me that the problem is with |getValueFromEnvironment|.  I
do not know exactly what it is supposed to do, but it seems that
coerceByFunction expects that the value is obtained via SPADCALL.

Maybe objVal should handle |getValueFromEnvironment|?  In any case,
getValueFromEnvironment does not appear often in the source:

interp/interp-proclaims.lisp:2780:            BOOT::|getValueFromEnvironment|
interp/i-intern.boot.pamphlet:568:-- getValueFromEnvironment(x,mode) ==
interp/i-intern.boot.pamphlet:572:getValueFromEnvironment(x,mode) ==
interp/i-spec1.boot.pamphlet:896:    op = "getValueFromEnvironment" => v
interp/i-analy.boot.pamphlet:430:      ['getValueFromEnvironment,MKQ id,MKQ envMode]

\start
Date: Thu, 7 Jun 2007 02:26:27 +0200 (CEST)
From: Waldek Hebisch
To: list
Subject: Database bootstrap

I just managed to bootstrap Axiom starting from essentially empty
databases.  How does it work?  It is a multistage process, and
at the end of given stage I dump databases and use them for the
next stage.  In first stage I create a number of fake categories and
domains -- they essentally serve as forward declarations using then
I compile all categories and a few core domains. Next I compile
domains and packages in bootstrap mode.  Then I compile categories
and core domains using bootstrapDomains flag.  Next I recompile
categories and core domains in normal mode, and then I compile in
normal mode  other files.  During main compile compilation of
a few files would fail, so I compile than later.  After that
resultion Axiom failed some tests, so as a final step I recompiled
several files (that fixed the failures).

Good news is that the whole process converged, but it is disturbing
that when some type information is missing Spad compiler can
make pretty weird type inferences.

\start
Date: Wed, 6 Jun 2007 19:51:04 -0500
From: Tim Daly
To: Waldek Hebisch
Subject: Database bootstrap!

Waldek,

That's excellent! Hopefully you've kept good notes about which
things are needed at each stage of the process so I can try to
reproduce it. Great work, painfully achieved, I'm sure.

\start
Date: 06 Jun 2007 22:04:21 -0400
From: Stephen Wilson
To: Waldek Hebisch
Subject: Re: Database bootstrap

Waldek,

I too would like to say Thanks!  Untangling such a rats-nest is very
much welcomed and appreciated.  I too hope you could provide some
notes describing the process.

\start
Date: Thu, 7 Jun 2007 14:00:41 +0200 (CEST)
From: Waldek Hebisch
To: Alasdair McAndrew
Subject: Re: Is anybody actually doing mathematics with	Axiom?
 
> Hi Martin,
> 
> Here is my ztrans.input file in its current diabolical form - all the
> cleverness is yours and Themos's; the extra hack work is my own.  It does
> forward transforms pretty well (of powers, exponential functions and
> mixtures thereof), but inverse transforms are less well handled.  For
> example,
> 
> ex:=ztrans(n^5,n,z)
> 
> produces a formidable polynomial quotient; to invert it you need to apply
> partial fractions to ex/z, and apply the inverse transform to each
> individual fractional term multiplied by z.  This is not happening right
> now.
> 
> As well, I need to implement shifts:
> 
> ztrans(f(n-k),n,z) == z^(-b)*ztrans(f(n),n,z)
> 
> and for f(n+k).
> 

Have you looked at laplace.spad.pamphlet?  Computing Laplace transform
is related to computing ztransforms.  In particular essentially all that 
inverseLaplace currently do is to decompose rational function into
partial fractions and apply rule to each term separately.

\start
Date: Thu, 7 Jun 2007 14:31:50 +0200 (CEST)
From: Waldek Hebisch
To: Franz Lehner
Subject: Re: Safe version

Franz Lehner wrote:
> > OTOH safety 3 means very significant slowdown.  On the same machine
> > safety 0 build took about 2.5 hours while safety 3 build needed
> > about 19 hours.
> It was roughly 12 hours here.
> Is runtime speed affected by this?
> 

I am just building safe version.  Testsuite run took 235 minutes
compared to 18 minutues for safety 1 version.  While testsuite
probably is different than normal workload, it clearly shows
that runtime speed is even more affected than build time.  Also,
IIRC one safe version I tested failed a few tests runnning out
of stack space: safe version had tail recursion elimination
disabled (but I do not see this probem in current build).

\start
Date: Thu, 7 Jun 2007 14:42:16 +0200 (CEST)
From: Waldek Hebisch
To: Bill Page
Subject: re: problem plotting simple functions

Bill Page wrote:
> On June 3, 2007 7:42 PM Waldek Hebisch wrote:
> > ... 
> > It seems that error occurs in manexp function.  More preciesly,
> > manexp calls sign function which looks like the only place which
> > could signal this error.
> > 
> > Could you try:
> > 
> > exponent(-5.0)$DoubleFloat
> 
> Here's the results:
> 
> ...
> 
> (1) -> )set break break
> (1) -> )lisp (si::use-fast-links nil)
> 
> Value = NIL
> (1) -> exponent(-5.0)$DoubleFloat
>    Loading
>  
> /export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/FLOAT.o
>       for domain Float
>    Loading
>  
> /export/home0/wspage/wh-test/target/i386-pc-solaris2.10/algebra/DFLOAT.o
>       for domain DoubleFloat
> 
>    >> Error detected within library code:
>    Not an integer
> 
> 
> Break.
> Broken at SYSTEM::BREAK-LEVEL.  Type :H for Help.
> BOOT>>:bt
> 
> BOOT>> (quit)
>
 
> > 
> > sign(-5.0)$DoubleFloat
> >
> 
> Same result.
> ...
> 
>    >> Error detected within library code:
>    Not an integer
>  
> > )lisp (float-sign -5.0 1.0)
> > 
> 
> This one works.
> 
> (1) -> )lisp (float-sign -5.0 1.0)
> 
> Value = -1.0
> 
> > The first line is intended to test manexp -- manexp is internal
> > to DoubleFloat, so we can not test it directly, but exponent
> > just calls manexp and extracts one of components.  
> > 
> > Also, it may worth checking int/algebra/DFLOAT.NRLIB/code.lsp. 
> 
> In my 'int/algebra/DFLOAT.NRLIB/code.lsp' I see the same code:
> 
> (DEFUN |DFLOAT;sign;$I;81| (|x| $)
>   (SPADCALL (FLOAT-SIGN |x| 1.0) (QREFELT $ 115)))
> 
> and
> 
> (DEFUN |DFLOAT;retract;$I;79| (|x| $)
>   (PROG (|n|)
>     (RETURN
>       (SEQ (LETT |n| (FIX |x|) |DFLOAT;retract;$I;79|)
>            (EXIT (COND
>                    ((= |x| (FLOAT |n| MOST-POSITIVE-DOUBLE-FLOAT)) |n|)
>                    ('T (|error| "Not an integer"))))))))
> 
> -----------
> 
> Did I mention earlier that I am testing this on a Solaris 10
> x86 system with the Blastwave toolchain?
> 
> -bash-3.00$ gcc --version
> gcc (GCC) 3.4.3 (csl-sol210-3_4-branch+sol_rpath)
> Copyright (C) 2004 Free Software Foundation, Inc.
> 
> Back in April my first attempts to build Axiom on this system
> failed due to a problem with gcl. But Camm Maquire was able to
> solve the gcl problem and his changes are in cvs gcl-2.6.8pre.
> This is the version of gcl that I am using now to build
> wh-sandbox. I have not found any other errors until now but
> I must admit that I did not review all of the test output.
> 
> Perhaps this is a gcl bug?
> 

Yes, this looks like gcl bug.  To be sure one would have to
perform by hand (step-by-sep) work done by DFLOAT;retract;$I;79
and see where it goes wrong (I suspect that MOST-POSITIVE-DOUBLE-FLOAT
may cause trouble).  It is possible that problems only occur in
compiled code (when you execute code from the command line
it is interpreted), however if some builtin gcl funtion gives
wrong result interpreted code should show this.

\start
Date: Fri, 08 Jun 2007 10:22:03 +0200
From: Christian Aistleitner
To: Martin Rubey
Subject: Re: AxiomUnit
Cc: Bill Page, Gabriel Dos Reis

Hello,

On Mon, 04 Jun 2007 21:02:23 +0200, Martin Rubey  
Martin Rubey wrote:

> I just did something extremely simple minded, with the following result:
>
> (5) -> )sh MyTextWriter
>  MyTextWriter  is a domain constructor
>  Abbreviation for MyTextWriter is MYTEXTW
>  This constructor is exposed in this frame.
>  Issue )edit csaxcompat2.as to see algebra source code for MYTEXTW
>
> ------------------------------- Operations  
> --------------------------------
>  flush! : % -> %                       stderr : () -> %
>  stdout : () -> %                      write! : (ACCharacter,%) -> Void
>  textWriter : (ACCharacter -> NIL) -> %
>  textWriter : ((ACCharacter -> NIL),(() -> NIL)) -> %
>
> (5) -> write!(char "H", stderr())
> H                                                                    
> Type: Void

Does not look too bad. I'm glad you eventually found time to work towards  
AxiomUnit :D

> Given that, what remains for AxiomUnit?

As we've already discussed in private mail some time ago, there are more  
things. But I suggest to switch to private communication again, as I do  
not want to abuse the Axiom Mailing list for third party projects.

\start
Date: Fri, 08 Jun 2007 10:47:43 +0200
From: Christian Aistleitner
To: Ralf Hemmecke, Gabriel Dos Reis
Subject: Re: merge branches/daly to trunk
Cc: Bill Page

Hello,

> But Christian might be better in saying something why AxiomUnit does not  
> yet exist.

it is actually quite some time since I attempted to get AldorUnit to  
Axiom. As the crucial parts af the discussion happen orally between me and  
Ralf, parts of the arguments are lost.

The most important aspect is improving the Axiom experience--during the  
invostigation of Axiom, it turned out that the most important improvements  
AldorUnit provides cannot be brought to Axiom.
Having a full blown AxiomUnit, one would have tools to debug segfaults  
(although they do not seem to be an issue for Axiom) and other really bad  
behaving code. One should get really usable output from the Testing  
environment.
Ease of writing tests and its integration into Axiom is another important  
issue.

Aldor's TextWriter abilities where crucial for providing usable textual  
output. These possibilities are not present in Axiom -- but it seems  
Martin did some work in this direction.

For evaluating the possible benefits of AxiomUnit I played around with  
using the Aldor compiler for Axiom and loading the resulting code.  
Although I do not have the details at hand, I managed to crash Axiom badly  
without writing evil-looking Aldor code. Axiom behaved unexpectedly when  
loading functions compiled with Aldor. I remember race conditions when  
loading libraries. Recovery from errors proofed to be a serious issue. All  
in all, my experience of using the Aldor compiler with Axiom wasn't the  
best.
I do not want to spread FUD, it's just some time off. So the details faded  
a bit.

However, I will have a look at Martin's work. Maybe this will help in  
finally providing AxiomUnit.

\start
Date: Fri, 8 Jun 2007 14:02:58 +0200 (CEST)
From: Franz Lehner
To: Waldek Hebisch
Subject: Re: Safe version

On Thu, 7 Jun 2007, Waldek Hebisch wrote:
> I am just building safe version.  Testsuite run took 235 minutes
> compared to 18 minutues for safety 1 version. While testsuite
> probably is different than normal workload, it clearly shows
> that runtime speed is even more affected than build time.
So it was not just my feeling ...
So I guess one has to have two versions around, one for working and 
another for testing. This way I can confirm that the building instructions 
for aldor are indeed correct, except for a typo

   (cd obj/x86_64-unknown-linux$; ln -s ../../src/interp/ .)
                               ^
and the fact that I did not mention that `document' must be in the path.

Now a question for the gurus:
If I now have two versions of libaxiom.al, one built from wh-sandbox with
safety 1 and another one with safety 3, but otherwise identical, is it
necessary to compile my own packages for each version separately?

\start
Date: Fri, 8 Jun 2007 09:35:00 -0400
From: Bill Page
To: Christian Aistleitner
Subject: Re: AxiomUnit
Cc: Bill Page, Gabriel Dos Reis

------=_Part_48112_14189798.1181309700648

On 6/8/07, Christian Aistleitner wrote:
>
> ...
> > Given that, what remains for AxiomUnit?
>
> As we've already discussed in private mail some time ago, there are more
> things. But I suggest to switch to private communication again, as I do
> not want to abuse the Axiom Mailing list for third party projects.


I am very glad that you are willing to help with adapting AldorUnit
to become AxiomUnit, but I am very confused as as to why you
would prefer private communication about a subjec that is
important to so many other Axiom users. What do you mean
by "third party projects"?

Regards,
Bill Page.

\start
Date: 08 Jun 2007 16:57:13 +0200
From: Martin Rubey
To: Alfredo Portes
Subject: Re: Live CD + Guess Package + Vmware

Dear Alfredo,

Alfredo Portes writes:

> I created a live cd of Waldek branch with your guess package in case you need
> to demonstrate your program. You can get it from:
> 
> http://alfredo.axiom-developer.org/axiom.zip
> 
> Actually the zip contains the vmware file to run it with vmware player. Like
> Bill pointed out in a previous email, this is a good way to have hyperdoc on
> windows, until a replacement/portable version is created.

Do you recall by chance whether this live cd contains Aldor, and Axiom with
Aldor support compiled?  If not, would it be difficult to add?  (I wonder why
people insist on MS Windows ...)

\start
Date: Fri, 8 Jun 2007 12:42:05 -0400
From: Alfredo Portes
To: Martin Rubey
Subject: Re: Live CD + Guess Package + Vmware

Hi Martin,

> Do you recall by chance whether this live cd contains Aldor, and Axiom with
> Aldor support compiled?  If not, would it be difficult to add?  (I wonder why
> people insist on MS Windows ...)

The one I uploaded for you does not have it. I think the current livecd has it,
but it is based on the gold version, so it does not have your guess package.

I could try to add it to a new image.

I will let you know,

\start
Date: Fri, 8 Jun 2007 10:04:25 -0700
From: Mike Hansen
To: list
Subject: Re: Problems building wh-sandbox

I'm running a standard copy of Ubuntu 7.04 on a Core 2 Duo.

Is there any other way to get a running copy of the wh-sandbox branch
with Aldor support?

--Mike

On 6/6/07, Waldek Hebisch wrote:
>
> > Hello,
> >
> > I'm building in a directory wh-build which is different than
> > wh-sandbox.  I removed my copy of gcl and tried to have it build gcl
> > from source.  After fixing problems with bfd.h and bfdlink.h by adding
> > --disable-dynsysbfd --disable-statsysbfd to GCLOPTS, I get the
> > following error while building GCL:
> >
> > cp init_pre_gcl.lsp.in init_pre_gcl.lsp.tmp
> > touch raw_pre_gcl_map
> > gcc -o raw_pre_gcl  \
> >                -L.  -Wl,-Map raw_pre_gcl_map   -lpre_gcl -lm  -lgmp
> > -lreadline -lncurses -lc -lgclp
> > cat init_pre_gcl.lsp.tmp | sed \
> >                -e "s#@LI-VERS@#(`cat ../majvers`.`cat ../minvers`) `date`#1" \
> >                -e "s#@LI-EXTVERS@#`cat ../minvers | cut -f2 -d.`#1" \
> >                -e "s#@LI-MINVERS@#`cat ../minvers | cut -f1 -d.`#1" \
> >                -e "s#@LI-MAJVERS@#`cat ../majvers`#1" \
> >                -e "s#@LI-CC@#\"gcc -c -Wall -DVOL=volatile
> > -fsigned-char -pipe \"#1" \
> >                -e "s#@LI-LD@#\"gcc -o \"#1" \
> >                -e "s#@LI-LD-LIBS@#\"   -lpre_gcl -lm  -lgmp
> > -lreadline -lncurses -lc -lgclp \"#1" \
> >                -e "s#@LI-OPT-THREE@#\"-O3 -fomit-frame-pointer\"#1" \
> >                -e "s#@LI-OPT-TWO@#\"-O\"#1" \
> >                -e "s#@LI-INIT-LSP@#\"init_pre_gcl.lsp\"#1" >init_pre_gcl.lsp
> > cp init_pre_gcl.lsp foo
> > echo " (in-package \"USER\")(system:save-system \"saved_pre_gcl\")" >>foo
> > /opt/axiom/wh-build/gcl/unixport/raw_pre_gcl
> > /opt/axiom/wh-build/gcl/unixport/ -libdir /opt/axiom/wh-build/gcl/ <
> > foo
> > GCL (GNU Common Lisp)  April 1994  262144 pages
> > Building symbol table for /opt/axiom/wh-build/gcl/unixport/raw_pre_gcl ..
> > I'm not an object
> > Lisp initialization failed.
> > rm raw_pre_gcl
> > make[2]: Leaving directory `/opt/axiom/wh-build/gcl/unixport'
> > (cd lsp; touch *.lsp ; make all)
> > make[2]: Entering directory `/opt/axiom/wh-build/gcl/lsp'
> > make[2]: Leaving directory `/opt/axiom/wh-build/gcl/lsp'
> > (cd cmpnew; touch *.lsp ; make all)
> > make[2]: Entering directory `/opt/axiom/wh-build/gcl/cmpnew'
> > make[2]: Leaving directory `/opt/axiom/wh-build/gcl/cmpnew'
> > [ "" == "" ] || (cd xgcl-2 && make LISP=../unixport/saved_pre_gcl)
> > [: 1: ==: unexpected operator
> > make[2]: Entering directory `/opt/axiom/wh-build/gcl/xgcl-2'
> > make[2]: *** No rule to make target `../unixport/saved_pre_gcl',
> > needed by `objects'.  Stop.
> > make[2]: Leaving directory `/opt/axiom/wh-build/gcl/xgcl-2'
> > make[1]: *** [unixport/saved_gcl] Error 2
> > make[1]: Leaving directory `/opt/axiom/wh-build/gcl'
> > make: *** [/opt/axiom/wh-build/build/x86_64-unknown-linux/bin/gcl] Error 2
> >
> >
>
> It looks that BFD library included with gcl is incompatible with
> your operating system.  Or maybe you use header files from included
> BFD library, but the system version of BFD library (which is
> clearly incompatible with version included with gcl).
>
> I am affraid I will not be able to help, but anybody trying to
> help will need more information: in particular version of
> software involved: OS (Linux version), BFD library, gcc.
>
> CC-ing Camm Maguire, gcl maintainer.

\start
Date: 08 Jun 2007 19:24:52 +0200
From: Martin Rubey
To: Mike Hansen
Subject: Re: Problems building wh-sandbox
Cc: Camm Maguire, Waldek Hebisch

Dear Mike, Camm, Waldek,

Camm, could you help?  (Mike: please copy Camm for gcl related questions.  He
is the guru.)

Mike Hansen writes:

> I'm running a standard copy of Ubuntu 7.04 on a Core 2 Duo.
> 
> Is there any other way to get a running copy of the wh-sandbox branch
> with Aldor support?

Oh dear, if I would have known that it is so difficult :-(

I guess that you currently have no axiom at all?  At least, you don't have
wh-sandbox, right?

In any case, I guess that for the workshop itself, aldor standalone will be
sufficient.  But that's hardly a remedy.

Maybe you could install wh-sandbox using SBCL?  (Warning: I have no idea
whether that's easier) You won't have graphics nor HyperDoc, but, on the other
hand, Aldor support should then be possible.

Martin

> 
> --Mike
> 
> On 6/6/07, Waldek Hebisch wrote:
> >
> > > Hello,
> > >
> > > I'm building in a directory wh-build which is different than
> > > wh-sandbox.  I removed my copy of gcl and tried to have it build gcl
> > > from source.  After fixing problems with bfd.h and bfdlink.h by adding
> > > --disable-dynsysbfd --disable-statsysbfd to GCLOPTS, I get the
> > > following error while building GCL:
> > >
> > > cp init_pre_gcl.lsp.in init_pre_gcl.lsp.tmp
> > > touch raw_pre_gcl_map
> > > gcc -o raw_pre_gcl  \
> > >                -L.  -Wl,-Map raw_pre_gcl_map   -lpre_gcl -lm  -lgmp
> > > -lreadline -lncurses -lc -lgclp
> > > cat init_pre_gcl.lsp.tmp | sed \
> > >                -e "s#@LI-VERS@#(`cat ../majvers`.`cat ../minvers`) `date`#1" \
> > >                -e "s#@LI-EXTVERS@#`cat ../minvers | cut -f2 -d.`#1" \
> > >                -e "s#@LI-MINVERS@#`cat ../minvers | cut -f1 -d.`#1" \
> > >                -e "s#@LI-MAJVERS@#`cat ../majvers`#1" \
> > >                -e "s#@LI-CC@#\"gcc -c -Wall -DVOL=volatile
> > > -fsigned-char -pipe \"#1" \
> > >                -e "s#@LI-LD@#\"gcc -o \"#1" \
> > >                -e "s#@LI-LD-LIBS@#\"   -lpre_gcl -lm  -lgmp
> > > -lreadline -lncurses -lc -lgclp \"#1" \
> > >                -e "s#@LI-OPT-THREE@#\"-O3 -fomit-frame-pointer\"#1" \
> > >                -e "s#@LI-OPT-TWO@#\"-O\"#1" \
> > >                -e "s#@LI-INIT-LSP@#\"init_pre_gcl.lsp\"#1" >init_pre_gcl.lsp
> > > cp init_pre_gcl.lsp foo
> > > echo " (in-package \"USER\")(system:save-system \"saved_pre_gcl\")" >>foo
> > > /opt/axiom/wh-build/gcl/unixport/raw_pre_gcl
> > > /opt/axiom/wh-build/gcl/unixport/ -libdir /opt/axiom/wh-build/gcl/ <
> > > foo
> > > GCL (GNU Common Lisp)  April 1994  262144 pages
> > > Building symbol table for /opt/axiom/wh-build/gcl/unixport/raw_pre_gcl ..
> > > I'm not an object
> > > Lisp initialization failed.
> > > rm raw_pre_gcl
> > > make[2]: Leaving directory `/opt/axiom/wh-build/gcl/unixport'
> > > (cd lsp; touch *.lsp ; make all)
> > > make[2]: Entering directory `/opt/axiom/wh-build/gcl/lsp'
> > > make[2]: Leaving directory `/opt/axiom/wh-build/gcl/lsp'
> > > (cd cmpnew; touch *.lsp ; make all)
> > > make[2]: Entering directory `/opt/axiom/wh-build/gcl/cmpnew'
> > > make[2]: Leaving directory `/opt/axiom/wh-build/gcl/cmpnew'
> > > [ "" == "" ] || (cd xgcl-2 && make LISP=../unixport/saved_pre_gcl)
> > > [: 1: ==: unexpected operator
> > > make[2]: Entering directory `/opt/axiom/wh-build/gcl/xgcl-2'
> > > make[2]: *** No rule to make target `../unixport/saved_pre_gcl',
> > > needed by `objects'.  Stop.
> > > make[2]: Leaving directory `/opt/axiom/wh-build/gcl/xgcl-2'
> > > make[1]: *** [unixport/saved_gcl] Error 2
> > > make[1]: Leaving directory `/opt/axiom/wh-build/gcl'
> > > make: *** [/opt/axiom/wh-build/build/x86_64-unknown-linux/bin/gcl] Error 2
> > >
> > >
> >
> > It looks that BFD library included with gcl is incompatible with
> > your operating system.  Or maybe you use header files from included
> > BFD library, but the system version of BFD library (which is
> > clearly incompatible with version included with gcl).
> >
> > I am affraid I will not be able to help, but anybody trying to
> > help will need more information: in particular version of
> > software involved: OS (Linux version), BFD library, gcc.
> >
> > CC-ing Camm Maguire, gcl maintainer.

\start
Date: Sat, 9 Jun 2007 12:13:20 +1000
From: Alasdair McAndrew
To: list
Subject: Axiom under windows

------=_Part_13288_18333181.1181355200766

As an experiment (to see if it would be possible to use with my students),
I'm experimenting to see if I can run Axiom under windows.  I've downloaded
Axiom 0.1.3, and that runs fine, in a console.  I've also downloaded
cygTeXmacs, which is a huge download (80Mb), which I haven't got working
quite yet.

Now the trouble is that this setup: Axiom in TeXmacs in Cygwin in Windows,
is three or four removes from a native system.  Ideally, we would want Axiom
in a windows native executable interface (such as WxMaxima).  Since windows
is, for better or worse, the predominant desktop OS currently, with no
change likely in the foreseeable future, I would have thought that to make
Axiom more popular, a native interface is required.  As an interim, maybe we
need some sort of Axiom+TeXmacs+Cygwin installer, which involves the
downloading of just one file, and which then installs itself in a directory
somewhere, with all appropriate links and paths set during the installing
process.

Just my Saturday morning 2 cents.

-Alasdair

\start
Date: Sat, 9 Jun 2007 00:23:47 -0400
From: Bill Page
To: Alasdair McAndrew
Subject: Re: Axiom under windows

On 6/8/07, Alasdair McAndrew wrote:

> As an experiment (to see if it would be possible to use with my students),
> I'm experimenting to see if I can run Axiom under windows.  I've downloaded
> Axiom 0.1.3, and that runs fine, in a console.  I've also downloaded
> cygTeXmacs, which is a huge download (80Mb), which I haven't got working
> quite yet.


Although the cygwin version of TeXmacs is more current, I would not
recommend running TeXmacs on Windows this way since it is both slow and
uncomfortable for someone familiar with Windows. But if you must do this,
then I recommend that at least you run Xming as your X-server instead of the
cygwin version. Xming is a native windows application that integrates quite
well with other windows applications.

I think the Windows native verison of TeXmacs is significantly more friendly
to Windows users and I have used it very successfully with the native
Windows version of Axiom. Unfortunately it is not currently actively
maintained by the TeXmacs developers. There are some installation
notes WinTeXmacs this at url:

http://wiki.axiom-developer.org/TeXmacs

If you must use the pre-compiled version of Axiom for Windows then I would
suggest you use the newer version 0.1.4. Unfortunately even this version is
badly out of date. So a better option would be to compile Axiom from the
wh-sandbox sources using MSYS/MinGW. See:

http://wiki.axiom-developer.org/BuildAxiom

(Building Axiom on Windows)


> Now the trouble is that this setup: Axiom in TeXmacs in Cygwin in Windows,
> is three or four removes from a native system.  Ideally, we would want Axiom
> in a windows native executable interface (such as WxMaxima).  Since windows
> is, for better or worse, the predominant desktop OS currently, with no
> change likely in the foreseeable future, I would have thought that to make
> Axiom more popular, a native interface is required.


Absolutely. We have been talking about this forever on the axiom-developer
email list but there are no resources available to implement such an
interface. The trouble is that by far most open source developers prefer
Linux over Windows. Since Windows is a commerical proprietary operating
system, the expectation is that the most appropriate develop and support
software for this environment is by following the same model. Unfortunately
there is no commerically motivated company that is currently interested in
Axiom.

As an interim, maybe we need some sort of Axiom+TeXmacs+Cygwin installer,
> which involves the downloading of just one file, and which then installs
> itself in a directory somewhere, with all appropriate links and paths set
> during the installing process.
>
> Just my Saturday morning 2 cents.


It would not be hard to create an Windows installer that included both Axiom
and WinTeXmacs. Both of these use the same NSIS installation program. In
fact the original Windows installer for Axiom was implemented by the same
person who ported TeXmacs to Windows. You can check-out this history in the
axiom-developer archive.

Regards,
Bill Page.

\start
Date: Sat, 9 Jun 2007 00:03:34 -0500
From: Tim Daly
To: Alasdair McAndrew
Subject: Axiom under Windows

Alasdair,

> ... Since windows is, for better or worse, the predominant desktop OS
> currently, with no change likely in the foreseeable future, I would
> have thought that to make Axiom more popular, a native interface 
> is required.

While I have the expertise to do this I have neither the time nor the
native toolchain (e.g. a native windows compiler, debugger, etc), all
of which cost actual cash. In the short term perhaps someone could look
at using the WxMaxima tools.

In the last couple weeks I posted some links to a native Hyperdoc.
But without the sman controller it cannot talk to Axiom and I did
not complete that part of the port. Gaby and Waldek have certainly
done a lot of work in this direction and can probably do the port.

I'm working on a branch that will replace the current user interface
with a standard browser, on a long term path toward the "crystal"
(see the mailing list history). This involves new code rather than
a port of the old code and should be more robust and portable in the
long run. The tools to do this are slowly becoming available. Some,
such as the <canvas> tag are there but not fully supported yet.

Porting is certainly a worthwhile project but it is one among many. At
this point I feel that fundamentals have priority, such as deep
documentation, correctness, clean code, a good theory behind interpreter
coercions, a review of the algebra hierarchy to align it more strongly
with theory, etc.  That's just my opinion and is not universal in the
group. This is, of course, free and open source software so code counts 
much more than opinions.

As for the "foreseeable future" I'd have to say that the 30-year
horizon (the project horizon) gives a lot of room for change. :-)

\start
Date: 09 Jun 2007 10:19:11 +0200
From: Martin Rubey
To: Alfredo Portes
Subject: Re: HyperDocReplacement

Dear Alfredo,

sorry, somehow I overlooked this mail.

Alfredo Portes writes:

> Martin,
> 
> I recompiled wh-sandbox and it seems to work fine the first two steps.
> However I get
> this:
> 
> (1) -> SOCKET(8080, getDocumentation$HyperDoc)

this should read

SOCKET(8080, getDocumentation$HyperDoc)$Lisp

(SOCKET is a Lisp function)

Please excuse me, if you find another problem, I'll try to answer quicker...

\start
Date: 09 Jun 2007 10:16:04 +0200
From: Martin Rubey
To: Tim Daly
Subject: Re: Axiom under Windows

Dear Tim,

Tim Daly writes:

> In the last couple weeks I posted some links to a native Hyperdoc.  But
> without the sman controller it cannot talk to Axiom and I did not complete
> that part of the port. 

Yes, when you sent me the mail, I misunderstood that part and thought that all
of the work was done already.

> I'm working on a branch that will replace the current user interface
> with a standard browser,

So, why don't we do this as a team?  I don't know really what your approach is,
but I think what I have shown in my proof of concept could be easily extended.

So, how could we join efforts?

    I do not understand how to extract the information about uses, users,
    dependends, dependents.  I can currently only get the documentation for
    operations and constructors, properly hyperlinked.  If you or anybody could
    help here, that would be wonderful.

The main advantage of my approach is that we can use an existing, well-tested,
well-supported tool, namely tex4ht, so we can to keep LaTeX documentation
(which is a requirement for me) but use any browser.  (another requirement: I
am not going to tie myself to firefox) Since I cache the generated html, the
time overhead is not an issue.  In my opinion, the results are beautiful.

At least to me it seems that my mini-webserver is robust enough for
professional work.  I was unable to crash it.

The code I have written is only a few lines (maybe 20 or so), it delegates a
lot of work to gcl, axiom, tex4ht, md5sum, a browser.


I'd really hope that we could work together,

\start
Date: 09 Jun 2007 10:00:57 +0200
From: Martin Rubey
To: Bill Page, Alfredo Portes
Subject: Re: Axiom under windows

Dear Bill, Alasdair,

maybe the live cd of Alfredo is another option.  I just cannot imagine that one
can get to know Axiom without HyperDoc.  Maybe even worse: no graphics.  Since
I don't have MS WIndows available, I never tried it, but at least that would
remove some of the non-native layers.

Alfredo said that it is compiled from recent wh-sandbox, and thus contains a
rather up tp date algebra, including my guessing package, which is certainly
fun for students.

Alfredo said he'd try to compile in Aldor support, too. In this case I'll try
to use this live cd for the workshop.

\start
Date: 09 Jun 2007 10:40:55 +0200
From: Martin Rubey
To: Tim Daly
Subject: Re: Axiom under Windows

Martin Rubey writes:

> At least to me it seems that my mini-webserver is robust enough for
> professional work.  I was unable to crash it.

Hm, that was wishful thinking, somehow.  Sorry.  It seems that I have given up
working on it after some time, since I got slightly frustrated. (Not with the
code, but with lack of interest of the community)

I'll resurrect it if there is interest.

\start
Date: 09 Jun 2007 10:49:18 +0200
From: Martin Rubey
To: Tim Daly
Subject: Re: Axiom under Windows

Martin Rubey writes:

> I'll resurrect it if there is interest.

I just realized that I forgot to compile my hyper.spad.  Now I'm happy
again. Tim, in case you have interest: another thing I do not know is how to
run the webserver in the background.  I don't really think that this is an
issue, I'd propose to start an axiom dedicated to documentation anyway.  But
others seem to think differently...

\start
Date: Sat, 09 Jun 2007 11:59:32 +0200
From: Gregory Vanuxem
To: Martin Rubey
Subject: Re: Axiom under Windows

Hello Martin,

Le samedi 09 juin 2007 =E0 10:40 +0200, Martin Rubey a =E9crit :
> Martin Rubey writes:
>
> > At least to me it seems that my mini-webserver is robust enough for
> > professional work.  I was unable to crash it.
>
> Hm, that was wishful thinking, somehow.  Sorry.  It seems that I have given up
> working on it after some time, since I got slightly frustrated. (Not with the
> code, but with lack of interest of the community)
>
> I'll resurrect it if there is interest.

I'm interested, since some time now, in console mode documentation so I
would like to play with your code. My main problem is that I don't now
what queries are acceptable. Can you give me some samples (in console
mode so something like getDocumentation("foo`%20`bar")) ?

\start
Date: 09 Jun 2007 15:35:10 +0200
From: Martin Rubey
To: Gregory Vanuxem
Subject: Re: Axiom under Windows

Gregory Vanuxem writes:

> > I'll resurrect it if there is interest.
> 
> I'm interested, since some time now, in console mode documentation so I would
> like to play with your code.

Hm, but the main point of my code is to display the doc in a browser.

> My main problem is that I don't now what queries are acceptable. Can you give
> me some samples (in console mode so something like
> getDocumentation("foo`%20`bar")) ?

OK.  But I'd rather suggest you use 

ops: Database IndexCard := getDatabase("o")$OperationsQuery

and read the documentation of Database.  In fact, there is an example in the
axiom book.

Note that getDatabase hould return some large number (the number of all
operations in axiom). if it doesn't, get a better axiom.

-------------------------------------------------------------------------------

getDocumentation takes a string of the form

"op`params`origin"

where pattern matching is supported via the special sequence %20. (should be
changed in fact, it should better be the empty string.)

It returns a string which is the name of a html file generated via htex4ht.
The name is the md5sum code for the complete specification.  For example:

(12) -> getDocumentation "binomial`%20`OutputForm"
   ["binomial","%20","OutputForm"]
   ["obinomial`2`n`(_$,_$)->_$`dOutputForm``253816"]
   "57fde9cb599e74b4e1917af8ae728a05"

   (12)  "57fde9cb599e74b4e1917af8ae728a05.html"
                                                                 Type: String

the result is (well, should be) the md5sum of

obinomial`2`n`(_$,_$)->_$`dOutputForm

Hmm, not sure what the `253816 is.  It seems that some debugging is
necessary...

\start
Date: Sat, 09 Jun 2007 16:47:23 +0200
From: Gregory Vanuxem
To: Martin Rubey
Subject: Re: Axiom under Windows

Le samedi 09 juin 2007 =E0 15:35 +0200, Martin Rubey a =E9crit :
> Gregory Vanuxem writes:
>
> > > I'll resurrect it if there is interest.
> >
> > I'm interested, since some time now, in console mode documentation so I would
> > like to play with your code.
>
> Hm, but the main point of my code is to display the doc in a browser.

Of course, I know that.

> > My main problem is that I don't now what queries are acceptable. Can you give
> > me some samples (in console mode so something like
> > getDocumentation("foo`%20`bar")) ?
>
> OK.  But I'd rather suggest you use
>
> ops: Database IndexCard := getDatabase("o")$OperationsQuery
>
> and read the documentation of Database.  In fact, there is an example in the
> axiom book.
> Note that getDatabase hould return some large number (the number of all
> operations in axiom). if it doesn't, get a better axiom.

Hmm... I have to get a better Axiom, getDatabase returns 42. Now I know,
apparently, why my tests were unsuccessful.

> -------------------------------------------------------------------------------
>
> getDocumentation takes a string of the form
>
> "op`params`origin"
>
> where pattern matching is supported via the special sequence %20. (should be
> changed in fact, it should better be the empty string.)
>
> It returns a string which is the name of a html file generated via htex4ht.
> The name is the md5sum code for the complete specification.
> For example:
> (12) -> getDocumentation "binomial`%20`OutputForm"
>    ["binomial","%20","OutputForm"]
>    ["obinomial`2`n`(_$,_$)->_$`dOutputForm``253816"]
>    "57fde9cb599e74b4e1917af8ae728a05"
>
>    (12)  "57fde9cb599e74b4e1917af8ae728a05.html"
>                                                                  Type: String
>
> the result is (well, should be) the md5sum of
>
> obinomial`2`n`(_$,_$)->_$`dOutputForm
>
> Hmm, not sure what the `253816 is.  It seems that some debugging is
> necessary...

Ok, thanks, that works for me with wh-sandbox and build-improvements. I
will now be able to test your code, better understand it and probably
experiment with it.

\start
Date: Sat, 9 Jun 2007 08:30:50 -0700 (PDT)
From: Cliff Yapp
To: list
Subject: Book on Parsing techniques

Does anyone have any experience with this book?:

Parsing Techniques - A Practical Guide
Dick Grune and Ceriel J.H. Jacobs 
http://www.cs.vu.nl/~dick/PTAPG.html

cl-web was a learning experience on how important parsing techniques
can be to performance, and given what likely lies ahead for SPAD/Aldor,
TeX, and who knows what else it would be nice to have a better grasp of
how to handle this task.  The above book looks interesting and I was
wondering if anyone more knowledgable could comment on whether it is a
good starting point.

\start
Date: Sat, 9 Jun 2007 11:44:04 -0400
From: Alfredo Portes
To: Gregory Vanuxem
Subject: Re: Axiom under Windows

Hi Greg,

On 6/9/07, Gregory Vanuxem wrote:

> Ok, thanks, that works for me with wh-sandbox and build-improvements. I
> will now be able to test your code, better understand it and probably
> experiment with it.

Can you share your experiences and how you got it to work. I have been trying
to test the code, but everytime it crashes on me...I had posted my
errors on the list but
no answer (maybe my problem was too obvious or silly)....I do not
think the documentation
on the wiki is correct or enough.

\start
Date: Sat, 9 Jun 2007 11:48:53 -0400
From: Alfredo Portes
To: Martin Rubey
Subject: Re: HyperDocReplacement

Hi Martin,

On 09 Jun 2007 10:19:11 +0200, Martin Rubey wrote:
> this should read
>
> SOCKET(8080, getDocumentation$HyperDoc)$Lisp
>
> (SOCKET is a Lisp function)
>
> Please excuse me, if you find another problem, I'll try to answer quicker...

Dont worry Martin. Actually inside your lisp code, it says how to run it in the
first line and there it is correct. I really would like to work on
this as soon as
I understand more the code.

\start
Date: 09 Jun 2007 17:57:52 +0200
From: Martin Rubey
To: Alfredo Portes
Subject: Re: Axiom under Windows

Alfredo Portes writes:

> Hi Greg,
> 
> On 6/9/07, Gregory Vanuxem wrote:
> 
> > Ok, thanks, that works for me with wh-sandbox and build-improvements. I
> > will now be able to test your code, better understand it and probably
> > experiment with it.
> 
> Can you share your experiences and how you got it to work. I have been trying
> to test the code, but everytime it crashes on me...I had posted my errors on
> the list but no answer (maybe my problem was too obvious or silly)....

Hm, did you get my mail from today?  (in any case: there is not problem that is
too obvious or silly! never say such things!) In case you didn't receive it, I
repeat it below.  I also updated the page on MathAction.

> I recompiled wh-sandbox and it seems to work fine the first two steps.
> However I get this:
> 
> (1) -> SOCKET(8080, getDocumentation$HyperDoc)

this should read

SOCKET(8080, getDocumentation$HyperDoc)$Lisp

(SOCKET is a Lisp function)

Please excuse me, if you find another problem, I'll try to answer quicker...

Just to make sure, here is the local version of my files.  I'm constantly
having problems to upload files to MathAction, unfortunately.

WARNINGS:

(1)

http://localhost:8080/?|integrate|

will take a *very* long time on the first run.  The idea of the design is to be
able to generate html on the fly, but only if absolutely necessary (i.e., if
third party libraries were added.)

I suggest that when axiom is built, or installed as a binary, the html should
be generated for everything already in the system.

(2)

since this code generates files in the current directory, I suggest that you
put it into a fresh directory.


Again, I'm very interested in feedback, especially from Windows users.

Martin

--hyper.input------------------------------------------------------------------

)lib HYPER
)lisp (load "hyper.lisp")
SOCKET(8080, getDocumentation$HyperDoc)$Lisp
-- direct the browser to
-- http://localhost:8080/?|binomial|
-- or
-- http://localhost:8080/?|binomial` `OutputForm|

--error.html-------------------------------------------------------------------

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title></title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht
  (http://www.cse.ohio-state.edu/~gurari/TeX4ht/mn.html)"> 
<meta name="originator" content="TeX4ht
  (http://www.cse.ohio-state.edu/~gurari/TeX4ht/mn.html)"> 
<!-- html --> 
<meta name="src" content="sum.tex"> 
<meta name="date" content="2007-04-21 21:59:00"> 
</head><body 
>
error
</body></html> 

--hyper.spad-------------------------------------------------------------------

)abbrev package HYPER HyperDoc
HyperDoc(): Exports == Implementation where

    Exports == with

        getDatabases: () -> Void

        getDocumentation: String -> String

    Implementation == add

        ops: Database IndexCard := getDatabase("o")$OperationsQuery

        getDatabases == 
            ops := getDatabase("o")$OperationsQuery


-- ostretch`2`x`(_$,ACMachineInteger)->_$`dCycleIndexSeries``

        filter(dbase: Database IndexCard, leq: List QueryEquation): Database
        IndexCard ==
            res: Database IndexCard := dbase
            for eq in leq repeat
                res := res.eq
            res

        getSpecification(op: IndexCard): String == 
            s: String := concat([op.'name, "`", op.'type, "`", op.'origin])
            systemCommand("sys rm myspec")$MoreSystemCommands
            f: TextFile := open("myspec"::FileName, "output")
            writeLine!(f, s)
            close! f
            systemCommand("sys md5sum myspec > md5spec")$MoreSystemCommands
            f: TextFile := open("md5spec"::FileName, "input")
            r := readLine! f
            close! f
            r.(1..32)

-- this function should really be in Database.  Well, actually Database should
-- export Table or some such
        coerce(dbase: Database IndexCard): List IndexCard ==
            dbase pretend List IndexCard

        getDocumentation s ==
            import QueryEquation
            import Database IndexCard
            ls := split(s, char "`")
            output(ls::OutputForm)$OutputPackage
            leq: List QueryEquation := []
            if ls.1 ~= "%20" then leq := [equation('name, ls.1)]
            if #ls > 1 and ls.2 ~= "%20" then leq := cons(equation('params,
            ls.2), leq)
            if #ls > 2 and ls.3 ~= "%20" then leq := cons(equation('origin,
            ls.3), leq)
            r: List IndexCard := coerce(filter(ops, leq))
            output(r::OutputForm)$OutputPackage
            if empty? r
            then "error.html"
            else
                res: String
                n := #r
                if n > 1 then 
                    res := "result.html"
                    output(res::OutputForm)$OutputPackage
                    g: TextFile := open(res::FileName, "output")
                    writeLine!(g, _ 
"<html > _
<head><title></title> _
<meta http-equiv=_"Content-Type_" content=_"text/html; charset=iso-8859-1_">_
</head><body>")
                    
                for op in r repeat
                    spec := getSpecification op
                    output(spec::OutputForm)$OutputPackage
                    if not exists?(concat(spec, ".html")::FileName) then
                        f: TextFile := open(concat(spec, ".tex")::FileName,
                    "output")
                        writeLine!(f, _ 
"\documentclass{amsart}_
\usepackage{hyperref}_
\newcommand{\spad}[1]{#1}_
\newcommand{\spadtype}[1]{#1}_
\newcommand{\spadfun}[1]{\href{http://localhost:8080/?|#1|}{#1}}_
\newcommand{\spadignore}[1]{#1}_
\newcommand{\undocumented}{{\bf undocumented}}_
\newcommand{\blankline}{\par}_
\newcommand{\indented}[2]{#2}_
\def\axiom{\spad}_
\def\axiomType{\spadtype}_
\begin{document}")
                        writeLine!(f, op.'doc)
                        writeLine!(f, "\end{document}")
                        close! f
                        systemCommand(concat ["sys htlatex '", spec, ".tex'
                    _"html,css-in_""])
                                     $MoreSystemCommands
                        systemCommand("sys rm
                    *.{log,4tc,4ct,lg,tmp,aux,dvi,idv,xref,css}")
                                     $MoreSystemCommands

                    if n = 1 
                    then res := concat(spec, ".html")
                    else writeLine!(g, concat ["<a href='|", spec, ".html|'> ",
                    _
                                    op.'origin, "</a>"])

                if n > 1 then 
                    writeLine!(g, "</body></html>") 
                    close! g
                res

--hyper.lisp-------------------------------------------------------------------

;; try it with
;; )lisp (load "hyper.lisp")
;; SOCKET(8080, getDocumentation$HyperDoc)$Lisp

(defvar *docfun*)

(defun socket (port docfun)
  (setq *docfun* docfun)
  (let ((s (si::socket port :server #'server)))
    (tagbody l
             (when (si::listen s)
               (let ((w (si::accept s)))
                 (server w)))
             (sleep 0.1)
             (go l))))

; server provides the stream which is sent by socket to localhost:port
; needs tidying, especially the checking whether fn changed.  
; Does it make sense to check this?
(defun server (s)

; I do not know how to prevent read from making everything uppercase. Please
  help! 
  (let* ((get (read s nil 'eof))

; fn contains the string after "localhost:port", i.e., it will commence with a
  "/",
; which subseq removes
         (fn (and (eq get 'get) 
                  (subseq (string (read s nil 'eof)) 1))))

; the following is just a debugging message
    (format t "Got ~S~%~%" fn)

; when the leading char is a question mark, we have to prepare documentation
    (when (string= (char fn 0) "?")
; *docfun* should return the name of an html file
; in case of an error, it will also return the name of an html file, which will
; contain the error message
      (setq fn (SPADCALL (subseq fn 1) *docfun*)))

; when the trailing four characters of the string are "html", we assume that we
; have an html file and tell our browser so.
; note that pictures or stylesheets do not like being introduced with this
; header.
    (when (string= (subseq fn (- (length fn) 4)) "html")
      (format s "HTTP/1.1 ~S~%" (if fn 200 403)))

; finally, we open the file, and display it
    (with-open-file  (q fn) (si::copy-stream q s))
    (close s)))

\start
Date: 09 Jun 2007 17:59:52 +0200
From: Martin Rubey
To: Alfredo Portes
Subject: Re: HyperDocReplacement

Alfredo Portes writes:

> > Please excuse me, if you find another problem, I'll try to answer
> > quicker...
> 
> Dont worry Martin. Actually inside your lisp code, it says how to run it in
> the first line and there it is correct. I really would like to work on this
> as soon as I understand more the code.

I'm confused.  Does it work now on your system?

\start
Date: Sat, 09 Jun 2007 18:33:56 +0200
From: Gregory Vanuxem
To: Alfredo Portes
Subject: Re: Axiom under Windows

Le samedi 09 juin 2007 =E0 11:44 -0400, Alfredo Portes a =E9crit :
> Hi Greg,
>
> On 6/9/07, Gregory Vanuxem wrote:
>
> > Ok, thanks, that works for me with wh-sandbox and build-improvements. I
> > will now be able to test your code, better understand it and probably
> > experiment with it.
>
> Can you share your experiences and how you got it to work. I have been trying
> to test the code, but everytime it crashes on me...I had posted my
> errors on the list but
> no answer (maybe my problem was too obvious or silly)....I do not
> think the documentation
> on the wiki is correct or enough.

Nothing more than what Martin just told you. Just one thing, Firefox
seems to translate ` to %60 so the request is badly parsed. I used
Konqueror. I have another problem, Htlatex does not work on my Debian
system (amd64 testing) but the LaTeX file is correctly generated.

\start
Date: Sat, 9 Jun 2007 12:34:27 -0400
From: Alfredo Portes
To: Martin Rubey
Subject: Re: HyperDocReplacement

Hi Martin,

> I'm confused.  Does it work now on your system?

Sorry for the confusion. I am able to run it...but it crashes on me when
I try to acces it from the browser. I am trying to see what I am doing
wrong.

(1) -> SOCKET(8080, getDocumentation$HyperDoc)$Lisp
Got "?binomial%60%20%60OutputForm"

   Loading
      /usr/local/lib/axiom/target/x86_64-unknown-linux/algebra/UNISEG.o
      for domain UniversalSegment
   Loading
      /usr/local/lib/axiom/target/x86_64-unknown-linux/algebra/OUT.o
      for package OutputPackage
   ["binomial%60%20%60OutputForm"]
   Loading
      /usr/local/lib/axiom/target/x86_64-unknown-linux/algebra/VOID.o
      for domain Void
   Loading
      /usr/local/lib/axiom/target/x86_64-unknown-linux/algebra/QEQUAT.o
      for domain QueryEquation

   >> Error detected within library code:
   index out of range

\start
Date: Sat, 9 Jun 2007 12:44:44 -0400
From: Alfredo Portes
To: Martin Rubey
Subject: Re: HyperDocReplacement

Hi Martin,

Greg just showed me why the problem with the %60 conversion.
It works on Konqueror. Thank you,

Alfredo

On 6/9/07, Alfredo Portes wrote:
> Hi Martin,
>
> > I'm confused.  Does it work now on your system?
>
> Sorry for the confusion. I am able to run it...but it crashes on me when
> I try to acces it from the browser. I am trying to see what I am doing
> wrong.
>
> (1) -> SOCKET(8080, getDocumentation$HyperDoc)$Lisp
> Got "?binomial%60%20%60OutputForm"
>
>    Loading
>       /usr/local/lib/axiom/target/x86_64-unknown-linux/algebra/UNISEG.o
>       for domain UniversalSegment
>    Loading
>       /usr/local/lib/axiom/target/x86_64-unknown-linux/algebra/OUT.o
>       for package OutputPackage
>    ["binomial%60%20%60OutputForm"]
>    Loading
>       /usr/local/lib/axiom/target/x86_64-unknown-linux/algebra/VOID.o
>       for domain Void
>    Loading
>       /usr/local/lib/axiom/target/x86_64-unknown-linux/algebra/QEQUAT.o
>       for domain QueryEquation
>
>    >> Error detected within library code:
>    index out of range

\start
Date: 09 Jun 2007 18:56:19 +0200
From: Martin Rubey
To: Gregory Vanuxem
Subject: Re: Axiom under Windows

Gregory Vanuxem writes:

> Just one thing, Firefox seems to translate ` to %60 so the request is badly
> parsed.

Oh dear.  Is there an ascii character which is forbidden in Axiom and left
unchanged by every browser?  Or, otherwise, is there a simple solution to make
Lisp keep the case? Currently I use vertical bars and

         (fn (and (eq get 'get) 
                  (subseq (string (read s nil 'eof)) 1))))

but I think that this is not satisfactory.

> I have another problem, Htlatex does not work on my Debian system (amd64
> testing) but the LaTeX file is correctly generated.

Oh, did you write Eitan?

Alfredo Portes writes:

> (1) -> SOCKET(8080, getDocumentation$HyperDoc)$Lisp
> Got "?binomial%60%20%60OutputForm"

>    ["binomial%60%20%60OutputForm"]

Yes, that's just what Greg explained.  The cure is to find another character
which is forbidden in Axiom and left unchanged by your browser (and preferably,
by any browser), and replace the "`" in line 46 of hyper.spad by that symbol.

           ls := split(s, char "`")

I did not check, but maybe "_" would be ok.  I chose "`" since it is used by
axiom as separator in the database, and I thought I'd better be consistent.

It does not matter what separator one uses in line 26:

            s: String := concat([op.'name, "`", op.'type, "`", op.'origin])

It is only important, that different name, type, origin triples are mapped to
different string.


Martin




\start
Date: 09 Jun 2007 18:58:15 +0200
From: Martin Rubey
To: Alfredo Portes
Subject: Re: HyperDocReplacement

Alfredo Portes writes:

> Hi Martin,
> 
> Greg just showed me why the problem with the %60 conversion.
> It works on Konqueror. Thank you,

Still, since you have firefox, (and I suspect also internet explorer) maybe you
could experiment a little.  Could you try "_" as separating character?

\start
Date: 09 Jun 2007 20:29:48 +0200
From: Martin Rubey
To: list
Subject: axiom mode

The following message is a courtesy copy of an article
that has been posted to gnu.emacs.help,comp.emacs.xemacs as well.

Dear emacs gurus,

as I have posted some time ago, I am writing an emacs mode for the free
computer algebra system axiom available at

http://wiki.axiom-developer.org/FrontPage

Meanwhile I am quite happy with it, save a few glitches.  Maybe some guru here
could help me out.  I attach the complete source, hoping not to violate
nettiquette...  I start the mode (after M-x load-file Ret axiom.el) with M-x
axiom.

I have three major problems:

* after loading axiom.el, using shell mode is a pain.  This is most annoying.
  It seems that all the hooks are still there, but I do not know the necessary
  magic to remove them.  I suppose, there are also some style guidelines?

* if axiom produces a lot of output, and one presses M-p while the output is
  being written to the buffer, everything gets messed up.  In particular, point
  moves to the previous prompt and further output is written *before* that
  prompt instead of afterwards.  For example, if you have axiom installed,
  enter, for example,

  for i in 1..20 repeat (output(i); [j for j in 1..5000])

  and

  press M-p during the computation.  I don't understand this behaviour, since I
  defined

(defun axiom-scroll-previous-input (&optional arg)
  "Fetch the previous input."
  (interactive "p")
  (unless (axiom-output? (point))
    (axiom-previous-prompt)
    (comint-set-process-mark)
    (comint-previous-input arg)
    ;; delete the rest
    (delete-region (point) (axiom-end-of-input))))

  So, before doing anything, I check whether I am in the output region, in
  which case I do nothing.  Can anyone explain that behaviour?  (I also tries
  (1- (point)), this didn't make any difference.)

* I cannot get it to run under xemacs.  I keep getting ^M characters, and
  comint-strip-ctrl-m didn't work for me.  I'm completely lost here.


Any help would be *greatly* appreciated, and of course, get your name on the
copyright message.

Many thanks in advance,

Martin

;; Copyright (C) 1995, 2006, 2007 by Jay Belanger, Francois Maltey, Martin
;; Rubey and Cliff Yapp
;; This program is free software; you can redistribute it and/or
;; modify it under the terms of the GNU General Public License as
;; published by the Free Software Foundation; either version 2 of
;; the License, or (at your option) any later version.
;;          
;; This program is distributed in the hope that it will be
;; useful, but WITHOUT ANY WARRANTY; without even the implied
;; warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
;; PURPOSE.  See the GNU General Public License for more details.
;;          
;; You should have received a copy of the GNU General Public
;; License along with this program; if not, write to the Free
;; Software Foundation, Inc., 59 Temple Place, Suite 330, Boston,
;; MA 02111-1307 USA

(require 'comint)

;; Variables used when starting Axiom
(defvar axiom-command "")  ;; There is a function to determine this value
(defvar axiom-localpaths) ;; Used when searching the system path
(defvar axiom-args "-noclef")  ;; Ignored when AXIOMsys is used.
(defvar axiom-prompt "^(\\([0-9]+\\)) -> ")
(defvar axiom-after-output-wait 100) ;; time to wait for axiom's prompt

;; Utility variables
(defvar axiom-mode-hook nil)
(defvar axiom-process nil)
(defvar axiom-system-command nil)
(defvar axiom-end-of-input 0)

;;due to William G. Dubuque 1994
(defun looking-backward-at (regexp &optional bound) 
  (let ((point (point))) 
    (save-restriction 
      (narrow-to-region (or bound (point-min)) point) 
      ;; Recall that \' matches end of buffer in a regexp. 
      ;; Todo: bug: regexp compiler does not appear to optimize this well 
      ;; (seems like test (eobp) is done after each match instead of anchoring 
      ;; at eob), so use a bound to improve efficiency. 
      (prog1 (re-search-backward (concat regexp "\\'") bound t) 
             (goto-char point))))) 

;; Utility functions
(defun axiom-buffer ()
  "Return the buffer in which the Axiom process is running, nil 
otherwise"
  (and (processp axiom-process) (process-buffer axiom-process)))

(defun axiom-clean-up-prompt ()
  (let ((inhibit-read-only t)
        (point-after-last-message nil)
        (point-before-current-marker nil))
    (goto-char (point-min))
    (search-forward "(1) ->")
    (search-backward "(1) ->")
    (setq point-after-last-message (point-marker))
    (goto-char (point-max))
    (re-search-backward "([0-9]+) -> ")
    (setq point-before-current-marker (point-marker))
    (if (not (eq point-after-last-message point-before-current-marker))
       (delete-region point-after-last-message point-before-current-marker))
    (goto-char (point-max))))
(defun axiom-cleanup ()
   (setq axiom-process nil))


(defun axiom-output? (position)
  "Non-nil if position is in the output region"
  (get-text-property position 'axiom-output))

(defun axiom-prompt? (position)
  "Non-nil if position is in the prompt region"
  (get-text-property position 'axiom-prompt))
(defun axiom-make-prompt (begin end)
  "Makes the region a prompt.  In particular, it gets the field property, the
right face, and is made read-only"
  (let ((inhibit-read-only t))
    (put-text-property begin end 'axiom-prompt t)
    (remove-text-properties begin end '(axiom-output nil))

    (put-text-property begin end 'face 'comint-highlight-prompt)
    (put-text-property begin end 'field t)
    (put-text-property begin end 'front-sticky t)
    (put-text-property begin end 'rear-nonsticky t)
    (put-text-property begin end 'read-only t)
))

(defun axiom-make-output (begin end)
  (let ((inhibit-read-only t))
    (put-text-property begin end 'axiom-output t)
    (put-text-property begin end 'face 'axiom-output)
    (put-text-property begin end 'front-sticky t)  ; otherwise can insert
    (put-text-property begin end 'rear-nonsticky t); otherwise cannot append
    (put-text-property begin end 'read-only t)
))

(defun axiom-output-filter (str)
  "Look for a new input prompt."
  (let ((comint-last-output-end 
	 (process-mark (get-buffer-process (current-buffer))))
	(prompt-start 
	 (string-match axiom-prompt str)))
;    (print (list comint-last-output-start comint-last-output-end))
    (axiom-make-output (1+ axiom-end-of-input)
                       (if prompt-start
                           (+ comint-last-output-start
                              prompt-start)
                         comint-last-output-end))
    (when prompt-start
      (axiom-make-prompt (+ comint-last-output-start
                            prompt-start)
                         comint-last-output-end))))


; for i in 1..5 repeat (output "(1) -> "; [j for j in 1..6000])
; )lisp (dotimes (i 5) (sleep 1) (format t "(1) -> ~%"))
(defun axiom-wait-for-output ()
  "Wait for output from the Axiom process."
  (sit-for 0 axiom-after-output-wait))
(defun axiom-get-command ()
   "Searches the local system PATH variable for the axiom binary"
   (setq axiom-localpaths exec-path)
   (while axiom-localpaths
     (when (file-executable-p (concat (car axiom-localpaths) "/axiom"))
       (setq axiom-localpaths nil)
       (setq axiom-command "axiom"))
     (setq axiom-localpaths (cdr axiom-localpaths)))
   ;; If we come up empty, default to AXIOMsys
   (unless (equal axiom-command "axiom")
     (setq axiom-command "AXIOMsys")))
(defun axiom-comint-run ()
  "Run PROGRAM in a comint buffer with ARGS and switch to it."
  (switch-to-buffer (make-comint "axiom" axiom-command nil axiom-args)))

(defun axiom-run()
  "Run Axiom in a buffer."
  ;; Get the command to use
  (axiom-get-command)
  ;; Run that command and switch to the new buffer
  (axiom-comint-run)
  ;; and identify the process as well:
  (setq axiom-process (get-buffer-process (current-buffer)))
  ;; We need a custom wait condition for the first case, since two input
  ;; prompts appear when "axiom" is used to as the startup command.
  ;; Note that the REGEXP used in re-search-backward
  ;; is not compatible with grep or other tools - it is specific to the
  ;; behavior of Emacs
  (when (equal axiom-command "axiom")
    (while (not (re-search-backward "(1) -> [^ ](1) ->" nil t))
      (accept-process-output axiom-process)))
  (when (equal axiom-command "AXIOMsys")
    (while (not (re-search-backward "(1) -> " nil t))
      (accept-process-output axiom-process)))
  (add-hook 'comint-output-filter-functions 'axiom-output-filter)
  (sit-for 0 axiom-after-output-wait))

;;################### Terminal Mode ########################
(defun axiom-previous-prompt ()
  "Put point just after the previous prompt and return this position.  If
there is no previous prompt, point stays where it is end we return nil.  We use
the regular expression to find a prompt, rather than the text-property, for
axiom-reset."
  (let ((found?))
    (while (and (setq found? (re-search-backward axiom-prompt nil t))
                (not (axiom-prompt? (point)))))
    (when found? 
      (end-of-line)
      (point))))

(defun axiom-previous-input ()
  "If in input, puts point just after the prompt before the previous prompt and
return this position. If in output, or at the first input line, puts point just
after the previous prompt. Otherwise, the behaviour is undefined."
  (interactive)
  (let ((found?))
    (if (or (axiom-output? (point))
            (axiom-prompt? (point)))
        (axiom-previous-prompt)
      (while (and (re-search-backward axiom-prompt nil t)
                  (not (axiom-prompt? (point)))))
      (while (and (setq found? (re-search-backward axiom-prompt nil t))
                  (not (axiom-prompt? (point)))))
      (end-of-line)
      (when found? (point)))))

(defun axiom-next-input ()
  "Puts point just after the next prompt and return this position.  If there
is no next prompt, point stays where it is end we return nil."
  (interactive)
  (let ((found?))
    (while (and (setq found? (re-search-forward axiom-prompt nil t))
                (not (axiom-prompt? (1- (point))))))
    found?))

(defun axiom-next-prompt ()
  "Puts point just before the next prompt and return this position.  If there
is no next prompt, point stays where it is end we return nil."
  (when (axiom-next-input) (re-search-backward axiom-prompt nil t)))

(defun axiom-end-of-input ()
  "Puts point at the end of the last input line and returns that position."
  (while (and (not (axiom-output? (point))) (looking-at ".*_ *$"))
    (next-line 1)
    (beginning-of-line))
  (end-of-line)
  (point))

(defun axiom-scroll-previous-input (&optional arg)
  "Fetch the previous input."
  (interactive "p")
  (unless (axiom-output? (point))
    (axiom-previous-prompt)
    (comint-set-process-mark)
    (comint-previous-input arg)
    ;; delete the rest
    (delete-region (point) (axiom-end-of-input))))

(defun axiom-scroll-next-input (&optional arg)
  "Move to the next input line."
  (interactive "p")
  (unless (axiom-output? (point))
    (axiom-previous-prompt)
    (comint-set-process-mark)
    (comint-next-input arg)
    ;; delete the rest
    (delete-region (point) (axiom-end-of-input))))

(defun axiom-backward-char (&optional arg)
  "Move left only if we stay in the input region."
  (interactive "p")
  (dotimes (i arg)
    (if (axiom-prompt? (1- (point)))
        (when (axiom-previous-input)
          (axiom-end-of-input))
      (backward-char))))

(defun axiom-forward-char (&optional arg)
  "Move right depending on the region we are in."
  (interactive "p")
  (dotimes (i arg)
    (cond ((eobp)) ; at the end of the buffer we signal an error 
          ((looking-at axiom-prompt)
           (re-search-forward axiom-prompt))
          ((and (not (axiom-output? (point)))
                (axiom-output? (1+ (point))))
           (axiom-next-input))
          (t (forward-char)))))
(defvar axiom-mode-map (copy-keymap comint-mode-map) 
  "local key map for Axiom terminal mode")

(define-key axiom-mode-map [(meta up)] 'axiom-previous-input)
(define-key axiom-mode-map [(meta down)] 'axiom-next-input)
(define-key axiom-mode-map [left] 'axiom-backward-char)
(define-key axiom-mode-map [right] 'axiom-forward-char)
(defun axiom-reset ()
   "Remove read-only properties from everything after the last prompt."
   (interactive)
   (save-excursion
     (let ((inhibit-read-only t))
       (goto-char (point-max))
       (remove-text-properties (axiom-previous-prompt) 
                               (point-max) 
                               (list 'axiom-output nil 'axiom-prompt nil 
                                     'face nil 'field nil 'front-sticky nil
                                     'rear-nonsticky nil 'read-only nil))
       (axiom-make-prompt (re-search-backward axiom-prompt nil t) (point)))))

(defun axiom-copy-to-clipboard (&optional arg)
   "Copy the arg previous input-output combinations into the kill-ring."
   (interactive "p")
   (save-excursion
     (let* ((end (or (axiom-next-prompt) (point-max)))
            (n arg)
            (begin (progn (while (< 0 n)
                            (axiom-previous-prompt)
                            (if (re-search-backward axiom-prompt nil t)
                                (setq n (1- n))
                              (setq n 0)
                              (goto-char (point-min))))
                          (point))))
       (clipboard-kill-ring-save begin end))))

(define-key axiom-mode-map [(meta k)] 'axiom-copy-to-clipboard)

(defface axiom-output '((t (:background "green")))
  "Face used for output."
  :group 'axiom)

(defface axiom-paint-lightblue '((t (:background "lightblue")))
  "Lightblue face to use for painting."
  :group 'axiom)

(defface axiom-paint-red '((t (:background "red")))
  "Red face to use for painting."
  :group 'axiom)

(defface axiom-paint-custom '((t nil))
  "Custom face to use for painting."
  :group 'axiom)

(defvar axiom-paint-face-alist
  '(("lightblue" axiom-paint-lightblue)
    ("red"  axiom-paint-red)
    ("custom"  axiom-paint-custom)
    ("output"  axiom-output)))

(defvar axiom-paint-face 'axiom-paint-lightblue)

(defun axiom-paint-face ()
  (interactive)
  (let ((newpaint (completing-read "New paint face: "
                                   axiom-paint-face-alist
                                   nil t)))
    (setq axiom-paint-face (cadr (assoc newpaint axiom-paint-face-alist)))))

(defun axiom-make-space-if-necessary-and-paint ()
  ;; The following is to make sure that a line does not end with a painted
  ;; character.  This would have the unwanted effect, that spaces appended by
  ;; either axiom-paint-previous-line or axiom-paint-next-line inherit the face
  ;; of the last character.
  (when (eolp)
    (insert-char 32 2 t)
    (backward-char 2))
  (forward-char 1)
  (when (eolp)
    (insert-char 32 1 t)
    (backward-char 1))
  (backward-char 1)
  
  (if (equal (get-text-property (point) 'face)
             axiom-paint-face)
      (if (axiom-output? (point))
          (put-text-property (point) (1+ (point)) 'face 'axiom-output)
        (remove-text-properties (point) (1+ (point)) '(face nil)))
    (put-text-property (point) (1+ (point)) 'face axiom-paint-face)))

(defun axiom-paint-previous-line ()
  (interactive)
  (when (axiom-output? (point))
    (let ((inhibit-read-only t)
          (old-column (current-column))
          (old-pos    (point)))
      (axiom-make-space-if-necessary-and-paint)
      (previous-line 1)
      (if (axiom-output? (point))
          (let ((difference (- old-column (current-column))))
            (when (> difference 0)
              (insert-char 32 difference t)))
        (goto-char old-pos)))))

(defun axiom-paint-next-line ()
  (interactive)
  (when (axiom-output? (point))
    (let ((inhibit-read-only t)
          (old-column (current-column))
          (old-pos    (point)))
      (axiom-make-space-if-necessary-and-paint)
      (next-line 1)
      (if (axiom-output? (point))
          (let ((difference (- old-column (current-column))))
            (when (> difference 0)
              (insert-char 32 difference t)))
        (goto-char old-pos)))))

(defun axiom-paint-previous-char ()
  (interactive)
  (when (axiom-output? (point))
    (let ((inhibit-read-only t))
      (axiom-make-space-if-necessary-and-paint)
      (when (axiom-output? (1- (point)))
        (backward-char 1)))))

(defun axiom-paint-next-char ()
  (interactive)
  (when (axiom-output? (point))
    (let ((inhibit-read-only t))
      (axiom-make-space-if-necessary-and-paint)
      (forward-char 1))))

(define-key axiom-mode-map [(shift up)] 'axiom-paint-previous-line)
(define-key axiom-mode-map [(shift down)] 'axiom-paint-next-line)
(define-key axiom-mode-map [(shift left)] 'axiom-paint-previous-char)
(define-key axiom-mode-map [(shift right)] 'axiom-paint-next-char)

(defface axiom-changed-input '((t (:foreground "red")))
  "Face to use to highlight input when `comint-highlight-input' is non-nil."
  :group 'axiom)

(defun axiom-clear-overlays ()
   "Clears all text properties at point"
   (while (overlays-at (point))
     (delete-overlay (car (overlays-at (point))))))

(defvar axiom-current-input "")
(defun axiom-flag-as-changed (overlay after-change begin end &optional len)
  "Handles updating the input prompt in question after a change.  We assume
that point is between begin and end."
  (let ((new-input (buffer-substring begin end)))
    (if after-change
	(unless (string= axiom-current-input new-input)
	  ;; Change the look of the text
	  (overlay-put overlay 'face 'axiom-changed-input)
	  ;; And remove this function from the modification hooks list
	  (overlay-put overlay 'modification-hooks '())
          ;; Mark all prompts below to indicate that they have to be taken with
          ;; care
          (let ((position end)
                (max (point-max))
                (inhibit-read-only t))
            (while (not (= position max))
              (if (axiom-prompt? position)
                  (let ((begin position))
                    (while (and (axiom-prompt? position)
                                (< position max))
                      (setq position (1+ position)))
                    (let ((overlay (make-overlay begin (- position 4) 
						 nil nil t)))
                      (overlay-put overlay 'face 'axiom-changed-input)))
                (setq position (1+ position))))
            (sit-for 0)))
      (setq axiom-current-input new-input))))

(defun axiom-make-input (begin end)
  "Call this when a new evaluation begins. It sets the 'modification-hooks 
property for the input after the current prompt.  It sets point at the end 
of the current input"
  (interactive)
  (axiom-clear-overlays)
  (let ((over (make-overlay begin end nil nil t)))
    (overlay-put over 'modification-hooks '(axiom-flag-as-changed))))

(defun axiom-repair-prompts ()
  "Repairs prompts at the end of the document once an overwrite eval is
complete.  Point is expected to be at the new prompt, after the last output.
Afterwards, point is where it was before."
  (save-excursion
    (let* ((new-prompt-start (re-search-backward axiom-prompt nil t))
	   (new-prompt-end (re-search-forward axiom-prompt nil t))
	   (new-prompt (buffer-substring new-prompt-start new-prompt-end))
	   (inhibit-read-only t))
      ;; Remove the new prompt and put it in the kill ring
      (delete-region new-prompt-start new-prompt-end)
      ;; Weed out the extra newline, if present.  For example, in case of an
      ;; error it is not present.  I guess it would be better to detect
      ;; errors by parsing the prompt, but I leave this for somebody else.
      (when (char-equal (char-after) 10)
	(delete-char 1))
      ;;  Finally we get rid of the old prompt at the end of the buffer and 
      ;;  insert the new one, which is currently somewhere in the middle of the
      ;;  buffer.
      (goto-char (point-max))
      (let ((old-prompt-start (re-search-backward axiom-prompt nil t)))
	(delete-region old-prompt-start (line-end-position))
	(insert new-prompt)
	(axiom-make-prompt old-prompt-start (point))))))

(defun axiom-overwrite-output-eval ()
  "Function which handles the actual mechanics of inserting a new IO pair.  It
expects point to be between the current and the next prompt."
  (let* (;; the old prompt is just before the input we want to evaluate
         (old-prompt-end (axiom-previous-prompt))
         (old-prompt-start (re-search-backward axiom-prompt nil t))
         ;; the new prompt is at the very end of the buffer
         (new-prompt (buffer-substring 
                      (progn (goto-char (point-max))
                             (re-search-backward axiom-prompt nil t))
                      (re-search-forward axiom-prompt nil t)))
         (inhibit-read-only t))
    ;; Delete the old prompt
    (delete-region old-prompt-start old-prompt-end)
    ;; Clear out any pre-existing text overlays - needed for the case
    ;; where the same input is being re-evaluated - if this isn't 
    ;; removed, the new prompt is bold.  If no overlay do nothing.
    (goto-char old-prompt-start)
    (axiom-clear-overlays)
    ;; Put the new prompt in
    (insert new-prompt)
    ;; Now we are done changing this prompt, and can prepare the input
    (comint-set-process-mark)
    (axiom-make-input (1- (point))
                      (setq axiom-end-of-input (axiom-end-of-input)))
    ;; Delete the old output
    (delete-region (1+ axiom-end-of-input)
                   (axiom-next-prompt))

    ;; send new input
    (goto-char axiom-end-of-input)
    (comint-send-input)
    (axiom-wait-for-output)))

(defun axiom-normal-eval ()
   "This function is used for evaluation at the 'front' Axiom prompt. It
expects point anywhere after the last prompt."
   (axiom-make-input (1- (axiom-previous-prompt))
                     (setq axiom-end-of-input (axiom-end-of-input)))
   (comint-send-input)
   (axiom-wait-for-output))

(defun axiom-eval ()
  "Evaluate the current input and insert output."
  (interactive)
  (if axiom-system-command 
      ;; we are responding to a system command.
      (progn 
	(setq axiom-system-command nil
              axiom-end-of-input (axiom-end-of-input))
	(comint-send-input)
	(axiom-wait-for-output)
        
        ;; If there is a prompt further down, we are overwriting old stuff.
	(when (re-search-forward axiom-prompt nil t)
          (re-search-backward axiom-prompt)
          (axiom-repair-prompts)
          (re-search-forward axiom-prompt nil t)
          (comint-set-process-mark)))

    ;; otherwise, we first check whether we have multiline input.
    (beginning-of-line)
    (if (looking-at ".*_ *$")
	(progn (end-of-line)
               (newline))

      ;; move to the the end of the preceding prompt
      (axiom-previous-prompt)
      (comint-set-process-mark)
      ;; is it a system command?
      (setq axiom-system-command (looking-at " *)"))
      
      ;; If there is a prompt further down, we are overwriting old stuff.
      (if (axiom-next-prompt)
	  (progn (axiom-overwrite-output-eval)
                 ;; if we are now looking at a prompt, we are certainly not
                 ;; answering a question posed by axiom.
                 (when (looking-backward-at axiom-prompt)
                   (setq axiom-system-command nil)
		   (axiom-repair-prompts)
                   (end-of-line) ;; this moves point to the end of the prompt!
                                 ;; it seems to work even if we type text
                                 ;; during a computation.
		   (comint-set-process-mark)))
	(axiom-normal-eval)
        (when (looking-backward-at axiom-prompt)
          (setq axiom-system-command nil))))))

;; Now that everything is defined, bind the return key to our new eval function
(define-key axiom-mode-map [return] 'axiom-eval)

(defun axiom-eval-append ()
  "Evaluate the current input and append output."
  (interactive)
  (let* ((input (buffer-substring (axiom-previous-prompt) 
                                  (axiom-end-of-input)))
         (end (progn (goto-char (point-max))
                     (point))))
    (delete-region (axiom-previous-prompt) end)
    (comint-set-process-mark)
    (insert input)
    (axiom-eval)))

(define-key axiom-mode-map [(meta return)] 'axiom-eval-append)

(define-derived-mode axiom-mode comint-mode "AXIOM")

(defun axiom ()
   "Run axiom in a terminal environment"
  (interactive)
  (if (and (processp axiom-process)
	   (eq (process-status axiom-process) 'run))
      (switch-to-buffer (axiom-buffer))
    (axiom-mode-new-axiom-process))
  (axiom-mode))

;; If there is a running axiom process switch to this axiom buffer
;; In the other case clean buffer and process variables and 
;; start a new process in a new buffer.

(defun axiom-mode-new-axiom-process ()
  (when (processp axiom-process)
    (delete-process axiom-process)
    (kill-buffer (axiom-buffer))
    (setq axiom-process nil))
  (setq axiom-end-of-input 0)
  ;; First, let's get axiom up and running. 
  (axiom-run)
  ;; we make also the banner write-protected
  ;; note that because of the axiom-output-filter we might be already have
  ;; write protected the banner.
  (let ((inhibit-read-only t))
    (remove-text-properties 1 (point) '(face nil rear-nonsticky nil))
    (put-text-property 1 (point) 'front-sticky t)
    (put-text-property 1 (point) 'read-only t)
    ;; We need to tell Emacs how to clean up if we close this
    ;; buffer - otherwise restarting is difficult:
    (add-hook 'kill-buffer-hook 'axiom-cleanup)
    ;; Then we clean up the prompt.
    (axiom-clean-up-prompt)
    ;; We need to explicitly write protect the first prompt, since it
    ;; is outside the normal write protect mode used for subsequent
    ;; output: 
    (axiom-make-prompt (- (point) 7) (point))
    ;; Next, we turn on some key bindings for our new mode:
    (use-local-map axiom-mode-map)
    (substitute-key-definition 'comint-previous-input 
                               'axiom-scroll-previous-input axiom-mode-map)
    (substitute-key-definition 'comint-next-input 
                               'axiom-scroll-next-input axiom-mode-map)
    ;; HyperDoc currently sends loading messages to the buffer.  Because of the
    ;; current setup, they are going to be read-only, and they are not followed
    ;; by a prompt.  Thus, lest we cannot append any further input, we have to
    ;; mute them.  Currently this is only possible via 
    ;; )set messages autoload off
    (insert ")se me au of")
    (axiom-eval)))

\start
Date: 10 Jun 2007 08:41:48 +0200
From: Martin Rubey
To: list
Subject: Re: axiom mode

The following message is a courtesy copy of an article
that has been posted to gnu.emacs.help,comp.emacs.xemacs as well.

Dear Tom,

Tom Tromey <tromey@redhat.com> writes:

> >>>>> "Martin" == Martin Rubey writes:
> 
> I'm just guessing, based on what you wrote & a quick glance at the code, but
> I think you want to set local hooks.
> 
> Martin>   (add-hook 'comint-output-filter-functions 'axiom-output-filter)
> 
> So here you would want:
> 
>   (add-hook 'comint-output-filter-functions 'axiom-output-filter nil t)

many thanks, that did the trick.

> I don't know the answers to your other questions, sorry.

well, there remain only two things I don't know how to do.  Maybe there are
some more emacs gurus around:

* port to xemacs

* write clean initalisation code.  In particular, it should be possible to have
  several buffers with different axiom processes, just like in shell mode.  I
  looked at shell.el, but fail to understand it.

  For those who don't want to dig through all the code, I copy the relevant
  four routines below.  (It's not me who wrote them, and I find them rather
  difficult to follow.)

Again, many many thanks

Martin

(defun axiom-comint-run ()
  "Run PROGRAM in a comint buffer with ARGS and switch to it."
  (switch-to-buffer (make-comint "axiom" axiom-command nil axiom-args)))


(define-derived-mode axiom-mode comint-mode "AXIOM")

(defun axiom ()
   "Run axiom in a terminal environment"
  (interactive)
  (if (and (processp axiom-process)
	   (eq (process-status axiom-process) 'run))
      (switch-to-buffer (axiom-buffer))
    (axiom-mode-new-axiom-process))
  (axiom-mode))

;; If there is a running axiom process switch to this axiom buffer
;; In the other case clean buffer and process variables and 
;; start a new process in a new buffer.

(defun axiom-mode-new-axiom-process ()
  (when (processp axiom-process)
    (delete-process axiom-process)
    (kill-buffer (axiom-buffer))
    (setq axiom-process nil))
  (setq axiom-end-of-input 0)
  ;; First, let's get axiom up and running. 
  (axiom-run)
  ;; we make also the banner write-protected
  ;; note that because of the axiom-output-filter we might already have
  ;; write protected the banner.
  (let ((inhibit-read-only t))
    (remove-text-properties 1 (point) '(face nil rear-nonsticky nil))
    (put-text-property 1 (point) 'front-sticky t)
    (put-text-property 1 (point) 'read-only t)
    ;; We need to tell Emacs how to clean up if we close this
    ;; buffer - otherwise restarting is difficult:
    (add-hook 'kill-buffer-hook 'axiom-cleanup)
    ;; Then we clean up the prompt.
    (axiom-clean-up-prompt)
    ;; We need to explicitly write protect the first prompt, since it
    ;; is outside the normal write protect mode used for subsequent
    ;; output: 
    (axiom-make-prompt (- (point) 7) (point))
    ;; Next, we turn on some key bindings for our new mode:
    (use-local-map axiom-mode-map)
    (substitute-key-definition 'comint-previous-input 
                               'axiom-scroll-previous-input axiom-mode-map)
    (substitute-key-definition 'comint-next-input 
                               'axiom-scroll-next-input axiom-mode-map)
    ;; HyperDoc currently sends loading messages to the buffer.  Because of the
    ;; current setup, they are going to be read-only, and they are not followed
    ;; by a prompt.  Thus, lest we cannot append any further input, we have to
    ;; mute them.  Currently this is only possible via 
    ;; )set messages autoload off
    (insert ")se me au of")
    (axiom-eval)))

(defun axiom-run ()
  "Run Axiom in a buffer."
  ;; Get the command to use
  (axiom-get-command)
  ;; Run that command and switch to the new buffer
  (axiom-comint-run)
  ;; and identify the process as well:
  (setq axiom-process (get-buffer-process (current-buffer)))
  ;; We need a custom wait condition for the first case, since two input
  ;; prompts appear when "axiom" is used to as the startup command.
  ;; Note that the REGEXP used in re-search-backward
  ;; is not compatible with grep or other tools - it is specific to the
  ;; behavior of Emacs
  (when (equal axiom-command "axiom")
    (while (not (re-search-backward "(1) -> [^ ](1) ->" nil t))
      (accept-process-output axiom-process)))
  (when (equal axiom-command "AXIOMsys")
    (while (not (re-search-backward "(1) -> " nil t))
      (accept-process-output axiom-process)))
;; Tom Tromey: last argument being true means that the hook is buffer-local
  (add-hook 'comint-output-filter-functions 'axiom-output-filter nil t)
  (sit-for 0 axiom-after-output-wait))

\start
Date: 10 Jun 2007 09:24:32 +0200
From: Martin Rubey
To: Martin Rubey
Subject: Re: [Axiom-mail] [ANN] new version of axiom.el

A new version of axiom.el (10-06-2007) is now available on 

http://wiki.axiom-developer.org/SandBoxAxiomEmacsMode

Thanks to Tom Tromey, shell mode works now even after having used axiom mode.

I also added some documentation.

Missing:

* xemacs port

* allow debugger to be entered, I.e., track when the prompt may change.  How
  does shell mode do this?

* implement repositioning of the process-mark consistently and safely.

* clean up initialisation routines.  At times a hit an error in statements like
  (process-mark axiom-process), because for some reasons axiom-process is nil.
  It shouldn't be nil of course.

\start
Date: Sun, 10 Jun 2007 16:30:32 +0200
From: Gregory Vanuxem
To: Martin Rubey
Subject: Re: Axiom under Windows

Le samedi 09 juin 2007 =E0 18:56 +0200, Martin Rubey a =E9crit :

[...]

      * Gregory Vanuxem writes:
>
> > Just one thing, Firefox seems to translate ` to %60 so the request
> is badly
> > parsed.
>
> Oh dear. Is there an ascii character which is forbidden in Axiom and
> left
> unchanged by every browser?  Or, otherwise, is there a simple solution
> to make
> Lisp keep the case? Currently I use vertical bars and
>
> (fn (and (eq get 'get)
> (subseq (string (read s nil 'eof)) 1))))
>
> but I think that this is not satisfactory.

No idea. I'm temporary resurrecting some hypertex functionalities in my
version of Axiom in such a way that compiling a spad file creates the
libdb.text. That will take some times since I know nothing about
hypertex and the libdb.text files (Gold is buggy here). I can no longer
use Axiom built on top of GCL because of a spurious bug in GCL
(conditional statements not handled) and wh-sandbox misses file related
functions when built on top of SBCL. Anyway when time will permit I'll
try your Lisp code on Windows and tell you if it works. I know that Camm
is working on socket code for Windows but I do not remember if his work
is finished, so... Another thing, Kai Kaminski did some work too in this
area, I wonder how it can be used since wh-sandbox can now be built on
top of Clisp.

>
> > I have another problem, Htlatex does not work on my Debian system (amd64
> > testing) but the LaTeX file is correctly generated.
>
> Oh, did you write Eitan?

No, that is right now, it's a bug in the Debian package.
Copying /etc/tex4ht/tex4ht.env to ~/.tex4ht fixed this issue.

I have looked at your HyperDoc package and in fact it's extremely simple
to obtain documentation from Spad. Shame on me, I thought it was more
difficult than that.

Greg

>
> Alfredo Portes writes:
>
> > (1) -> SOCKET(8080, getDocumentation$HyperDoc)$Lisp
> > Got "?binomial%60%20%60OutputForm"
>
> >    ["binomial%60%20%60OutputForm"]
>
> Yes, that's just what Greg explained.  The cure is to find another character
> which is forbidden in Axiom and left unchanged by your browser (and preferably,
> by any browser), and replace the "`" in line 46 of hyper.spad by that symbol.
>
>            ls := split(s, char "`")
>
> I did not check, but maybe "_" would be ok.  I chose "`" since it is used by
> axiom as separator in the database, and I thought I'd better be consistent.
>
> It does not matter what separator one uses in line 26:
>
>             s: String := concat([op.'name, "`", op.'type, "`", op.'origin])
>
> It is only important, that different name, type, origin triples are mapped to
> different string.

\start
Date: Sun, 10 Jun 2007 15:37:28 -0400
From: William Sit
To: Martin Rubey
Subject: testing hyperdoc package on Windows

Dear Martin:

I tried hyperdoc package on Windows
/mathaction/SandBoxHyperDocReplacement. 
It compiled and loaded, but SOCKET does not work:

OPTIMIZE levels: Safety=0 (No runtime error checking),
Space=0, Speed=3, (Debug
quality ignored)
Finished compiling
j:/OpenAxiom/axiom014/mnt/windows/lib/HYPER.NRLIB/code.lsp.
------------------------------------------------------------------------
   HyperDoc is now explicitly exposed in frame initial
   HyperDoc will be automatically loaded when needed from
      /OpenAxiom/axiom014/mnt/windows/lib/hyper.NRLIB/code

(1) -> )lisp (load "hyper.lisp")

Value = T
(1) -> SOCKET(8080, getDocumentation$HyperDoc)
   Loading
/OpenAxiom/axiom014/mnt/windows/lib/hyper.NRLIB/code for
      package HyperDoc
   Loading
j:/OpenAxiom/axiom014/mnt/windows/algebra/OPQUERY.o for
      package OperationsQuery

   >> System error:
   GREP is invalid as a function.

protected-symbol-warn called with (NIL)


I put GREP.EXE (windows version) into the same directory,
but the same error.

Do I need to run some webserver on Windows? Thanks.

\start
Date: 10 Jun 2007 21:44:54 +0200
From: Martin Rubey
To: William Sit
Subject: Re: testing hyperdoc package on Windows

William Sit writes:

> (1) -> SOCKET(8080, getDocumentation$HyperDoc)
>    Loading
> /OpenAxiom/axiom014/mnt/windows/lib/hyper.NRLIB/code for
>       package HyperDoc
>    Loading
> j:/OpenAxiom/axiom014/mnt/windows/algebra/OPQUERY.o for
>       package OperationsQuery
> 
>    >> System error:
>    GREP is invalid as a function.
> 
> protected-symbol-warn called with (NIL)
> 
> 
> I put GREP.EXE (windows version) into the same directory,
> but the same error.

Try to put grep into the path. I guess that it's called by boot.

\start
Date: Sun, 10 Jun 2007 17:02:45 -0400
From: Bill Page
To: Martin Rubey
Subject: re: testing hyperdoc package on Windows

------=_Part_61636_17269102.1181509365093

On 10 Jun 2007 21:44:54 +0200, Martin Rubey wrote:

> William Sit writes:
>
> > (1) -> SOCKET(8080, getDocumentation$HyperDoc)
> >    Loading
> > /OpenAxiom/axiom014/mnt/windows/lib/hyper.NRLIB/code for
> >       package HyperDoc
> >    Loading
> > j:/OpenAxiom/axiom014/mnt/windows/algebra/OPQUERY.o for
> >       package OperationsQuery
> >
> >    >> System error:
> >    GREP is invalid as a function.
> >
> > protected-symbol-warn called with (NIL)
> >
> >
> > I put GREP.EXE (windows version) into the same directory,
> > but the same error.
>
> Try to put grep into the path. I guess that it's called by boot.


No, the message says: "GREP is invalid as a function". This
means that OPQUERY was trying to call a Lisp *function*
whose name is GREP. This has nothing directly to do with the
unix grep utility -- except that it does: We know from other
discussions about Axiom on Windows that the Lisp function
GREP was one of those things that was re-written by NAG as
a C extension of CCL when they ported Axiom to Windows.
On Linux the GREP function just calls OBEY "grep ..." which
uses SI::SYSTEM to call the grep utility, but (usually) this is
not possible on Windows so they wrote it in C. But this was
not back-ported to GCL when GCL was used to implement
Axiom on Windows.

It is possible that including some "grep-like" command on
Windows *might* work if you also disable the "Saturn" option.
This might re-enable the Linux-compatible GREP function
which would then call your fake grep utility much like on linux.
As I recall there were some other reasons why Saturn should
be disabled on windows - check the axiom-developer email list
for how to do that.

Otherwise, if that doesn't work, you might have to provide such
a GREP function yourself (just copy from the Axiom source).

Regards,
Bill Page.

------=_Part_61636_17269102.1181509365093

<div><span class="gmail_quote">On 10 Jun 2007 21:44:54 +0200, <b class="gmail_sendername">Martin Rubey</b>&nbsp;wrote:</span></div>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">William Sit &lt;<a href="mailto:William Sit">William Sit</a>&gt; writes:<br><br>&gt; (1) -&gt; SOCKET(8080, getDocumentation$HyperDoc)
<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp;Loading<br>&gt; /OpenAxiom/axiom014/mnt/windows/lib/hyper.NRLIB/code for<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; package HyperDoc<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp;Loading<br>&gt; j:/OpenAxiom/axiom014/mnt/windows/algebra/OPQUERY.o for<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; package OperationsQuery
<br>&gt;<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt; System error:<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp;GREP is invalid as a function.<br>&gt;<br>&gt; protected-symbol-warn called with (NIL)<br>&gt;<br>&gt;<br>&gt; I put GREP.EXE (windows version) into the same directory,
<br>&gt; but the same error.<br><br>Try to put grep into the path. I guess that it&#39;s called by boot.</blockquote>
<div>&nbsp;</div>
<div>No, the message says: &quot;GREP is invalid as a function&quot;. This</div>
<div>means that OPQUERY was trying to call a Lisp *function*</div>
<div>whose name is GREP. This has nothing directly to do with the</div>
<div>unix grep utility -- except that it does: We know from other</div>
<div>discussions about Axiom on Windows that the Lisp function</div>
<div>GREP was one of those things that was re-written by NAG as</div>
<div>a C extension of CCL when they ported Axiom to Windows.</div>
<div>On Linux the GREP function just calls OBEY &quot;grep ...&quot; which</div>
<div>uses SI::SYSTEM to call the grep utility, but (usually) this is</div>
<div>not possible on Windows so they wrote it in C. But this was</div>
<div>not back-ported to GCL when GCL was used to implement</div>
<div>Axiom on Windows.</div>
<div>&nbsp;</div>
<div>It is possible that including some &quot;grep-like&quot; command on</div>
<div>Windows *might* work if you also disable the &quot;Saturn&quot; option.</div>
<div>This might re-enable the Linux-compatible GREP function</div>
<div>which would then call your fake grep utility much like on linux.</div>
<div>As I recall there were some other reasons why Saturn should</div>
<div>be disabled on windows - check the axiom-developer email list</div>
<div>for how to do that.</div>
<div>&nbsp;</div>
<div>Otherwise, if that doesn&#39;t work, you might have to provide such</div>
<div>a GREP function yourself (just copy from the Axiom source).</div>
<div>&nbsp;</div>
<div>Regards,</div>
<div>Bill Page.<br>&nbsp;</div>

------=_Part_61636_17269102.1181509365093--

\start
Date: Sun, 10 Jun 2007 19:12:16 -0500 (CDT)
From: Gabriel Dos Reis
To: list
Subject: Spad and its object model

  I've been thinking about the following for a long time now, and I
susect it is time for me to let it go to the Axiom  community for feedback.

  Spad fundamentally uses arrays of function pointers (also known as vtables)
as implementation technology for categories, domains, packages, and 
inheritance.  Each function defined gets a slot in a vtable (the thing that
materializes a domain or a package) and call to that function may be
resolved by poking at that slot and dereferencing the result. The vtable is
an array to allow constant time indexing.  That is fast.  OK.

  However, I do believe the use of arrays has inherent problems in 
terms of maintaining coherence of function pointers assigned to slots.
Because the mapping from declarations order to integer has lost important
informations (name, types, etc) of the functions being mapped.

  I would like to suggest the idea of using hastables as opposed to
arrays to implement vtables (materialization of domains and packages).
Not only it would help tame the problem of coherence, but also move
to functionalities like "post facto extensions".

\start
Date: 10 Jun 2007 21:48:26 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Spad and its object model

Hello Gaby,

Gabriel Dos Reis writes:
[...]
>   However, I do believe the use of arrays has inherent problems in 
> terms of maintaining coherence of function pointers assigned to slots.
> Because the mapping from declarations order to integer has lost important
> informations (name, types, etc) of the functions being mapped.

Im not sure if this is fundamental to an array.  I think it is
entierly possible to define vtable elements at a fixed offset which
provide alternative methods of indexing.  Indeed, I belive the current
layout provides such a rudimentary facility of mapping export labels
to arity and argument type information, but the details escape me (Its
been a long time since I looked at this.  I recall making notes.  I
need to do some digging).

>   I would like to suggest the idea of using hastables as opposed to
> arrays to implement vtables (materialization of domains and packages).
> Not only it would help tame the problem of coherence, but also move
> to functionalities like "post facto extensions".

Roughly, what are the keys?  What do the entries look like?

I assume "post facto extensions" motivate the choice of a hash as they
are easily extensible (new elements are readily added).  Could we not
simply make vtable vectors expressly adjustable?

I would need a clear picture of what the semantics would be for "post
facto extensions".  Do you sugest following Aldor explicitly? IIRC new
exports introduced by `extend' are not visible to previous
definitions, except via `has' predicates which execute during
runtime.  Are there other issues involved?

\start
Date: 11 Jun 2007 09:46:37 +0200
From: Martin Rubey
To: Stephen Wilson
Subject: Re: Spad and its object model
Cc: Gabriel Dos Reis

Stephen Wilson writes:

> I would need a clear picture of what the semantics would be for "post facto
> extensions".  Do you sugest following Aldor explicitly?

In any case, please try to "stay" compatible with Aldor semantics as far as
possible!  

> IIRC new exports introduced by `extend' are not visible to previous
> definitions, except via `has' predicates which execute during runtime.  Are
> there other issues involved?

I do not understand.  What is a "previous" definition in Aldor?

Martin

martin@rubey-laptop:~/aldor-test$ aldor -fx -laldor extend.as 
martin@rubey-laptop:~/aldor-test$ ./extend
Hi there!

-------------------------------------------------------------------------------
#include "aldor"
#include "aldorio"

f(i: Integer): String == {
        import from Integer;
        foo i;
}

extend Integer: with {
        foo: % -> String;
} == add {
        foo(i: %): String == "Hi there!";
}

main(): () == {
        import from Integer, Character, TextWriter;
        stdout << f(1) << newline;
}

main()


\start
Date: 11 Jun 2007 09:57:43 +0200
From: Martin Rubey
To: William Sit
Subject: Re: testing hyperdoc package on Windows

Dear all,

I uploaded a new version of hyper.spad and hyper.lisp to mathaction, it now
deals correctly with the %60 problem.  (There is even some documentation :-)
Furthermore, the second string (delimited by `) now refers correctly to 'type,
i.e., like (_$,_$)->_$ for +.

Bill: uploading worked just fine now.  I guess I checked the wrong directory on
the MathAction server, it should be href="uploads/..." now, right?

William, I just saw

> (1) -> SOCKET(8080, getDocumentation$HyperDoc)

don't you need to package call SOCKET$Lisp ?

If you are able to work around the GREP problem, please let me know.  Not
unlikely you will have another problem, I don't know whether that has been
fixed in axiom014 already: Try

ops: Database IndexCard := getDatabase("o")$OperationsQuery

it should return something like 6477 or perhaps a little smaller.  (That's the
number of operations in the database.)

If it is 42 or so, you need to get a better axiom.

\start
Date: Mon, 11 Jun 2007 10:25:35 +0200
From: Ralf Hemmecke
To: Martin Rubey
Subject: Re: Spad and its object model
Cc: Gabriel Dos Reis

>> IIRC new exports introduced by `extend' are not visible to previous
>> definitions, except via `has' predicates which execute during runtime.  Are
>> there other issues involved?

> I do not understand.  What is a "previous" definition in Aldor?

If you extend Integer then it will not be visible globally. Clearly, it 
is visible only for those things that "see" the extension.

Try the following via

aldor -laldor -fo -fao aaa.as
aldor -lalgebra -laldor -fx bbb.as aaa.o
bbb

The output is:
foo  == F
foo2 == T
although Integer gets extended in libalgebra. However, the package Pkg, 
was compiled before and does not "see" the extension.

Ralf

---BEGIN aaa.as
#include "aldor"
Pkg: with {
   foo: () -> Boolean;
} == add {
   foo(): Boolean == Integer has with {binomial: (%, %) -> %}
}
---END aaa.as


---BEGIN aaa.as
#include "algebra"
#include "aldorio"
#library AAA "aaa.ao"
import from AAA;

Pkg2: with {
   foo2: () -> Boolean;
} == add {
   foo2(): Boolean == Integer has with {binomial: (%, %) -> %}
}

main(): () == {
	stdout << "foo  == " << foo()$Pkg << newline;
	stdout << "foo2 == " << foo2()$Pkg2 << newline;
}

main();
---END aaa.as

\start
Date: Mon, 11 Jun 2007 06:45:49 -0400
From: Alfredo Portes
To: Bill Page
Subject: re: testing hyperdoc package on Windows

To remove the grep error do as explained by Waldek:

)lisp (setf |$standard| 't)
)lisp (setf |$saturn| 'nil)

Also you will need a newer version of axiom like wh-sandbox,
as Martin explained in a previous email. Bill, were you able
to compile wh-sandbox or build-improvements in windows?

On 6/10/07, Bill Page wrote:
> On 10 Jun 2007 21:44:54 +0200, Martin Rubey wrote:
> > William Sit writes:
> >
> > > (1) -> SOCKET(8080, getDocumentation$HyperDoc)
> > >    Loading
> > > /OpenAxiom/axiom014/mnt/windows/lib/hyper.NRLIB/code
> for
> > >       package HyperDoc
> > >    Loading
> > > j:/OpenAxiom/axiom014/mnt/windows/algebra/OPQUERY.o for
> > >       package OperationsQuery
> > >
> > >    >> System error:
> > >    GREP is invalid as a function.
> > >
> > > protected-symbol-warn called with (NIL)
> > >
> > >
> > > I put GREP.EXE (windows version) into the same directory,
> > > but the same error.
> >
> > Try to put grep into the path. I guess that it's called by boot.
>
>
> No, the message says: "GREP is invalid as a function". This
> means that OPQUERY was trying to call a Lisp *function*
> whose name is GREP. This has nothing directly to do with the
> unix grep utility -- except that it does: We know from other
> discussions about Axiom on Windows that the Lisp function
> GREP was one of those things that was re-written by NAG as
> a C extension of CCL when they ported Axiom to Windows.
> On Linux the GREP function just calls OBEY "grep ..." which
> uses SI::SYSTEM to call the grep utility, but (usually) this is
> not possible on Windows so they wrote it in C. But this was
> not back-ported to GCL when GCL was used to implement
> Axiom on Windows.
>
> It is possible that including some "grep-like" command on
> Windows *might* work if you also disable the "Saturn" option.
> This might re-enable the Linux-compatible GREP function
> which would then call your fake grep utility much like on linux.
> As I recall there were some other reasons why Saturn should
> be disabled on windows - check the axiom-developer email list
> for how to do that.
>
> Otherwise, if that doesn't work, you might have to provide such
> a GREP function yourself (just copy from the Axiom source).

\start
Date: Mon, 11 Jun 2007 07:16:04 -0400
From: William Sit
To: Martin Rubey,William Sit
Subject: Re: testing hyperdoc package on Windows

On 11 Jun 2007 09:57:43 +0200
Martin Rubey wrote:
>William, I just saw
>
>> (1) -> SOCKET(8080, getDocumentation$HyperDoc)
>
>don't you need to package call SOCKET$Lisp ?
Thanks Martin. I was just following your directions :-).
[...]
>Try
>ops: Database IndexCard := getDatabase("o" $OperationsQuery


(1) -> )library hyper
    HyperDoc is now explicitly exposed in frame initial
    HyperDoc will be automatically loaded when needed from
       /OpenAxiom/axiom014/mnt/windows/lib/hyper.NRLIB/code
(1) -> SOCKET(8080, getDocumentation$HyperDoc)

    >> System error:
    GREP is invalid as a function.

protected-symbol-warn called with (NIL)
(1) -> SOCKET(8080, getDocumentation$HyperDoc)$Lisp

    SOCKET is not a lisp function and so cannot be used 
with $Lisp.
(1) -> ops: Database IndexCard := 
getDatabase("o")$OperationsQuery

    >> System error:
    GREP is invalid as a function.

protected-symbol-warn called with (NIL)
(1) -> )sys grep hyper hyper~1.spa
\usepackage{hyperref}_

Note that grep IS in the path. (the hyper~1.spa is the DOS 
alias for hyper.spad: DOS uses 8.3 convention for file 
names and Axiom runs in DOS.)

\start
Date: Mon, 11 Jun 2007 07:36:39 -0400
From: William Sit
To: Alfredo Portes, Bill Page
Subject: re: testing hyperdoc package on Windows

On Mon, 11 Jun 2007 06:45:49 -0400
  Alfredo Portes wrote:
>To remove the grep error do as explained by Waldek:
>
>)lisp (setf |$standard| 't)
>)lisp (setf |$saturn| 'nil)

Yes, that does get around the GREP problem, but a new one 
pops up:

(1) -> )sys grep hyper hyper~1.spa
\usepackage{hyperref}_
(1) -> )lisp (setf |$standard| 't)

Value = T
(1) -> )lisp (setf |$saturn| 'nil)

Value = NIL
(1) -> SOCKET(8080, getDocumentation$HyperDoc)
The system cannot find the path specified.

    >> System error:
    Cannot open the file /tmp/target.txt.NIL.

protected-symbol-warn called with (NIL)
(1) -> ops: Database IndexCard := 
getDatabase("o")$OperationsQuery
The system cannot find the path specified.

    >> System error:
    Cannot open the file /tmp/target.txt.NIL.

protected-symbol-warn called with (NIL)

I understand /tmp/ is a directory just below root. So I 
created a /tmp directory in the partition where Axiom 
lives. This allows the write to /tmp/target.txt.NIL.  Now 
I have:
(1) -> SOCKET(8080, getDocumentation$HyperDoc)
grep.exe: libdb.text: No such file or directory
[...]

I believe this is due to the 8.3 convention. I see 
libdb.text in the path: .../windows/lib/.

I see that you are also creating other files with long 
names. This will not work as long as Axiom runs in a DOS 
windows.

William

>Also you will need a newer version of axiom like 
>wh-sandbox,
>as Martin explained in a previous email. Bill, were you 
>able
>to compile wh-sandbox or build-improvements in windows?

Yes, please Bill, if you can post a binary. But it needs 
to be more "native" to handle long file names.

\start
Date: Mon, 11 Jun 2007 08:00:46 -0400
From: William Sit
To: Alfredo Portes, Bill Page
Subject: re: testing hyperdoc package on Windows

On Mon, 11 Jun 2007 07:36:39 -0400
  William Sit wrote:

>(1) -> SOCKET(8080, getDocumentation$HyperDoc)
>grep.exe: libdb.text: No such file or directory
>[...]
>
>I believe this is due to the 8.3 convention. I see 
>libdb.text in the path: .../windows/lib/.
>
>I see that you are also creating other files with long 
>names. This will not work as long as Axiom runs in a DOS 
>windows.

I used a newer (circa 2002) version of grep from cygwin 
and I have:

(1) -> ops: Database IndexCard := 
getDatabase("o")$OperationsQuery

    (1)  146
                                                      Type: 
Database IndexCard
(2) -> SOCKET(8080, getDocumentation$HyperDoc)$Lisp

    SOCKET is not a lisp function and so cannot be used 
with $Lisp.
(2) -> SOCKET(8080, getDocumentation$HyperDoc)
    There are no library operations named SOCKET
       Use HyperDoc Browse or issue
                                )what op SOCKET
       to learn if there is any operation containing " 
SOCKET " in its
       name.

    Cannot find a definition or applicable library 
operation named
       SOCKET with argument type(s)
                                PositiveInteger
                              (String -> String)

       Perhaps you should use "@" to indicate the required 
return type,
       or "$" to specify which version of the function you 
need.


I am not worried about the small database 146 value 
because I am running the hyperdoc package in 
.../windows/lib which is my personal library. I assume 
that if I can set the path to include the actual Axiom 
library I would be able to get the entire database.

I guess the newer Axiom would understand SOCKET?

\start
Date: 11 Jun 2007 14:50:04 +0200
From: Martin Rubey
To: William Sit
Subject: Re: testing hyperdoc package on Windows

William Sit writes:

> (1) -> )library hyper
>     HyperDoc is now explicitly exposed in frame initial
>     HyperDoc will be automatically loaded when needed from
>        /OpenAxiom/axiom014/mnt/windows/lib/hyper.NRLIB/code
> (1) -> SOCKET(8080, getDocumentation$HyperDoc)
> 
>     >> System error:
>     GREP is invalid as a function.


but SOCKET is defined in hyper.lisp?  Did I forget to mention that you also
need to say

)lisp (load "hyper.lisp")

before trying SOCKET?

> I am not worried about the small database 146 value because I am running the
> hyperdoc package in .../windows/lib which is my personal library. I assume
> that if I can set the path to include the actual Axiom library I would be
> able to get the entire database.

No, I don't think that this will work.  But to be honest, I do not know.  In
any case, at least wh-sandbox does not have this problem.

\start
Date: 11 Jun 2007 08:55:11 -0400
From: Stephen Wilson
To: Ralf Hemmecke
Subject: Re: Spad and its object model
Cc: Gabriel Dos Reis

Hi Ralf,

Ralf Hemmecke writes:
> If you extend Integer then it will not be visible globally. Clearly,
> it is visible only for those things that "see" the extension.

Of course you are completely correct.  The specific issue I was trying
to point out is illustrated by the following (note that I have not
been able to get Aldor working locally for a long time.   Binaries
from aldor.org do not work for some reason.  This is from, possibly
bad, memory):


    Foo(T: Type): with {
        foo: () -> Boolean;
    } == add {
        if T has with {bar:() -> T} then
            foo(): Boolean == true;
        else
            foo(): Boolean == false;
    }


In such a situation, I belive the `has' predicate will see exports
defined via an `extend' occurring in a seperate compilation unit.
Perhaps you could verify?


I always thought Aldor's `extend' was designed to allow for the
enrichment of domains defined within a closed-source library, not as a
general mechanism for solving the kind of mutually recursive
definitions found in Axioms algebra.

\start
Date: Mon, 11 Jun 2007 09:49:43 -0400
From: William Sit
To: Martin Rubey
Subject: Re: testing hyperdoc package on Windows

On 11 Jun 2007 14:50:04 +0200
  Martin Rubey wrote:
>William Sit writes:
>
>> (1) -> )library hyper
>>     HyperDoc is now explicitly exposed in frame initial
>>     HyperDoc will be automatically loaded when needed 
>>from
>>        /OpenAxiom/axiom014/mnt/windows/lib/hyper.NRLIB/code
>> (1) -> SOCKET(8080, getDocumentation$HyperDoc)
>> 
>>     >> System error:
>>     GREP is invalid as a function.
>
>
>but SOCKET is defined in hyper.lisp?  Did I forget to 
>mention that you also
>need to say
>
>)lisp (load "hyper.lisp")
>
>before trying SOCKET?

I guess you didn't, but I did when restarting Axiom. So 
now:
SOCKET(8080, getDocumentation$HyperDoc)$Lisp

simply "freeze" with no output. According to my firewall, 
it did ask to be a server and I allowed it. What should be 
expected?

Putting url

http://localhost:8080/|?binomial` `OutputForm|

simply says: waiting for localhost



>> I am not worried about the small database 146 value 
>>because I am running the
>> hyperdoc package in .../windows/lib which is my personal 
>>library. I assume
>> that if I can set the path to include the actual Axiom 
>>library I would be
>> able to get the entire database.
>
>No, I don't think that this will work.  But to be honest, 
>I do not know.  In
>any case, at least wh-sandbox does not have this problem.
>
>
>Martin
>

I have trouble with setting paths, but this is a known bug 
in Windows Axiom. But the present immediate problem is the 
socket to browser interface.

\start
Date: Mon, 11 Jun 2007 09:58:26 -0400
From: William Sit
To: Martin Rubey
Subject: Re: testing hyperdoc package on Windows

On Mon, 11 Jun 2007 09:49:43 -0400
  William Sit wrote:
>SOCKET(8080, getDocumentation$HyperDoc)$Lisp
>
>simply "freeze" with no output. According to my firewall, 
>it did ask to be a server and I allowed it. What should 
>be expected?
>
>Putting url
>
>http://localhost:8080/|?binomial` `OutputForm|
>
>simply says: waiting for localhost

I tried again and now:

(3) -> SOCKET(8080, getDocumentation$HyperDoc)$Lisp

    >> System error:
    Could not connect

protected-symbol-warn called with (NIL)

(Recall I have set permission to allow Axiomsys.exe to be 
a server.) Is there any additional Windows app I need to 
run (to make my machine serve webpages? -- actually I 
probably don't want this at all; I would like only to 
serve pages to my local home network).

\start
Date: 11 Jun 2007 17:14:09 +0200
From: Martin Rubey
To: William Sit
Subject: Re: testing hyperdoc package on Windows

Dear William,

first of all, thank you for your patience!

William Sit writes:

> On Mon, 11 Jun 2007 09:49:43 -0400
>   William Sit wrote:
> >SOCKET(8080, getDocumentation$HyperDoc)$Lisp
> >
> > simply "freeze" with no output. According to my firewall, it did ask to be a
> > server and I allowed it. What should be expected?

roughly: (I put 

  )lib HYPER
  )lisp (load "hyper.lisp")
  SOCKET(8080, getDocumentation$HyperDoc)$Lisp

into a file hyper.input)

-------------------------------------------------------------------------------
(1) -> )re hyper
)lib HYPER

   HyperDoc is now explicitly exposed in frame frame0
   HyperDoc will be automatically loaded when needed from
      /home/martin/martin/Axiom/hyperdoc-replacement/HYPER.NRLIB/code
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/bc-matrix.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/bc-misc.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/bc-solve.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/bc-util.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/ht-util.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/htsetvar.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/ht-root.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/br-con.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/br-data.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/showimp.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/br-op1.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/br-op2.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/br-search.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/br-util.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/topics.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/br-prof.
   Loading /home/martin/lib/axiom/target/i686-pc-linux/autoload/br-saturn.
)lisp (load "hyper.lisp")

Value = T
SOCKET(8080, getDocumentation$HyperDoc)$Lisp

   Loading
      /home/martin/martin/Axiom/hyperdoc-replacement/HYPER.NRLIB/code
      for package HyperDoc
   Loading
      /home/martin/lib/axiom/target/i686-pc-linux/algebra/OPQUERY.o for
      package OperationsQuery

-------------------------------------------------------------------------------
(no more output after that.  In particular, you need another axiom process to
do computations afterwards, but that's a bug, not a feature...)

> >Putting url
> >
> >http://localhost:8080/|?binomial` `OutputForm|
> >
> >simply says: waiting for localhost

It should start tex4ht in the axiom console...

> I tried again and now:
> 
> (3) -> SOCKET(8080, getDocumentation$HyperDoc)$Lisp
> 
>     >> System error:
>     Could not connect
> 
> protected-symbol-warn called with (NIL)

Hm, I don't have any MS Windows, and I don't know what that means.  Maybe you
could say

  )lisp (si:use-fast-links nil)

and

  )set break break

before starting SOCKET, after the error it should fall into a debugger, type

  :bt

and send the result to the list and to Camm (including a copy of hyper.lisp).
But I'm unlikely to be able to help.  In particular, this probably means that
my work was wasted, since it does not seem to work on windows. :-(

\start
Date: Mon, 11 Jun 2007 17:14:54 +0200
From: Ralf Hemmecke
To: Stephen Wilson
Subject: Re: Spad and its object model
Cc: Gabriel Dos Reis

On 06/11/2007 02:55 PM, Stephen Wilson wrote:
> Hi Ralf,
> 
> Ralf Hemmecke writes:
>> If you extend Integer then it will not be visible globally. Clearly,
>> it is visible only for those things that "see" the extension.
> 
> Of course you are completely correct.  The specific issue I was trying
> to point out is illustrated by the following (note that I have not
> been able to get Aldor working locally for a long time.   Binaries
> from aldor.org do not work for some reason.

Send complaints to Stephen Watt and Lauretiu Dragan. But if you have a 
64bit machine that could be some problem. There should be a hint by 
Christian Aistleitner concerning the 64bit problem in the aldor-l archive.

See also

http://www.aldor.org/pipermail/aldor-l/2005-September/000100.html

and maybe that is also relevant.

http://www.aldor.org/pipermail/aldor-l/2005-June/000074.html

> This is from, possibly
> bad, memory):
> 
> 
>     Foo(T: Type): with {
>         foo: () -> Boolean;
>     } == add {
>         if T has with {bar:() -> T} then
>             foo(): Boolean == true;
>         else
>             foo(): Boolean == false;
>     }
> 
> 
> In such a situation, I belive the `has' predicate will see exports
> defined via an `extend' occurring in a seperate compilation unit.
> Perhaps you could verify?

OK.

---BEGIN aaa.as
#include "aldor"
Foo(T: Type): with {
     foo: () -> Boolean;
} == add {
     if T has with {binomial: (%, %) -> %} then
         foo(): Boolean == true;
     else
         foo(): Boolean == false;
}
---END aaa.as


---BEGIN bbb.as
#include "algebra"
#include "aldorio"
#library AAA "aaa.ao"
import from AAA;

main(): () == {
     stdout << "foo i == " << foo()$Foo(Integer) << newline;
     stdout << "foo s == " << foo()$Foo(String) << newline;
}

main();
---END bbb.as


aldor -laldor -fo -fao aaa.as
aldor -lalgebra -laldor -fx bbb.as aaa.o
bbb
foo i == T
foo s == F

But I could have told you the result without actually compiling. The 
reason is that Foo is a function and only at the time you call 
Foo(Integer) the "has" predicate gets evaluated.

It is more interesting to ask what happens in an interactive 
environment. So let's try.

woodpecker:~/scratch>aldor -gloop
      AA  L      DDDD      OOO    RRRR
     A A  L      D   D    O   O   R   R
    A  A  L      D    D  O     O  R   R
   AAAAA  L      D    D  O     O  RRRR
  A    A  L      D   D    O   O   R  R
A     A  LLLLL  DDDD      OOO    R   R

(c) Numerical Algorithms Group Ltd 1995-2001
Release: Aldor(C) version 1.0.3 for LINUX(glibc2.3) (debug version)
Type "#int help" for more details.
%1 >> #include "aldor"
%2 >> #include "aldorinterp"
%3 >> #library AAA "aaa.ao"
%4 >> import from AAA;
%5 >> foo()$Foo(Integer)
F @ Boolean
%6 >> #include "algebra"
%7 >> foo()$Foo(Integer)
T @ Boolean

You cannot even say that this is wrong or right. Foo(Integer) appears in 
a "type context" and according to the Aldor specification, it might or 
might not be evaluated.

> I always thought Aldor's `extend' was designed to allow for the
> enrichment of domains defined within a closed-source library, not as a
> general mechanism for solving the kind of mutually recursive
> definitions found in Axioms algebra.

I must say, even in an open-source environment, "extend" allows you to 
introduce layers of your library and thus allows to put more structure 
in the design.

One doesn't have to recompile the whole Axiom library if one thinks that 
Integer misses some function. That new function is completely irrelevant 
to existing parts of the library and only plays a role in newer parts. 
"extend" in my eyes helps to keep libraries maintainable.

\start
Date: Mon, 11 Jun 2007 11:55:21 -0400
From: William Sit
To: Martin Rubey
Subject: Re: testing hyperdoc package on Windows

Martin Rubey wrote:
> 
> Dear William,
> 
> first of all, thank you for your patience!

Thank you, and Bill, and Alfredo for helping.


> roughly: (I put
> 
>   )lib HYPER
>   )lisp (load "hyper.lisp")
>   SOCKET(8080, getDocumentation$HyperDoc)$Lisp
> 
> into a file hyper.input)

I still can't read an input file!

(1) -> )re hyper.input

   >> System error:
   Cannot coerce NIL to a PATHNAME.

protected-symbol-warn called with (NIL)
 

> Hm, I don't have any MS Windows, and I don't know what that means.  Maybe you
> could say
> 
>   )lisp (si:use-fast-links nil)
> 
> and
> 
>   )set break break
> 
> before starting SOCKET, after the error it should fall into a debugger, type
> 
>   :bt
> 
> and send the result to the list and to Camm (including a copy of hyper.lisp).
> But I'm unlikely to be able to help.  In particular, this probably means that
> my work was wasted, since it does not seem to work on windows. :-(
> 
> Martin

See below (I have never learnt how to debug with boot :-( ):

(2) -> SOCKET(8080, getDocumentation$HyperDoc)$Lisp

Error: Could not connect
Error signalled by LET.
Broken at SYSTEM::BREAK-LEVEL.  Type :H for Help.
BOOT>>:bt

#0   APPLY {loc0=#<compiled-function
system:universal-error-handler>,loc1=:error
,loc2=nil,l...} [ihs=31]
#1   APPLY {loc0=#<compiled-function
system:universal-error-handler>,loc1=:error
,loc2=nil,l...} [ihs=30]
#2   LAMBDA {} [ihs=27]
#3   SOCKET {loc0=8080,loc1=nil,loc2=(lambda-block server
(s) ...),loc3=nil,loc4
=nil,loc5=ni...} [ihs=26]
#4   SOCKET {} [ihs=24]
#5   EVAL {loc0=nil,loc1=nil,loc2=nil,loc3=(lambda-block
socket (port docfun) ..
.),loc4=80...} [ihs=23]
#6   timedEvaluate {loc0=(socket 8080 (quote (# . #<vector
1bbcddc8>))),loc1=(so
cket 8080 (quote (#...} [ihs=22]
#7   timedEVALFUN {loc0=(socket 8080 (quote (# . #<vector
1bbcddc8>)))} [ihs=21]

#8   upLispCall {loc0=#<vector 1bbcdbb4>,loc1=(#<vector
1bbcdb98> #<vector 1bbcd
b7c> (#<vector 1...} [ihs]
#9   upDollar {loc0=(#<vector 1bbcdbb4> |Lisp| (#<vector
1bbcdb98> #<vector 1bbc
db7c> (# # #))...} [ihs=19]
#10   bottomUp {loc0=(#<vector 1bbcdbb4> |Lisp| (#<vector
1bbcdb98> #<vector 1bb
cdb7c> (# # #))...} [ihs=18]
#11   interpret1 {loc0=((|$elt| |Lisp| socket) 8080 (|$elt|
|HyperDoc| |getDocum
entation|)),loc1=...} [ihs=17]
#12   interpret {loc0=((|$elt| |Lisp| socket) 8080 (|$elt|
|HyperDoc| |getDocume
ntation|)),loc1=...} [ihs=16]
#13   interpretTopLevel {loc0=((|$elt| |Lisp| socket) 8080
(|$elt| |HyperDoc| |g
etDocumentation|)),loc1=...} [ihs=15]
#14   processInteractive1 {loc0=((|$elt| |Lisp| socket) 8080
(|$elt| |HyperDoc|
|getDocumentation|)),loc1=...} [ihs=14]
#15   processInteractive {loc0=((|$elt| |Lisp| socket) 8080
(|$elt| |HyperDoc| |
getDocumentation|)),loc1=...} [ihs=13]
#16   intInterpretPform {loc0=(|Application| (|Fromdom| (# .
socket) (# . |Lisp|
)) (|Tuple| (# # #)))} [ihs=12]
#17   ncConversationPhase {loc0=#<compiled-function
|phInterpret|>,loc1=(((# # #
 ...))),loc2=(((# . 1) . "...} [ihs=11]
#18   intloopSpadProcess,interp {loc0=((|carrier| (# . t) (#
. #1=(# # #)) ...))
,loc1=(|Application| (|Fromdom| ...} [ihs=10]
#19   intloopSpadProcess {loc0=1,loc1=(((# . 1) .
"SOCKET(8080, getDocumentation
$HyperDoc)$Lisp")),loc2=(...} [ihs=9]
#20   intloopProcess {loc0=1,loc1=t,loc2=(((#) (# # #))
|nonnullstream| #<compil
ed-function |incAppen...} [ihs=8]
#21   intloopProcessString {loc0="SOCKET(8080,
getDocumentation$HyperDoc)$Lisp",
loc1=1} [ihs=7]
#22   RESTART {} [ihs=6]
#23   TOP-LEVEL
{loc0=nil,loc1=0,loc2=0,loc3=nil,loc4=nil,loc5=nil,loc6=nil,loc7
="c:/cvs/head/ax...} [ihs=5]
#24   FUNCALL {loc0=#<compiled-function system:top-level>}
[ihs=4]
NIL
BOOT>>

\start
Date: 11 Jun 2007 18:10:23 +0200
From: Martin Rubey
To: list
Subject: Re: testing hyperdoc package on Windows

Martin Rubey writes:

> William Sit writes:
> 
> > > roughly: (I put
> > > 
> > >   )lib HYPER
> > >   )lisp (load "hyper.lisp")
> > >   SOCKET(8080, getDocumentation$HyperDoc)$Lisp
> > > 
> > > into a file hyper.input)
> > 
> > I still can't read an input file!
> 
> > (1) -> )re hyper.input
> > 
> >    >> System error:
> >    Cannot coerce NIL to a PATHNAME.
> > 
> > protected-symbol-warn called with (NIL)
> 
> What?  Is this axiom in 2007?  How can you use axiom without reading input files?
> 
> > See below (I have never learnt how to debug with boot :-( ):
> 
> OK, we're out of luck here.  I have no idea why it doesn't work.  I guess that
> your gcl doesn't like
> 
>   (let ((s (si::socket port :server #'server)))
> 
> i.e., the second line of SOCKET$Lisp.
> 
> Did anybody get my code running on windows at all? Does si::socket work on
> windows?

\start
Date: Mon, 11 Jun 2007 18:23:11 +0200 (CEST)
From: Franz Lehner
To: Martin Rubey
Subject: re: testing hyperdoc package on Windows

>> What?  Is this axiom in 2007?  How can you use axiom without reading 
>> input files?
well, some of my students reported that copy and paste does not work and 
came up with handwritten notes for the exercise sessions ... but 
apparently reading input files worked.
I did not investigate this further however.

\start
Date: Mon, 11 Jun 2007 12:28:49 -0400
From: William Sit
To: Franz Lehner, Martin Rubey
Subject: re: testing hyperdoc package on Windows

On Mon, 11 Jun 2007 18:23:11 +0200 (CEST)
  Franz Lehner wrote:
>>>What?  Is this axiom in 2007?  How can you use axiom 
>>>without reading 
>>>input files?
>well, some of my students reported that copy and paste 
>does not work and came up with handwritten notes for the 
>exercise sessions ... but apparently reading input files 
>worked.
>I did not investigate this further however.
>
>Franz

I recall it worked before too, but then it didn't again. 
On the other hand, (multi-line) cut and paste works (not 
worked). Maybe there was a patch and I lost it.

\start
Date: Mon, 11 Jun 2007 11:51:29 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Spad and its object model

On Sun, 10 Jun 2007, Stephen Wilson wrote:

| Hello Gaby,
| 
| Gabriel Dos Reis writes:
| [...]
| >   However, I do believe the use of arrays has inherent problems in 
| > terms of maintaining coherence of function pointers assigned to slots.
| > Because the mapping from declarations order to integer has lost important
| > informations (name, types, etc) of the functions being mapped.
| 
| Im not sure if this is fundamental to an array.  I think it is
| entierly possible to define vtable elements at a fixed offset which
| provide alternative methods of indexing.  Indeed, I belive the current
| layout provides such a rudimentary facility of mapping export labels
| to arity and argument type information, but the details escape me (Its
| been a long time since I looked at this.  I recall making notes.  I
| need to do some digging).

I'm not sure I agree.  For the array representation, numeric integrs
are the key.  The only information they carry is the order of
declaration.  In a context where declarations are scatered over
different modules  (or files), there no longer is a natural order
of declarations.  Chaos ensures.

| >   I would like to suggest the idea of using hastables as opposed to
| > arrays to implement vtables (materialization of domains and packages).
| > Not only it would help tame the problem of coherence, but also move
| > to functionalities like "post facto extensions".
| 
| Roughly, what are the keys?  What do the entries look like?

The keys would be faithfull encodings of operation names, their types
(and possibly their scope, in case we go with nested scopes).

| I assume "post facto extensions" motivate the choice of a hash as they
| are easily extensible (new elements are readily added).  Could we not
| simply make vtable vectors expressly adjustable?

The fundamental problem I see there is that there is no natural
order of declarations, so the real problem is not that the vtable
has a fixed lenght; it is because it is very tricky to ensure consistency.

| I would need a clear picture of what the semantics would be for "post
| facto extensions".  Do you sugest following Aldor explicitly? IIRC new
| exports introduced by `extend' are not visible to previous
| definitions, except via `has' predicates which execute during
| runtime.  Are there other issues involved?

If you do static resolution of names (which I believe we should retain),
then "future" dos not interfer with "past".

\start
Date: 11 Jun 2007 12:51:47 -0400
From: Stephen Wilson
To: Ralf Hemmecke
Subject: Re: Spad and its object model
Cc: Gabriel Dos Reis

Thanks for doing the tests Ralf.  The results do not suprise me, so I
guess my memory is OK is this regard. 


Ralf Hemmecke writes:
[...]
> It is more interesting to ask what happens in an interactive
> environment. So let's try.

> 
> woodpecker:~/scratch>aldor -gloop
>       AA  L      DDDD      OOO    RRRR
>      A A  L      D   D    O   O   R   R
>     A  A  L      D    D  O     O  R   R
>    AAAAA  L      D    D  O     O  RRRR
>   A    A  L      D   D    O   O   R  R
> A     A  LLLLL  DDDD      OOO    R   R
> 
> (c) Numerical Algorithms Group Ltd 1995-2001
> Release: Aldor(C) version 1.0.3 for LINUX(glibc2.3) (debug version)
> Type "#int help" for more details.
> %1 >> #include "aldor"
> %2 >> #include "aldorinterp"
> %3 >> #library AAA "aaa.ao"
> %4 >> import from AAA;
> %5 >> foo()$Foo(Integer)
> F @ Boolean
> %6 >> #include "algebra"
> %7 >> foo()$Foo(Integer)
> T @ Boolean
> 
> You cannot even say that this is wrong or right. Foo(Integer) appears
> in a "type context" and according to the Aldor specification, it might
> or might not be evaluated.

I would say the above is `right'.

Though the Aldor spec does leaves this unspecified, I would not doubt
a specification is possible.  I would think it to be desierable if the
feature were to be included in SPAD. 

One basic rule would be that a domain `functor' memoizes its
arguments, and always returns the same object for equal arguments,
performing any required initialization on the first call.  Of course
equality is an issue in and of itself, but (for the purpos of functor
memoization) my feeling is that Integer should not be equal to 'extend
Integer ...'  except when the extension is empty.  Furthere, no
extended domain D would be equal to any other extension of D,
similarly for extensions of extensions, etc.

As an aside, I feel that runtime equality checks on values (domain
elements) should be permited only for those domains which implement
BasicType (in which case I would support making BasicType a primitive
language defined category).  Another option being to use whatever
export '=: (%, %) -> Boolean' the domain admits, or perhaps the
equivalent Aldor `generic tie-in' which I think is `test'.

I strongly feel that SPAD should define precise semantics for any
notion of equality used by the compiler.

> > I always thought Aldor's `extend' was designed to allow for the
> > enrichment of domains defined within a closed-source library, not as a
> > general mechanism for solving the kind of mutually recursive
> > definitions found in Axioms algebra.
> 
> I must say, even in an open-source environment, "extend" allows you to
> introduce layers of your library and thus allows to put more structure
> in the design.
> 
> One doesn't have to recompile the whole Axiom library if one thinks
> that Integer misses some function. That new function is completely
> irrelevant to existing parts of the library and only plays a role in
> newer parts. "extend" in my eyes helps to keep libraries maintainable.

This is exactly how I used `extend' myself.  For resursive definitions
I simply placed them all within the same compilation unit.

\start
Date: 11 Jun 2007 13:15:02 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Spad and its object model

Gabriel Dos Reis writes:

> On Sun, 10 Jun 2007, Stephen Wilson wrote:
> 
> | Hello Gaby,
> | 
> | Gabriel Dos Reis writes:
> | [...]
> | >   However, I do believe the use of arrays has inherent problems in 
> | > terms of maintaining coherence of function pointers assigned to slots.
> | > Because the mapping from declarations order to integer has lost important
> | > informations (name, types, etc) of the functions being mapped.
> | 
> | Im not sure if this is fundamental to an array.  I think it is
> | entierly possible to define vtable elements at a fixed offset which
> | provide alternative methods of indexing.  Indeed, I belive the current
> | layout provides such a rudimentary facility of mapping export labels
> | to arity and argument type information, but the details escape me (Its
> | been a long time since I looked at this.  I recall making notes.  I
> | need to do some digging).
> 
> I'm not sure I agree.  For the array representation, numeric integrs
> are the key.  The only information they carry is the order of
> declaration.  In a context where declarations are scatered over
> different modules  (or files), there no longer is a natural order
> of declarations.  Chaos ensures.

Notice that I said the vtable could have a entry to provide
alternative indexing strategies at a _fixed_ offset.  Such an entry
could be a hash, an assoc list, etc.  The current vtables do have such
a stucture.  I belive the following mappings are currently possible
(but this is only theory, I need to work out the details):

     index -> function slot
     index -> name
     name -> arity
     name -> target type
     name -> argument type(s)
     name -> index

This is not a complete list.  For example we could map a type
signature to the list of exports which satisfy.

Spad vtables potentially support many types of keys for indexing, not
just integers.

> | >   I would like to suggest the idea of using hastables as opposed to
> | > arrays to implement vtables (materialization of domains and packages).
> | > Not only it would help tame the problem of coherence, but also move
> | > to functionalities like "post facto extensions".
> | 
> | Roughly, what are the keys?  What do the entries look like?
> 
> The keys would be faithfull encodings of operation names, their types
> (and possibly their scope, in case we go with nested scopes).

OK.  My initial feeling is that there would be a great deal of
overhead involved in computing the hashes for such keys.  Caching
would help but would that not provide an opportunity for coherence
problems to arise?

> | I assume "post facto extensions" motivate the choice of a hash as they
> | are easily extensible (new elements are readily added).  Could we not
> | simply make vtable vectors expressly adjustable?
> 
> The fundamental problem I see there is that there is no natural
> order of declarations, so the real problem is not that the vtable
> has a fixed lenght; it is because it is very tricky to ensure consistency.

I hope I have a clear understanding of your concerns.

> | I would need a clear picture of what the semantics would be for "post
> | facto extensions".  Do you sugest following Aldor explicitly? IIRC new
> | exports introduced by `extend' are not visible to previous
> | definitions, except via `has' predicates which execute during
> | runtime.  Are there other issues involved?
> 
> If you do static resolution of names (which I believe we should retain),
> then "future" dos not interfer with "past".

I think I understand your statement, but not how it connects.  `has'
is (in part) an introspective runtime operation.  Often the argument
contains a free variable.  I dont see how static resolution of names
fits in this context.

\start
Date: Mon, 11 Jun 2007 12:35:53 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Spad and its object model

On Mon, 11 Jun 2007, Stephen Wilson wrote:

| Gabriel Dos Reis writes:
| 
| > On Sun, 10 Jun 2007, Stephen Wilson wrote:
| > 
| > | Hello Gaby,
| > | 
| > | Gabriel Dos Reis writes:
| > | [...]
| > | >   However, I do believe the use of arrays has inherent problems in 
| > | > terms of maintaining coherence of function pointers assigned to slots.
| > | > Because the mapping from declarations order to integer has lost important
| > | > informations (name, types, etc) of the functions being mapped.
| > | 
| > | Im not sure if this is fundamental to an array.  I think it is
| > | entierly possible to define vtable elements at a fixed offset which
| > | provide alternative methods of indexing.  Indeed, I belive the current
| > | layout provides such a rudimentary facility of mapping export labels
| > | to arity and argument type information, but the details escape me (Its
| > | been a long time since I looked at this.  I recall making notes.  I
| > | need to do some digging).
| > 
| > I'm not sure I agree.  For the array representation, numeric integrs
| > are the key.  The only information they carry is the order of
| > declaration.  In a context where declarations are scatered over
| > different modules  (or files), there no longer is a natural order
| > of declarations.  Chaos ensures.
| 
| Notice that I said the vtable could have a entry to provide
| alternative indexing strategies at a _fixed_ offset.  Such an entry
| could be a hash, an assoc list, etc.  The current vtables do have such
| a stucture.  I belive the following mappings are currently possible
| (but this is only theory, I need to work out the details):
| 
|      index -> function slot
|      index -> name
|      name -> arity
|      name -> target type
|      name -> argument type(s)
|      name -> index
| 
| This is not a complete list.  For example we could map a type
| signature to the list of exports which satisfy.

I guess what I trying to get at is what are the benefits of those 
additional indirections over simple, hash table representation.

>From all I can see, the "index" key relies on order declaration which is a
non-started.  The scheme "name" key is essentiablly equivalent to using a hash
table.  If an extrat indirection is required to get the type, what is he
point?  

| Spad vtables potentially support many types of keys for indexing, not
| just integers.

Maybe.  I'm talking of Spad and its object model representation as of today.
I'm considering ways to get supports verification and extensions without
excessive performance regression.  

| > | >   I would like to suggest the idea of using hastables as opposed to
| > | > arrays to implement vtables (materialization of domains and packages).
| > | > Not only it would help tame the problem of coherence, but also move
| > | > to functionalities like "post facto extensions".
| > | 
| > | Roughly, what are the keys?  What do the entries look like?
| > 
| > The keys would be faithfull encodings of operation names, their types
| > (and possibly their scope, in case we go with nested scopes).
| 
| OK.  My initial feeling is that there would be a great deal of
| overhead involved in computing the hashes for such keys.

If you use strings as encoding (traditional technique), then what you really
put in the hastable is the symbol whose name is the encoding.  In that case,
the "intern" operation is done by the compiler, NOT at runtime, and look
up is quite fast.

|  Caching
| would help but would that not provide an opportunity for coherence
| problems to arise?

More specificaly?

[...]

| > | I would need a clear picture of what the semantics would be for "post
| > | facto extensions".  Do you sugest following Aldor explicitly? IIRC new
| > | exports introduced by `extend' are not visible to previous
| > | definitions, except via `has' predicates which execute during
| > | runtime.  Are there other issues involved?
| > 
| > If you do static resolution of names (which I believe we should retain),
| > then "future" dos not interfer with "past".
| 
| I think I understand your statement, but not how it connects.  `has'
| is (in part) an introspective runtime operation.

There are two stages operations:  static resolution of (function) names,
and dynamic resolution of the residual.

|  Often the argument
| contains a free variable.  I dont see how static resolution of names
| fits in this context.

Example of cases where it won't work?

The hashtable repreentation vs. array representation has no semantics effect
on well formed programs.

\start
Date: Mon, 11 Jun 2007 19:42:12 +0200
From: Ralf Hemmecke
To: Stephen Wilson
Subject: Re: Spad and its object model
Cc: Gabriel Dos Reis

 > One basic rule would be that a domain `functor' memoizes its
 > arguments, and always returns the same object for equal arguments,
 > performing any required initialization on the first call.

Of course you know that globally defined functors can be called in a 
local environment which would allow Foo(Integer) and Foo(Integer) to be 
different things in different contexts of the same program.

 > Of course
 > equality is an issue in and of itself, but (for the purpos of functor
 > memoization) my feeling is that Integer should not be equal to 'extend
 > Integer ...'  except when the extension is empty.

Ask two mathematician of all the properties of "integer". They probably 
tell you different sets of functions. But if we use Integer in a program 
all we care about is what properties it has at the time we use it.

How would you distinguish 'Integer' from 'extend Integer' anyway? I 
think for me the difference is irrelevant. All I want to see is Integer 
and not Integer1, Integer2, etc.

 > Furthere, no
 > extended domain D would be equal to any other extension of D,
 > similarly for extensions of extensions, etc.

 > As an aside, I feel that runtime equality checks on values (domain
 > elements) should be permited only for those domains which implement
 > BasicType (in which case I would support making BasicType a primitive
 > language defined category).

Why should BasicType (i.e. =:(%,%)->Boolean) be a primitive? I don't see 
any need.

 > Another option being to use whatever
 > export '=: (%, %) -> Boolean' the domain admits, or perhaps the
 > equivalent Aldor `generic tie-in' which I think is `test'.

What? "test" is not a replacement for "=" in Aldor.

 > I strongly feel that SPAD should define precise semantics for any
 > notion of equality used by the compiler.

If I am not completely wrong then Aldor does not define any meaning for 
=. It is a function as any other that a user defines.

In Aldor one cannot currently compile something like

   if T = Integer then ... else ...

because there is no (implementation of a) function

   =: (Type, Type) -> Boolean

and defining one yourself you would have to use "pretend Pointer". But 
even then I guess it might happen that you have "T=T" returning false.

\start
Date: Mon, 11 Jun 2007 19:45:57 +0200 (CEST)
From: Franz Lehner
To: Ralf Hemmecke
Subject: Re: Spad and its object model

> Send complaints to Stephen Watt and Lauretiu Dragan. But if you have a 64bit 
> machine that could be some problem. There should be a hint by Christian 
> Aistleitner concerning the 64bit problem in the aldor-l archive.
this made me curious.
I got
http://wiki.axiom-developer.org/public/aldor-linux-x86_64-v1.0.2.bin
and so far it works fine from with in axiom (debian etch amd64).
Is this a true 64bit version?

however with your instructions I get
> aldor -laldor -fo -fao aaa.as
cc1: error: unrecognized command line option "-fwritable-strings"
#1 (Fatal Error) C compile failed.  Command was: unicl 
-I/usr/opt/AxiomAldor-1.0.2/aldor/linux/1.0.2/include -c aaa.c
#1 (Warning) Removing file `aaa.c'.

Is this one of the errors
http://www.aldor.org/pipermail/aldor-l/2005-June/000074.html
talks about?

\start
Date: 11 Jun 2007 14:20:47 -0400
From: Stephen Wilson
To: Ralf Hemmecke
Subject: Re: Spad and its object model
Cc: Gabriel Dos Reis

Ralf Hemmecke writes:

>  > One basic rule would be that a domain `functor' memoizes its
>  > arguments, and always returns the same object for equal arguments,
>  > performing any required initialization on the first call.
> 
> Of course you know that globally defined functors can be called in a
> local environment which would allow Foo(Integer) and Foo(Integer) to
> be different things in different contexts of the same program.

Yes.  But those would be two different functors.  The same rules would
apply independently to both.

>  > Of course
>  > equality is an issue in and of itself, but (for the purpos of functor
>  > memoization) my feeling is that Integer should not be equal to 'extend
>  > Integer ...'  except when the extension is empty.
> 
> Ask two mathematician of all the properties of "integer". They
> probably tell you different sets of functions. But if we use Integer
> in a program all we care about is what properties it has at the time
> we use it.

The rules I gave jive with my personal understanding of Aldor
semantics (despite the semantics are not strictly specified).  I
wanted to present some rules which were consistent with others
experience and expectations.

However, I am more than open to the possibility of providing a more
general mechanism.

> How would you distinguish 'Integer' from 'extend Integer' anyway? I
> think for me the difference is irrelevant. All I want to see is
> Integer and not Integer1, Integer2, etc.

This is basicly what you get in Aldor.  The virtue of the rules I gave
is that they are dirt simple.  Do you know of a way to define functor
application and the calculation of predicated exports which `works'
naturally when extend is involved, but that does not yield such
`versioned domains'?

>  > Furthere, no
>  > extended domain D would be equal to any other extension of D,
>  > similarly for extensions of extensions, etc.
> 
>  > As an aside, I feel that runtime equality checks on values (domain
>  > elements) should be permited only for those domains which implement
>  > BasicType (in which case I would support making BasicType a primitive
>  > language defined category).
> 
> Why should BasicType (i.e. =:(%,%)->Boolean) be a primitive? I don't
> see any need.

The basic rationale is that in order to memoize a functor, we need an
equality test for its arguments.  For domain elements, it seems only
natural to have a canonical place to define what equality means for
that domain.  This is in contrast to the compiler choosing what
equality means.  For example, the compiler might choose pointer
equality, but then it is likely that two bignums, although numericly
equal, would compare as different.  That is the kind of situation im
trying to avoid with my sugesstion.

> 
>  > Another option being to use whatever
>  > export '=: (%, %) -> Boolean' the domain admits, or perhaps the
>  > equivalent Aldor `generic tie-in' which I think is `test'.
> 
> What? "test" is not a replacement for "=" in Aldor.

Ah, now I recall. "test" serves as a coercion to boolean values.  It
was "case" that I was thinking about, as used in Aldors select
statement.  "case" is not a replacement for "=", but is used as a
`canonical' name for the purpose of equality testing in compiler
generated constructs.

My point is that the user should have a facility to define equality
and the compiler should respect that definition at runtime. 

>  > I strongly feel that SPAD should define precise semantics for any
>  > notion of equality used by the compiler.
> 
> If I am not completely wrong then Aldor does not define any meaning
> for =. It is a function as any other that a user defines.

>From memory, I agree.

> In Aldor one cannot currently compile something like
> 
>    if T = Integer then ... else ...
> 
> because there is no (implementation of a) function
> 
>    =: (Type, Type) -> Boolean
> 
> and defining one yourself you would have to use "pretend Pointer". But
> even then I guess it might happen that you have "T=T" returning false.

\start
Date: Mon, 11 Jun 2007 20:22:45 +0200
From: Ralf Hemmecke
To: Franz Lehner
Subject: Re: Spad and its object model

Hi Franz,

that is a question that should be sent to aldor-l@aldor.org.

> I got
> http://wiki.axiom-developer.org/public/aldor-linux-x86_64-v1.0.2.bin
> and so far it works fine from with in axiom (debian etch amd64).
> Is this a true 64bit version?

> however with your instructions I get
>> aldor -laldor -fo -fao aaa.as
> cc1: error: unrecognized command line option "-fwritable-strings"
> #1 (Fatal Error) C compile failed.  Command was: unicl 
> -I/usr/opt/AxiomAldor-1.0.2/aldor/linux/1.0.2/include -c aaa.c
> #1 (Warning) Removing file `aaa.c'.
> 
> Is this one of the errors
> http://www.aldor.org/pipermail/aldor-l/2005-June/000074.html
> talks about?
> 
> Franz

I think it is rather a problem with gcc 4.0. To be more precise: The 
C-code produced by the Aldor compiler must be compiled with gcc 3.3 or 
so. gcc4.0 does not work.

On my debian machine I have installed an older gcc and use that for Aldor.

You have to modify $ALDORROOT/include/aldor.conf at the section [linux].
Here comes what I have.

----------------------------
[linux]
   inherit       = linuxcore
# these enforce ieee
#  ieee-opts = -ffloat-store -mieee-fp
   ieee-opts = -ffloat-store
   fast-opts = -ffast-math -O2
   cc-name = gcc-3.3
   link-name = gcc-3.3	
----------------------------

The last two lines are interesting for you.

woodpecker:/usr/bin>ll gcc*
lrwxrwxrwx 1 root root      7 2007-04-19 16:47 gcc -> gcc-4.1
-rwxr-xr-x 1 root root  74104 2006-07-13 18:47 gcc-2.95
-rwxr-xr-x 1 root root  80976 2007-01-03 19:48 gcc-3.3
-rwxr-xr-x 1 root root 183444 2006-12-10 15:46 gcc-4.1
lrwxrwxrwx 1 root root     10 2007-04-19 16:47 gccbug -> gccbug-4.1
-rwxr-xr-x 1 root root  15963 2007-01-03 19:42 gccbug-3.3
-rwxr-xr-x 1 root root  16283 2006-12-10 15:44 gccbug-4.1
-rwxr-xr-x 1 root root   2018 2006-12-20 03:02 gccmakedep

Hope that lets you use Aldor now.

\start
Date: 11 Jun 2007 15:00:40 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Spad and its object model

Gabriel Dos Reis writes:

> On Mon, 11 Jun 2007, Stephen Wilson wrote:
> 
> | Gabriel Dos Reis writes:
> | 
> | > On Sun, 10 Jun 2007, Stephen Wilson wrote:
> | > 
> | > | Hello Gaby,
> | > | 
> | > | Gabriel Dos Reis writes:
> | > | [...]
> | > | >   However, I do believe the use of arrays has inherent problems in 
> | > | > terms of maintaining coherence of function pointers assigned to slots.
> | > | > Because the mapping from declarations order to integer has lost important
> | > | > informations (name, types, etc) of the functions being mapped.
> | > | 
> | > | Im not sure if this is fundamental to an array.  I think it is
> | > | entierly possible to define vtable elements at a fixed offset which
> | > | provide alternative methods of indexing.  Indeed, I belive the current
> | > | layout provides such a rudimentary facility of mapping export labels
> | > | to arity and argument type information, but the details escape me (Its
> | > | been a long time since I looked at this.  I recall making notes.  I
> | > | need to do some digging).
> | > 
> | > I'm not sure I agree.  For the array representation, numeric integrs
> | > are the key.  The only information they carry is the order of
> | > declaration.  In a context where declarations are scatered over
> | > different modules  (or files), there no longer is a natural order
> | > of declarations.  Chaos ensures.
> | 
> | Notice that I said the vtable could have a entry to provide
> | alternative indexing strategies at a _fixed_ offset.  Such an entry
> | could be a hash, an assoc list, etc.  The current vtables do have such
> | a stucture.  I belive the following mappings are currently possible
> | (but this is only theory, I need to work out the details):
> | 
> |      index -> function slot
> |      index -> name
> |      name -> arity
> |      name -> target type
> |      name -> argument type(s)
> |      name -> index
> | 
> | This is not a complete list.  For example we could map a type
> | signature to the list of exports which satisfy.
> 
> I guess what I trying to get at is what are the benefits of those 
> additional indirections over simple, hash table representation.

I would imagine that the vast number of lookups would suffice with an
integer index.  Tiny fraction would require higher level keys. 

> >From all I can see, the "index" key relies on order declaration which is a
> non-started.  The scheme "name" key is essentiablly equivalent to using a hash
> table.  If an extrat indirection is required to get the type, what is he
> point?  

This indirection could certainly be made fast, probably on par with a
hash.

I dont think of the integer index as having anything to do with the
order of declarations.  I prefer to think of the relationship as
coincidental.  

> 
> | Spad vtables potentially support many types of keys for indexing, not
> | just integers.
> 
> Maybe.  I'm talking of Spad and its object model representation as of today.
> I'm considering ways to get supports verification and extensions without
> excessive performance regression.  

I am talking about the representaion as of today too.  But as I said,
I have yet to hammer out all the details.

I belive that verification and extension operations would consume only tiny
fraction of lookups.   The slight (if any) performance bottle-neck
in the current scheme would not compinsate for the global reduction in
performance which a hash representation would introduce.

> | > | >   I would like to suggest the idea of using hastables as opposed to
> | > | > arrays to implement vtables (materialization of domains and packages).
> | > | > Not only it would help tame the problem of coherence, but also move
> | > | > to functionalities like "post facto extensions".
> | > | 
> | > | Roughly, what are the keys?  What do the entries look like?
> | > 
> | > The keys would be faithfull encodings of operation names, their types
> | > (and possibly their scope, in case we go with nested scopes).
> | 
> | OK.  My initial feeling is that there would be a great deal of
> | overhead involved in computing the hashes for such keys.
> 
> If you use strings as encoding (traditional technique), then what you really
> put in the hastable is the symbol whose name is the encoding.  In that case,
> the "intern" operation is done by the compiler, NOT at runtime, and look
> up is quite fast.

Well, intern happens at runtime quite often, but thats not the point.
Im surprised that you would want to use strings.  They are not as
easily manipulated as, say, a struct or sexpression
representation. Considering that your concerned about such high level
operations such as extension, I would have thought a more malable
representation would be critical.  If you are constantly converting
from, say, a struct representation to the corresponding string, you
may just as well use the struct itself and a custom hash to index the
table.

> |  Caching
> | would help but would that not provide an opportunity for coherence
> | problems to arise?
> 
> More specificaly?

Im just following the general notion that cached data can become out of
sync.  Its dependent on the implementation.  I would trust that any
solution you propose would not suffer in that regard.
 
> [...]
> 
> | > | I would need a clear picture of what the semantics would be for "post
> | > | facto extensions".  Do you sugest following Aldor explicitly? IIRC new
> | > | exports introduced by `extend' are not visible to previous
> | > | definitions, except via `has' predicates which execute during
> | > | runtime.  Are there other issues involved?
> | > 
> | > If you do static resolution of names (which I believe we should retain),
> | > then "future" dos not interfer with "past".
> | 
> | I think I understand your statement, but not how it connects.  `has'
> | is (in part) an introspective runtime operation.
> 
> There are two stages operations:  static resolution of (function) names,
> and dynamic resolution of the residual.

Ok. So long as elimination of residual variables is dynamic, we are on
the same page.

> |  Often the argument
> | contains a free variable.  I dont see how static resolution of names
> | fits in this context.
> 
> Example of cases where it won't work?

No, not with the dynamic component.  I read "If you do static
resolution of names then future does not interfere with past" as
meaning you advocated purely compile-time resolution.

> The hashtable repreentation vs. array representation has no semantics effect
> on well formed programs.

Agreed.

\start
Date: Mon, 11 Jun 2007 15:50:12 -0400
From: Bill Page
To: William Sit
Subject: RE: [#358 Variable is apparently always assumed to be positive?] Functions and Segments

William,

Thanks for adding your comments to the wiki. I have
re-arranged this a little by separating the comments about
segment from those about functions so that now your
comments about segments appears here:

http://wiki.axiom-developer.org/SandBoxFloatSegment

On June 7, 2007 9:21 PM William Sit wrote:

> ...
> I am overwhelmed by the amount of Axiom emails and most
> I  could not follow. I don't even have the guts to try 
> compiling the newest versions. To me, it is very
> confusing, but it does seem that Axiom is in excellent 
> hands.
>

Jump in any time, your contributions are like a "breath
of fresh air" ;-)

Perhaps the multiple versions are a bit confusing but so
far there seems to be a reasonable amount of co-operation
so I think things are proceeding very much as one would
expect/hope in open source development.
 
> I'm looking forward to your comments on Segment. It
> just feels strange that the implementation is so 
> "uncategorical".
> 

I added a slightly changed version of Segment to this
page:

http://wiki.axiom-developer.org/SandBoxFloatSegment

All I did was require that Segment be defined over
a Ring and then re-iterpreted BY as specifying the
separation of elements of the segment.

This seems more "categorical" to me given what I
expect to be the normal use-case although it is in
some ways more restrictive than the original as you
pointed out in your email. Can you imagine an actual
application where it is interesting to define a
segment over something that is not a Ring?

\start
Date: Mon, 11 Jun 2007 15:20:51 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Spad and its object model

On Mon, 11 Jun 2007, Stephen Wilson wrote:

| > I guess what I trying to get at is what are the benefits of those 
| > additional indirections over simple, hash table representation.
| 
| I would imagine that the vast number of lookups would suffice with an
| integer index.  Tiny fraction would require higher level keys. 

Lookup with integer index is OK when you have all information at the
same place and at the same time and have a way to enforce its
semantics.  Currently, Spad is such that one needs to have all
the information when constructing the vtable but there is no means
to enforce consistency.  Going to a world with "extend" makes
the problem even more accute.

| 
| > >From all I can see, the "index" key relies on order declaration which is a
| > non-started.  The scheme "name" key is essentiablly equivalent to using a hash
| > table.  If an extrat indirection is required to get the type, what is he
| > point?  
| 
| This indirection could certainly be made fast, probably on par with a
| hash.

How would that be faster than the scheme that uses only one lookup?

| I dont think of the integer index as having anything to do with the
| order of declarations.

Please elaborate on its semantics then.

[...]

| Well, intern happens at runtime quite often,

Not, in the scheme I'm proposing.

| but thats not the point.
| Im surprised that you would want to use strings. 

I don't want to use strings.  I want to use symbols.  I mentioned
string to explain how the symbol is used.  How can that be surprising?

| [...] If you are constantly converting
| from, say, a struct representation to the corresponding string,

But, I'm not doing that.

\start
Date: Mon, 11 Jun 2007 23:10:35 +0200 (CEST)
From: Waldek Hebisch
To: Gabriel Dos Reis
Subject: Re: Spad and its object model

> 
> Hi,
> 
>   I've been thinking about the following for a long time now, and I
> susect it is time for me to let it go to the Axiom  community for feedback.
> 
>   Spad fundamentally uses arrays of function pointers (also known as vtables)
> as implementation technology for categories, domains, packages, and 
> inheritance.  Each function defined gets a slot in a vtable (the thing that
> materializes a domain or a package) and call to that function may be
> resolved by poking at that slot and dereferencing the result. The vtable is
> an array to allow constant time indexing.  That is fast.  OK.
> 
>   However, I do believe the use of arrays has inherent problems in 
> terms of maintaining coherence of function pointers assigned to slots.
> Because the mapping from declarations order to integer has lost important
> informations (name, types, etc) of the functions being mapped.
>

Gaby, did you look how Axiom uses arrays of function pointers?  At
the first glance they are like vtables.  But there is a fundamental
difference: Spad domain uses only its own domain vector -- it never
directly uses ancestor vector.  More precisely, at compile time
Spad compiler determines all "external" values used by given
domain and assigns them slot numbers.  There is no problem of
coherence due to fixed numbers: as long as you use the same object
file the numbers stay fixed.  Once you recompile, the numbers will
change, but the change affects all uses of given number, so things
stay consisten.   Of coures, crucial to consistency is fact that
other domains use only its own vector and do not care about
domain vectors of other domains. 

One mau ask how it is possible?  Essentially the arrays of function
pointers is a cache -- it is filled with calls to lookup routine
which a runtime fills slots with correct functions.  So actually,
spad domain vector not a vtable in OO sense, but rather a like
procedure linkage table in ELF shared library.

There are issues with coherence, but IMHO they are unavoidable
given static typechecking and dynamic runtime:  Spand compiler
checks that intefaces to domians are compatible at compile
time, but you may redefine things in incompatible way and
recompile only some objects later.  Say you compile D which
references Integer.  Later you redefine Integer in incompatible
way and recompile Integer (but keep ald object for D).  D 
references Integer by name and in fresh inage will pick
new definition of Integer, giving runtime problems.  Still,
if you just add new functions to Integer things will stay
more or less sane.
 
>   I would like to suggest the idea of using hastables as opposed to
> arrays to implement vtables (materialization of domains and packages).
> Not only it would help tame the problem of coherence, but also move
> to functionalities like "post facto extensions".
> 
> Comments?
> 

IMHO using just using hastables in place of arrays does not make any
sense, because arrays are just cache lookups.  Using hastables for
core lookups make some sense -- my impression was that core lookup
used linear search.  However, then you need to face issue of coherence...
You may also think about different lookup policy, but that would
significantly change Spad semantic.

AFAICS problems of "post facto extensions" have nothing to do
with usage of arrays to cache lookups.  IMHO main problem is
that Axiom has just one "handle" to access given domain.
Namely domain Integer defines function also  named Integer
which build domain vector.  If an extension tries to redefine
Integer one looses handle to original domain.  The solution
is to have two (or more) handles: one to current interface
and one for each element of the extension set.  So domain
Integer should define Interface-Integer and Implementation-Integer.
Latey an extension MyExtension will redefine Interface-Integer
(replacing original interface by an extended one) and
Implementation-MyExtension.  Implementation-MyExtension still
can reach old Integer via Implementation-Integer and delegate
things.  In principle Interface-Integer can know that it
is implemented by Implementation-Integer and Implementation-MyExtension
and if Integer is redefined later the new interface can notice
that it also needs parts from Implementation-MyExtension.

IIUC Aldor is using sheme as above, only names differ.

\start
Date: 11 Jun 2007 17:12:15 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Spad and its object model

Gabriel Dos Reis writes:

> On Mon, 11 Jun 2007, Stephen Wilson wrote:
> 
> | > I guess what I trying to get at is what are the benefits of those 
> | > additional indirections over simple, hash table representation.
> | 
> | I would imagine that the vast number of lookups would suffice with an
> | integer index.  Tiny fraction would require higher level keys. 
> 
> Lookup with integer index is OK when you have all information at the
> same place and at the same time and have a way to enforce its
> semantics.  Currently, Spad is such that one needs to have all
> the information when constructing the vtable but there is no means
> to enforce consistency.  Going to a world with "extend" makes
> the problem even more accute.

If the vtable can be interrogated with a variety of keys, allowing
useful mapping of elements, I dont see how a hash is any more
flexible.  Perhaps you could provide an example?

> | 
> | > >From all I can see, the "index" key relies on order declaration which is a
> | > non-started.  The scheme "name" key is essentiablly equivalent to using a hash
> | > table.  If an extrat indirection is required to get the type, what is he
> | > point?  
> | 
> | This indirection could certainly be made fast, probably on par with a
> | hash.
> 
> How would that be faster than the scheme that uses only one lookup?

I didnt say faster, I said on par.  Either scheme is O(1), and the
constant difference would be small.

I suspect the difference in lookup time would become noticable only
when everything that can be accomplished using a simple integer index
is replaced by a hash lookup.
 
> | I dont think of the integer index as having anything to do with the
> | order of declarations.
> 
> Please elaborate on its semantics then.

Nothing fancy. Its just a key, no more, no less.

[...]

I belive for this dicussion to be productive some prototype
implementation would be useful as the focus now seems to be
on efficiency.

Unless you have already explored this alternative, I can write a few
functions which exploit the current vtable structure to provide some
of the mappings which you require.  I hope to clarify my own rusty
comprehension of their layout in the process.  Perhaps then we could
look at the issues involved in more detail.

\start
Date: Mon, 11 Jun 2007 16:26:48 -0500 (CDT)
From: Gabriel Dos Reis
To: Waldek Hebisch
Subject: Re: Spad and its object model

On Mon, 11 Jun 2007, Waldek Hebisch wrote:

| Gaby, did you look how Axiom uses arrays of function pointers? 

Yes.  :-)

| At
| the first glance they are like vtables.  But there is a fundamental
| difference: Spad domain uses only its own domain vector -- it never
| directly uses ancestor vector.
  ^^^^^^^^

What do yo mean by "never directly"?

check out lookupCompete and lookupIncomplete.

[...]

| There are issues with coherence, but IMHO they are unavoidable
| given static typechecking and dynamic runtime:  Spand compiler
| checks that intefaces to domians are compatible at compile
| time, but you may redefine things in incompatible way and
| recompile only some objects later.

Why do you believe this is unavoidable?

| Say you compile D which
| references Integer.  Later you redefine Integer in incompatible
| way and recompile Integer (but keep ald object for D). 

The system should be able to catch that, precisely.

| D 
| references Integer by name and in fresh inage will pick
| new definition of Integer, giving runtime problems.

this is one root of the problem.  Another root is the way lookup
functions work.

[...]

| AFAICS problems of "post facto extensions" have nothing to do
| with usage of arrays to cache lookups.  IMHO main problem is
| that Axiom has just one "handle" to access given domain.
| Namely domain Integer defines function also  named Integer
| which build domain vector.

I don't think, that is the main problem.

\start
Date: 11 Jun 2007 16:36:43 -0500
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Spad and its object model

Stephen Wilson writes:

| Gabriel Dos Reis writes:
| 
| > On Mon, 11 Jun 2007, Stephen Wilson wrote:
| > 
| > | > I guess what I trying to get at is what are the benefits of those 
| > | > additional indirections over simple, hash table representation.
| > | 
| > | I would imagine that the vast number of lookups would suffice with an
| > | integer index.  Tiny fraction would require higher level keys. 
| > 
| > Lookup with integer index is OK when you have all information at the
| > same place and at the same time and have a way to enforce its
| > semantics.  Currently, Spad is such that one needs to have all
| > the information when constructing the vtable but there is no means
| > to enforce consistency.  Going to a world with "extend" makes
| > the problem even more accute.
| 
| If the vtable can be interrogated with a variety of keys, allowing
| useful mapping of elements, I dont see how a hash is any more
| flexible.  Perhaps you could provide an example?

Did I say "more flexible"?

When you have an array and you index it with value 2, what does "2"
means? 

[...]

| > | I dont think of the integer index as having anything to do with the
| > | order of declarations.
| > 
| > Please elaborate on its semantics then.
| 
| Nothing fancy. Its just a key, no more, no less.

Sorry, "nothing fancy" is not an executable semantics.

\start
Date: 11 Jun 2007 18:05:58 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Spad and its object model

Gabriel Dos Reis writes:
> | If the vtable can be interrogated with a variety of keys, allowing
> | useful mapping of elements, I dont see how a hash is any more
> | flexible.  Perhaps you could provide an example?
> 
> Did I say "more flexible"?
> 
> When you have an array and you index it with value 2, what does "2"
> means? 

As I said, you are not limited to using an integer.  You could use
any key which makes sense.  You suffer slight cost of indirection, but
cost comparable to a hash I suspect.
 
> [...]
> 
> | > | I dont think of the integer index as having anything to do with the
> | > | order of declarations.
> | > 
> | > Please elaborate on its semantics then.
> | 
> | Nothing fancy. Its just a key, no more, no less.
> 
> Sorry, "nothing fancy" is not an executable semantics.

Like most bytes, one needs to infer the meaning by context.  An
integer index is fast because it does not carry more information than
the context can provide.  For other situations, a different key can be
used.

\start
Date: Mon, 11 Jun 2007 17:14:56 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Spad and its object model

On Mon, 11 Jun 2007, Stephen Wilson wrote:

| Gabriel Dos Reis writes:
| > | If the vtable can be interrogated with a variety of keys, allowing
| > | useful mapping of elements, I dont see how a hash is any more
| > | flexible.  Perhaps you could provide an example?
| > 
| > Did I say "more flexible"?
| > 
| > When you have an array and you index it with value 2, what does "2"
| > means? 
| 
| As I said, you are not limited to using an integer.  You could use
| any key which makes sense.

In that case, can you remind me of your main objection to what I 
originally suggested?

\start
Date: 11 Jun 2007 18:30:10 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Spad and its object model

Gabriel Dos Reis writes:

> On Mon, 11 Jun 2007, Stephen Wilson wrote:
> 
> | Gabriel Dos Reis writes:
> | > | If the vtable can be interrogated with a variety of keys, allowing
> | > | useful mapping of elements, I dont see how a hash is any more
> | > | flexible.  Perhaps you could provide an example?
> | > 
> | > Did I say "more flexible"?
> | > 
> | > When you have an array and you index it with value 2, what does "2"
> | > means? 
> | 
> | As I said, you are not limited to using an integer.  You could use
> | any key which makes sense.
> 
> In that case, can you remind me of your main objection to what I 
> originally suggested?

My objection was that the current implementation allows interrorgation
based not only on integer keys, but also w.r.t operation names.
Further functionality could be added to allow other indexing schemes
_without_ changing the underlying representation.

Global change to a hash would certainly cost us in execution time.  I
have not yet seen anything convincing me that a change is essential.

\start
Date: Tue, 12 Jun 2007 01:06:40 +0200
From: Gregory Vanuxem
To: Martin Rubey
Subject: Re: testing hyperdoc package on Windows

Here are my tests:

gcl-2.6.8pre just checked out today : fails in 'accept' with error:

  "not such file or directory"

gcl-2.6.5w (the version on which the packaged version of Axiom for
Windows is built) never handles the request, seems to wait indefinitely.

And the good news, I have a version of Axiom build-improvement built in
december (gcl-2.6.8pre), this one handles the request successfully. I
only tested hyper.lisp and the function 'server' printed "Got TEST" for
the url 127.0.0.1:8080/test. Will try to know why 2.6.8pre from cvs
fails in accept (windows only).

\start
Date: Mon, 11 Jun 2007 18:32:48 -0500
From: Tim Daly
To: list
Subject: lookup mechanisms

Gaby, Waldek, Stephen,

It would be useful if you all cooperated in developing a document
that describes the current mechanisms in detail.

\start
Date: 11 Jun 2007 19:43:51 -0400
From: Stephen Wilson
To: Tim Daly
Subject: Re: lookup mechanisms

Tim Daly writes:

> Gaby, Waldek, Stephen,
> 
> It would be useful if you all cooperated in developing a document
> that describes the current mechanisms in detail.

I would be more then happy to contribute to such an effort.  Count me
in.

\start
Date: Mon, 11 Jun 2007 19:43:56 -0400
From: William Sit
To: list
Subject: Re: [#358 Variable is apparently always assumed to be positive?]Functions and Segments

Bill Page wrote:
> 
> William,
> 
> Thanks for adding your comments to the wiki. I have
> re-arranged this a little by separating the comments about
> segment from those about functions so that now your
> comments about segments appears here:
> 
> http://wiki.axiom-developer.org/SandBoxFloatSegment

I wonder why you did not move it to a separate IssueTracker?
It is bug in the implementation of 'expand' (incompatibility
with 'BY').

> 
> On June 7, 2007 9:21 PM William Sit wrote:
> 
> > ...
> > I am overwhelmed by the amount of Axiom emails and most
> > I  could not follow. I don't even have the guts to try
> > compiling the newest versions. To me, it is very
> > confusing, but it does seem that Axiom is in excellent
> > hands.
> >
> 
> Jump in any time, your contributions are like a "breath
> of fresh air" ;-)

Would you jump into the ocean without knowing how to swim
(even with lifeguards around), or would you rather work on
some beauties at the beach? 

[...]

> I added a slightly changed version of Segment to this
> page:
> 
> http://wiki.axiom-developer.org/SandBoxFloatSegment
> 
> All I did was require that Segment be defined over
> a Ring and then re-iterpreted BY as specifying the
> separation of elements of the segment.
> 
> This seems more "categorical" to me given what I
> expect to be the normal use-case although it is in
> some ways more restrictive than the original as you
> pointed out in your email. 

I made some comments on your construction, see
http://wiki.axiom-developer.org/SandBoxFloatSegment

> Can you imagine an actual
> application where it is interesting to define a
> segment over something that is not a Ring?


I gave a simple example of MWF as a segment of M..S by 2. 

In general, one can define a segment in any chain (linearly
ordered set) or even a partially ordered set such as the set
of some algebraic substructures between two substructures,
ordered by inclusion. Such substructures can be subfields,
ideals in a ring, subsets of a set, etc.  For example, in
solving an equation by radicals, one may want to select a
shortest chain in the poset of algebraic subextensions of a
field where a solution by radical exists to minimize the
number of radicals used. Or, one may want to compute 

     [dim i for i in p..q] 

for the set of prime ideals between two primes p and q in a
ring. One can then select a maximal chain in this poset, and
later construct the "lying over" chain to this chain in an
overring. Of course, one has to be able to perform "expand"
in these situations. For specific posets, such as subsets of
a finite set, this may be possible. The 'BY' construction
(expansion by adding) may not be that meaningful in this
context (the meaning of "add" is usually missing), although
it certainly make sense to do expansion by counting. That is
why there should be two 'BY' constructs. Unfortunately,
putting them in the same package would cause confusion when
the parameter of SEGMENT is Integer.

\start
Date: Tue, 12 Jun 2007 03:31:32 +0200 (CEST)
From: Waldek Hebisch
To: Tim Daly
Subject: Re: Database bootstrap!

> Waldek,
> 
> That's excellent! Hopefully you've kept good notes about which
> things are needed at each stage of the process so I can try to
> reproduce it. Great work, painfully achieved, I'm sure.
> 

I have rather sparse notes.  My experiece is that even with best
notes it may be quite hard to reproduce build process -- this is
not restricted to Axiom.  So I normaly use scripts, they are
much better at recording needed steps and much easier to test
for correctnes.  And when I read code 6 month later I can
immediatly see what is done, no need to guess what given
piece of prose is intended to say.

I you (or somebody else) want to see details I have put the
diff (against wh-sandbox revision 593) at:

http://www.math.uni.wroc.pl/~hebisch/prog/db-boo4.diff

The diffs hooks into algebra Makefile, but the essential part
is really a build script: stamp-bootstrap rule has as a
dependency stamp-db rule.  stamp-db rule has as dependency
all spad file, so all spad files are unpacked from 
pamphlets before bootstrap.  The action on stamp-db rule runs
main database build script boot-sum.sh.  Once the stamp-db
is made we have databases which are good enough for the next
step and also a set of object files corresponding to categories
and core domains.  

As I wrote, one need a bunch of tweaks to the build process, and
action on stamp-bootstrap is really a build script implementing
those tweaks.

I think that the only part needed for bootstrap which is not in
the patch is $bootstrapDomains flag (implementation of this flag
consists of two lines).

Those scripts needs cleanup.  ATM the process is very sequential
and hard to restart in the middle if something goes wrong.  Many
files are recompiled needlessly.  Also, I use lists of files
which hardcode order -- ideally we should automatically generate
such lists.

\start
Date: Tue, 12 Jun 2007 03:39:24 +0200 (CEST)
From: Waldek Hebisch
To: Tim Daly
Subject: re: Database bootstrap!

I wrote:
> 
> I you (or somebody else) want to see details I have put the
> diff (against wh-sandbox revision 593) at:
> 
> http://www.math.uni.wroc.pl/~hebisch/prog/db-boo4.diff
> 

If you want to try the diff there is an important detail:
before applying the patch you need to remove src/share/*.daase

I ommited the removal part from the diff because it would blow
up size to few megabytes and make patch hard to read.

\start
Date: Tue, 12 Jun 2007 00:01:53 -0400
From: Bill Page
To: William Sit
Subject: re: [#358 Variable is apparently always assumed to be positive?]Functions and Segments

On 6/11/07, William Sit wrote:
> Bill Page wrote:
> >
> > Thanks for adding your comments to the wiki. I have
> > re-arranged this a little by separating the comments about
> > segment from those about functions so that now your
> > comments about segments appears here:
> >
> > http://wiki.axiom-developer.org/SandBoxFloatSegment
>
> I wonder why you did not move it to a separate IssueTracker?
> It is bug in the implementation of 'expand' (incompatibility
> with 'BY').
>

If you mean the interpretation of BY in terms of "counting" that is
implied by the description then I think that would be incompatible
with the intention of the original question, but of course it is plausible
and I agree that it is inconsistent with the implementation of expand.
Please feel free to submit such an issue report if you like. Giving a
new meaning to BY as I did in my modified Segment would then
be one possible resolution of this issue (which also happens to
satisfy the original question.)

> ...
> I made some comments on your construction, see
> http://wiki.axiom-developer.org/SandBoxFloatSegment
>

Thanks!

> > Can you imagine an actual application where it is interesting
> > to define a segment over something that is not a Ring?
>
> I gave a simple example of MWF as a segment of M..S by 2.
>

But  ZMOD 7 has Ring, so what you wrote can be cast in this
form naturually. :-) We can define this segment but we cannot
expand it as a list since it does not have OrderedRing. But
since it does have Finite, we could resort to a simple test for
equality in such cases so I agree the OrderedRing is probably
too strong a requirement.

> In general, one can define a segment in any chain (linearly
> ordered set) ..

Yes, I agree. Thanks for the explanation. So in this case we must
have

  Segment(S:OrderedSet)

In which case a Segment would have to be something represented
by Record(low:S and high:S) only, no 'incr' since there may not be
any 1 or 'nextItem' in S. For example it does not make any sense
to define Segment Float by only considering every other point.

> The 'BY' construction  (expansion by adding) may not be that
> meaningful in this context (the meaning of "add" is usually
> missing), although it certainly make sense to do expansion
> by counting.

I am not sure. I think that in Axiomatic terms it might be necessary
that the domain also be a member of the category STEP, i.e. where
'nextItem' is defined but I do not see any apriori reason why 'nextItem'
need respect some fixed total ordering.

> That is why there should be two 'BY' constructs. Unfortunately,
> putting them in the same package would cause confusion when
> the parameter of SEGMENT is Integer.
>

I am more inclined to think that the original definition given to BY
was just a little ill conceived.

\start
Date: Tue, 12 Jun 2007 00:19:26 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Spad and its object model

On Mon, 11 Jun 2007, Stephen Wilson wrote:

| Gabriel Dos Reis writes:
| 
| > On Mon, 11 Jun 2007, Stephen Wilson wrote:
| > 
| > | Gabriel Dos Reis writes:
| > | > | If the vtable can be interrogated with a variety of keys, allowing
| > | > | useful mapping of elements, I dont see how a hash is any more
| > | > | flexible.  Perhaps you could provide an example?
| > | > 
| > | > Did I say "more flexible"?
| > | > 
| > | > When you have an array and you index it with value 2, what does "2"
| > | > means? 
| > | 
| > | As I said, you are not limited to using an integer.  You could use
| > | any key which makes sense.
| > 
| > In that case, can you remind me of your main objection to what I 
| > originally suggested?
| 
| My objection was that the current implementation allows interrorgation
| based not only on integer keys, but also w.r.t operation names.
| Further functionality could be added to allow other indexing schemes
| _without_ changing the underlying representation.

That is precisel where I disagree.  
The current representation forces uses of integer as index.
And I'm back to my question:  when you index the vtable with value 2,
what is the meaning of value 2?  You have not answer that question so far;
except saying you are opposed to any change.

| Global change to a hash would certainly cost us in execution time.

Why does that cost more than what you have proposed so far?

| I have not yet seen anything convincing me that a change is essential.

I was looking more for feedback than convincing you -- I don't think I 
can convince you of anything.

\start
Date: Tue, 12 Jun 2007 01:21:36 -0500
From: Tim Daly
To: Martin Rubey
Subject: Hyperdoc

Martin,

Sorry for the delay in your question about working together on 
the hyperdoc issue. I've been giving it some thought. I have a
long term view of the "porting problem" which might be different
from your (or anyone else's) view so this is purely my opinion.
I'd welcome feedback on it.

For me the current hyperdoc is "so last year". The issue is not that it
uses old-looking technology. Hyperdoc shows a lot of the features
found in current browsers and was way ahead of its time.  However, I
want to do things now that are "way ahead of their time" so that 30
years from now the complaint will be that the world has finally caught
up.

There is the fundamental design issue, which I've been calling the
"Crystal" problem. It involves a multi-faceted view of a single
unified core problem. Lets ignore the deeper issues of the embedded
semantic network, the "intentional stance tracking", etc and just
focus on the low-level technology issues.

I've been doing isolated "experiments" to try to test these tools
to see what they can now do and find things they still need to do
(e.g. the lisp replacement for javascript does not yet do <canvas>).
The experiments are simply learning exercises to try to find the
limits of what the current tools do. But there are some low-level
goals that lie behind these exercises:

END-TO-END-LISP

I see the lisp as the base of axiom all the way to the base of the
web browser. End-to-end lisp is important because it gives me a lot
of power with very little work. I can dynamically create executable
expressions that can be evaluated in the browser and/or in the axiom
image. 

With tools like Hunchentoot I can map URLs directly into lisp function
calls. This means that I can dynamically create pages and hyperlinks
and have them execute function calls. Thus URLs can be created to
directly execute algebra, to dynamically create hyperdoc pages, etc.
<http://weitz.de/hunchentoot>

With Kamen Lisp (which replaces javascript in the browser) I can 
dynamically upload/download lisp functions. I can remotely manipulate
the document structure. I can communicate between multiple tabs so
that one tab can have the "worksheet" and another can have an axiom
workspace where I try axiom expressions. I can have multiple browser
windows communicating with each other so that I can manipulate a
graphics object in one window (e.g. rotate, scale, subset, etc) and
have the corresponding expression show up in another window. 
<http://www.cs.stevens.edu/~dlong/software/kamen/index.php>

With Apache I can configure it to talk to lisp and axiom directly
<http://www.accela.net/~dankna/guide.html>
Thus I can have apache manage the connections. If Axiom is
configured to sit directly behind apache I have the option of
having each browser tab be a separate axiom session, or the tab
could have its own workspace (axiom supports multiple workspaces)
or I have have them all share a session. Indeed I could have
a tab open to an axiom running on a different server entirely.

BROWSER DOES GRAPHICS

A near term goal is to lift the graphics out of the C code and
into lisp. Once this is done the graphics can be dynamically
manipulated by lisp and lisp can be dynamically manipulated by
the graphics. Thus the algebra code can interact directly with
the image allowing things like continous rotation (lisp drives
the graphics) or have data from the graph be transmitted back
to the algebra (e.g. picking the endpoints of the domain of
a function, deciding control points of inflection, interactive
root finding, etc).

This opens the way for doing things like solid modeling where
I can use Axiom to compute the stresses and strains in the
model where it takes input from forces applied by the user.

I can manipulate strings of primitive objects (folding, twisting,
attaching) to shape objects which know how to self-assemble since
I can keep the operations in a data structure parallel to the
graphics. Replaying the data structure on a primitive string
re-folds the object.

The tools to do this are the <canvas> tag and Kamen lisp on the
front end and a lisp-based graphics/algebra connection on the
back end. 

I also see a tighter connection between the graphics and the
axiom data structures. So if I create a complex graph object
(such as the dependency graph of the algebra) I can see the
graph object drawn directly from the algebra. If I implement
a "cost" primitive it would be possible to compute the cost of
a computation and show the computational costs of an algorithm
on the graph. Geometric objects (sheaves, splines, manifolds)
can be visualized an manipulated "visually" while the computation
occurs in parallel symbolically.


BROWSER DOES HYPERDOC

Hyperdoc also needs to be lifted into lisp and made a more integral
part of the system. Hyperdoc needs to know how to handle pamphlet
files directly, that is, how to construct html from the pamphlet
and pamphlets from input from the browser. This would allow the 
documentation to live in the pamphlet files. It would also allow
dynamic documentation (e.g. new algebra domains recently compiled)
to be shown. Since lisp has access to all of the algebra there is
a wide range of searching capabilities that could be implemented
(e.g. show all domains such that domain D has property P.

The internal language of the documentation for Axiom is latex. The
back end needs to know how to convert this to html (e.g. by using
tex2html or some tool like it) and from html to latex. Further we
need to think about things like MathML (I've done no experiments
with this yet).

BROWSER DOES FORMATTED I/O

For the browser front-end to be useful in the long term we need to
be able to manipulate the equations using tools like cut and paste.
It should be possible to select a subset of an equation, clip it,
or paste over it, and then see the computation repeated with the
change. History needs to be easily manipulated. Web pages with
results (e.g. as a notebook) need to be able to be exported as 
pamphlet files. The user should be able to use the browser as a
complete front end, doing input, output, and interaction (e.g. such
as graphics rotations which are sent back). It should be possible
to visit other sites, clip an equation, and have it entered into
the system.

BROWSER DOES DRAG-AND-DROP

It is important that we be able to take a pamphlet file, drag it
onto the browser, and have it added to the system. This facility
is fundamental to the idea that literate papers at a conference,
or from a web publication, can be immediately added. The user 
should be able to do things like change the equations in the paper
and see tables derived from the equation updated in real time.
Bibliographic links should be fetchable in an ASDF or YUM-like
form so that literate papers can reference other literate papers.

Pamphlet integration is vital to the long term front end.

FACETS

Once we enter into the idea of the crystal we introduce the idea of a
facet, which is a view into a piece of information about a unified
problem. The facets are all connected, giving multiple views of the
same problem while tracking the user's intentional stance. Facets
are found by rotating the crystal.

There's more but it takes us off into areas that only I care about
(as if we're not there already) such as a semantic network problem
representation and the interaction with the facets.

I'm basically tracking toward the crystal idea and focused on the
long term design. Thus I'm not spending a whole lot of time thinking
about porting issues. I don't see porting issues as being fundamental
in the long term view. I don't think the current design is sufficient
to carry us much further into the future. Indeed it is hardly sufficient
to carry us between platforms. I think it needs to be created anew.

\start
Date: 12 Jun 2007 10:01:07 +0200
From: Martin Rubey
To: Tim Daly
Subject: Re: Hyperdoc

Dear Tim,

Tim Daly writes:

> Martin,
> 
> Sorry for the delay in your question about working together on the hyperdoc
> issue. I've been giving it some thought. I have a long term view of the
> "porting problem" which might be different from your (or anyone else's) view
> so this is purely my opinion.  I'd welcome feedback on it.

Thanks for answering.  However, I must admit that your answer is quite
disappointing for me.  I'm not interested in having a hyperdoc replacement, be
it as good as it may, next year or even later.  I need something that's usable
this september.  And last but not least, I disagree entirely with you that the
design of hyperdoc is dated.  Quite on the contrary, I think it's mostly *very*
intelligently done.  If I compare to Mathematica, Maple, Maxima and even MuPAD,
it is *far* better.  (The design of HyperDoc, that is.  I'm not at all talking
about the missing documentation.)

Furthermore, your idea of using lisp for everything sounds quite dangerous to
me.  It sounds like: I don't really know what I'm going to do, but I'm going to
use lisp.

And replacing LaTeX with some lisp typesetter is, in my opinion, the most
stupid thing that could happen to axiom.

If you manage to do graphics as nice as currently available,  I'd love it.

In any case, since we are probably both continuing on our own, maybe you could
still tell me how to get users, uses, dependents and depends.  After all, this
would have to be part of the "Crystal", too?

\start
Date: Tue, 12 Jun 2007 04:27:28 -0700 (PDT)
From: Cliff Yapp
To: Martin Rubey, Tim Daly
Subject: re: Hyperdoc

--- Martin Rubey wrote:

> Furthermore, your idea of using lisp for everything sounds quite
> dangerous to me.  It sounds like: I don't really know what I'm
> going to do, but I'm going to use lisp.

Heh - that's usually a good situation in which to use Lisp, actually -
when you aren't sure what your going to do.  Lisp makes it very easy to
try many things quickly.

> And replacing LaTeX with some lisp typesetter is, in my opinion, the
> most stupid thing that could happen to axiom.

There are two ways to interpret that:

1.  Replace the LaTeX typesetting language with something based on
Lisp.

    I think we all agree this is not a good idea - this is not a point
of debate.  LaTeX as a documentation markup format has pretty well
stood the test of time, and extending it to support features it doesn't
currently have is almost routine (hyperref, xypic, pstricks, etc.)  We
don't need to switch away from LaTeX and there are good reasons not to.

2.  Replace the programs that translate LaTeX into other formats with
programs doing the same job, but written in Lisp.

    This is more my area of interest, and I don't know that anyone else
shares it - I think Tim might be innocent here ;-).  However, since
this wouldn't even be VISIBLE to anyone unless they were calling the
typesetting tools by hand (even now, doesn't the build wrap that in the
document script?) I don't see why anyone should be worried by
discussing the possibility.  The documents will be LaTeX, and LaTeX
won't go away - no one is forcing the use of a "lisp typesetter" (which
doesn't currently exist in usable form anyway.)  It's like with cl-web
- noweb is still there, and in fact even in the ASDF scenario it may be
possible to optionally use noweb for the pamphlet part of things (I'm
still wading through ASDF and CLOS documentation, but I think the
biggest single difficulty there would be calling noweb portably on
different platforms.)

\start
Date: Tue, 12 Jun 2007 14:54:03 +0200 (CEST)
From: Waldek Hebisch
To: Gregory Vanuxem
Subject: Re: Axiom under Windows

Gregory Vanuxem wrote:
> hypertex and the libdb.text files (Gold is buggy here). I can no longer
> use Axiom built on top of GCL because of a spurious bug in GCL
> (conditional statements not handled) and wh-sandbox misses file related
> functions when built on top of SBCL. Anyway when time will permit I'll

Could you be more specific about file handling in Windows SBCL?  AFAIK
makedir is problematic (but I hoped that it would work if you have mkdir
program in correct place) also chdir does not do much (but IIRC it is
taken verbatim from your Windows version).  Do you have problems with
other functions?  Also, do you how to pass file names to Windows
utilities in a way that avoid damage due to command line parsing
-- Unix shell has more qouting rules which allow you to pass any legal
charater as part of filename (I plan to add a simple encoder which
quotes all characters that need quoting).  I hope that Windows has
equivalent functionality.

\start
Date: Tue, 12 Jun 2007 15:24:17 +0200
From: Christian Aistleitner
To: Bill Page
Subject: Re: AxiomUnit
Cc: Gabriel Dos Reis

Hello Bill,

On Fri, 08 Jun 2007 15:35:00 +0200, Bill Page  
wrote:

> On 6/8/07, Christian Aistleitner wrote:
>>
>> ...
>> > Given that, what remains for AxiomUnit?
>>
>> As we've already discussed in private mail some time ago, there are more
>> things. But I suggest to switch to private communication again, as I do
>> not want to abuse the Axiom Mailing list for third party projects.
>
> [...], but I am very confused as as to why you
> would prefer private communication about a subjec that is
> important to so many other Axiom users.

If I'd know that AldorUnit could be nicely ported to Axiom and if I'd also  
know that this approach would be the only valid one, I'd probably discuss  
the whole process on the mailing list. However, I've been told that  
currently there are some scripts around to test Axiom code which one is  
the best?
I assume you would not want full length discussion about every single  
issue of all such scripts on the list. AxiomUnit would not automatically  
be better.

To me AxiomUnit should be developed as an add-on library to Axiom. Along  
with tools to facilitate writing test (suites/cases/s) and executing them.
If later on people decide to integrate them into Axiom, it's fine.

It's similar to other add-on libraries of Axiom.
I suppose, you do not want to have the discussion of every Axiom add-on  
library on the list ;)

> What do you mean
> by "third party projects"?

AldorUnit has been developed for Aldor. But it is not entangled with  
Aldor.org in any way.
AldorUnit is coming from RISC, which is not entangled with Aldor.org as  
far as I can tell. Ralf might chime in here, if this not accurate.
By "Third party project" I meant a project not endorsed or encouraged by  
Axiom.

\start
Date: Tue, 12 Jun 2007 15:29:44 +0200
From: Ralf Hemmecke
To: Cliff Yapp
Subject: re: Hyperdoc

> 2.  Replace the programs that translate LaTeX into other formats with
> programs doing the same job, but written in Lisp.
> 
>     This is more my area of interest, and I don't know that anyone else
> shares it - I think Tim might be innocent here ;-).  However, since
> this wouldn't even be VISIBLE to anyone unless they were calling the
> typesetting tools by hand (even now, doesn't the build wrap that in the
> document script?) I don't see why anyone should be worried by
> discussing the possibility.

You have probably noticed that any current program that translates LaTeX 
into some other format treats only a subset of the TeX language. TeX4ht 
does a very good job here and it has one big advantage. It uses TeX (the 
program) itself to interpret the input. I'm pretty sure that you could 
even produce a LISP format of your LaTeX input if you use tex4ht and 
translate to xml (which is just a slightly different way of putting the 
parens---so basically you have the tree structure of LISP).

Cliff, I don't know why it is better to write everything anew in LISP.
Use the tools at hand and build something that can actually compete with 
current CAS (plural). We fight with the future and haven't even reached 
the present.

Tim, my statement is in no way against your visions. In fact, I *very* 
much like that you every now and then tell us to lift our heads and look 
ahead of time. But still, we first need something reasonably good so 
that Axiom becomes more attractive to more developers. We desparately 
need more people.

\start
Date: Tue, 12 Jun 2007 09:49:11 -0400
From: Bill Page
To: Christian Aistleitner
Subject: Re: AxiomUnit
Cc: Gabriel Dos Reis

On 6/12/07, Christian Aistleitner wrote:
>
> On Fri, 08 Jun 2007 15:35:00 +0200, Bill Page wrote:
>
> > On 6/8/07, Christian Aistleitner wrote:
> >>
> >> ...
> >> > Given that, what remains for AxiomUnit?
> >>
> >> As we've already discussed in private mail some time ago, there
> >> are more things. But I suggest to switch to private communication
> >> again, as I do not want to abuse the Axiom Mailing list for third
> >> party projects.
> >
> > [...], but I am very confused as as to why you
> > would prefer private communication about a subjec that is
> > important to so many other Axiom users.
>
> If I'd know that AldorUnit could be nicely ported to Axiom and if I'd
> also know that this approach would be the only valid one, I'd probably
> discuss the whole process on the mailing list. However, I've been told
> that currently there are some scripts around to test Axiom code=97
> which one is the best?

Right now there is only a very rudimentary implementation of regression
testing that is part of what will become Axiom Silver. There is currently
no systematic method for doing unit testing in Axiom. So I would strongly
encourage you (Do I need to plead with you?) to please discuss AldorUnit
on this list.

> I assume you would not want full length discussion about every single
> issue of all such scripts on the list. AxiomUnit would not automatically
> be better.
>

Clearly one purpose of discussion is to consider what approach might
be better, but in open source projects it seems that one seldom
actually reach consensus. Instead sooner or later one (or several)
developers get tired of the discussion and find the motivation to just
strike-off in one of the directions discussed. Sometimes other developers
follow. I know that sounds like a crazy unworkable development model
but it is hard to argue with the success of a lot of other open source
projects...

> To me AxiomUnit should be developed as an add-on library to Axiom.
> Along with tools to facilitate writing test (suites/cases/s) and executing
> them. If later on people decide to integrate them into Axiom, it's fine.
>

I agree.

> It's similar to other add-on libraries of Axiom.

I agree.

> I suppose, you do not want to have the discussion of every Axiom
> add-on library on the list ;)
>

Well I do not wish to limit discussion in any manner. If there is
discussion of every Axiom add-on library, then the result is a
potentially rich source of documentation about these aspects of
Axiom.

> > What do you mean by "third party projects"?
>
> AldorUnit has been developed for Aldor. But it is not entangled with
> Aldor.org in any way. AldorUnit is coming from RISC, which is not
> entangled with Aldor.org as far as I can tell. Ralf might chime in here,
> if this not accurate.

I think that is a good thing. If there are issues relating to rights that
should be attributed to RISC or any other organization then of course you
should be specific about the license and copyright that you associate
with your work.

> By "Third party project" I meant a project not endorsed or encouraged
> by Axiom.
>

Since Axiom is a collaborative open source project I think it is quite
hard to define exactly what is and is not "endorsed or encouraged by
Axiom". Essentialy what is encouraged is that you and other people
contribute to this project in what ever way you find appropriate to you.
In return about the only thing that the Axiom project can promise is that
there will be a large number of other people who will be very grateful for
your work.

\start
Date: Tue, 12 Jun 2007 09:54:52 -0400
From: Bill Page
To: Ralf Hemmecke
Subject: re: Hyperdoc

On 6/12/07, Ralf Hemmecke wrote:
> ..
> Cliff, I don't know why it is better to write everything anew in LISP.
> Use the tools at hand and build something that can actually compete
> with current CAS (plural). We fight with the future and haven't even
> reached the present.
>

+1 Hear, hear!

>  We fight with the future and haven't even reached the present.

That's worth repeating! :-)

\start
Date: 12 Jun 2007 10:18:18 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Spad and its object model

Gabriel Dos Reis writes:
[...]
> That is precisel where I disagree.  
> The current representation forces uses of integer as index.
> And I'm back to my question:  when you index the vtable with value 2,
> what is the meaning of value 2?  You have not answer that question so far;
> except saying you are opposed to any change.

I think that Tim's suggestion of getting a document together detailing
the layout of domain vectors would be a good idea.  I know what most
of the elements of a domain vector represent, and I assume you do as
well.  I hope we can cooperate to produce a document which details
what we have come to understand.

> | Global change to a hash would certainly cost us in execution time.
> 
> Why does that cost more than what you have proposed so far?

Lookup via hash vs. direct indexing?  Over millions of iterations?  Im
confident the current implementation would win. 

There has obviously been a huge amount of effort invested in getting
axioms domain representation resonably compact and fast.

> | I have not yet seen anything convincing me that a change is essential.
> 
> I was looking more for feedback than convincing you -- I don't think I 
> can convince you of anything.

You might just suprise yourself.  After all, you did manage to
convince me that using a hash as doman representation is a bad idea :)

Your proposing a deep systemic change.  Such things must be torn apart
and analyzed.  Im just attempting to contribute to that process.

\start
Date: Tue, 12 Jun 2007 16:22:15 +0200
From: Ondrej Certik
To: list
Subject: src_aldor2.tgz compilation problems

the usual question these days - I installed aldor from aldor.org and
then compiled axiom from wh-sandbox using commands:

cd ~/extprograms
svn co https://axiom.svn.sourceforge.net/svnroot/axiom/branches/wh-sandbox
wh-sandbox
cd wh-sandbox
./configure
make

then I did:

export AXIOM=$HOME/extprograms/wh-sandbox/build/i686-pc-linux
tar xzf src_aldor2.tgz
cd aldor
notangle Makefile.pamphlet > Makefile

(I don't know that the "document" command is, I didn't find it in any
package in Debian, but the notangle from the package noweb seems to
work).

ondra@pc232:~/extprograms/aldor/aldor$ make
/bin/sh: line 0: cd:
/home/ondra/extprograms/wh-sandbox/build/i686-pc-linux/../../obj: No
such file or directory
make: Nothing to be done for `all'.


So there seems to be missing the "obj" directory in wh-sandbox after
compilation. What am I doing wrong?

In the meantime, I installed axiom, which is in Debian, but that is
the version 20050901-9. And I also installed the binary from:

http://wiki.axiom-developer.org/Mirrors?go=/public/axiom-aldor-20060621.tgz&it=Axiom+with+Aldor+binary

and followed the instructions at:

http://wiki.axiom-developer.org/AxiomBinaries

And this works fine, but it is a version from 20060621.

\start
Date: Tue, 12 Jun 2007 09:34:51 -0500
From: Tim Daly
To: Martin Rubey
Subject: Hyperdoc

Martin,

> Furthermore, your idea of using lisp for everything sounds quite
> dangerous to me. It sounds like: I don't really know what I'm going
> to do, but I'm going to use lisp.

Well I don't know why it sounds "dangerous". 

I can't claim that I know "how" to achieve all that I want to achieve
in the crystal idea. However, I do have experience in developing and
using large, complex programs in Lisp (e.g Axiom). 

I also authored a large lisp program that was both a semantic network
and a rule-based program called KROPS that was used as the knowledge
representation language for IBM's expert system called FAME. I want to
use this kind of technology to provide intelligence behind Axiom. KROPS
depends fundamentally on the mirror image that program representation
== data representation.  I don't know how to write such self-modifying
learning programs in C, Haskell, or any other language. But
self-modification is fundamental to the learning aspect and the
semantic/rule duality. And learning is fundamental to crystal.


Based on my lisp background I see the great advantage that I can create
s-expressions "on the fly", store them in files, transmit them, modify
them, and evaluate them. Doing this in any other language requires a
pile of parsers everywhere. In another project I'm doing we have several
parsers (XML, and several "intermediate languages"). They aren't hard to
write but each one uses a different surface syntax with slightly 
different semantics. Each one is more unnecessary machinery. Each one
is sliding down the slope of "optimizing", trying to generate "better"
code, adding "types", working on bringing in more compiler technology.
Each little language has to duplicate the function of the other 
languages (e.g. storing symbols). Each adds maintenance overhead.

Using lisp allows intermediate languages but they are just "more lisp"
so it is trivial to manipulate, store, transmit, modify, and evaluate.

But this all quickly devolves into language wars and religious debate.



> And replacing LaTeX with some lisp typesetter is, in my opinion, the most
> stupid thing that could happen to axiom.

Eh? I never suggested this. I would prefer that the browser "spoke" latex
so that I could use it in conjunction with html. But that's a project for
someone else. Perhaps some bright spot will make a Tex4ht "plugin".

On the other hand I see the browser as an "input" program as well as a
display program so I'd like to see it generate information in a format
that Axiom can use. That is, I'd like to see equations (mathml?),
s-expressions (e.g. graph structures) and latex pamphlets coming back
to axiom from the browser front end. This requires a decent
programming language in the browser.

\start
Date: Tue, 12 Jun 2007 09:35:05 -0500
From: Tim Daly
To: Martin Rubey
Subject: Hyperdoc

Martin,

> In any case, since we are probably both continuing on our own, maybe
> you could still tell me how to get users, uses, dependents and depends.

I'll look at this. These cannot be derived from the databases but
require a running axiom image. Do you happen to know where the code
is that computes this information? I know its in there somewhere but
I don't know off the top of my head.

\start
Date: Tue, 12 Jun 2007 10:22:21 -0500
From: Tim Daly
To: Christian Aistleitner
Subject: AxiomUnit

Christian,

I'd encourage you to discuss AldorUnit/AxiomUnit on this list.
There are a lot of people who are interested.

The current regression testing machinery uses string comparison of
new output against previous output. It has the advantage of being
simple but handling most kinds of results, including failure messages.

It also steps around the zero-equivalence problem. How can we test
Axiom integration by using differentiation? They may be inverse 
operations in some cases but Axiom can't simplify the results to 0.

However AldorUnit may be useful for testing various aspects of the
system which are not handled well with the current simplistic scheme.
For instance, the current scheme does not handle randomly generated
input gracefully.

Any and all forms of testing are vital and are to be strongly encouraged.

\start
Date: Tue, 12 Jun 2007 11:15:38 -0500
From: Tim Daly
To: Ralf Hemmecke, Bill Page
Subject: Hyperdoc

Ralf, Bill,

> Use the tools at hand and build something that can actually compete
> with current CAS (plural). We fight with the future and haven't even
> reached the present.

This isn't a competition, at least in my mind. My view is that this
is the early development of the science of computational mathematics.
Thus I see no reason to try to compete with existing systems. Besides,
MMA and Maple clearly have better resources. Chasing them is a never
ending task. The science is bigger than they imagine.

But why should we bother thinking about an "assume" facility, which is
clearly wrong, when we can do research in provisos? Why worry about
matching their symbolic (as opposed to algebraic) abilities when there
are clear advantages to an algebraic approach? Why encourage the
construction of more dead code when it is clear that code needs
extensive documentation to live? Why not raise our standards to
struggle with proving algorithms correct rather than handwave at the
problem? Why not change the expectations so that computational
mathematics papers are expected to be literate?

The future need not be a linear projection of the past.
Henry Ford didn't breed faster horses.
We can shape our future in fundamentally new ways.
Look to the 30 year horizon and imagine.

\start
Date: Tue, 12 Jun 2007 11:29:50 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Spad and its object model

On Tue, 12 Jun 2007, Stephen Wilson wrote:

| > | Global change to a hash would certainly cost us in execution time.
| > 
| > Why does that cost more than what you have proposed so far?
| 
| Lookup via hash vs. direct indexing?  Over millions of iterations?  Im
| confident the current implementation would win. 

Except that in the scheme you proposed, the result of the indexing is not
directly the operation, but another step must be taken.

| There has obviously been a huge amount of effort invested in getting
| axioms domain representation resonably compact and fast.

There obviously is a huge effort invested in avoiding to answer issues
I've raised.

\start
Date: 12 Jun 2007 18:36:34 +0200
From: Martin Rubey
To: Tim Daly
Subject: Market share, was: Re: Hyperdoc
Cc: Bill Page

Tim Daly writes:

> Ralf, Bill,
> 
> > Use the tools at hand and build something that can actually compete with
> > current CAS (plural). We fight with the future and haven't even reached the
> > present.
> 
> This isn't a competition, at least in my mind.

You are quite wrong here, I think.  Worldwide there are maybe 1000
Mathematicians interested in writing code, I suspect less.  There are currently
at least four competitors in the market of general purpose case, not counting
SAGE.

MuPAD is so similar to Axiom, that, once it is more commonly adopted, we have
*no* chance of getting any new contributors.  In most contries, the cost of
licencing MuPAD is negligible in comparison with the cost of salaries.

We need (good) contributors now.  I'm working quite hard on that.  But I tell
you, if we are still less than 20 contributors end of next year, I'll probably
stop with Axiom.  (I think we are currently about 10, but I didn't count.)

\start
Date: Tue, 12 Jun 2007 17:54:51 +0100 (GMT Standard Time)
From: Arthur Norman
To: Bill Page
Subject: RE: CCL maintenance.
Cc: 'axiom-devel' <list>

As term comes to an end I re-scanned the Axiom list and observe the 
discussion about CCL. Those who view the parenthesised abstract machine 
with bignum arithmetic and a garbage collector as separate from Axiom 
itself are liable to want to fall in with whatever standards Common/ANSI 
Lisp purveys. If they are careful they will limit themselves to using JUST 
the standardised facilities so that they have multiple "vendors" of that 
support substrate.

An alternative view (which is closer to the one I have) is that code at 
that level can serve more like a kernel for an algebra system, and that 
almost nobody writes "(de foo (...))" directly. As little as possible of 
that is written to allow a bootstrap process to lift the bulk of coding to 
a higher level. That sort of stuff may be the output of a translator from 
a higher level notation, but the output from translators is essentially 
guaranteed to be stylised and readily controllable. If the "lisp" becomes 
a dedicated kernel for an algebra system one loses a big vibrant 
world-wide community of Lisp developers maintaining it for the benefit of 
other projects. Hmmm - I do not know how many of such there actually are!
What one gains is the chance to have something significantly smaller and 
thus cheaper to support than FULL Lisp, and a chance to embed system 
interfaces within it where that helps flexibility of performance.

If the Axiom Community takes the first of these views then CCL is 
not of great interest to it, regardless of the use it had in the NAG days. 
If that is the case I would view it as sensible to remove the achchaic 
snapshop of my code from the Axiom servers since if it just sits there it 
causes a confusion.

For what it is worth these are some of the characteristics of CCL that may 
have caused NAG to view it as a plausible route...

(1) Way back, machines did not have as much memory as they do now and use 
of Axiom REQUIRED machines of a scale that limited potential uptake. CCL 
provided a modest footprint compared with alternatives and that made a big 
difference to real-world performance.  The world has probably changed 
since then! Enthusiasts in well funded labs had the big machines and did 
not need to worry, but everybody who was not a specially funded specialist 
did.

(2) Geography and time-zones  meant that from Cambridge in England it was 
easy to talk to NAG in Oxford, and I have previously worked with Griesmer, 
Jenks and Blair back in the Scrathpad days.

(3) CCL is designed not for developers but for delivery.
   (a) Most code is converted into compact bytecodes. But when one has
       built a system that way you can profile it to identify hot-spot
       functions. Those can then be off-line compiled into C that is
       statically linked into the CCL kernel. The scheme these is MUCH less
       flexible than the usual compile-via-C Lisp, but then it is MUCH
       easier! With say 10% of the whole code compiled into C one hopes for
       80% of the performance of a fully native-compiled system, but with
       much less bulk of compiled code. And the customer who then got a CD
       or the simple mathmatician who would now just download a pre-built
       binary just sees a smaller system and does not care about how or
       what gets compiled when.
   (b) CCL keeps all its loadable modules within a single file along
       with the initial heap image that it will reload when started.
       So Axiom (eg) could ship as a native executable file plus this
       image file (plus documentation directories etc). This keeps
       everything together in one place and reduces risks of muddle if
       one sub-file gets lost or mangled.
   (c) The image files for CCL contain bytecoded definitions (plus
       references to stuff compiled into C and linked into the kernel)
       and are machine independent. Well strctly you need to make one
       image for 32-bit and another for 64-bit platforms, but with more
       work I could fix that too. So to make a release you compile a
       simple fairly flat directory of cautiously portable C to make
       an executable. You use that to make an image file, and while you
       need to build executables for each platform your one image file
       can be shipped for Linux, Solaris, Windows, Mac, SGI, HP, ...
       and you are confident of delivering a compatible product on all.
   (d) The CCL files in C have at various stages built with essentially
       no pain on Linux (32 & 64), Windows (32. It builds on 64 but until
       there is a mingw64 the build process is a bit odd, but the result is
       OK), Solaris x86, Solaris sparc, Mac OS X, SGI, HP, a Linksys
       router, my ipaq PDA, and basically anything it is thrown at. Oh
       older Macs as well and other historic stuff. It has built with
       a range of vendor-supplied C compilers as well as gcc. Its Makefiles
       roughly just need to say "compile all the *.c files in this
       directory and link what you get", with some grungy #ifdef messing to
       provide me with portability in code to traverse directory trees etc.

(4) CCL tried tolerably hard to be safe, so it checks each CAR and CDR to 
ensure you are working on a cons object (or nil), and it polices array 
bounds etc etc. If checks that functions are called with the expected 
number of arguments. Depending on your point of view this is either jolly 
good for finding places where a typo in the non-strongly-typed Lisp was 
about to bite you, or a cause of existing Lisp code that used to just 
car/cdr through fixnums with gay abandon now fails.


There are a number of things that at a technical level may mean that CCL 
would cause some people pain:

(1) because loadable modules are within one file their date-stamps are 
something I maintain within that file, and "make" can not readily find 
them. That tends to be a slight blight if you want to use Make to 
autocompile just the modes for which source has altered. But if you want 
to do that properly you would have to get dependency tracking really 
working well and since CCL compiles things tolerably fast (because it is 
all within itself) I view a full clean rebuild from scratch as safest 
anyway, and since I do not need to repeat that on a per-platform basis I 
do not mind. OR I make my own smart-rebuild code live as Lisp code within 
the system where it obviously has easy access to all it needs. But the 
difference that this is from some other models may make it a pain to have 
build-systems for both CCL and a different Lisp?

(2) the "static optimisation" scheme is to my mind a good compromise for a 
system where you are looking at users who fetch and use it. My expectation 
would always be that open source or not MOST users of any successful 
package will be in that category. But for those involved in rapid 
development the effect is that when they change or redefine functions then 
the things they alter end up running as bytecoded (I use checksums to 
avoid messing up when a user redefines code that has been compiled into C 
in the kernel - the C code is only activated if a checksum match says it 
is the version wanted...). So over time such a user sees slowly degrading 
performance and gets uptight. And running a proper profile job to 
re-decide where hot-spots are ought to be time-consuming since it ought to 
be comprehensive.  Equally if a user runs applications that do not match 
the profile scripts at all they will hurt a bit.

(3) I do not provide amazing Lisp-level debugging tools. I duck out with 
the view that (trace '(foo)) is good, but that anybody who feels they need 
a big interactive lisp-level visualisation workbench had better go 
elsewhere. I do not know about debuggers in the Lisps currently in use, 
but Harlequin used to try harder on that front, and until Common Lisp came 
along Interlisp's DWIM was a dream for some if a nightmare for others!

(4) If somebody is doing a lot of coding at the direct Lisp level and they 
are used to exploiting all the features of Common Lisp then the fact that 
CCL has just that subset of Common capabilities that Axiom needed will 
annoy them to distaction. I of course rhink they should not be coding in 
an agressive manner at such a low level.



If I try to give a really short summary. CCL sees itself as an "OEM 
product" not as a "retail product" and thus is complementary to the other 
Lisps used by Axiom. If Axiom is mostly targetted at hackers it is 
irrelevant and should be purged from the Axiom tree. If Axiom wanted to 
stress effortless portability and a neat deliverable package it may be of 
some use to you.

\start
Date: 12 Jun 2007 13:16:39 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Spad and its object model

Gabriel Dos Reis writes:

> On Tue, 12 Jun 2007, Stephen Wilson wrote:
> 
> | > | Global change to a hash would certainly cost us in execution time.
> | > 
> | > Why does that cost more than what you have proposed so far?
> | 
> | Lookup via hash vs. direct indexing?  Over millions of iterations?  Im
> | confident the current implementation would win. 
> 
> Except that in the scheme you proposed, the result of the indexing is not
> directly the operation, but another step must be taken.

Just for the sake of completeness:

 I argued that integer indexes were one of several possible methods
available to interrorgate a domain vector.  I posited that the vast
majority of such interrorgations could be handled using integer keys,
the remainder could use alternative keys.  The cost of using
alternative keys could be made small, on par with a hash. Thus, the
ratio of lookups using alternative keys / integer keys would be small.
Performance would not be impacted, and you have all the flexibility
which you need in order to adress your issues with coherence.

\start
Date: Tue, 12 Jun 2007 12:17:01 -0500
From: Tim Daly
To: Martin Rubey
Subject: Hyperdoc

Martin,

>> This isn't a competition, at least in my mind. 

> You are quite wrong here, I think

Hmmm. Well the only hope that we would have in a competition would be
to drive a "standardization" campaign. All of the systems should
deliver the same answers to the same input (modulo syntax). This would
make systems into commodities.  Since commodity-based products are
chosen on price Axiom would have a clear advantage.

I do think that there should be standard answers that we should expect
from every system. That is the notion behind the CATS (Computer
Algebra Test Suite) idea. So far I've seen no-one who has even cared
enough about standards to bother to comment on the idea.

\start
Date: Tue, 12 Jun 2007 17:23:57 +0000
From: Vladimir Bondarenko
To: list
Subject: Re: Market share, was: Re: Hyperdoc

Hello *,

> Tim Daly writes:
>
>> Ralf, Bill,
>>
>>> Use the tools at hand and build something that can actually compete with
>>> current CAS (plural). We fight with the future and haven't even 
>>> reached the present.

>> This isn't a competition, at least in my mind.

> You are quite wrong here, I think.  Worldwide there are maybe 1000
> Mathematicians interested in writing code, I suspect less.  There
> are currently at least four competitors in the market of general
> purpose case, not counting SAGE.

> MuPAD is so similar to Axiom, that, once it is more commonly adopted, we have
> *no* chance of getting any new contributors.

You can relax.

MuPAD 4 has acquired challenging development problems.

So the time when "it is more commonly adopted" can set in never...

> In most countries, the cost of licensing MuPAD is negligible in 
> comparison with the cost of salaries.
>
> We need (good) contributors now.  I'm working quite hard on that.  But I tell
> you, if we are still less than 20 contributors end of next year, I'll 
> probably
> stop with Axiom.

This would be sad to the extreme.

On the other hand, I am almost sure that there could be possible
(not easy though) to locate some funds to continue AXIOM development.

(I mean private investors rather than organizations... but I am not
sure about if this a way AXIOM developers could consider...)

Long live AXIOM developers!
Long live AXIOM!

Vladimir Bondarenko

VM and GEMM architect Co-founder, CEO, Mathematical Director

http://www.cybertester.com/  Cyber Tester, LLC 
http://maple.bug-list.org/   Maple Bugs Encyclopaedia 
http://www.CAS-testing.org/  CAS Testing



> (I think we are currently about 10, but I didn't count.)

> Martin

\start
Date: Tue, 12 Jun 2007 20:00:46 +0200 (CEST)
From: Franz Lehner
To: Ondrej Certik
Subject: Re: src_aldor2.tgz compilation problems

Hi,

> So there seems to be missing the "obj" directory in wh-sandbox after
> compilation. What am I doing wrong?
nothing, just have a look at
http://lists.nongnu.org/archive/html/axiom-developer/2007-06/msg00192.html
except for 64 bit, you are in exactly the same situation as I was ...

\start
Date: 12 Jun 2007 20:03:42 +0200
From: Martin Rubey
To: Tim Daly
Subject: Re: Hyperdoc

Tim Daly writes:

> Martin,
> 
> >> This isn't a competition, at least in my mind. 
> 
> > You are quite wrong here, I think
> 
> Hmmm. Well the only hope that we would have in a competition would be
> to drive a "standardization" campaign. All of the systems should
> deliver the same answers to the same input (modulo syntax). This would
> make systems into commodities.  Since commodity-based products are
> chosen on price Axiom would have a clear advantage.

So, what are you going to compare the functionality of the summation algorithms
Mathematica has with? (developed at RISC)

What are you going to compare the functionality of the MuPAD expression domain
with? (developed at Paderborn)

What are you going to compare GFUN, MGFUN and all the powerful packages for
asymptotics developed for Maple with (INRIA)

This is only the combinatorics world.

The only chance axiom has is to attract new contributors, and the way to do
that is, I believe,

* to have good support given on the mailing lists

* strive for easy installation and good portability

* to have a usable online help

* write good code instead of talking about writing excellent code.

I think, the easiest way to put off people is to discuss what great things one
will do in the future.

> I do think that there should be standard answers that we should expect from
> every system. That is the notion behind the CATS (Computer Algebra Test
> Suite) idea. So far I've seen no-one who has even cared enough about
> standards to bother to comment on the idea.

Do you realize that I'm trying hard to get somebody to port AldorUnit to Axiom?
If we had this, writing tests would be fairly trivial, i.e., reduced to the
mathematics.

> > In any case, since we are probably both continuing on our own, maybe
> > you could still tell me how to get users, uses, dependents and depends.
> 
> I'll look at this. 

This would be really great.

> These cannot be derived from the databases but require a running axiom
> image. Do you happen to know where the code is that computes this
> information? I know its in there somewhere but I don't know off the top of my
> head.

No I don't.  Perhaps Waldek knows about it (I don't whether he is going to read
this thread, so it might be better to ask him directly), since he made it work
in wh-sandbox.  As you know, in gold it does still not work.

\start
Date: Tue, 12 Jun 2007 14:30:18 -0500 (CDT)
From: Gabriel Dos Reis
To: list
Subject: Merging build-improvements to trunk

  Last night I tried to do a merge of simple patches of Waldek (e.g. renaming 
of poly.ht to polys.ht) to trunk, but failed.  I must confess right
away that I do not have full access to my development environment andI was
trying all this operation remotely from a windows machine with a flaky
network connection.  I use SVK (an SVN client), which in many 
regards is higher level than bare SVN.  I did not succeet but mostly,
I believe, because I was not patient enough and because I did not have
good access to my machine.  I'll not try similar operations before
a while.  So, this is just a note that I tried something and I did not
succeed. 

  "svk merge" will not succeed because axiom.build-improvements was 
branched from something we called "silver" at the time, which no longer exists
(a long time ago), and axiom.trunk seems to come from something else
-- at least that is what I seem to have from the history, maybe I get that
part wrong.

  "svk smerge" needs a "base" to start with; I have not look a the history
to pick a sensible common base yet.

That is all.

\start
Date: 12 Jun 2007 14:04:45 -0500
From: Gabriel Dos Reis
To: Martin Rubey
Subject: re: Hyperdoc

Martin Rubey writes:

| I think, the easiest way to put off people is to discuss what great
| things one will do in the future.

Amen.

\start
Date: Tue, 12 Jun 2007 21:42:36 +0200
From: Ralf Hemmecke
To: Gabriel Dos Reis
Subject: Re: Merging build-improvements to trunk

> "svk smerge" needs a "base" to start with; I have not look a the history
> to pick a sensible common base yet.

I had once collected that data...

What do we have on Sourceforge?

trunk this was some snapshot of the axiom--main--1--patch-49 but it was 
later
brought (nearly) in sync with --patch-50.

build-improvements   branched from trunk (r30)
wh-sandbox           branched from build-improvements (r263)
gdr-sandbox          branched from build-improvements (r335)
daly                 branched from trunk (r6)

\start
Date: Tue, 12 Jun 2007 14:57:50 -0500
From: Tim Daly
To: Martin Rubey
Subject: Hyperdoc

Martin,

>> I think, the easiest way to put off people is to discuss what great
>> things one will do in the future

> Amen

ummm, ok. so you'd prefer that i spend my time being a good chap and
finding the solution to your problems rather than thinking about or
working on my futuristic ideas.

right. i'm on it. my time is yours.

\start
Date: 12 Jun 2007 23:01:00 +0200
From: Martin Rubey
To: Tim Daly
Subject: Re: Hyperdoc

Tim Daly writes:

> Martin,
> 
> >> I think, the easiest way to put off people is to discuss what great
> >> things one will do in the future
> 
> > Amen
> 
> ummm, ok. so you'd prefer that i spend my time being a good chap and
> finding the solution to your problems rather than thinking about or
> working on my futuristic ideas.
> 
> right. i'm on it. my time is yours.

maybe this hits from grep -i "dependents" is of interest:

database.boot.pamphlet:

dependentsgetUsersOfConstructor(con) ==
  stream := readLib1('USERS, 'DATABASE, 'a)
  val := rread(con, stream, nil)
  RSHUT stream
  val

getDependentsOfConstructor(con) ==
  stream := readLib1('DEPENDENTS, 'DATABASE, 'a)
  val := rread(con, stream, nil)
  RSHUT stream
  val

\start
Date: Tue, 12 Jun 2007 16:08:45 -0500
From: Tim Daly
To: Martin Rubey
Subject: Hyperdoc

If you do
  )lisp (trace |dependentsgetUsersOfConstructor|)
  )lisp (trace |getDependentsOfConstructor|)
and then do a dependents lookup that interests you 
please post a trace.

also, let me know what version of the system you're using.

\start
Date: Tue, 12 Jun 2007 23:53:23 +0200 (CEST)
From: Waldek Hebisch
To: Martin Rubey
Subject: re: Hyperdoc

Martin Rubey wrote:

> In any case, since we are probably both continuing on our own, maybe
> you could still tell me how to get users, uses, dependents and
> depends.  After all, this would have to be part of the "Crystal",
> too?

Later Martin wrote:

> getUsersOfConstructor(con) ==
>   stream := readLib1('USERS, 'DATABASE, 'a)
>   val := rread(con, stream, nil)
>   RSHUT stream
>   val

> getDependentsOfConstructor(con) ==
>   stream := readLib1('DEPENDENTS, 'DATABASE, 'a)
>   val := rread(con, stream, nil)
>   RSHUT stream
>   val

Yes, this is correct place.  In general many HyperDoc pages are
dynamically generated.  Each page has its own function responsible
for generating the page.  One way to find out which function is
responsible for given page is to eavesdrop communication between
hypertex and AXIOMsys (say using strace).  Another is just look
at code generating starting page and chase links.

Concerning pages that interests you we have:

Page                generator
Users               kcuPage
Uses                kcnPage
Dependents          kcdePage

Looking at kcuPage one sees that it calls getUsersOfConstructor.
Similarly kcnPage calls getImports.

\start
Date: Tue, 12 Jun 2007 15:06:42 -0700 (PDT)
From: Cliff Yapp
To: Ralf Hemmecke
Subject: re: Hyperdoc

> Cliff, I don't know why it is better to write everything anew in
> LISP. Use the tools at hand and build something that can actually
> compete with current CAS (plural). We fight with the future and 
> haven't even reached the present.

I'm not claiming it is better - it is simply one of my interests.  My
interest in Axiom is a program that does mathematics Right.  That
includes human readable display of said mathematics, and formatting of
mathematics - Knuth's TeX represents a high point in this art, as far
as I am aware.  Some possible applications of typesetting quality
mathematical display don't seem to be well supported by TeX in its
current form.  So, what are the algorithms, tools, etc. needed to go
from ASCII text to DVI/pdf?  How do they work, what are their
limiations, can they be expanded to support high quality 2D
mathematical input as well?  Can the flexibility of the Lisp language
lend itself to new and interesting uses of these algorithms?

It's a long term interest of mine - I have not even started looking at
cl-typesetting yet.  It doesn't have any bearing on the Axiom project
in its current form, so I'll leave it be on this list.
 
> But still, we first need something reasonably good so that Axiom
> becomes more attractive to more developers. We desparately 
> need more people.

That's true, but what is "reasonably good"?  Do we need to first
implement a language and support environment that lets people explore
the connection between CASs and formal proof software?  (In my view
this direction is one of the only opportunities to provide a
sufficiently compelling mathematical tool to prompt people to retrain
themselves, but that's just my opinion.) I assume the "standard"
definition is "compiles and runs cleanly in modern environments and
provides a reasonably functional interactive environment"?

\start
Date: Wed, 13 Jun 2007 01:19:30 +0200
From: Gregory Vanuxem
To: Waldek Hebisch
Subject: Re: Axiom under Windows

Le mardi 12 juin 2007 =E0 14:54 +0200, Waldek Hebisch a =E9crit :
> Gregory Vanuxem wrote:
> > hypertex and the libdb.text files (Gold is buggy here). I can no longer
> > use Axiom built on top of GCL because of a spurious bug in GCL
> > (conditional statements not handled) and wh-sandbox misses file related
> > functions when built on top of SBCL. Anyway when time will permit I'll
>
> Could you be more specific about file handling in Windows SBCL?  AFAIK
> makedir is problematic (but I hoped that it would work if you have mkdir
> program in correct place) also chdir does not do much (but IIRC it is
> taken verbatim from your Windows version).

No, I was speaking about SBCL wh-sandbox built on Linux, sorry I was not
clear. Your version misses writablep and consort (try to read the
fname.input file). Attached is the file that I use (I think you already
have it), it's a literal translation of the C code in
Build-improvements. This code is not satisfactory and file/directory
handling should be reworked I think. For Windows it's a real pain to
work on file or directory, as a matter of fact the code here returns
always true (readablep, writablep etc..). I quickly looked at your code
and you seem to assume a unix environment, why not using obey.bat ? That
gives you a "shell" which provides some file related functions (after
all this is Windows...).

> Do you have problems with other functions?

(Do not take me wrong, consider what I'm saying with the tonality of a
joke). Yes a lot! I would like to be able to (Windows and Linux):

  )cd Something (a namestring is missing apparently)

  )fin (a problem here, some Lisp implementations do not fall in a
read-eval-print loop when a "main" function is provided)

  )trace INT )op + )break after

  have better error message (using (format nil "%a" ...) ?)

  Suppress the warnings, particularly when you compile a Spad file
  since it's a pain to find the Spad error (even if the error is
  NoValueMode is an Unknown mode  :-)

  Some other things that I do not remember.

I know, of course, I can send some patches but actually this is really
difficult :-(


> Also, do you how to pass file names to Windows
> utilities in a way that avoid damage due to command line parsing
> -- Unix shell has more qouting rules which allow you to pass any legal
> charater as part of filename (I plan to add a simple encoder which
> quotes all characters that need quoting).  I hope that Windows has
> equivalent functionality.

No idea, I'm a Windows newbie. Via obey.bat ?

Many thanks.

Greg

PS 1: I have not tested wh-sandbox on Windows but be sure, I'll do.

PS 2: An important thing, many many thanks for the new bootstrap mode
(suppression of cached Lisp in Spad file). I added it to my tree: a real
pleasure since I have done a lot of tests : modifying core domains,
added domains to $optimizableConstructorNames etc.. That saved me a lot
of time.

--=-TME0RQM3uV6KGuWp5afs
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\start
Date: Tue, 12 Jun 2007 20:49:31 -0400
From: Bill Page
To: Waldek Hebisch
Subject: Re: Axiom under Windows

On 6/12/07, Waldek Hebisch wrote:

> ...  Also, do you how to pass file names to Windows
> utilities in a way that avoid damage due to command line parsing
> -- Unix shell has more qouting rules which allow you to pass any
> legal charater as part of filename (I plan to add a simple encoder
> which quotes all characters that need quoting).  I hope that
> Windows has equivalent functionality.
>

As far as I know there is no method in Windows that allows to pass
all legal characters via the command line. The common method to
pass command line arguments with minimal interference from the
shell is to enclose them in "quotation marks". To pass a quotation
mark itself requires double "" but quotation marks are ignored if used
as part  of a file name. The character \ (path separator) and * (wildcard)
cannot be used in a file name even when occurring between "...".
Comma , space semicolon ; and some other punctuation characters
in file names is ok if appearing between " ... ", etc. etc.

It is hard to find a good reference but easy to find complaints. :-)
Try:

http://www.microsoft.com/technet/scriptcenter/topics/winpsh/cmdline_std.mspx

\start
Date: Tue, 12 Jun 2007 20:09:31 -0500 (CDT)
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Re: Merging build-improvements to trunk

On Tue, 12 Jun 2007, Ralf Hemmecke wrote:

| > "svk smerge" needs a "base" to start with; I have not look a the history
| > to pick a sensible common base yet.
| 
| I had once collected that data...
| 
| What do we have on Sourceforge?
| 
| trunk this was some snapshot of the axiom--main--1--patch-49 but it was later
| brought (nearly) in sync with --patch-50.
| 
| build-improvements   branched from trunk (r30)
| wh-sandbox           branched from build-improvements (r263)
| gdr-sandbox          branched from build-improvements (r335)
| daly                 branched from trunk (r6)
| 
| Ralf


Ralf --

  Many thanks!

  Given Ralf's accurate historical data above, I would like to amend my
previous statements: "svk merge" will work (and does) just fine.  I was able
to "forward port" Waldek's change from revision 242 to 243 -- renaming
poly.{,p}ht to polys.{,p}ht.

\start
Date: 12 Jun 2007 21:21:55 -0500
From: Gabriel Dos Reis
To: Bill Page
Subject: Re: Axiom under Windows

Bill Page writes:

| On 6/12/07, Waldek Hebisch wrote:
| 
| > ...  Also, do you how to pass file names to Windows
| > utilities in a way that avoid damage due to command line parsing
| > -- Unix shell has more qouting rules which allow you to pass any
| > legal charater as part of filename (I plan to add a simple encoder
| > which quotes all characters that need quoting).  I hope that
| > Windows has equivalent functionality.
| >
| 
| As far as I know there is no method in Windows that allows to pass
| all legal characters via the command line. The common method to
| pass command line arguments with minimal interference from the
| shell is to enclose them in "quotation marks". To pass a quotation
| mark itself requires double "" but quotation marks are ignored if used
| as part  of a file name. The character \ (path separator) and * (wildcard)
| cannot be used in a file name even when occurring between "...".
| Comma , space semicolon ; and some other punctuation characters
| in file names is ok if appearing between " ... ", etc. etc.
| 
| It is hard to find a good reference but easy to find complaints. :-)
| Try:
| 
| http://www.microsoft.com/technet/scriptcenter/topics/winpsh/cmdline_std.mspx

Indeed.

My personal opinion is that funny characters (yes, I consider
whitespace in pathnames as funny) in pathnames are Evil.  We should
not spend too much resource trying to support Evil beyond reasonable.
People who like spaces in pathnames should just learn leaving with
that restriction in Axiom.  Given the choice between Evil and useful
functionality in Axiom, I don't hesitate one second.

\start
Date: Tue, 12 Jun 2007 22:40:10 -0400
From: Bill Page
To: Gabriel Dos Reis
Subject: Re: Axiom under Windows

On 12 Jun 2007 21:21:55 -0500, Gabriel Dos Reis wrote:
> Bill Page writes:
> ...
> My personal opinion is that funny characters (yes, I consider
> whitespace in pathnames as funny) in pathnames are Evil.  We
> should not spend too much resource trying to support Evil beyond
> reasonable. People who like spaces in pathnames should just learn
> leaving with that restriction in Axiom.  Given the choice between
> Evil and useful functionality in Axiom, I don't hesitate one second.
>

Get real Gaby! Even Linux supports file names with embedded spaces.
It's old hacks like you who refuse to write proper shell scripts that keep
us all living in the dark ages ... Before you know it you will be arguing
(like Tim Daly) that no one really needs lower case characters. ;-) ;-)
While the rest of the World is working madly for full multilingual unicode
support.

Really, on Windows it is impossible to avoid dealing with paths that
contain spaces since the standard locations for files are things like
"Documents and Settings", "Program Files" and "My Documents".

\start
Date: Wed, 13 Jun 2007 04:48:34 +0200 (CEST)
From: Waldek Hebisch
To: Gabriel Dos Reis
Subject: Re: Axiom under Windows

> Bill Page writes:
> 
> | On 6/12/07, Waldek Hebisch wrote:
> | 
> | > ...  Also, do you how to pass file names to Windows
> | > utilities in a way that avoid damage due to command line parsing
> | > -- Unix shell has more qouting rules which allow you to pass any
> | > legal charater as part of filename (I plan to add a simple encoder
> | > which quotes all characters that need quoting).  I hope that
> | > Windows has equivalent functionality.
> | >
> | 
> | As far as I know there is no method in Windows that allows to pass
> | all legal characters via the command line. The common method to
> | pass command line arguments with minimal interference from the
> | shell is to enclose them in "quotation marks". To pass a quotation
> | mark itself requires double "" but quotation marks are ignored if used
> | as part  of a file name. The character \ (path separator) and * (wildcard)
> | cannot be used in a file name even when occurring between "...".
> | Comma , space semicolon ; and some other punctuation characters
> | in file names is ok if appearing between " ... ", etc. etc.
> | 
> | It is hard to find a good reference but easy to find complaints. :-)
> | Try:
> | 
> | http://www.microsoft.com/technet/scriptcenter/topics/winpsh/cmdline_std.mspx
> 
> Indeed.
> 
> My personal opinion is that funny characters (yes, I consider
> whitespace in pathnames as funny) in pathnames are Evil.  We should
> not spend too much resource trying to support Evil beyond reasonable.
> People who like spaces in pathnames should just learn leaving with
> that restriction in Axiom.  Given the choice between Evil and useful
> functionality in Axiom, I don't hesitate one second.
> 

I think that using funny characters in pathnames is stupid.  But
programs that mishandle such names are clearly broken.

\start
Date: 13 Jun 2007 00:04:10 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Merging build-improvements to trunk

Gaby,

I am curious about this change to truck.

This is the SVN copy of Silver, no?.  I was under the impression that
Tim would approve such changes.  Am I mistaken?

Moreover, Silver lives in SVN and Git.  Where is the corresponding
push to Git?

\start
Date: 13 Jun 2007 06:35:23 +0200
From: Martin Rubey
To: Waldek Hebisch
Subject: re: Hyperdoc

Waldek Hebisch writes:

> > getUsersOfConstructor(con) ==
> >   stream := readLib1('USERS, 'DATABASE, 'a)
> >   val := rread(con, stream, nil)
> >   RSHUT stream
> >   val
> 
> > getDependentsOfConstructor(con) ==
> >   stream := readLib1('DEPENDENTS, 'DATABASE, 'a)
> >   val := rread(con, stream, nil)
> >   RSHUT stream
> >   val
> 
> Yes, this is correct place.  

Waldek, in case you know, could you just provide an example call from within
the Axiom interpreter?  I tried

getDependentsOfConstructor(Integer)$Lisp

but only nil was returned.

Many many thanks for the debugging trick below!

Martin

> In general many HyperDoc pages are
> dynamically generated.  Each page has its own function responsible
> for generating the page.  One way to find out which function is
> responsible for given page is to eavesdrop communication between
> hypertex and AXIOMsys (say using strace).  Another is just look
> at code generating starting page and chase links.
> 
> Concerning pages that interests you we have:
> 
> Page                generator
> Users               kcuPage
> Uses                kcnPage
> Dependents          kcdePage
> 
> Looking at kcuPage one sees that it calls getUsersOfConstructor.
> Similarly kcnPage calls getImports.

\start
Date: Wed, 13 Jun 2007 00:44:37 -0500 (CDT)
From: Gabriel Dos Reis
To: Bill Page
Subject: Re: Axiom under Windows

On Tue, 12 Jun 2007, Bill Page wrote:

| Get real Gaby!

There is nothing unreal in what I stated.  
Please contribute working codes if you believe you have time to argue for its
support.   

| Really, on Windows it is impossible to avoid dealing with paths that
| contain spaces since the standard locations for files are things like
| "Documents and Settings", "Program Files" and "My Documents".

You can put your files in different place.  GHC installs in c:/GHC.

\start
Date: Wed, 13 Jun 2007 00:46:42 -0500 (CDT)
From: Gabriel Dos Reis
To: Waldek Hebisch
Subject: Re: Axiom under Windows

On Wed, 13 Jun 2007, Waldek Hebisch wrote:

| I think that using funny characters in pathnames is stupid.  But
| programs that mishandle such names are clearly broken.

While I'll not recommend to do anything active to unsupport funny characters,
I'll clearly NOT spend excessive amount of resource getting it work.
Those who believe the darly need them should contribute working codes.

\start
Date: Wed, 13 Jun 2007 00:53:21 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Merging build-improvements to trunk

On Tue, 13 Jun 2007, Stephen Wilson wrote:

| Gaby,
| 
| I am curious about this change to truck.

It is a change everybody discusses here a long time ago and agrees that
it is what we have to do.  If you believe people spend resource making stupid
pathnames work, then you should logically approve the idea of supporting check
out of Axiom source code on brain damaged file systems that are care
preserving but case insensitive.  
The change in question disambiguate between poly.ht and Poly.ht.  Tim has
already incorporate similar changes.  

The patch in question is already in the repository.  It consists in
renaming a file.  

\start
Date: Wed, 13 Jun 2007 04:19:42 -0400
From: Bill Page
To: Gabriel Dos Reis
Subject: Re: Axiom under Windows

On 6/13/07, Gabriel Dos Reis wrote:
> On Tue, 12 Jun 2007, Bill Page wrote:
>
> | Get real Gaby!
>
> There is nothing unreal in what I stated.
> Please contribute working codes if you believe you have
> time to argue for its support.

??? The current versions of GCL and Axiom on Windows already
supports this. Could you give an example where the use of spaces
in file names causes problems?

>
> | Really, on Windows it is impossible to avoid dealing with paths that
> | contain spaces since the standard locations for files are things like
> | "Documents and Settings", "Program Files" and "My Documents".
>
> You can put your files in different place.  GHC installs in c:/GHC.
>

Why? That is like telling a Windows user that they should not store
files in their HOME directory.  It does not make sense to design a
system that only works if you put your files in a non-standard place.
This applies equally to Linux and Windows. What do you think is
so hard about writing software that conforms fully to the file name
conventions of these systems?

\start
Date: Wed, 13 Jun 2007 18:54:04 +1000
From: Alasdair McAndrew
To: list
Subject: Re: Axiom under Windows

I must say that window's handling of file names is pretty strange.  I run a
subject which uses Matlab, in which the students have to use the "path"
command to extend the path to inlcude a directory which holds some files
specific to the subject.  Windows sometimes likes the drive and file names
in lower case; sometimes in upper; sometimes in a mixture.  We can never
tell...

I do think that file and directory names should follow the alphanumeric
convention of program variables, and not include white spaces or strange
characters.  But then, I'm old fashioned.

-Alasdair

On 6/13/07, Bill Page wrote:
>
> On 6/13/07, Gabriel Dos Reis wrote:
> > On Tue, 12 Jun 2007, Bill Page wrote:
> >
> > | Get real Gaby!
> >
> > There is nothing unreal in what I stated.
> > Please contribute working codes if you believe you have
> > time to argue for its support.
>
> ??? The current versions of GCL and Axiom on Windows already
> supports this. Could you give an example where the use of spaces
> in file names causes problems?
>
> >
> > | Really, on Windows it is impossible to avoid dealing with paths that
> > | contain spaces since the standard locations for files are things like
> > | "Documents and Settings", "Program Files" and "My Documents".
> >
> > You can put your files in different place.  GHC installs in c:/GHC.
> >
>
> Why? That is like telling a Windows user that they should not store
> files in their HOME directory.  It does not make sense to design a
> system that only works if you put your files in a non-standard place.
> This applies equally to Linux and Windows. What do you think is
> so hard about writing software that conforms fully to the file name
> conventions of these systems?

\start
Date: Wed, 13 Jun 2007 11:51:12 +0200
From: Ondrej Certik
To: Franz Lehner
Subject: Re: src_aldor2.tgz compilation problems

> nothing, just have a look at
> http://lists.nongnu.org/archive/html/axiom-developer/2007-06/msg00192.html
> except for 64 bit, you are in exactly the same situation as I was ...

Thanks very much, that helped a lot. Here are the steps, that worked
for me, but still I get some error at the end (I looked into the
axiom-dev archives, but didn't find a way how to fix it):

svn co https://axiom.svn.sourceforge.net/svnroot/axiom/branches/wh-sandbox
cd wh-sandbox
svn co
https://axiom.svn.sourceforge.net/svnroot/axiom/branches/build-improvements/gcl
gcl
cd zips
wget
https://axiom.svn.sourceforge.net/svnroot/axiom/trunk/axiom/zips/noweb-2.10a.tgz

cd ../..
mkdir ax-build
cd ax-build
../wh-sandbox/configure
make

#get some coffee
#the build took 12 hours on AMD Athlon(tm) 64 Processor 3000+
#3 hours on intel core duo


#Aldor
export AXIOM=$WHEREVERYOUARE/ax-build/target/i686-pc-linux
export ALDORROOT=<ALDOR-directory>/linux/1.0.2


(cd $AXIOM/bin; ln -s ../../../build/scripts/document .)
mkdir -p obj/i686-pc-linux
cd obj/i686-pc-linux
ln -s ../../build/i686-pc-linux/bin .
ln -s ../../src/interp/ .
cd ../..

cd src
#for axiom.sty
ln -s ../../wh-sandbox/src/scripts/ .


tar xzf ../../src_aldor2.tgz
cd aldor
ln -s ../../build/i686-pc-linux .


#extract the Makefiles
for pp in *.pamphlet; do document $pp;done


make
#after error
touch ../../int/aldor/dep_spad.stamp
document Make.functions.pamphlet
make
#crossed my fingers and got:

ondra@syslik:~/ext/ax-build/src/aldor$ make
Building libaxiom.al and associated files
/home/ondra/ext/ax-build/int/aldor
make[1]: Entering directory `/home/ondra/ext/ax-build/src/aldor'
/home/ondra/ext/ax-build/src/aldor/types.mk:156:
/home/ondra/ext/ax-build/int/aldor/saxiom/spadset.mk
/home/ondra/ext/ax-build/src/aldor/Make.rules:179: ALL SPADSETS  sax0 saxiom
/home/ondra/ext/ax-build/src/aldor/Make.rules:200: (0,0)
/home/ondra/ext/ax-build/src/aldor/Make.rules:200: (1,1)
/home/ondra/ext/ax-build/src/aldor/Make.rules:106: W: 1 I: 1
/home/ondra/ext/ax-build/src/aldor/Make.rules:107: W:
/home/ondra/ext/ax-build/int/aldor/sax0/spadset.mk
cp /home/ondra/ext/ax-build/src/aldor/as/attrib.as.head
/home/ondra/ext/ax-build/int/aldor/as/attrib.as
Please add new attributes to /attrib.as.head
make[1]: *** [/home/ondra/ext/ax-build/int/aldor/as/attrib.as] Error 1
make[1]: *** Deleting file `/home/ondra/ext/ax-build/int/aldor/as/attrib.as'
make[1]: Leaving directory `/home/ondra/ext/ax-build/src/aldor'
make: *** [all] Error 2

\start
Date: Wed, 13 Jun 2007 06:10:58 -0400
From: Bill Page
To: Alasdair McAndrew
Subject: Re: Axiom under Windows

On 6/13/07, Alasdair McAndrew wrote:
> ...
> I do think that file and directory names should follow the alphanumeric
> convention of program variables, and not include white spaces or strange
> characters.  But then, I'm old fashioned.
>

Well, instead of just annoying Gaby by suggesting that coding styles
that do not conform to the file name conventions of the operating
system are simply deficient, I should admit that it does make sense
to me to restrict the allowed filenames when portability is the main
issue. For example the POSIX standard does make such a restriction:

http://www.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap03.html#tag_03_276

But the point is that one should not implement software that assumes
this restriction. I think Waldek said it best: "programs that mishandle
such names [with funny characters] are clearly broken".

\start
Date: Wed, 13 Jun 2007 13:46:51 +0200 (CEST)
From: Waldek Hebisch
To: Martin Rubey
Subject: re: Hyperdoc

Martin Rubey rote:
> 
> Waldek, in case you know, could you just provide an example call from within
> the Axiom interpreter?  I tried
> 
> getDependentsOfConstructor(Integer)$Lisp
> 
> but only nil was returned.
> 

>From interpreter you may use:

)lisp (|getDependentsOfConstructor| '|Integer|)

The argument is an unevaluated (because of quote) symbol.  If you want to
call it from Spad you need to use something like:

(getDependentsOfConstructor$Lisp)((INTERN$Lisp)("Integer"))

or maybe use FIND_-SYMBOL insted of INTERN.  I do not know if there
is easier method to pass Lisp symbol from Spad to Lisp function.

\start
Date: 13 Jun 2007 08:45:24 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Merging build-improvements to trunk

Gabriel Dos Reis writes:

> On Tue, 13 Jun 2007, Stephen Wilson wrote:
> 
> | Gaby,
> | 
> | I am curious about this change to truck.
> 
> It is a change everybody discusses here a long time ago and agrees that
> it is what we have to do.  If you believe people spend resource making stupid
> pathnames work, then you should logically approve the idea of supporting check
> out of Axiom source code on brain damaged file systems that are care
> preserving but case insensitive.  
> The change in question disambiguate between poly.ht and Poly.ht.  Tim has
> already incorporate similar changes.  
> 
> The patch in question is already in the repository.  It consists in
> renaming a file.  

I did not ask if the patch was worth commiting.  Its trivial, I have
no objection.

My question was with regards to the commit process.

\start
Date: Wed, 13 Jun 2007 10:19:30 -0400
From: Bill Page
To: Waldek Hebisch
Subject: re: Hyperdoc

On 6/13/07, Waldek Hebisch wrote:
> Martin Rubey rote:
>
> > Waldek, in case you know, could you just provide an example call from
> > within the Axiom interpreter?  I tried
> >
> > getDependentsOfConstructor(Integer)$Lisp
> >
> > but only nil was returned.
> >
>
> >From interpreter you may use:
>
> )lisp (|getDependentsOfConstructor| '|Integer|)
>
> The argument is an unevaluated (because of quote) symbol.  If you want to
> call it from Spad you need to use something like:
>
> (getDependentsOfConstructor$Lisp)((INTERN$Lisp)("Integer"))
>
> or maybe use FIND_-SYMBOL insted of INTERN.  I do not know if there
> is easier method to pass Lisp symbol from Spad to Lisp function.
>

Excellent!

Depending on what you know about an object you might
also prefer to use devaluate to get the symbol for example:

(1) -> parentsOf(CAR(devaluate(Integer)$Lisp)$Lisp)$Lisp

   (1)
   (((IntegerNumberSystem) . T) ((ConvertibleTo (String)) . T) ((OpenMath) . T))
                                                   Type: SExpression

Note that on Axiom for Windows 0.1.4 I get the following error:

(2) ->  )lisp (|getDependentsOfConstructor| '|Integer|)

   >> System error:
   Caught fatal error [memory may be damaged]

but I think that may be corrected in wh-sandbox compiled for Windows.
I will test that later.

\start
Date: 13 Jun 2007 12:42:28 -0400
From: Stephen Wilson
To: list
Subject: Re: Merging build-improvements to trunk
Cc: Gabriel Dos Reis

Stephen Wilson writes:
[...]
> I did not ask if the patch was worth commiting.  Its trivial, I have
> no objection.

Actually, now that I gave this a breif thought, I do have an objection
to this patch.

Changes to Silver should be in the form of a changeset.  They should
always represent a good-faith attempt at solving a particular bug or
add a particular feature -- in short, represent a concept has a whole.

My understanding of case-insensitive/case-preserving file-systems
tells me that there are other files in Silver which would cause
conflicts.  I know of, (not including the poly conflict):

   src/doc/ps : SEGBIND.ps <--> segbind.ps
   src/hyper/bitmaps : ATX=B.bitmap <--> aTx=b.bitmap

I did not do an exhustive search, so there may still be others.

Changing just poly.ht and poly.pht does not solve the problem.

I would like to _strongly_ petition commiters to Silver to attempt
commits which respect the notion of a changeset.

\start
Date: Wed, 13 Jun 2007 17:28:49 -0500
From: Tim Daly
To: Stephen Wilson, Gabriel Dos Reis
Subject: Merging build-improvements to trunk

The change to poly.ht and poly.pht are part of a global change
I am making to fix bug #353. I'm in the process of downcasing all
filenames. This will be released as a single changeset as soon as
it is complete. It is fairly complex as downcasing #include filenames
means that all references need to be changed. So far this has 
involved 513 individual changes.

I have made a commitment to keep the git and SVN versions in sync
so I'll have to backport Gaby's change. Unfortunately this will 
collide with the #353 bug fix.

\start
Date: Wed, 13 Jun 2007 18:38:48 -0400
From: Bill Page
To: Waldek Hebisch
Subject: re: Hyperdoc

On 6/13/07, Waldek Hebisch wrote:
> Martin Rubey wrote:
> >
> > Waldek, in case you know, could you just provide an example call
> > from within the Axiom interpreter?  I tried
> >
> > getDependentsOfConstructor(Integer)$Lisp
> >
> > but only nil was returned.
> >
>
> >From interpreter you may use:
>
> )lisp (|getDependentsOfConstructor| '|Integer|)
>
> The argument is an unevaluated (because of quote) symbol.  If you
> want to call it from Spad you need to use something like:
>
> (getDependentsOfConstructor$Lisp)((INTERN$Lisp)("Integer"))
>
> or maybe use FIND_-SYMBOL insted of INTERN.  I do not know if
> there is easier method to pass Lisp symbol from Spad to Lisp
> function.
>

Martin,

Perhaps the ultimate example of what you want (except
nicely formated HTML output) is 'displayDatabase' defined in
/src/interp/as.boot.pamphlet.

For example:

(1) -> displayDatabase(INTERN("Integer")$Lisp)$Lisp

----------------- CONSTRUCTORFORM --------------------
(|Integer|)
----------------- CONSTRUCTORKIND --------------------
|domain|
----------------- CONSTRUCTORMODEMAP --------------------
(((|Integer|)
  (|Join| (|IntegerNumberSystem|) (|ConvertibleTo| (|String|))
          (|OpenMath|)
          (CATEGORY |domain| (SIGNATURE |random| ($ $))
              (ATTRIBUTE |canonical|) (ATTRIBUTE |canonicalsClosed|)
              (ATTRIBUTE |noetherian|) (ATTRIBUTE |infinite|))))
 (T |Integer|))
----------------- ABBREVIATION --------------------
INT
----------------- CONSTRUCTORCATEGORY --------------------
(|Join| (|IntegerNumberSystem|) (|ConvertibleTo| (|String|))
        (|OpenMath|)
        (CATEGORY |domain| (SIGNATURE |random| ($ $))
            (ATTRIBUTE |canonical|) (ATTRIBUTE |canonicalsClosed|)
            (ATTRIBUTE |noetherian|) (ATTRIBUTE |infinite|)))
----------------- PARENTS --------------------
NIL

\start
Date: Thu, 14 Jun 2007 16:55:29 +0200 (CEST)
From: Waldek Hebisch
To: list
Subject: Algebra speedups

Below you will find a patch (applied to wh-sandbox 603) which
significantly reduces time to run the testsuite (on my machine
from 20 minutes down to 12 minutes).

Some remarks:
- the patch somewhat reduces abstraction (for example uses Lisp
  EQ to quickly confirm equality).  IMHO this is necessary
  (and in case of this patch moderate) price for speed.
- surprisingly, manipulations on operators and kernels take a lot
  of time, one could get more speed replacing linear search in
  SortedCache by smarter method (say binary search) but that would
  require changing data structures.  Also, a lot of time is spent
  searching for weight property -- this raises the question if
  we should have a weight field in the operator representation
  (currently accessing weight requires searching list of
  operator properties).
- this speedup is mainly fruit of sbcl port.  More precisely,
  the hot spots were identified using sbcl profiler.

I belive that there are many other places in Axiom where one
can easily gain significant speedups.  If you want to try compile
sbcl based Axiom.  After starting Axiom do:

)lisp (require :sb-sprof)

)lisp (sb-sprof:start-profiling)

Your computation

)lisp (sb-sprof:stop-profiling)

)lisp (sb-sprof:report)

Notes:  the report is typically rather long, so use something like
script program to capture it.  Also, computation between 5-50 
seconds give best results (shorter are less accurate, longer may
overflow memory when generationg report).

And now the patch:

diff -ru por/wh-20070530/src/algebra/elemntry.spad.pamphlet wh-20070530/src/algebra/elemntry.spad.pamphlet
--- por/wh-20070530/src/algebra/elemntry.spad.pamphlet	Fri Jun  1 21:17:44 2007
+++ wh-20070530/src/algebra/elemntry.spad.pamphlet	Sun Jun 10 03:34:26 2007
@@ -623,18 +623,29 @@
       zero? x => 1
       is?(x, oplog) => first argument kernel x
       x < 0 and empty? variables x => inv iexp(-x)
-      h  := inv(2::F)
-      i  := iisqrt1()
-      s2 := h * iisqrt2()
-      s3 := h * iisqrt3()
-      u  := specialTrigs(x / i, [[1,false],[-1,false], [i,false], [-i,false],
-            [h + i * s3,false], [-h + i * s3, false], [-h - i * s3, false],
-             [h - i * s3, false], [s2 + i * s2, false], [-s2 + i * s2, false],
-              [-s2 - i * s2, false], [s2 - i * s2, false], [s3 + i * h, false],
-               [-s3 + i * h, false], [-s3 - i * h, false], [s3 - i * h, false]])
-      u case F => u :: F
+      R has RetractableTo Z =>
+        i  := iisqrt1()
+        xi := x / i
+        y := xi / pi()
+        -- this test saves us a lot of effort in the common case
+        -- when no trigonometic simplifiaction is possible
+        retractIfCan(y)@Union(Fraction Z, "failed") case "failed" =>
+          kernel(opexp, x)
+        h  := inv(2::F)
+        s2 := h * iisqrt2()
+        s3 := h * iisqrt3()
+        u  := specialTrigs(xi, [[1,false],[-1,false], [i,false],
+                 [-i,false], [h + i * s3,false], [-h + i * s3, false],
+                 [-h - i * s3, false], [h - i * s3, false],
+                 [s2 + i * s2, false], [-s2 + i * s2, false],
+                 [-s2 - i * s2, false], [s2 - i * s2, false],
+                 [s3 + i * h, false], [-s3 + i * h, false],
+                 [-s3 - i * h, false], [s3 - i * h, false]])
+        u case F => u :: F
+        kernel(opexp, x)
       kernel(opexp, x)
 
+
 -- THIS DETERMINES WHEN TO PERFORM THE log exp f -> f SIMPLIFICATION
 -- CURRENT BEHAVIOR:
 --     IF R IS COMPLEX(S) THEN ONLY ELEMENTS WHICH ARE RETRACTABLE TO R
diff -ru por/wh-20070530/src/algebra/float.spad.pamphlet wh-20070530/src/algebra/float.spad.pamphlet
--- por/wh-20070530/src/algebra/float.spad.pamphlet	Fri Jun  1 21:17:44 2007
+++ wh-20070530/src/algebra/float.spad.pamphlet	Sun Jun 10 03:37:25 2007
@@ -636,6 +636,8 @@
    shift(x:%,n:I) == [x.mantissa,x.exponent+n]
 
    x = y ==
+      x.exponent = y.exponent =>
+          x.mantissa = y.mantissa
       order x = order y and sign x = sign y and zero? (x - y)
    x < y ==
       y.mantissa = 0 => x.mantissa < 0
diff -ru por/wh-20070530/src/algebra/gdpoly.spad.pamphlet wh-20070530/src/algebra/gdpoly.spad.pamphlet
--- por/wh-20070530/src/algebra/gdpoly.spad.pamphlet	Fri Jun  1 21:17:44 2007
+++ wh-20070530/src/algebra/gdpoly.spad.pamphlet	Sun Jun 10 03:38:56 2007
@@ -87,7 +87,18 @@
         ground?(p) => leadingCoefficient p
         "failed"
 
-      degree(p: %,v: OV) == degree(univariate(p,v))
+      degree(p: %,v: OV) ==
+         -- degree(univariate(p,v))
+         zero?(p) => 0
+         res : NonNegativeInteger := 0
+         locv := lookup v
+         while not empty? p repeat
+             t := first p
+             j := t.k.locv
+             if j > res then res := j
+             p := rest p
+         res
+
       minimumDegree(p: %,v: OV) == minimumDegree(univariate(p,v))
       differentiate(p: %,v: OV) ==
             multivariate(differentiate(univariate(p,v)),v)
diff -ru por/wh-20070530/src/algebra/op.spad.pamphlet wh-20070530/src/algebra/op.spad.pamphlet
--- por/wh-20070530/src/algebra/op.spad.pamphlet	Fri Jun  1 21:17:44 2007
+++ wh-20070530/src/algebra/op.spad.pamphlet	Sat Jun  9 19:53:20 2007
@@ -156,6 +156,7 @@
 -- property EQUAL? contains a function f: (BOP, BOP) -> Boolean
 -- such that f(o1, o2) is true iff o1 = o2
     op1 = op2 ==
+      (EQ$Lisp)(op1, op2) => true
       name(op1) ^= name(op2) => false
       op1.narg ^= op2.narg => false
       brace(keys properties op1)^=$Set(String) brace(keys properties op2) => false
diff -ru por/wh-20070530/src/algebra/vector.spad.pamphlet wh-20070530/src/algebra/vector.spad.pamphlet
--- por/wh-20070530/src/algebra/vector.spad.pamphlet	Fri Jun  1 21:17:44 2007
+++ wh-20070530/src/algebra/vector.spad.pamphlet	Sun Jun 10 03:40:22 2007
@@ -344,7 +344,11 @@
         same?: % -> Boolean
         same? z == every?(#1 = z(minIndex z), z)
  
-        x = y == _and/[qelt(x,i)$Rep = qelt(y,i)$Rep for i in 1..dim]
+        x = y ==
+          for i in 1..dim repeat
+            ^(qelt(x,i)$Rep = qelt(y,i)$Rep) => return false
+          true
+          -- _and/[qelt(x,i)$Rep = qelt(y,i)$Rep for i in 1..dim]
  
         retract(z:%):R ==
           same? z => z(minIndex z)

\start
Date: Thu, 14 Jun 2007 11:04:17 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Merging build-improvements to trunk

On Wed, 13 Jun 2007, Stephen Wilson wrote:

| Gabriel Dos Reis writes:
| 
| > On Tue, 13 Jun 2007, Stephen Wilson wrote:
| > 
| > | Gaby,
| > | 
| > | I am curious about this change to truck.

| > It is a change everybody discusses here a long time ago and agrees
| > that it is what we have to do.  If you believe people spend
| > resource making stupid pathnames work, then you should logically
| > approve the idea of supporting check out of Axiom source code on
| > brain damaged file systems that are care preserving but case
| > insensitive.  The change in question disambiguate between poly.ht
| > and Poly.ht.  Tim has already incorporate similar changes.

| > The patch in question is already in the repository.  It consists in
| > renaming a file.  
| 
| I did not ask if the patch was worth commiting.  Its trivial, I have
| no objection.

As I said, the patch is already in the archive.  

BTW, I don't have a working git tool on windows.

\start
Date: Thu, 14 Jun 2007 11:12:59 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Merging build-improvements to trunk

On Wed, 13 Jun 2007, Stephen Wilson wrote:

| Stephen Wilson writes:
| [...]
| > I did not ask if the patch was worth commiting.  Its trivial, I have
| > no objection.
| 
| Actually, now that I gave this a breif thought, I do have an objection
| to this patch.

I'm very happy to revert this patch and let people with more time and
interest to make it happen.

[...]

| My understanding of case-insensitive/case-preserving file-systems
| tells me that there are other files in Silver which would cause
| conflicts. 

In fact, there were many.  Tim partially picked the patches; I was just
attempting to complete what he did.  But, I'm very happy to let people with
more resources to do it -- I'll revert my commit in a moment.  It does not
seem that I critically depend on it -- I can build wh-sandbox and
build-improvements. 

\start
Date: Thu, 14 Jun 2007 11:24:25 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: Re: Merging build-improvements to trunk

On Wed, 13 Jun 2007, Tim Daly wrote:

| The change to poly.ht and poly.pht are part of a global change
| I am making to fix bug #353. I'm in the process of downcasing all
| filenames. This will be released as a single changeset as soon as
| it is complete. It is fairly complex as downcasing #include filenames
| means that all references need to be changed. So far this has 
| involved 513 individual changes.
| 
| I have made a commitment to keep the git and SVN versions in sync
| so I'll have to backport Gaby's change. Unfortunately this will 
| collide with the #353 bug fix.

I just arrived at my final destination, travelling all day yesterday, so I did
not have access to network.  I'm a bit jet lagged, but as soon as I recover a
bit of my brain I'll revert my commit in case you have not committed already. 

\start
Date: Thu, 14 Jun 2007 11:52:51 -0500 (CDT)
From: Gabriel Dos Reis
To: Bill Page
Subject: Re: Axiom under Windows

On Wed, 13 Jun 2007, Bill Page wrote:

| On 6/13/07, Gabriel Dos Reis wrote:
| > On Tue, 12 Jun 2007, Bill Page wrote:
| >
| > | Get real Gaby!
| >
| > There is nothing unreal in what I stated.
| > Please contribute working codes if you believe you have
| > time to argue for its support.
| 
| ??? The current versions of GCL and Axiom on Windows already
| supports this. 

If you have a version of Axiom that works fine with that, great!
I just know that on mingw/msys, I do have troubles with filnames with 
embedded spaces.  Mingw/msys FAQ says I should use different naming scheme.

[...]

| > | Really, on Windows it is impossible to avoid dealing with paths that
| > | contain spaces since the standard locations for files are things like
| > | "Documents and Settings", "Program Files" and "My Documents".
| >
| > You can put your files in different place.  GHC installs in c:/GHC.
| >
| 
| Why? That is like telling a Windows user that they should not store
| files in their HOME directory.

Proof by analogy is fraud.

"My Document" isn't anolog to HOME.


And personally, I never found "My Documents" descriptive enough to 
put anything there.  But, again, I'll not stand in the way of people with
resources to solve that problem if they believe it is the most important thing
they need.  It isn't for me.  And if given a choice I would prefer to have
Waldek's fixes than wasting his resources to solve a non-problem.

I guess, I'm the only one to care about "priority given limited resources", 
"good enough" and "incremental improvements".  This is my last word on the
subject. 

\start
Date: Thu, 14 Jun 2007 18:12:30 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: Re: Merging build-improvements to trunk

On Thu, 14 Jun 2007, Gabriel Dos Reis wrote:

| I just arrived at my final destination, travelling all day yesterday, so I did
| not have access to network.  I'm a bit jet lagged, but as soon as I recover a
| bit of my brain I'll revert my commit in case you have not committed already. 
Done.

\start
Date: 15 Jun 2007 07:49:11 +0200
From: Martin Rubey
To: Bill Page
Subject: Re: [Axiom-mail] A slow summation

Bill Page writes:

> > reduce(+,[1.0/i for i in 1..20000])
> >
> > This works, but is (I think) unreasonably slow; it takes over 21 seconds on
> > my computer.  The equivalent command in Maxima takes less than 1 second.

Bill, could you file that as a bug on MathAction, please.

(If you have an sbcl compiled axiom available, you could check whether it is
gcl's fault, or rather a bug in axiom.)

\start
Date: 15 Jun 2007 07:57:45 +0200
From: Martin Rubey
To: Bill Page
Subject: re: Hyperdoc
Cc: Camm Maguire

Dear Bill, et al.,

> Perhaps the ultimate example of what you want (except
> nicely formated HTML output) is 'displayDatabase' defined in
> /src/interp/as.boot.pamphlet.

Many thanks for the hint.  I guess I have now everthing together, save some
html knowledge and, most importantly, sockets on windows!

For some reason I believed that the "webserver" would run on windows, but
apparently, this is not the case.  Is there a chance to have something similar
on windows?  Or would that, in fact, mean that we could run the old hyperdoc on
windows, too?  Sorry that I'm so ignorant about these things.

Maybe some other lisp that can compile axiom on windows has some possibility to
communicate with a browser?

\start
Date: Fri, 15 Jun 2007 02:25:38 -0400
From: Bill Page
To: Martin Rubey
Subject: re: Hyperdoc
Cc: Camm Maguire

On 15 Jun 2007 07:57:45 +0200, Martin Rubey wrote:
>
> > Perhaps the ultimate example of what you want (except
> > nicely formated HTML output) is 'displayDatabase' defined in
> > /src/interp/as.boot.pamphlet.
>
> Many thanks for the hint.  I guess I have now everthing together, save
> some html knowledge

HTML is very simple, I am sure you kind find someone near by to help
you.

> and, most importantly, sockets on windows!

??? There is support for sockets on Windows in GCL and this works
for axiom-0.1.4 on Windows.

>
> For some reason I believed that the "webserver" would run on
> windows, but apparently, this is not the case.

Why do you say that? I also believe that it should run on windows.

> Is there a chance to have something similar on windows?

When I first did the tests for running the basic "little webserver
in Lisp" I was running it all in Axiom on Windows.

> Or would that, in fact, mean that we could run the old hyperdoc
> on windows, too?  Sorry that I'm so ignorant about these things.

No, that is a completely different issue - a problem with not having
any support for X-windows plus a few other details like pty etc.

>
> Maybe some other lisp that can compile axiom on windows has
> some possibility to communicate with a browser?
>

GCL on windows should work fine.

I suppose now you are going to ask me to spend my time to
prove it. I have been trying just to be helpful without having to get
directly involved... I was sure hoping that someone else would do
this work. -:(

BTW, how is the Axiom Workshop going?

\start
Date: 15 Jun 2007 08:35:48 +0200
From: Martin Rubey
To: Bill Page
Subject: re: Hyperdoc
Cc: Camm Maguire

Bill Page writes:

> > and, most importantly, sockets on windows!
> 
> ??? There is support for sockets on Windows in GCL and this works
> for axiom-0.1.4 on Windows.

In fact, that's good news.

But, why couldn't anybody run my code on windows so far?  See for example
William Sit's attempts.

\start
Date: Fri, 15 Jun 2007 02:40:47 -0400
From: Bill Page
To: Martin Rubey
Subject: Re: [Axiom-mail] A slow summation

On 15 Jun 2007 07:49:11 +0200, Martin Rubey wrote:
>
> > > reduce(+,[1.0/i for i in 1..20000])

> > > This works, but is (I think) unreasonably slow; it takes over 21
> > > seconds on my computer.  The equivalent command in Maxima takes
> > > less than 1 second.

> Bill, could you file that as a bug on MathAction, please.

Well, I would rather that somebody new do that. Alasdair? :-)

The "issue" (I am not quite sure to call it a "bug") is probably some
very inefficient implementation of list comprehension in the Axiom
interpreter. E.g.

(1) -> )set message time on
(1) -> [i for i in 1..20000];

                                               Type: List PositiveInteger
      Time: 14.73 (EV) + 0.02 (OT) + 0.05 (GC) = 14.80 sec

(2) -> expand(1..20000);

                                                           Type: List Integer
                             Time: 0.07 (IN) + 0.18 (OT) = 0.25 sec

-------

Both (1) and (2) do essentially the same thing.

>
> (If you have an sbcl compiled axiom available, you could check
> whether it is gcl's fault, or rather a bug in axiom.)
>

I am quite sure that this is not a lisp implementation issue,
but no I don't have a sbcl version of Axiom available. Do you?
Still, maybe this is a job for someone who knows how to use
the sbcl profiler to find out where the Axiom interpreter is
spending all it's time - Waldek?

\start
Date: Fri, 15 Jun 2007 02:50:32 -0400
From: Alfredo Portes
To: Martin Rubey
Subject: re: Hyperdoc

Hi Martin,

> But, why couldn't anybody run my code on windows so far?  See for example
> William Sit's attempts.

But I think you pointed out that one needs wh-sandbox fixes to run the code.
I do not know how many people have it on windows.

\start
Date: Fri, 15 Jun 2007 02:58:05 -0400
From: Bill Page
To: Martin Rubey
Subject: re: Hyperdoc
Cc: Camm Maguire

On 15 Jun 2007 08:35:48 +0200, Martin Rubey wrote:
> Bill Page writes:
>
> > > and, most importantly, sockets on windows!
> >
> > ??? There is support for sockets on Windows in GCL and this
> > works for axiom-0.1.4 on Windows.
>
> In fact, that's good news.
>
> But, why couldn't anybody run my code on windows so far?  See for
> example William Sit's attempts.
>

Well, Gregory Vanuxem last message on this issue suggests
that it might be a problem with the version of GCL that was used
to build axiom-0.1.4. That could be true. Now that I think of it,
the tests that I did were all done with a version of Axiom compiled
from the same sources as axiom-0.1.4 but with a new GCL
compiler.

\start
Date: Fri, 15 Jun 2007 12:49:56 +0200
From: Gregory Vanuxem
To: Ondrej Certik
Subject: Re: src_aldor2.tgz compilation problems
Cc: Franz Lehner

Hello Ondrej,

Look at section 10 of

http://wiki.axiom-developer.org/AldorForAxiom

What you encounter is the "additional problem".

Hope that helps.

Greg

Le mercredi 13 juin 2007 =E0 11:51 +0200, Ondrej Certik a =E9crit :
> > nothing, just have a look at
> > http://lists.nongnu.org/archive/html/axiom-developer/2007-06/msg00192.html
> > except for 64 bit, you are in exactly the same situation as I was ...
>
> Thanks very much, that helped a lot. Here are the steps, that worked
> for me, but still I get some error at the end (I looked into the
> axiom-dev archives, but didn't find a way how to fix it):
>
> svn co https://axiom.svn.sourceforge.net/svnroot/axiom/branches/wh-sandbox
> cd wh-sandbox
> svn co
> https://axiom.svn.sourceforge.net/svnroot/axiom/branches/build-improvements/gcl
> gcl
> cd zips
> wget
> https://axiom.svn.sourceforge.net/svnroot/axiom/trunk/axiom/zips/noweb-2.10a.tgz
>
> cd ../..
> mkdir ax-build
> cd ax-build
> ../wh-sandbox/configure
> make
>
> #get some coffee
> #the build took 12 hours on AMD Athlon(tm) 64 Processor 3000+
> #3 hours on intel core duo
>
>
> #Aldor
> export AXIOM=$WHEREVERYOUARE/ax-build/target/i686-pc-linux
> export ALDORROOT=<ALDOR-directory>/linux/1.0.2
>
>
> (cd $AXIOM/bin; ln -s ../../../build/scripts/document .)
> mkdir -p obj/i686-pc-linux
> cd obj/i686-pc-linux
> ln -s ../../build/i686-pc-linux/bin .
> ln -s ../../src/interp/ .
> cd ../..
>
> cd src
> #for axiom.sty
> ln -s ../../wh-sandbox/src/scripts/ .
>
>
> tar xzf ../../src_aldor2.tgz
> cd aldor
> ln -s ../../build/i686-pc-linux .
>
>
> #extract the Makefiles
> for pp in *.pamphlet; do document $pp;done
>
>
> make
> #after error
> touch ../../int/aldor/dep_spad.stamp
> document Make.functions.pamphlet
> make
> #crossed my fingers and got:
>
> ondra@syslik:~/ext/ax-build/src/aldor$ make
> Building libaxiom.al and associated files
> /home/ondra/ext/ax-build/int/aldor
> make[1]: Entering directory `/home/ondra/ext/ax-build/src/aldor'
> /home/ondra/ext/ax-build/src/aldor/types.mk:156:
> /home/ondra/ext/ax-build/int/aldor/saxiom/spadset.mk
> /home/ondra/ext/ax-build/src/aldor/Make.rules:179: ALL SPADSETS  sax0 saxiom
> /home/ondra/ext/ax-build/src/aldor/Make.rules:200: (0,0)
> /home/ondra/ext/ax-build/src/aldor/Make.rules:200: (1,1)
> /home/ondra/ext/ax-build/src/aldor/Make.rules:106: W: 1 I: 1
> /home/ondra/ext/ax-build/src/aldor/Make.rules:107: W:
> /home/ondra/ext/ax-build/int/aldor/sax0/spadset.mk
> cp /home/ondra/ext/ax-build/src/aldor/as/attrib.as.head
> /home/ondra/ext/ax-build/int/aldor/as/attrib.as
> Please add new attributes to /attrib.as.head
> make[1]: *** [/home/ondra/ext/ax-build/int/aldor/as/attrib.as] Error 1
> make[1]: *** Deleting file `/home/ondra/ext/ax-build/int/aldor/as/attrib.as'
> make[1]: Leaving directory `/home/ondra/ext/ax-build/src/aldor'
> make: *** [all] Error 2
>
\start
Date: Fri, 15 Jun 2007 13:28:46 +0200 (CEST)
From: Waldek Hebisch
To: Bill Page
Subject: Re: [Axiom-mail] A slow summation

Bill Page wrote:
> On 15 Jun 2007 07:49:11 +0200, Martin Rubey wrote:
> >
> > > > reduce(+,[1.0/i for i in 1..20000])

> > > > This works, but is (I think) unreasonably slow; it takes over
> > > > 21 seconds on my computer.  The equivalent command in Maxima
> > > > takes less than 1 second.

> > Bill, could you file that as a bug on MathAction, please.
> 
> Well, I would rather that somebody new do that. Alasdair? :-)
> 
> The "issue" (I am not quite sure to call it a "bug") is probably some
> very inefficient implementation of list comprehension in the Axiom
> interpreter. E.g.
> 
> (1) -> )set message time on
> (1) -> [i for i in 1..20000];
> 
>                                                Type: List PositiveInteger
>       Time: 14.73 (EV) + 0.02 (OT) + 0.05 (GC) = 14.80 sec
> 
> (2) -> expand(1..20000);
> 
>                                                            Type: List Integer
>                              Time: 0.07 (IN) + 0.18 (OT) = 0.25 sec
> 
> -------
> 
> Both (1) and (2) do essentially the same thing.
> 
> >
> > (If you have an sbcl compiled axiom available, you could check
> > whether it is gcl's fault, or rather a bug in axiom.)
> >
> 
> I am quite sure that this is not a lisp implementation issue,
> but no I don't have a sbcl version of Axiom available. Do you?
> Still, maybe this is a job for someone who knows how to use
> the sbcl profiler to find out where the Axiom interpreter is
> spending all it's time - Waldek?
> 

On my machine, I get the following (on the second run, to
exclude time for loading):

                                      gcl      sbcl          sbcl
                                             interpreted  compiled
 reduce(+,[1.0/i for i in 1..20000])   8.70      1.76        0.17
 [i for i in 1..20000];                6.23      0.78        0.01
 expand(1..20000);                     0         0.004       0.01

Comment: sbcl evaluator has two modes of operation: interpreted
and compiled.  In compiled mode the code is first compiled and
then the resulting machine code is run.  One can switch mode
setting variable sb-ext:*evaluator-mode*:

)lisp (setf sb-ext:*evaluator-mode* :compile)

or

)lisp (setf sb-ext:*evaluator-mode* :interpret)

sbcl profiler showed that 98% of time were spent in Lisp evaluator,
and that agrees very well with getting much higher speed using
compiled mode.

\start
Date: Fri, 15 Jun 2007 14:13:33 +0200
From: Ondrej Certik
To: Gregory Vanuxem
Subject: Re: src_aldor2.tgz compilation problems
Cc: Franz Lehner
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=

\start
Date: Fri, 15 Jun 2007 11:59:45 -0400
From: Bill Page
To: Waldek Hebisch
Subject: Re: [Axiom-mail] A slow summation
Cc: Camm Maguire

On 6/15/07, Waldek Hebisch wrote:
> Bill Page wrote:
> > ...
> > I am quite sure that this is not a lisp implementation issue,
> > but no I don't have a sbcl version of Axiom available. Do you?
> > Still, maybe this is a job for someone who knows how to use
> > the sbcl profiler to find out where the Axiom interpreter is
> > spending all it's time - Waldek?
> >
>
> On my machine, I get the following (on the second run, to
> exclude time for loading):
>
>                                       gcl      sbcl          sbcl
>                                              interpreted  compiled
>  reduce(+,[1.0/i for i in 1..20000])   8.70      1.76        0.17
>  [i for i in 1..20000];                6.23      0.78        0.01
>  expand(1..20000);                     0         0.004       0.01
>
> Comment: sbcl evaluator has two modes of operation: interpreted
> and compiled.  In compiled mode the code is first compiled and
> then the resulting machine code is run.  One can switch mode
> setting variable sb-ext:*evaluator-mode*:
>
> )lisp (setf sb-ext:*evaluator-mode* :compile)
>
> or
>
> )lisp (setf sb-ext:*evaluator-mode* :interpret)
>
> sbcl profiler showed that 98% of time were spent in Lisp evaluator,
> and that agrees very well with getting much higher speed using
> compiled mode.
>

Waldek, thank you very much for running this comparison!

So, the conclusion might be that I was wrong: the slowness *is*
because of the way that Axiom interpreter runs this code in
interpreted mode in GCL, right? It could still be that this interpreted
Lisp code is not written in an optimal manner.

Maybe it is possible in GCL with some additional coding to also
convince GCL to compile the code first before executing it?
I know that Axiom includes the command:

  )set function compile on/off

that affects compilation of user defined functions in the interpreter.
Perhaps this can be extended to the [... for ... ] case?

Alternatively:

Camm, Tim, and Lisp et al., is there anything equivalent to:

  (setf sb-ext:*evaluator-mode* :compile)

in GCL? A quick google for this did not turn up anything.

\start
Date: Fri, 15 Jun 2007 12:02:07 -0400
From: William Sit
To: Martin Rubey
Subject: re: Hyperdoc
Cc: Camm Maguire

Martin Rubey wrote:

> Bill Page writes:
>
> > > and, most importantly, sockets on windows!
> >
> > ??? There is support for sockets on Windows in GCL and this works
> > for axiom-0.1.4 on Windows.
>
> In fact, that's good news.
>
> But, why couldn't anybody run my code on windows so far?  See for example
> William Sit's attempts.
>
> Martin

I tried again, this time starting Windows "World Wide Web Publishing" service
before hand. My browsers (Firefox and I.E.7) both could not find the URL.
http://localhost:8080/|?binomial` `OutputForm|
I also tried some other functions that are in the database instead of
binomial.
I note that in /tmp, there is a file named target.txt.NIL (38k size).

So I break into BOOT. Output below.

William
---

(2) -> SOCKET(8080, getDocumentation$HyperDoc)$Lisp

Error: Console interrupt.
Error signalled by GO.
Broken at SYSTEM::BREAK-LEVEL.  Type :H for Help.
BOOT>>

:bt

#0   APPLY {loc0=#<compiled-function
system:universal-error-handler>,loc1=:error
,loc2=nil,l...} [ihs=33]
#1   APPLY {loc0=#<compiled-function
system:universal-error-handler>,loc1=:error
,loc2=nil,l...} [ihs=32]
#2   LAMBDA {} [ihs=29]
#3   SOCKET {} [ihs=24]
#4   EVAL {loc0=nil,loc1=nil,loc2=nil,loc3=(lambda-block socket (port docfun)
..
.),loc4=80...} [ihs=23]
#5   timedEvaluate {loc0=(socket 8080 (quote (# . #<vector
1b16ba48>))),loc1=(so
cket 8080 (quote (#...} [ihs=22]
#6   timedEVALFUN {loc0=(socket 8080 (quote (# . #<vector 1b16ba48>)))}
[ihs=21]

#7   upLispCall {loc0=#<vector 1b16be54>,loc1=(#<vector 1b16be38> #<vector
1b16b
e1c> (#<vector 1...} [ihs]
#8   upDollar {loc0=(#<vector 1b16be54> |Lisp| (#<vector 1b16be38> #<vector
1b16
be1c> (# # #))...} [ihs=19]
#9   bottomUp {loc0=(#<vector 1b16be54> |Lisp| (#<vector 1b16be38> #<vector
1b16
be1c> (# # #))...} [ihs=18]
#10   interpret1 {loc0=((|$elt| |Lisp| socket) 8080 (|$elt| |HyperDoc|
|getDocum
entation|)),loc1=...} [ihs=17]
#11   interpret {loc0=((|$elt| |Lisp| socket) 8080 (|$elt| |HyperDoc|
|getDocume
ntation|)),loc1=...} [ihs=16]
#12   interpretTopLevel {loc0=((|$elt| |Lisp| socket) 8080 (|$elt| |HyperDoc|
|g
etDocumentation|)),loc1=...} [ihs=15]
#13   processInteractive1 {loc0=((|$elt| |Lisp| socket) 8080 (|$elt|
|HyperDoc|
|getDocumentation|)),loc1=...} [ihs=14]
#14   processInteractive {loc0=((|$elt| |Lisp| socket) 8080 (|$elt|
|HyperDoc| |
getDocumentation|)),loc1=...} [ihs=13]
#15   intInterpretPform {loc0=(|Application| (|Fromdom| (# . socket) (# .
|Lisp|
)) (|Tuple| (# # #)))} [ihs=12]
#16   ncConversationPhase {loc0=#<compiled-function |phInterpret|>,loc1=(((#
# #
 ...))),loc2=(((# . 1) . "...} [ihs=11]
#17   intloopSpadProcess,interp {loc0=((|carrier| (# . t) (# . #1=(# # #))
...))
,loc1=(|Application| (|Fromdom| ...} [ihs=10]
#18   intloopSpadProcess {loc0=2,loc1=(((# . 1) . "SOCKET(8080,
getDocumentation
$HyperDoc)$Lisp")),loc2=(...} [ihs=9]
#19   intloopProcess {loc0=2,loc1=t,loc2=(((#) (# # #)) |nonnullstream|
#<compil
ed-function |incAppen...} [ihs=8]
#20   intloopProcessString {loc0="SOCKET(8080,
getDocumentation$HyperDoc)$Lisp",
loc1=2} [ihs=7]
#21   RESTART {} [ihs=6]
#22   TOP-LEVEL
{loc0=nil,loc1=0,loc2=0,loc3=nil,loc4=nil,loc5=nil,loc6=nil,loc7
="c:/cvs/head/ax...} [ihs=5]
#23   FUNCALL {loc0=#<compiled-function system:top-level>} [ihs=4]
NIL
BOOT>>:q
BOOT>>:q
(2) -> SOCKET(8080, getDocumentation$HyperDoc)$Lisp

Error: Could not connect
Error signalled by LET.
Broken at SYSTEM::BREAK-LEVEL.  Type :H for Help.
BOOT>>:bt

#0   APPLY {loc0=#<compiled-function
system:universal-error-handler>,loc1=:error
,loc2=nil,l...} [ihs=36]
#1   APPLY {loc0=#<compiled-function
system:universal-error-handler>,loc1=:error
,loc2=nil,l...} [ihs=35]
#2   LAMBDA {} [ihs=32]
#3   SOCKET {loc0=8080,loc1=nil,loc2=(lambda-block server (s)
...),loc3=nil,loc4
=nil,loc5=ni...} [ihs=31]
#4   SOCKET {} [ihs=29]
#5   EVAL {loc0=nil,loc1=nil,loc2=nil,loc3=(lambda-block socket (port docfun)
..
.),loc4=80...} [ihs=28]
#6   timedEvaluate {loc0=(socket 8080 (quote (# . #<vector
1b16ba48>))),loc1=(so
cket 8080 (quote (#...} [ihs=27]
#7   timedEVALFUN {loc0=(socket 8080 (quote (# . #<vector 1b16ba48>)))}
[ihs=26]

#8   upLispCall {loc0=#<vector 1b16b8dc>,loc1=(#<vector 1b16b8c0> #<vector
1b16b
7fc> (#<vector 1...} [ihs=25]
#9   upDollar {loc0=(#<vector 1b16b8dc> |Lisp| (#<vector 1b16b8c0> #<vector
1b16
b7fc> (# # #))...} [ihs=24]
#10   bottomUp {loc0=(#<vector 1b16b8dc> |Lisp| (#<vector 1b16b8c0> #<vector
1b1
6b7fc> (# # #))...} [ihs=23]
#11   interpret1 {loc0=((|$elt| |Lisp| socket) 8080 (|$elt| |HyperDoc|
|getDocum
entation|)),loc1=...} [ihs=22]
#12   interpret {loc0=((|$elt| |Lisp| socket) 8080 (|$elt| |HyperDoc|
|getDocume
ntation|)),loc1=...} [ihs=21]
#13   interpretTopLevel {loc0=((|$elt| |Lisp| socket) 8080 (|$elt| |HyperDoc|
|g
etDocumentation|)),loc1=...} [ihs]
#14   processInteractive1 {loc0=((|$elt| |Lisp| socket) 8080 (|$elt|
|HyperDoc|
|getDocumentation|)),loc1=...} [ihs=19]
#15   processInteractive {loc0=((|$elt| |Lisp| socket) 8080 (|$elt|
|HyperDoc| |
getDocumentation|)),loc1=...} [ihs=18]
#16   intInterpretPform {loc0=(|Application| (|Fromdom| (# . socket) (# .
|Lisp|
)) (|Tuple| (# # #)))} [ihs=17]
#17   ncConversationPhase {loc0=#<compiled-function |phInterpret|>,loc1=(((#
# #
 ...))),loc2=(((# . 1) . "...} [ihs=16]
#18   intloopSpadProcess,interp {loc0=((|carrier| (# . t) (# . #1=(# # #))
...))
,loc1=(|Application| (|Fromdom| ...} [ihs=15]
#19   intloopSpadProcess {loc0=1,loc1=(((# . 1) . "SOCKET(8080,
getDocumentation
$HyperDoc)$Lisp")),loc2=(...} [ihs=14]
#20   intloopProcess {loc0=1,loc1=t,loc2=(((#) (# # #)) |nonnullstream|
#<compil
ed-function |incAppen...} [ihs=13]
#21   intloopProcessString {loc0="SOCKET(8080,
getDocumentation$HyperDoc)$Lisp",
loc1=1} [ihs=12]
#22   intloopReadConsole {loc0="",loc1=1,loc2="",loc3="SOCKET(8080,
getDocumenta
tion$HyperDoc)$Lisp",loc4...} [ihs=11]
#23   SpadInterpretStream {loc0=1,loc1=(tim daly
?),loc2=t,loc3="axiom014",loc4"mnt",loc5="windows",loc6=...} [ihs=10]
#24   intloop {} [ihs=9]
#25   ncIntLoop {loc0=".axiom.input",loc1=".axiom.input"} [ihs=8]
#26   ncTopLevel {loc0=nil,loc1=|.axiom|,loc2=:internal,loc3=#<synonym stream
to
 *terminal-io*>,l...} [ihs=7]
#27   RESTART {} [ihs=6]
#28   TOP-LEVEL
{loc0=nil,loc1=0,loc2=0,loc3=nil,loc4=nil,loc5=nil,loc6=nil,loc7
="c:/cvs/head/ax...} [ihs=5]
#29   FUNCALL {loc0=#<compiled-function system:top-level>} [ihs=4]
NIL
BOOT>>:ihs

  IHS[4]: #<compiled-function FUNCALL> ---> VS[14]
  IHS[5]: #<compiled-function SYSTEM:TOP-LEVEL> ---> VS[15]
    FRS[2]: (CATCH (QUOTE (NIL)) ***) ---> IHS[5],VS[8],BDS[9]
  IHS[6]: #<compiled-function RESTART> ---> VS[88]
    FRS[3]: (CATCH (QUOTE (NIL)) ***) ---> IHS[6],VS[8],BDS[11]
    FRS[4]: (CATCH (QUOTE |coerceFailure|) ***) ---> IHS[6],VS[8],BDS[11]
    FRS[5]: (CATCH (QUOTE |top_level|) ***) ---> IHS[6],VS[8],BDS[11]
  IHS[7]: #<compiled-function |ncTopLevel|> ---> VS[52]
  IHS[8]: #<compiled-function |ncIntLoop|> ---> VS[59]
  IHS[9]: #<compiled-function |intloop|> ---> VS[61]
    FRS[6]: (CATCH (QUOTE |top_level|) ***) ---> IHS[9],VS[8],BDS[20]
  IHS[10]: #<compiled-function |SpadInterpretStream|> ---> VS[61]
  IHS[11]: #<compiled-function |intloopReadConsole|> ---> VS[76]
  IHS[12]: #<compiled-function |intloopProcessString|> ---> VS[81]
  IHS[13]: #<compiled-function |intloopProcess|> ---> VS[83]
  IHS[14]: #<compiled-function |intloopSpadProcess|> ---> VS[86]
    FRS[7]: (CATCH (QUOTE |SpadCompileItem|) ***) ---> IHS[14],VS[8],BDS[33]
    FRS[8]: (CATCH (QUOTE |coerceFailure|) ***) ---> IHS[14],VS[8],BDS[33]
    FRS[9]: (CATCH (QUOTE SPAD_READER) ***) ---> IHS[14],VS[8],BDS[33]
  IHS[15]: #<compiled-function |intloopSpadProcess,interp|> ---> VS[91]
  IHS[16]: #<compiled-function |ncConversationPhase|> ---> VS[94]
    FRS[10]: (UNWIND-PROTECT ***) ---> IHS[16],VS[8],BDS[35]
  IHS[17]: #<compiled-function |intInterpretPform|> ---> VS[103]
  IHS[18]: #<compiled-function |processInteractive|> ---> VS[104]
  IHS[19]: #<compiled-function |processInteractive1|> ---> VS[131]
  IHS[20]: #<compiled-function |interpretTopLevel|> ---> VS[134]
    FRS[11]: (CATCH (QUOTE |interpreter|) ***) ---> IHS[20],VS[8],BDS[60]
  IHS[21]: #<compiled-function |interpret|> ---> VS[136]
  IHS[22]: #<compiled-function |interpret1|> ---> VS[141]
  IHS[23]: #<compiled-function |bottomUp|> ---> VS[146]
  IHS[24]: #<compiled-function |upDollar|> ---> VS[148]
  IHS[25]: #<compiled-function |upLispCall|> ---> VS[150]
  IHS[26]: #<compiled-function |timedEVALFUN|> ---> VS[152]
  IHS[27]: #<compiled-function |timedEvaluate|> ---> VS[153]
  IHS[28]: #<compiled-function EVAL> ---> VS[156]
  IHS[29]: (SOCKET (# #) (# # #) (# # #)) ---> VS[162]
    FRS[12]: (BLOCK SOCKET ***) ---> IHS[29],VS[162],BDS[63]
  IHS[30]: LET ---> VS[166]
  IHS[31]: #<compiled-function SYSTEM:SOCKET> ---> VS[175]
  IHS[32]: (LAMBDA (# # # # ...) (# #)) ---> VS[191]
  IHS[33]: (LAMBDA (#) (# # # # ...)) ---> VS[198]
  IHS[34]: BLOCK ---> VS[202]
    FRS[13]: (BLOCK NIL ***) ---> IHS[34],VS[202],BDS[63]
  IHS[35]: #<compiled-function APPLY> ---> VS[206]
  IHS[36]: #<compiled-function APPLY> ---> VS[213]
  IHS[37]: #<compiled-function SYSTEM:UNIVERSAL-ERROR-HANDLER> ---> VS[220]
@ IHS[38]: #<compiled-function SYSTEM::BREAK-LEVEL> ---> VS[241]
NIL
BOOT>>:b
Backtrace: funcall > system:top-level > restart > |ncTopLevel| > |ncIntLoop|
> |
intloop| > |SpadInterpretStream| > |intloopReadConsole| >
|intloopProcessString|
 > |intloopProcess| > |intloopSpadProcess| > |intloopSpadProcess,interp| >
|ncCo
nversationPhase| > |intInterpretPform| > |processInteractive| >
|processInteract
ive1| > |interpretTopLevel| > |interpret| > |interpret1| > |bottomUp| >
|upDolla
r| > |upLispCall| > |timedEVALFUN| > |timedEvaluate| > eval > socket > let >
sys
tem:socket > lambda > lambda-closure > block > apply > apply >
system:universal-
error-handler > SYSTEM::BREAK-LEVEL
NIL
BOOT>>:vs

  IHS[4]: #<compiled-function FUNCALL> ---> VS[14]
VS[14]: #<compiled-function SYSTEM:TOP-LEVEL>
  IHS[5]: #<compiled-function SYSTEM:TOP-LEVEL> ---> VS[15]
VS[15]: NIL
VS[16]: 0
VS[17]: 0
VS[18]: NIL
VS[19]: NIL
VS[20]: NIL
VS[21]: NIL
VS[22]: "c:/cvs/head/axiom/mnt/windows/bin/"
VS[23]: "c:/cvs/head/axiom/mnt/windows/bin/"
VS[24]: NIL
VS[25]: T
VS[26]: #<OBJNULL>
VS[27]: #<OBJNULL>
VS[28]: #<OBJNULL>
VS[29]: #P"j:/OpenAxiom/axiom014/mnt/windows/lib/"
VS[30]: "./"
VS[31]: "J:/OpenAxiom/axiom014/mnt/windows/lib/"
VS[32]: "J:/OpenAxiom/axiom014/mnt/windows/lib/"
VS[33]: "J"
VS[34]: "j"
VS[35]: (:ABSOLUTE "OpenAxiom" "axiom014" "mnt" "windows" "lib")
VS[36]: "OpenAxiom"
VS[37]: "axiom014"
VS[38]: "mnt"
VS[39]: "windows"
VS[40]: "lib"
VS[41]: #P"j:/OpenAxiom/axiom014/mnt/windows/lib/"
VS[42]: T
VS[43]: T
VS[44]: T
VS[45]: T
VS[46]: T
VS[47]: T
VS[48]: T
VS[49]: NIL
VS[50]: (|input|)
VS[51]: |%initialize%|
VS[52]: NIL
VS[53]: |.axiom|
VS[54]: :INTERNAL
VS[55]: #<synonym stream to *TERMINAL-IO*>
VS[56]: "axiom.input"
VS[57]: "j:/OpenAxiom/axiom014/mnt/windows/doc/spadhelp/.axiom.input"
VS[58]: ".axiom.input"
VS[59]: ".axiom.input"
VS[60]: ".axiom.input"
VS[61]: 1
VS[62]: (TIM DALY ?)
VS[63]: T
VS[64]: "axiom014"
VS[65]: "mnt"
VS[66]: "windows"
VS[67]: "doc"
VS[68]: "spadhelp"
VS[69]: "axiom.input"
VS[70]: #P"j:/OpenAxiom/axiom014/mnt/windows/doc/spadhelp/.axiom.input"
VS[71]: T
VS[72]: T
VS[73]: ""
VS[74]: "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
VS[75]: NIL
VS[76]: ""
VS[77]: 1
VS[78]: ""
VS[79]: "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
VS[80]: NIL
VS[81]: "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
VS[82]: 1
VS[83]: 1
VS[84]: T
VS[85]: ((((((0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings")
.
1) . "SOCKET(8080, getDocumentation$HyperDoc)$Lisp")) (|Application|
(|Fromdom|
((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1
"strings")
. 0)) . SOCKET) ((|id| (|posn| (0 "SOCKET(8080,
getDocumentation$HyperDoc)$Lisp"
 1 1 "strings") . 40)) . |Lisp|)) (|Tuple| (|listOf| ((|integer| (|posn| (0
"SOC
KET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 7)) . "8080")
(|From
dom| ((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1
"strin
gs") . 13)) . |getDocumentation|) ((|id| (|posn| (0 "SOCKET(8080,
getDocumentati
on$HyperDoc)$Lisp" 1 1 "strings") . 30)) . |HyperDoc|)))))) |nonnullstream|
#<co
mpiled-function |incAppend1|> NIL (|nonnullstream| #<compiled-function
|next1|>
#<compiled-function |ncloopParse|> (|nonnullstream| #<compiled-function
|incAppe
nd1|> NIL (|nonnullstream| #<compiled-function |next1|> #<compiled-function
|lin
eoftoks|> (|nullstream|)))))
VS[86]: 1
VS[87]: ((((0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") .
1)
 . "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"))
  IHS[6]: #<compiled-function RESTART> ---> VS[88]
  IHS[7]: #<compiled-function |ncTopLevel|> ---> VS[52]
  IHS[8]: #<compiled-function |ncIntLoop|> ---> VS[59]
  IHS[9]: #<compiled-function |intloop|> ---> VS[61]
  IHS[10]: #<compiled-function |SpadInterpretStream|> ---> VS[61]
  IHS[11]: #<compiled-function |intloopReadConsole|> ---> VS[76]
  IHS[12]: #<compiled-function |intloopProcessString|> ---> VS[81]
  IHS[13]: #<compiled-function |intloopProcess|> ---> VS[83]
  IHS[14]: #<compiled-function |intloopSpadProcess|> ---> VS[86]
VS[88]: (|Application| (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocumentati
on$HyperDoc)$Lisp" 1 1 "strings") . 0)) . SOCKET) ((|id| (|posn| (0
"SOCKET(8080
, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 40)) . |Lisp|)) (|Tuple|
(|l
istOf| ((|integer| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
1 1
 "strings") . 7)) . "8080") (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocume
ntation$HyperDoc)$Lisp" 1 1 "strings") . 13)) . |getDocumentation|) ((|id|
(|pos
n| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 30)) .
|Hy
perDoc|)))))
VS[89]: T
VS[90]: (|nonnullstream| #<compiled-function |incAppend1|> NIL
(|nonnullstream|
#<compiled-function |next1|> #<compiled-function |ncloopParse|>
(|nonnullstream|
 #<compiled-function |incAppend1|> NIL (|nonnullstream| #<compiled-function
|nex
t1|> #<compiled-function |lineoftoks|> (|nullstream|)))))
  IHS[15]: #<compiled-function |intloopSpadProcess,interp|> ---> VS[91]
VS[91]: ((|carrier| (|ok?| . T) (|ptreePremacro| |Application| (|Fromdom|
((|id|
 (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") .
0))
. SOCKET) ((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1
1 "
strings") . 40)) . |Lisp|)) (|Tuple| (|listOf| ((|integer| (|posn| (0
"SOCKET(80
80, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 7)) . "8080")
(|Fromdom| (
(|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1
"strings") .
 13)) . |getDocumentation|) ((|id| (|posn| (0 "SOCKET(8080,
getDocumentation$Hyp
erDoc)$Lisp" 1 1 "strings") . 30)) . |HyperDoc|))))) (|ptree| |Application|
(|Fr
omdom| ((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1
"str
ings") . 0)) . SOCKET) ((|id| (|posn| (0 "SOCKET(8080,
getDocumentation$HyperDoc
)$Lisp" 1 1 "strings") . 40)) . |Lisp|)) (|Tuple| (|listOf| ((|integer|
(|posn|
(0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 7)) .
"8080")
 (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
1 1
 "strings") . 13)) . |getDocumentation|) ((|id| (|posn| (0 "SOCKET(8080,
getDocu
mentation$HyperDoc)$Lisp" 1 1 "strings") . 30)) . |HyperDoc|))))) (|lines|
(((0
"SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 1) .
"SOCKET(808
0, getDocumentation$HyperDoc)$Lisp")) (|messages|) (|stepNumber| . 1)))
VS[92]: (|Application| (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocumentati
on$HyperDoc)$Lisp" 1 1 "strings") . 0)) . SOCKET) ((|id| (|posn| (0
"SOCKET(8080
, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 40)) . |Lisp|)) (|Tuple|
(|l
istOf| ((|integer| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
1 1
 "strings") . 7)) . "8080") (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocume
ntation$HyperDoc)$Lisp" 1 1 "strings") . 13)) . |getDocumentation|) ((|id|
(|pos
n| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 30)) .
|Hy
perDoc|)))))
VS[93]: T
  IHS[16]: #<compiled-function |ncConversationPhase|> ---> VS[94]
VS[94]: #<compiled-function |phInterpret|>
VS[95]: (((|carrier| (|ok?| . T) (|ptreePremacro| |Application| (|Fromdom|
((|id
| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") .
0))
 . SOCKET) ((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1
1
"strings") . 40)) . |Lisp|)) (|Tuple| (|listOf| ((|integer| (|posn| (0
"SOCKET(8
080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 7)) . "8080")
(|Fromdom|
((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1
"strings")
. 13)) . |getDocumentation|) ((|id| (|posn| (0 "SOCKET(8080,
getDocumentation$Hy
perDoc)$Lisp" 1 1 "strings") . 30)) . |HyperDoc|))))) (|ptree| |Application|
(|F
romdom| ((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1
"st
rings") . 0)) . SOCKET) ((|id| (|posn| (0 "SOCKET(8080,
getDocumentation$HyperDo
c)$Lisp" 1 1 "strings") . 40)) . |Lisp|)) (|Tuple| (|listOf| ((|integer|
(|posn|
 (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 7)) .
"8080"
) (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
1
1 "strings") . 13)) . |getDocumentation|) ((|id| (|posn| (0 "SOCKET(8080,
getDoc
umentation$HyperDoc)$Lisp" 1 1 "strings") . 30)) . |HyperDoc|))))) (|lines|
(((0
 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 1) .
"SOCKET(80
80, getDocumentation$HyperDoc)$Lisp")) (|messages|) (|stepNumber| . 1))))
VS[96]: ((((0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") .
1)
 . "SOCKET(8080, getDocumentation$HyperDoc)$Lisp") |nullstream|)
VS[97]: ((|Application| (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocumentat
ion$HyperDoc)$Lisp" 1 1 "strings") . 0)) . SOCKET) ((|id| (|posn| (0
"SOCKET(808
0, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 40)) . |Lisp|)) (|Tuple|
(|
listOf| ((|integer| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
1
1 "strings") . 7)) . "8080") (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocum
entation$HyperDoc)$Lisp" 1 1 "strings") . 13)) . |getDocumentation|) ((|id|
(|po
sn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 30)) .
|H
yperDoc|))))))
VS[98]: (OK)
VS[99]: #<compiled-function |phInterpret|>
VS[100]: ((|carrier| (|ok?| . T) (|ptreePremacro| |Application| (|Fromdom|
((|id
| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") .
0))
 . SOCKET) ((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1
1
"strings") . 40)) . |Lisp|)) (|Tuple| (|listOf| ((|integer| (|posn| (0
"SOCKET(8
080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 7)) . "8080")
(|Fromdom|
((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1
"strings")
. 13)) . |getDocumentation|) ((|id| (|posn| (0 "SOCKET(8080,
getDocumentation$Hy
perDoc)$Lisp" 1 1 "strings") . 30)) . |HyperDoc|))))) (|ptree| |Application|
(|F
romdom| ((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1
"st
rings") . 0)) . SOCKET) ((|id| (|posn| (0 "SOCKET(8080,
getDocumentation$HyperDo
c)$Lisp" 1 1 "strings") . 40)) . |Lisp|)) (|Tuple| (|listOf| ((|integer|
(|posn|
 (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 7)) .
"8080"
) (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
1
1 "strings") . 13)) . |getDocumentation|) ((|id| (|posn| (0 "SOCKET(8080,
getDoc
umentation$HyperDoc)$Lisp" 1 1 "strings") . 30)) . |HyperDoc|))))) (|lines|
(((0
 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 1) .
"SOCKET(80
80, getDocumentation$HyperDoc)$Lisp")) (|messages|) (|stepNumber| . 1)))
VS[101]: ((|carrier| (|ok?| . T) (|ptreePremacro| |Application| (|Fromdom|
((|id
| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") .
0))
 . SOCKET) ((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1
1
"strings") . 40)) . |Lisp|)) (|Tuple| (|listOf| ((|integer| (|posn| (0
"SOCKET(8
080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 7)) . "8080")
(|Fromdom|
((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1
"strings")
. 13)) . |getDocumentation|) ((|id| (|posn| (0 "SOCKET(8080,
getDocumentation$Hy
perDoc)$Lisp" 1 1 "strings") . 30)) . |HyperDoc|))))) (|ptree| |Application|
(|F
romdom| ((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1
"st
rings") . 0)) . SOCKET) ((|id| (|posn| (0 "SOCKET(8080,
getDocumentation$HyperDo
c)$Lisp" 1 1 "strings") . 40)) . |Lisp|)) (|Tuple| (|listOf| ((|integer|
(|posn|
 (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 7)) .
"8080"
) (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
1
1 "strings") . 13)) . |getDocumentation|) ((|id| (|posn| (0 "SOCKET(8080,
getDoc
umentation$HyperDoc)$Lisp" 1 1 "strings") . 30)) . |HyperDoc|))))) (|lines|
(((0
 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 1) .
"SOCKET(80
80, getDocumentation$HyperDoc)$Lisp")) (|messages|) (|stepNumber| . 1)))
VS[102]: |ptree|
  IHS[17]: #<compiled-function |intInterpretPform|> ---> VS[103]
VS[103]: (|Application| (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocumentat
ion$HyperDoc)$Lisp" 1 1 "strings") . 0)) . SOCKET) ((|id| (|posn| (0
"SOCKET(808
0, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 40)) . |Lisp|)) (|Tuple|
(|
listOf| ((|integer| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
1
1 "strings") . 7)) . "8080") (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocum
entation$HyperDoc)$Lisp" 1 1 "strings") . 13)) . |getDocumentation|) ((|id|
(|po
sn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 30)) .
|H
yperDoc|)))))
  IHS[18]: #<compiled-function |processInteractive|> ---> VS[104]
VS[104]: ((|$elt| |Lisp| SOCKET) 8080 (|$elt| |HyperDoc| |getDocumentation|))

VS[105]: (|Application| (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocumentat
ion$HyperDoc)$Lisp" 1 1 "strings") . 0)) . SOCKET) ((|id| (|posn| (0
"SOCKET(808
0, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 40)) . |Lisp|)) (|Tuple|
(|
listOf| ((|integer| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
1
1 "strings") . 7)) . "8080") (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocum
entation$HyperDoc)$Lisp" 1 1 "strings") . 13)) . |getDocumentation|) ((|id|
(|po
sn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 30)) .
|H
yperDoc|)))))
VS[106]: ?
VS[107]: ((|$elt| |Lisp| SOCKET) 8080 (|$elt| |HyperDoc| |getDocumentation|))

VS[108]: NIL
VS[109]: NIL
VS[110]: NIL
VS[111]: NIL
VS[112]: NIL
VS[113]: NIL
VS[114]: (|getDocumentation|)
VS[115]: #<"BOOT" package>
VS[116]: NIL
VS[117]: NIL
VS[118]: :INHERITED
VS[119]: NIL
VS[120]: NIL
VS[121]: NIL
VS[122]: NIL
VS[123]: 8080
VS[124]: 4
VS[125]: 4
VS[126]: NIL
VS[127]: NIL
VS[128]: 8080
VS[129]: #<readtable 1a008f78>
VS[130]: 8080
  IHS[19]: #<compiled-function |processInteractive1|> ---> VS[131]
VS[131]: ((|$elt| |Lisp| SOCKET) 8080 (|$elt| |HyperDoc| |getDocumentation|))

VS[132]: (|Application| (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocumentat
ion$HyperDoc)$Lisp" 1 1 "strings") . 0)) . SOCKET) ((|id| (|posn| (0
"SOCKET(808
0, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 40)) . |Lisp|)) (|Tuple|
(|
listOf| ((|integer| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
1
1 "strings") . 7)) . "8080") (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocum
entation$HyperDoc)$Lisp" 1 1 "strings") . 13)) . |getDocumentation|) ((|id|
(|po
sn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 30)) .
|H
yperDoc|)))))
VS[133]: 0
  IHS[20]: #<compiled-function |interpretTopLevel|> ---> VS[134]
VS[134]: ((|$elt| |Lisp| SOCKET) 8080 (|$elt| |HyperDoc| |getDocumentation|))

VS[135]: (|Application| (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocumentat
ion$HyperDoc)$Lisp" 1 1 "strings") . 0)) . SOCKET) ((|id| (|posn| (0
"SOCKET(808
0, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 40)) . |Lisp|)) (|Tuple|
(|
listOf| ((|integer| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
1
1 "strings") . 7)) . "8080") (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocum
entation$HyperDoc)$Lisp" 1 1 "strings") . 13)) . |getDocumentation|) ((|id|
(|po
sn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 30)) .
|H
yperDoc|)))))
  IHS[21]: #<compiled-function |interpret|> ---> VS[136]
VS[136]: ((|$elt| |Lisp| SOCKET) 8080 (|$elt| |HyperDoc| |getDocumentation|))

VS[137]: (|Application| (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocumentat
ion$HyperDoc)$Lisp" 1 1 "strings") . 0)) . SOCKET) ((|id| (|posn| (0
"SOCKET(808
0, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 40)) . |Lisp|)) (|Tuple|
(|
listOf| ((|integer| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
1
1 "strings") . 7)) . "8080") (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocum
entation$HyperDoc)$Lisp" 1 1 "strings") . 13)) . |getDocumentation|) ((|id|
(|po
sn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 30)) .
|H
yperDoc|)))))
VS[138]: (|analysis| |other|)
VS[139]: (|other|)
VS[140]: NIL
  IHS[22]: #<compiled-function |interpret1|> ---> VS[141]
VS[141]: ((|$elt| |Lisp| SOCKET) 8080 (|$elt| |HyperDoc| |getDocumentation|))

VS[142]: NIL
VS[143]: (|Application| (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocumentat
ion$HyperDoc)$Lisp" 1 1 "strings") . 0)) . SOCKET) ((|id| (|posn| (0
"SOCKET(808
0, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 40)) . |Lisp|)) (|Tuple|
(|
listOf| ((|integer| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
1
1 "strings") . 7)) . "8080") (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocum
entation$HyperDoc)$Lisp" 1 1 "strings") . 13)) . |getDocumentation|) ((|id|
(|po
sn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 30)) .
|H
yperDoc|)))))
VS[144]: ((|$elt| |Lisp| SOCKET) 8080 (|$elt| |HyperDoc| |getDocumentation|))

VS[145]: (|Application| (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocumentat
ion$HyperDoc)$Lisp" 1 1 "strings") . 0)) . SOCKET) ((|id| (|posn| (0
"SOCKET(808
0, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 40)) . |Lisp|)) (|Tuple|
(|
listOf| ((|integer| (|posn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp"
1
1 "strings") . 7)) . "8080") (|Fromdom| ((|id| (|posn| (0 "SOCKET(8080,
getDocum
entation$HyperDoc)$Lisp" 1 1 "strings") . 13)) . |getDocumentation|) ((|id|
(|po
sn| (0 "SOCKET(8080, getDocumentation$HyperDoc)$Lisp" 1 1 "strings") . 30)) .
|H
yperDoc|)))))
  IHS[23]: #<compiled-function |bottomUp|> ---> VS[146]
VS[146]: (#<vector 1b16b8dc> |Lisp| (#<vector 1b16b8c0> #<vector 1b16b7fc>
(#<ve
ctor 1b16b7e0> |HyperDoc| #<vector 1b16b7c4>)))
VS[147]: (#<vector 1b16b8dc> |Lisp| (#<vector 1b16b8c0> #<vector 1b16b7fc>
(#<ve
ctor 1b16b7e0> |HyperDoc| #<vector 1b16b7c4>)))
  IHS[24]: #<compiled-function |upDollar|> ---> VS[148]
VS[148]: (#<vector 1b16b8dc> |Lisp| (#<vector 1b16b8c0> #<vector 1b16b7fc>
(#<ve
ctor 1b16b7e0> |HyperDoc| #<vector 1b16b7c4>)))
VS[149]: |up|
  IHS[25]: #<compiled-function |upLispCall|> ---> VS[150]
VS[150]: #<vector 1b16b8dc>
VS[151]: (#<vector 1b16b8c0> #<vector 1b16b7fc> (#<vector 1b16b7e0>
|HyperDoc| #
<vector 1b16b7c4>))
  IHS[26]: #<compiled-function |timedEVALFUN|> ---> VS[152]
VS[152]: (SOCKET 8080 (QUOTE (#<compiled-function
|HYPER;getDocumentation;2S;5|>
 . #<vector 1b16ba48>)))
  IHS[27]: #<compiled-function |timedEvaluate|> ---> VS[153]
VS[153]: (SOCKET 8080 (QUOTE (#<compiled-function
|HYPER;getDocumentation;2S;5|>
 . #<vector 1b16ba48>)))
VS[154]: (SOCKET 8080 (QUOTE (#<compiled-function
|HYPER;getDocumentation;2S;5|>
 . #<vector 1b16ba48>)))
VS[155]: (SOCKET 8080 (QUOTE (#<compiled-function
|HYPER;getDocumentation;2S;5|>
 . #<vector 1b16ba48>)))
  IHS[28]: #<compiled-function EVAL> ---> VS[156]
VS[156]: NIL
VS[157]: NIL
VS[158]: NIL
VS[159]: (LAMBDA-BLOCK SOCKET (PORT DOCFUN) (SETQ *DOCFUN* DOCFUN) (LET ((S
(SYS
TEM:SOCKET PORT :SERVER (FUNCTION SERVER)))) (TAGBODY L (WHEN (LISTEN S) (LET
((
W (SYSTEM::ACCEPT S))) (SERVER W))) (SLEEP 0.10000000000000001) (GO L))))
VS[160]: 8080
VS[161]: (#<compiled-function |HYPER;getDocumentation;2S;5|> . #<vector
1b16ba48
>)
  IHS[29]: (SOCKET (# #) (# # #) (# # #)) ---> VS[162]
VS[162]: ((DOCFUN (#<compiled-function |HYPER;getDocumentation;2S;5|> .
#<vector
 1b16ba48>)) (PORT 8080))
VS[163]: NIL
VS[164]: ((SOCKET BLOCK #<@1AE63760>))
VS[165]: ((SETQ *DOCFUN* DOCFUN) (LET ((S (SYSTEM:SOCKET PORT :SERVER
(FUNCTION
SERVER)))) (TAGBODY L (WHEN (LISTEN S) (LET ((W (SYSTEM::ACCEPT S))) (SERVER
W))
) (SLEEP 0.10000000000000001) (GO L))))
  IHS[30]: LET ---> VS[166]
VS[166]: ((DOCFUN (#<compiled-function |HYPER;getDocumentation;2S;5|> .
#<vector
 1b16ba48>)) (PORT 8080))
VS[167]: NIL
VS[168]: ((SOCKET BLOCK #<@1AE63760>))
VS[169]: S
VS[170]: NIL
VS[171]: (SYSTEM:SOCKET PORT :SERVER (FUNCTION SERVER))
VS[172]: NIL
VS[173]: ((TAGBODY L (WHEN (LISTEN S) (LET ((W (SYSTEM::ACCEPT S))) (SERVER
W)))
 (SLEEP 0.10000000000000001) (GO L)))
VS[174]: #<compiled-function SYSTEM:SOCKET>
  IHS[31]: #<compiled-function SYSTEM:SOCKET> ---> VS[175]
VS[175]: 8080
VS[176]: NIL
VS[177]: (LAMBDA-BLOCK SERVER (S) (LET* ((GET (READ S NIL (QUOTE EOF))) (FN
(AND
 (EQ GET (QUOTE GET)) (LET* ((S1 (SUBSEQ (STRING (READ S NIL (QUOTE EOF)))
1)) (
N (LENGTH S1)) (S2 (MAKE-STRING N))) (DO ((I 0 (INCF I)) (J 0 (INCF J))) ((I N
) (SUBSEQ S2 0 J)) (IF (CHAR= (CHAR S1 I) #\%) (SETF (CHAR S2 J) (CODE-CHAR
(REA
D-FROM-STRING (CONCAT "#x" (SUBSEQ S1 (INCF I) (1+ (INCF I))))))) (SETF (CHAR
S2
 J) (CHAR S1 I)))))))) (FORMAT T "Got ~S~%~%" FN) (WHEN (STRING= (CHAR FN 0)
"?"
) (SETQ FN (SPADCALL (SUBSEQ FN 1) *DOCFUN*))) (WHEN (STRING= (SUBSEQ FN (-
(LEN
GTH FN) 4)) "html") (FORMAT S "HTTP/1.1 ~S~%" (IF FN 200 403)))
(WITH-OPEN-FILE
(Q FN) (SYSTEM:COPY-STREAM Q S)) (CLOSE S)))
VS[178]: NIL
VS[179]: NIL
VS[180]: NIL
VS[181]: NIL
VS[182]: T
VS[183]: NIL
VS[184]: NIL
VS[185]: NIL
VS[186]: :ERROR
VS[187]: NIL
VS[188]: LET
VS[189]: ""
VS[190]: "Could not connect"
  IHS[32]: (LAMBDA (# # # # ...) (# #)) ---> VS[191]
VS[191]: ((ARGS NIL) (ERROR-STRING "Could not connect") (CONTINUE-STRING "")
(OP
 LET) (CORRECTABLE? NIL) (TYPE :ERROR))
VS[192]: NIL
VS[193]: NIL
VS[194]: (((LAMBDA (SYSTEM:UNIVERSAL-ERROR-HANDLER) (BLOCK NIL (SETQ
|$NeedToSig
nalSessionManager| T) (IF (AND (BOUNDP (QUOTE |$inLispVM|)) (BOUNDP (QUOTE
|$Bre
akMode|))) (COND ((EQ |$BreakMode| (QUOTE |validate|)) (|systemError|
(ERROR-FOR
MAT ERROR-STRING ARGS))) ((AND (EQ |$BreakMode| (QUOTE |trapNumerics|)) (EQ
TYPE
 :ERROR)) (SETQ |$BreakMode| NIL) (THROW (QUOTE |trapNumerics|)
|$numericFailure
|)) ((AND (EQ |$BreakMode| (QUOTE |trapNumerics|)) (BOUNDP (QUOTE
|$oldBreakMode
|)) (SETQ |$BreakMode| |$oldBreakMode|) NIL)) ((AND (NULL |$inLispVM|) (MEMQ
|$B
reakMode| (QUOTE (|nobreak| |query| |resume|)))) (LET ((|$inLispVM| T))
(RETURN
(|systemError| (ERROR-FORMAT ERROR-STRING ARGS))))) ((EQ |$BreakMode| (QUOTE
|le
tPrint2|)) (SETQ |$BreakMode| NIL) (THROW (QUOTE |letPrint2|) NIL)))) (APPLY
SYS
TEM:UNIVERSAL-ERROR-HANDLER TYPE CORRECTABLE? OP CONTINUE-STRING ERROR-STRING
AR
GS))) (QUOTE #<compiled-function SYSTEM:UNIVERSAL-ERROR-HANDLER>)))
VS[195]: (LAMBDA-CLOSURE ((ARGS NIL) (ERROR-STRING "Could not connect")
(CONTINU
E-STRING "") (OP LET) (CORRECTABLE? NIL) (TYPE :ERROR)) NIL NIL
(SYSTEM:UNIVERSA
L-ERROR-HANDLER) (BLOCK NIL (SETQ |$NeedToSignalSessionManager| T) (IF (AND
(BOU
NDP (QUOTE |$inLispVM|)) (BOUNDP (QUOTE |$BreakMode|))) (COND ((EQ
|$BreakMode|
(QUOTE |validate|)) (|systemError| (ERROR-FORMAT ERROR-STRING ARGS))) ((AND
(EQ
|$BreakMode| (QUOTE |trapNumerics|)) (EQ TYPE :ERROR)) (SETQ |$BreakMode|
NIL) (
THROW (QUOTE |trapNumerics|) |$numericFailure|)) ((AND (EQ |$BreakMode|
(QUOTE |
trapNumerics|)) (BOUNDP (QUOTE |$oldBreakMode|)) (SETQ |$BreakMode|
|$oldBreakMo
de|) NIL)) ((AND (NULL |$inLispVM|) (MEMQ |$BreakMode| (QUOTE (|nobreak|
|query|
 |resume|)))) (LET ((|$inLispVM| T)) (RETURN (|systemError| (ERROR-FORMAT
ERROR-
STRING ARGS))))) ((EQ |$BreakMode| (QUOTE |letPrint2|)) (SETQ |$BreakMode|
NIL)
(THROW (QUOTE |letPrint2|) NIL)))) (APPLY SYSTEM:UNIVERSAL-ERROR-HANDLER TYPE
CO
RRECTABLE? OP CONTINUE-STRING ERROR-STRING ARGS)))
VS[196]: (LAMBDA-CLOSURE ((ARGS NIL) (ERROR-STRING "Could not connect")
(CONTINU
E-STRING "") (OP LET) (CORRECTABLE? NIL) (TYPE :ERROR)) NIL NIL
(SYSTEM:UNIVERSA
L-ERROR-HANDLER) (BLOCK NIL (SETQ |$NeedToSignalSessionManager| T) (IF (AND
(BOU
NDP (QUOTE |$inLispVM|)) (BOUNDP (QUOTE |$BreakMode|))) (COND ((EQ
|$BreakMode|
(QUOTE |validate|)) (|systemError| (ERROR-FORMAT ERROR-STRING ARGS))) ((AND
(EQ
|$BreakMode| (QUOTE |trapNumerics|)) (EQ TYPE :ERROR)) (SETQ |$BreakMode|
NIL) (
THROW (QUOTE |trapNumerics|) |$numericFailure|)) ((AND (EQ |$BreakMode|
(QUOTE |
trapNumerics|)) (BOUNDP (QUOTE |$oldBreakMode|)) (SETQ |$BreakMode|
|$oldBreakMo
de|) NIL)) ((AND (NULL |$inLispVM|) (MEMQ |$BreakMode| (QUOTE (|nobreak|
|query|
 |resume|)))) (LET ((|$inLispVM| T)) (RETURN (|systemError| (ERROR-FORMAT
ERROR-
STRING ARGS))))) ((EQ |$BreakMode| (QUOTE |letPrint2|)) (SETQ |$BreakMode|
NIL)
(THROW (QUOTE |letPrint2|) NIL)))) (APPLY SYSTEM:UNIVERSAL-ERROR-HANDLER TYPE
CO
RRECTABLE? OP CONTINUE-STRING ERROR-STRING ARGS)))
VS[197]: #<compiled-function SYSTEM:UNIVERSAL-ERROR-HANDLER>
  IHS[33]: (LAMBDA (#) (# # # # ...)) ---> VS[198]
VS[198]: ((SYSTEM:UNIVERSAL-ERROR-HANDLER #<compiled-function
SYSTEM:UNIVERSAL-E
RROR-HANDLER>) (ARGS NIL) (ERROR-STRING "Could not connect") (CONTINUE-STRING
""
) (OP LET) (CORRECTABLE? NIL) (TYPE :ERROR))
VS[199]: NIL
VS[200]: NIL
VS[201]: ((BLOCK NIL (SETQ |$NeedToSignalSessionManager| T) (IF (AND (BOUNDP
(QU
OTE |$inLispVM|)) (BOUNDP (QUOTE |$BreakMode|))) (COND ((EQ |$BreakMode|
(QUOTE
|validate|)) (|systemError| (ERROR-FORMAT ERROR-STRING ARGS))) ((AND (EQ
|$Break
Mode| (QUOTE |trapNumerics|)) (EQ TYPE :ERROR)) (SETQ |$BreakMode| NIL)
(THROW (
QUOTE |trapNumerics|) |$numericFailure|)) ((AND (EQ |$BreakMode| (QUOTE
|trapNum
erics|)) (BOUNDP (QUOTE |$oldBreakMode|)) (SETQ |$BreakMode| |$oldBreakMode|)
NI
L)) ((AND (NULL |$inLispVM|) (MEMQ |$BreakMode| (QUOTE (|nobreak| |query|
|resum
e|)))) (LET ((|$inLispVM| T)) (RETURN (|systemError| (ERROR-FORMAT
ERROR-STRING
ARGS))))) ((EQ |$BreakMode| (QUOTE |letPrint2|)) (SETQ |$BreakMode| NIL)
(THROW
(QUOTE |letPrint2|) NIL)))) (APPLY SYSTEM:UNIVERSAL-ERROR-HANDLER TYPE
CORRECTAB
LE? OP CONTINUE-STRING ERROR-STRING ARGS)))
  IHS[34]: BLOCK ---> VS[202]
VS[202]: ((SYSTEM:UNIVERSAL-ERROR-HANDLER #<compiled-function
SYSTEM:UNIVERSAL-E
RROR-HANDLER>) (ARGS NIL) (ERROR-STRING "Could not connect") (CONTINUE-STRING
""
) (OP LET) (CORRECTABLE? NIL) (TYPE :ERROR))
VS[203]: NIL
VS[204]: ((NIL BLOCK #<@1AE63758>))
VS[205]: #<compiled-function APPLY>
  IHS[35]: #<compiled-function APPLY> ---> VS[206]
VS[206]: #<compiled-function SYSTEM:UNIVERSAL-ERROR-HANDLER>
VS[207]: :ERROR
VS[208]: NIL
VS[209]: LET
VS[210]: ""
VS[211]: "Could not connect"
VS[212]: NIL
  IHS[36]: #<compiled-function APPLY> ---> VS[213]
VS[213]: #<compiled-function SYSTEM:UNIVERSAL-ERROR-HANDLER>
VS[214]: :ERROR
VS[215]: NIL
VS[216]: LET
VS[217]: ""
VS[218]: "Could not connect"
VS[219]: NIL
  IHS[37]: #<compiled-function SYSTEM:UNIVERSAL-ERROR-HANDLER> ---> VS[220]
VS[220]: :ERROR
VS[221]: NIL
VS[222]: LET
VS[223]: ""
VS[224]: "Could not connect"
VS[225]: T
VS[226]: #<compiled-function SYSTEM:UNIVERSAL-ERROR-HANDLER>
VS[227]: :ERROR
VS[228]: NIL
VS[229]: LET
VS[230]: ""
VS[231]: "Could not connect"
VS[232]: NIL
VS[233]: LET
VS[234]: :CONTINUE-STRING
VS[235]: ""
VS[236]: NIL
VS[237]: "Error signalled by ~:@(~S~).~%"
VS[238]: LET
VS[239]: #<string-output stream 1b6030fc>
VS[240]: #S(SERROR::ERROR-CONDITION SERROR::NAME :ERROR STRING "Could not
connec
t" FUNCTION LET SERROR::CONTINUE-STRING "" SERROR::FORMAT-ARGS NIL
SERROR::ERROR
-HANDLER-ARGS (:ERROR NIL LET "" "Could not connect"))
@ IHS[38]: #<compiled-function SYSTEM::BREAK-LEVEL> ---> VS[241]
VS[241]: "Could not connect"
NIL
BOOT>>

\start
Date: Fri, 15 Jun 2007 12:11:25 -0400
From: William Sit
To: Martin Rubey
Subject: re: Hyperdoc
Cc: Camm Maguire

According the Microsoft, after World Wide Web Publishing
started, web pages should be placed in C:\Inetpub\wwwroot.
Is there a patch I can do for hyper.lisp that would change
where files served are located?

"Your Web service is now running.

"You do not currently have a default Web page established
for your users. Any users attempting to connect to your Web
site from another machine are currently receiving an Under
Construction page. Your Web server lists the following files
as possible default Web pages:
default.aspx,default.htm,default.asp,index.htm,iisstart.asp.
Currently, only iisstart.asp exists.

"To add documents to your default Web site, save files in
c:\inetpub\wwwroot\.

\start
Date: Fri, 15 Jun 2007 12:34:43 -0400
From: William Sit
To: Martin Rubey
Subject: re: Hyperdoc
Cc: Camm Maguire

So if anyone knows how to write a cgi script (or other 
script) that reads the URL and communicate with Axiomsys 
so a file can be placed in c:\inetpub\wwwroot (with 
appropriate privileges), then the script can post it?

I assume it is possible to restrict the web access to 
local (trusted) network like a home network.

Or is the Axiomsys to Browser connection independent of 
World Wide Web Publishing?

On Fri, 15 Jun 2007 12:11:25 -0400
  William Sit wrote:
>According the Microsoft, after World Wide Web Publishing
>started, web pages should be placed in 
>C:\Inetpub\wwwroot.
>Is there a patch I can do for hyper.lisp that would 
>change
>where files served are located?
>
>"Your Web service is now running.
>
>"You do not currently have a default Web page established
>for your users. Any users attempting to connect to your 
>Web
>site from another machine are currently receiving an 
>Under
>Construction page. Your Web server lists the following 
>files
>as possible default Web pages:
>default.aspx,default.htm,default.asp,index.htm,iisstart.asp.
>Currently, only iisstart.asp exists.
>
>"To add documents to your default Web site, save files in
>c:\inetpub\wwwroot\.
>
>William
>
>

\start
Date: Fri, 15 Jun 2007 12:58:42 -0400
From: Bill Page
To: William Sit
Subject: re: Hyperdoc
Cc: Camm Maguire

On 6/15/07, William Sit wrote:
> So if anyone knows how to write a cgi script (or other
> script) that reads the URL and communicate with Axiomsys
> so a file can be placed in c:\inetpub\wwwroot (with
> appropriate privileges), then the script can post it?
>

That would be a completely different way of interacting with
Axiom. It has nothing to do with Martin's approach.

> I assume it is possible to restrict the web access to
> local (trusted) network like a home network.
>

The only way to do that is by the use of a local firewall (such
as provided by Windows XP). You will have to configure it
so that only the kind of access you want is allowed.

> Or is the Axiomsys to Browser connection independent of
> World Wide Web Publishing?
>

Martin's "AXIOMsys to Browser connection" is completely
independent of Microsoft'w World Wide Web Publishing software.
It is *not* necessary to use this at all (and if you are not already
using if for other purposes perhaps it should be disabled to
avoid any potential for interference (not likely but possible).

What Martin wrote provides it's own web server that runs entirely
within the AXIOMsys program.

\start
Date: 15 Jun 2007 19:57:16 -0400
From: Camm Maguire
To: Robert Boyer,Warren Hunt
Subject: real and complex floating point on C stack

Greetings!  Just FYI regarding some recent gcl work:

=============================================================================
/tmp/mb.l
=============================================================================
(defconstant +reps+ 10000000)

(let ((f (compile nil (lambda (x) (declare (long-float x)) (dotimes (i +reps+) (let ((z x)) (setq z (cos z)) z))))))
  (time (funcall f 1.0d0)))

(let ((f (compile nil (lambda (x) (declare (long-float x)) (dotimes (i +reps+) (let ((z x)) (setq z (sqrt (exp z)) z (exp (- (* z z)))) z))))))
  (time (funcall f 1.0d0)))

(let ((f (compile nil (lambda (x) (declare (long-float x)) (dotimes (i +reps+) (let ((z x)) (setq z (exp (atan z))) z))))))
  (time (funcall f 1.0d0)))

(let ((f (compile nil (lambda (x) (declare ((complex long-float) x)) (dotimes (i +reps+) (let ((z x)) (setq z (exp (atan z))) z))))))
  (time (funcall f #c(1.0d0 1.0d0))))
=============================================================================
>(load "/tmp/mb.l")

;; Loading /tmp/mb.l
;; Compiling /tmp/gazonk_14798_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_14798_0.o.
;; Loading /tmp/gazonk_14798_0.o
 ;; start address -T 0xaa75e0 ;; Finished loading /tmp/gazonk_14798_0.o
real time       :      0.910 secs
run-gbc time    :      0.920 secs
child run time  :      0.000 secs
gbc time        :      0.000 secs
;; Compiling /tmp/gazonk_14798_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_14798_0.o.
;; Loading /tmp/gazonk_14798_0.o
 ;; start address -T 0xa6f2e0 ;; Finished loading /tmp/gazonk_14798_0.o
real time       :      5.050 secs
run-gbc time    :      5.050 secs
child run time  :      0.000 secs
gbc time        :      0.000 secs
;; Compiling /tmp/gazonk_14798_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_14798_0.o.
;; Loading /tmp/gazonk_14798_0.o
 ;; start address -T 0xaac250 ;; Finished loading /tmp/gazonk_14798_0.o
real time       :      3.010 secs
run-gbc time    :      3.010 secs
child run time  :      0.000 secs
gbc time        :      0.000 secs
;; Compiling /tmp/gazonk_14798_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_14798_0.o.
;; Loading /tmp/gazonk_14798_0.o
 ;; start address -T 0xa6c6e8 ;; Finished loading /tmp/gazonk_14798_0.o
real time       :      5.780 secs
run-gbc time    :      5.770 secs
child run time  :      0.000 secs
gbc time        :      0.000 secs
;; Finished loading /tmp/mb.l
T

>
=============================================================================

GCL is able to infer the types from the above and conclude that a
direct call to the C routine in libm can proceed without boxing.
These are just some examples -- many other such functions have now
been implemented in gcl_mnum.lsp.

\start
Date: Fri, 15 Jun 2007 20:15:51 -0400
From: Camm Maguire
To: Robert Boyer, Warren Hunt
Subject: New dynamic library access in GCL

Greetings!  GCL now has the ability to access arbitrary external
shared library routines in a persitent fashion -- i.e. the binding is
kept across image saves:

=============================================================================
camm@intech19:/fix/t1/camm/debian/gcl/tmp/tmp/foo1$ unixport/saved_gcl
GCL (GNU Common Lisp)  2.7.0 CLtL1    Jun 15 2007 19:45:46
Source License: LGPL(gcl,gmp,pargcl), GPL(unexec,bfd,xgcl)
Binary License:  GPL due to GPL'ed components: (XGCL READLINE BFD UNEXEC)
Modifications of this banner must retain notice of a compatible license
Dedicated to the memory of W. Schelter

Use (help) to get some basic information on how to use GCL.

Temporary directory for compiler files set to /tmp/

>(|libm|:|erf| 1.0)

Error: ERROR "Cannot find the external symbol erf in #<\"libm\" package>."
Fast links are on: do (si::use-fast-links nil) for debugging
Signalled by READ.
ERROR "Cannot find the external symbol erf in #<\"libm\" package>."

Broken at READ.  Type :H for Help.
>:q

>(si::show-lib-syms)

(LIB:|libm| 1074447640 #<"libm" package>) 
(|libm|:|atan| 1094141472 #<compiled-function |libm|:|atan|>) 
(|libm|:|ctan| 1094156208 #<compiled-function |libm|:|ctan|>) 
(|libm|:|csqrt| 1094159152 #<compiled-function |libm|:|csqrt|>) 
(|libm|:|clogf| 1094183232 #<compiled-function |libm|:|clogf|>) 
(|libm|:|acosh| 1094146080 #<compiled-function |libm|:|acosh|>) 
(|libm|:|ccosh| 1094153584 #<compiled-function |libm|:|ccosh|>) 
(|libm|:|expf| 1094176432 #<compiled-function |libm|:|expf|>) 
(|libm|:|atanhf| 1094176064 #<compiled-function |libm|:|atanhf|>) 
(|libm|:|casin| 1094154864 #<compiled-function |libm|:|casin|>) 
(|libm|:|cexpf| 1094181648 #<compiled-function |libm|:|cexpf|>) 
(|libm|:|acosf| 1094175504 #<compiled-function |libm|:|acosf|>) 
(|libm|:|sqrtf| 1094180496 #<compiled-function |libm|:|sqrtf|>) 
(|libm|:|exp| 1094146864 #<compiled-function |libm|:|exp|>) 
(|libm|:|atanh| 1094146512 #<compiled-function |libm|:|atanh|>) 
(|libm|:|ccosf| 1094184128 #<compiled-function |libm|:|ccosf|>) 
(|libm|:|ctanh| 1094156960 #<compiled-function |libm|:|ctanh|>) 
(|libm|:|cosh| 1094146672 #<compiled-function |libm|:|cosh|>) 
(|libm|:|ccoshf| 1094182688 #<compiled-function |libm|:|ccoshf|>) 
(|libm|:|cosf| 1094172320 #<compiled-function |libm|:|cosf|>) 
(|libm|:|atanf| 1094172032 #<compiled-function |libm|:|atanf|>) 
(|libm|:|cos| 1094141792 #<compiled-function |libm|:|cos|>) 
(|libm|:|cacos| 1094157584 #<compiled-function |libm|:|cacos|>) 
(|libm|:|tanh| 1094145584 #<compiled-function |libm|:|tanh|>) 
(|libm|:|ctanf| 1094185024 #<compiled-function |libm|:|ctanf|>) 
(|libm|:|csinhf| 1094182144 #<compiled-function |libm|:|csinhf|>) 
(|libm|:|tanf| 1094175168 #<compiled-function |libm|:|tanf|>) 
(|libm|:|tan| 1094145536 #<compiled-function |libm|:|tan|>) 
(|libm|:|asin| 1094146208 #<compiled-function |libm|:|asin|>) 
(|libm|:|sinh| 1094150832 #<compiled-function |libm|:|sinh|>) 
(|libm|:|csin| 1094155520 #<compiled-function |libm|:|csin|>) 
(|libm|:|sinf| 1094175120 #<compiled-function |libm|:|sinf|>) 
(|libm|:|cabs| 1094152304 #<compiled-function |libm|:|cabs|>) 
(|libm|:|sin| 1094145488 #<compiled-function |libm|:|sin|>) 
(|libm|:|catanhf| 1094187072 #<compiled-function |libm|:|catanhf|>) 
(|libm|:|coshf| 1094176224 #<compiled-function |libm|:|coshf|>) 
(|libm|:|catanh| 1094158672 #<compiled-function |libm|:|catanh|>) 
(|libm|:|fabs| 1094144096 #<compiled-function |libm|:|fabs|>) 
(|libm|:|catanf| 1094183504 #<compiled-function |libm|:|catanf|>) 
(|libm|:|tanhf| 1094175216 #<compiled-function |libm|:|tanhf|>) 
(|libm|:|acoshf| 1094175632 #<compiled-function |libm|:|acoshf|>) 
(|libm|:|asinh| 1094141232 #<compiled-function |libm|:|asinh|>) 
(|libm|:|csinh| 1094152928 #<compiled-function |libm|:|csinh|>) 
(|libm|:|asinhf| 1094171792 #<compiled-function |libm|:|asinhf|>) 
(|libm|:|atan2f| 1094175888 #<compiled-function |libm|:|atan2f|>) 
(|libm|:|asinf| 1094175760 #<compiled-function |libm|:|asinf|>) 
(|libm|:|sinhf| 1094180368 #<compiled-function |libm|:|sinhf|>) 
(|libm|:|atan2| 1094146336 #<compiled-function |libm|:|atan2|>) 
(|libm|:|csinf| 1094184448 #<compiled-function |libm|:|csinf|>) 
(|libm|:|cabsf| 1094181552 #<compiled-function |libm|:|cabsf|>) 
(|libm|:|fabsf| 1094174288 #<compiled-function |libm|:|fabsf|>) 
(|libm|:|casinhf| 1094186160 #<compiled-function |libm|:|casinhf|>) 
(|libm|:|logf| 1094179104 #<compiled-function |libm|:|logf|>) 
(|libm|:|casinh| 1094157680 #<compiled-function |libm|:|casinh|>) 
(|libm|:|clog| 1094154112 #<compiled-function |libm|:|clog|>) 
(|libm|:|casinf| 1094183888 #<compiled-function |libm|:|casinf|>) 
(|libm|:|ctanhf| 1094185616 #<compiled-function |libm|:|ctanhf|>) 
(|libm|:|csqrtf| 1094187472 #<compiled-function |libm|:|csqrtf|>) 
(|libm|:|log| 1094149536 #<compiled-function |libm|:|log|>) 
(|libm|:|cacoshf| 1094186624 #<compiled-function |libm|:|cacoshf|>) 
(|libm|:|cacosh| 1094158144 #<compiled-function |libm|:|cacosh|>) 
(|libm|:|catan| 1094154432 #<compiled-function |libm|:|catan|>) 
(|libm|:|cacosf| 1094186080 #<compiled-function |libm|:|cacosf|>) 
(|libm|:|cexp| 1094152400 #<compiled-function |libm|:|cexp|>) 
(|libm|:|acos| 1094145952 #<compiled-function |libm|:|acos|>) 
(|libm|:|sqrt| 1094150976 #<compiled-function |libm|:|sqrt|>) 
(|libm|:|ccos| 1094155168 #<compiled-function |libm|:|ccos|>) 
(|libm|:|abs| 1090798240 #<compiled-function |libm|:|abs|>) 
(LIB:|libc| 1074448272 #<"libc" package>) 
(|libc|:|setjmp| 1090786864 NIL) 
(|libc|:|feof| 1090993296 NIL) 
(|libc|:|memset| 1091054096 NIL) 
(|libc|:|getc| 1090994720 NIL) 
(|libc|:|bzero| 1091054432 NIL) 
(|libc|:|putc| 1090995664 NIL) 

>(in-package 'compiler)

#<"COMPILER" package>

COMPILER>(defdlfun (:double "erf" "libm.so") :double)

|libm|:|erf|

COMPILER>(compile *)

;; Compiling /tmp/gazonk_18613_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_18613_0.o.
;; Loading /tmp/gazonk_18613_0.o
 ;; start address -T 0xa02000 ;; Finished loading /tmp/gazonk_18613_0.o
#<compiled-function |libm|:|erf|>
NIL
NIL

COMPILER>(|libm|:|erf| 1.0)

0.84270079294971489

COMPILER>(|libm|:|erf| 1.0s0)

Correctable error: TYPE-ERROR :DATUM 1.0S0 :EXPECTED-TYPE LONG-FLOAT NIL
Fast links are on: do (si::use-fast-links nil) for debugging
Signalled by EVAL.
If continued: choose a new value
TYPE-ERROR :DATUM 1.0S0 :EXPECTED-TYPE LONG-FLOAT NIL

Broken at EVAL.  Type :H for Help.
COMPILER>>:q

Top level.
COMPILER>(disassemble '(lambda (x) (|libm|:|erf| x)) nil)

;; Compiling /tmp/gazonk_18613_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_18613_0.o.

#include "gazonk_18613_0.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function CMP-ANON	*/

static object LI1(V2)

object V2;
{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;
	{object V3 = (/* erf */(*LnkLI0)((V2)));VMR1
	(V3);}
	return Cnil;
}
static object  LnkTLI0(object first,...){object V1;va_list ap;va_start(ap,first);V1=(object )call_proc_new(((object)VV[0]),0,0,(void **)(void *)&LnkLI0,1,first,ap);va_end(ap);return V1;} /* erf */
#(#(erf
    (%INIT
     . #((LET ((*DISABLE-RECOMPILE* T))
           (MFSFUN 'CMP-ANON 0 1 0)
           (ADD-HASH 'CMP-ANON '((T) T) '((erf (FLOAT) T))COMPILER
libmerf-
               '/tmp/gazonk_18613_0.lsp))
         (DO-RECOMPILE)))))
static object LI1();
#define VMB1
#define VMS1
#define VMV1
#define VMR1(VMT1) return(VMT1);
#define VM1 0
static void * VVi[2]={
#define Cdata VV[1]
(void *)(LI1)
};
#define VV (VVi)
static object  LnkTLI0(object,...);
static object  (*LnkLI0)() = (object (*)()) LnkTLI0;
NIL

COMPILER>(disassemble '(lambda (x) (declare (long-float x)) (|libm|:|erf| x)) nil)

;; Compiling /tmp/gazonk_18613_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_18613_0.o.

#include "gazonk_18613_0.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function CMP-ANON	*/

static double LI1(V2)

double V2;
{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;
	{double V3 = ((double(*)(double))dlerf)(V2);VMR1
	(V3);}
}
/*	global entry for the function CMP-ANON	*/

static void L1()
{	register object *base=vs_base;
	base[0]=make_longfloat(LI1(lf(base[0])));
	vs_top=(vs_base=base)+1;
}
#(#(NIL
    (%INIT
     . #((MDL 'erf 'libm 1)
         (LET ((*DISABLE-RECOMPILE* T))
           (MF 'CMP-ANON 0)
           (ADD-HASH 'CMP-ANON '((LONG-FLOAT) LONG-FLOAT)
               '((erf (FLOAT) T))
LISPLAMBDA!!,DECLAR,OPTIMIZ,SAFETY
libmerf-
               '/tmp/gazonk_18613_0.lsp))
         (DO-RECOMPILE)))))
static void L1();
static double LI1();
static void *dlerf;
#define VMB1
#define VMS1
#define VMV1
#define VMR1(VMT1) return(VMT1);
#define VM1 0
static void * VVi[2]={
#define Cdata VV[1]
(void *)(L1),
(void *)(&dlerf)
};
#define VV (VVi)
NIL

COMPILER>(funcall (compile nil  '(lambda (x) (|libm|:|erf| x))) 1.0)

;; Compiling /tmp/gazonk_18613_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_18613_0.o.
;; Loading /tmp/gazonk_18613_0.o
 ;; start address -T 0x9e8b08 ;; Finished loading /tmp/gazonk_18613_0.o
0.84270079294971489

COMPILER>(funcall (compile nil  '(lambda (x) (declare (long-float x)) (|libm|:|erf| x))) 1.0)

;; Compiling /tmp/gazonk_18613_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_18613_0.o.
;; Loading /tmp/gazonk_18613_0.o
 ;; start address -T 0xa08948 ;; Finished loading /tmp/gazonk_18613_0.o
0.84270079294971489

COMPILER>(si::save-system "/tmp/h")
camm@intech19:/fix/t1/camm/debian/gcl/tmp/tmp/foo1$ /tmp/h
GCL (GNU Common Lisp)  2.7.0 CLtL1    Jun 15 2007 19:45:46
Source License: LGPL(gcl,gmp,pargcl), GPL(unexec,bfd,xgcl)
Binary License:  GPL due to GPL'ed components: (XGCL READLINE BFD UNEXEC)
Modifications of this banner must retain notice of a compatible license
Dedicated to the memory of W. Schelter

Use (help) to get some basic information on how to use GCL.

Temporary directory for compiler files set to /tmp/

>(|libm|:|erf| 1.0)

0.84270079294971489

>
=============================================================================

Notes: 

0) based on dlopen
1) Not yet tested on static linking
2) Cannot run such functions interpreted for the moment
3) compiling gives both a function with error checking, and an inline
   providing single instuction access through a C pointer where
   possible.
4) Plan on shipping a little blas, maybe mpi and lapack file to be
   optionally loaded in the GCL distribution
5) package LIB contains libary name symbols bound to the dlopen
   address of the library
6) each library has its own package with symbols bound to the external
   function address.
7) symbols are created and linked on .o load if necessary
8) loaded .o code keeps a list of its external pointers in use, which
   are then reset on image re-execution.

\start 
Date: Fri, 15 Jun 2007 20:25:39
From: Camm Maguire 
To: Robert Boyer, Warren Hunt
Subject: GCL and complex arithmetic

Greetings!  GCL now supports unboxed complex arithmetic using the C99
C semantics for complex operations.  THis is precisely akin to the
traditional support for unboxed fixnums, short and double floats.  My
commenst below next to ***:

==========================
==========================
==========================
==
>(disassemble 'sin nil)

;; Compiling /tmp/gazonk_22733_0.lsp.
;; End of Pass 1. 
;; End of Pass 2. 
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_22733_0.o.

#include "gazonk_22733_0.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function SIN	*/

static object LI1(V2)

register object V2;
{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;
	if(!(numberp((V2)))){
	goto T5;}
	goto T3;
	goto T5;
T5:;
	V2= (VFUN_NARGS=4,(/* CHECK-TYPE-SYMBOL */(*LnkLI7)(((object)VV[0]),(V2),((object)VV[1]),Cnil)));
	goto T3;
T3:;
	{register object V4;
	V4= V2;
	/*(CNUM-TYPE X)*/
	{object V6;
	V6= (V4);
	{fixnum V7;
	V7= (fixnum)type_of((V6));
	V8 = V7;
	if(!((V8)!=((fixnum)6))){
	goto T10;}
	V5= V7;
	goto T7;
	goto T10;
T10:;switch((fixnum)type_of(((V6))->cmp.cmp_real)){
	case 4:
	goto T13;
T13:;
	V5= (fixnum)30;
	goto T7;
	case 5:
	goto T14;
T14:;
	V5= (fixnum)31;
	goto T7;
	default:
	goto T15;
T15:;
	V5= (fixnum)6;
	goto T7;
	V5= fix(Cnil);
	goto T7;}
	V5= fix(Cnil);}}
	/* END (CNUM-TYPE X)*/
	goto T7;
T7:;switch(V5){
	case 5:
	goto T18;
T18:;
	{object V9 = make_longfloat(((double(*)(double))dlsin)(lf((V4))));VMR1
	(V9);}
	case 4:
	goto T19;
T19:;
	{object V10 = make_shortfloat(((float(*)(float))dlsinf)(sf((V4))));VMR1
	(V10);}
	case 1:
	goto T20;
T20:;
	case 2:
	goto T21;
T21:;
	case 3:
	goto T22;
T22:;
	/*(FLOAT X 0.0)*/
	{register object V12;
	register double V13;
	V12= (V4);
	V13= lf(((object)VV[2]));
	V13= lf(((object)VV[2]));
	{register object V14;
	V14= (V12);
	/*(CNUM-TYPE X)*/
	{register object V16;
	V16= (V14);
	{register fixnum V17;
	V17= (fixnum)type_of((V16));
	V15= V17;}}
	/* END (CNUM-TYPE X)*/switch(V15){
	case 1:
	goto T43;
T43:;
	V11= (    1.    )*(fix((V14)));
	goto T32;
	case 2:
	goto T44;
T44:;
	{register double V18;
	V18= big_to_double((V14));
	V11= V18;
	goto T32;}
	case 3:
	goto T45;
T45:;
	{register double V19;
	base[0]= (V14);
	vs_top=(vs_base=base+0)+1;
	(void) (*Lnk8)();
	vs_top=sup;
	V19= lf(({register object _z=vs_base[0];_z;}));
	V11= V19;
	goto T32;}
	V11= lf(Cnil);
	goto T32;}
	V11= lf(Cnil);}}
	/* END (FLOAT X 0.0)*/
	goto T32;
T32:;
	{object V20 = make_longfloat(((double(*)(double))dlsin)(V11));VMR1
	(V20);}
	case 31:
	goto T23;
T23:;   *** lfc/sfc are C macros unboxing a complex from the lisp object
	{object V21 = make_dcomplex(((dcomplex(*)(dcomplex))dlcsin)(lfc((V4))));VMR1
	(V21);}
	case 30:
	goto T24;
T24:;
	{object V22 = make_fcomplex(((fcomplex(*)(fcomplex))dlcsinf)(sfc((V4))));VMR1
	(V22);}
	default:
	goto T25;
T25:;
	/*(FLOAT (REALPART X) 0.0)*/
	{register object V24;
	register double V25;
	{object V26;
	/*(REALPART X)*/
	{register object V27;
	V27= (V4);
	{register object V28;
	V28= (V27);
	/*(CNUM-TYPE X)*/
	{register object V29;
	V29= (V28);switch((fixnum)type_of(((V29))->cmp.cmp_real)){
	default:
	goto T70;
T70:;
	goto T68;
	goto T68;}}
	/* END (CNUM-TYPE X)*/
	goto T68;
T68:;
	V26= ((V28))->cmp.cmp_real;}}
	/* END (REALPART X)*/
	V24=V26;}
	V25= lf(((object)VV[2]));
	V25= lf(((object)VV[2]));
	{register object V30;
	V30= (V24);
	/*(CNUM-TYPE X)*/
	{register object V16;
	V16= (V30);
	{register fixnum V17;
	V17= (fixnum)type_of((V16));
	V31= V17;}}
	/* END (CNUM-TYPE X)*/switch(V31){
	case 1:
	goto T84;
T84:;
	V23= (    1.    )*(fix((V30)));
	goto T63;
	case 2:
	goto T85;
T85:;
	{register double V32;
	V32= big_to_double((V30));
	V23= V32;
	goto T63;}
	case 3:
	goto T86;
T86:;
	{register double V33;
	base[0]= (V30);
	vs_top=(vs_base=base+0)+1;
	(void) (*Lnk8)();
	vs_top=sup;
	V33= lf(({register object _z=vs_base[0];_z;}));
	V23= V33;
	goto T63;}
	V23= lf(Cnil);
	goto T63;}
	V23= lf(Cnil);}}
	/* END (FLOAT (REALPART X) 0.0)*/
	goto T63;
T63:;
	/*(FLOAT (IMAGPART X) 0.0)*/
	{register object V35;
	register double V36;
	{object V37;
	/*(IMAGPART X)*/
	{register object V38;
	V38= (V4);
	{register object V39;
	V39= (V38);
	/*(CNUM-TYPE X)*/
	{register object V29;
	V29= (V39);switch((fixnum)type_of(((V29))->cmp.cmp_real)){
	default:
	goto T104;
T104:;
	goto T102;
	goto T102;}}
	/* END (CNUM-TYPE X)*/
	goto T102;
T102:;
	V37= ((V39))->cmp.cmp_imag;}}
	/* END (IMAGPART X)*/
	V35=V37;}
	V36= lf(((object)VV[2]));
	V36= lf(((object)VV[2]));
	{register object V40;
	V40= (V35);
	/*(CNUM-TYPE X)*/
	{register object V16;
	V16= (V40);
	{register fixnum V17;
	V17= (fixnum)type_of((V16));
	V41= V17;}}
	/* END (CNUM-TYPE X)*/switch(V41){
	case 1:
	goto T118;
T118:;
	V34= (    1.    )*(fix((V40)));
	goto T97;
	case 2:
	goto T119;
T119:;
	{register double V42;
	V42= big_to_double((V40));
	V34= V42;
	goto T97;}
	case 3:
	goto T120;
T120:;
	{register double V43;
	base[0]= (V40);
	vs_top=(vs_base=base+0)+1;
	(void) (*Lnk8)();
	vs_top=sup;
	V43= lf(({register object _z=vs_base[0];_z;}));
	V34= V43;
	goto T97;}
	V34= lf(Cnil);
	goto T97;}
	V34= lf(Cnil);}}
	/* END (FLOAT (IMAGPART X) 0.0)*/
	goto T97;
T97:;   *** V23 + I * V34 is the C expression generating the complex
        *** from two reals
	{object V44 = make_dcomplex(((dcomplex(*)(dcomplex))dlcsin)((V23 + I * V34)));VMR1
	(V44);}
	{object V45 = Cnil;VMR1
	(V45);}}
	{object V46 = Cnil;VMR1
	(V46);}}
	base[0]=base[0];
	return Cnil;
}
static void LnkT8(){ call_or_link(((object)VV[8]),0,(void **)(void *)&Lnk8);} /* RATIO-TO-DOUBLE */
static object  LnkTLI7(object first,...){object V1;va_list ap;va_start(ap,first);V1=(object )call_vproc_new(((object)VV[7]),0,0,(void **)(void *)&LnkLI7,first,ap);va_end(ap);return V1;} /* CHECK-TYPE-SYMBOL */
#(#(X NUMBER NIL (OR NULL FLOAT) REAL SHORT-FLOAT 1.0 CHECK-TYPE-SYMBOL
    RATIO-TO-DOUBLE
    (%INIT
     . #((MDL 'sin 'libm 1) (MDL 'sinf 'libm 2) (MDL 'csin 'libm 3)
         (MDL 'csinf 'libm 4)
         (LET ((*DISABLE-RECOMPILE* T))
           (SETVV 2 (* 0.0 LEAST-POSITIVE-LONG-FLOAT))
           (MFSFUN 'SIN 0 1 0)
           (ADD-HASH 'SIN
               '((NUMBER)
                 (OR (LONG-FLOAT -1.0 1.0) (SHORT-FLOAT -1.0S0 1.0S0)
                     FCOMPLEX DCOMPLEX))
               '((IMAGPART (NUMBER) REAL) (REALPART (NUMBER) REAL)
                 (COMPLEX (*) *) (csinf (NUMBER) T) (csin (NUMBER) T)
                 (FLOAT (REAL *) FLOAT) (sinf (FLOAT) T)
                 (sin (FLOAT) T) (CNUM-TYPE (T) (INTEGER 0 31))
                 (CHECK-TYPE-SYMBOL (T T T *) T) (NUMBERP (T) BOOLEAN)
                 (TYPEP (T T *) T))
=06SYSTEM=07,DECLAR,OPTIMIZ=06,SAFETY=01=09
,CHECK-TYPE-=06,NUMBER	=05,BLOCK=03,SIN	=03,LET--=06=04,CAS	.CNUM-TYPE-	=07=05	=A1=04,SETQ-	!=03,THE!
=04libmsin-	=07=04	=AF=AD	=B0=A1=0B,SHORT-FLOAT=043sinf-		=01=02=03	=AF=AD	=B0=A1=AC=D2=C1=D4=C9=CF=CE=C1=CC=B2	=A1=05,FLOAT-=1D0.0)	=07=1F	=AF=AD	=B0=A1=AE=C4=C3=CF=CD=D0=CC=C5=D8=A1=043csin-	=07=1E	=AF=AD	=B0=A1=AE=C6=C3=CF=CD=D0=CC=C5=D8=053csinf-		,OTHERWISE	/-	=03,NOT=06=02,OR97541=028	=07,COMPLEX	,REALPART-=1D0.0)	,IMAGPART-=1D0.0)=02=02=18
               '/tmp/gazonk_22733_0.lsp))
         (DO-RECOMPILE)))))
static object LI1();
static void *dlsin;
static void *dlsinf;
static void *dlcsin;
static void *dlcsinf;
#define VMB1 register object *base=vs_top; fixnum  V41; double  V34; fixnum  V31; double  V23; fixnum  V15; double  V11; fixnum  V8; fixnum  V5;
#define VMS1 register object *sup=vs_top+1;vs_top=sup;
#define VMV1 vs_check;
#define VMR1(VMT1) vs_top=base ; return(VMT1);
#define VM1 1
static void * VVi[10]={
#define Cdata VV[9]
(void *)(LI1),
(void *)(&dlsin),
(void *)(&dlsinf),
(void *)(&dlcsin),
(void *)(&dlcsinf)
};
#define VV (VVi)
static void LnkT8();
static void (*Lnk8)() = LnkT8;
static object  LnkTLI7(object,...);
static object  (*LnkLI7)() = (object (*)()) LnkTLI7;
NIL

>(disassemble '(lambda (x y z) (declare (long-float z)((complex long-float) x y)) (* z (+ z (* x (+ x y))))) nil)

;; Compiling /tmp/gazonk_22733_1.lsp.
;; End of Pass 1. 
;; End of Pass 2. 
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_22733_1.o.

#include "gazonk_22733_1.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function CMP-ANON	*/

static dcomplex LI1(V4,V5,V6)

dcomplex V4;dcomplex V5;double V6;
{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;   *** unboxed C multiplication etc.
	{dcomplex V7 = (V6)*((V6)+((V4)*((V4)+(V5))));VMR1
	(V7);}
}
/*	global entry for the function CMP-ANON	*/

static void L1()
{	register object *base=vs_base;
	base[0]=make_dcomplex(LI1(lfc(base[0]),lfc(base[1]),lf(base[2])));
	vs_top=(vs_base=base)+1;
}
#(#((%INIT
     . #((LET ((*DISABLE-RECOMPILE* T))
           (MF 'CMP-ANON 0)
           (ADD-HASH 'CMP-ANON
               '((DCOMPLEX DCOMPLEX LONG-FLOAT) DCOMPLEX)
               '((+ (*) T) (* (*) T))
=04LISPLAMBDA	!=0C=01X!=0C=01Y!=0C=01!=07,DECLAR,OPTIMIZ=06,SAFETY=00	=A1COMPILERCMP-ANON	!=01,*/	!=01,+/	3-	4-.=02=18
               '/tmp/gazonk_22733_1.lsp))
         (DO-RECOMPILE)))))
static void L1();
static dcomplex LI1();
#define VMB1
#define VMS1
#define VMV1
#define VMR1(VMT1) return(VMT1);
#define VM1 0
static void * VVi[1]={
#define Cdata VV[0]
(void *)(L1)
};
#define VV (VVi)
NIL

\start
Date: Sat, 16 Jun 2007 03:00:25 +0200 (CEST)
From: Waldek Hebisch
To: Bill Page
Subject: Re: [Axiom-mail] A slow summation
Cc: Camm Maguire, list

Bill Page wrote:
> On 6/15/07, Waldek Hebisch wrote:
> > On my machine, I get the following (on the second run, to
> > exclude time for loading):
> >
> >                                       gcl      sbcl          sbcl
> >                                              interpreted  compiled
> >  reduce(+,[1.0/i for i in 1..20000])   8.70      1.76        0.17
> >  [i for i in 1..20000];                6.23      0.78        0.01
> >  expand(1..20000);                     0         0.004       0.01
> >
> > Comment: sbcl evaluator has two modes of operation: interpreted
> > and compiled.  In compiled mode the code is first compiled and
> > then the resulting machine code is run.  One can switch mode
> > setting variable sb-ext:*evaluator-mode*:
> >
> > )lisp (setf sb-ext:*evaluator-mode* :compile)
> >
> > or
> >
> > )lisp (setf sb-ext:*evaluator-mode* :interpret)
> >
> > sbcl profiler showed that 98% of time were spent in Lisp evaluator,
> > and that agrees very well with getting much higher speed using
> > compiled mode.
> >
> 
> Waldek, thank you very much for running this comparison!
> 
> So, the conclusion might be that I was wrong: the slowness *is*
> because of the way that Axiom interpreter runs this code in
> interpreted mode in GCL, right? It could still be that this interpreted
> Lisp code is not written in an optimal manner.
>

It seems that the code is suboptimal and probably wrong.  IIUC
in:

 [1.0/i for i in 1..20000]

i should be local.  But Lisp code generated by Axiom accesses global
Lisp variable i.  Making variables local may speed up this code.
But OTOH compiled code is reasonably fast, and both sbcl and
clisp show that the code can be interpreted few times faster.
 
> Maybe it is possible in GCL with some additional coding to also
> convince GCL to compile the code first before executing it?
> I know that Axiom includes the command:
> 
>   )set function compile on/off
> 
> that affects compilation of user defined functions in the interpreter.
> Perhaps this can be extended to the [... for ... ] case?
> 

Well, I think it is not hard to compile _everything_.  But compilation
not always wins, one has to add compile time to execution time
and especially with GCL compilation may take substantial time.
For one-shot code (executed just once, without loops) compilation
will almost certainly loose.  Axiom generate a lot of such
one-shot pieces of code and evaluates them.  So it is not clear
if compilation is better.  In fact, I switched sbcl to use
interpreted mode, because this gives significant savings during
bootstrap...

BTW: one can see effect of compilation in GCL using alternate
formulation of the problem.  Namely, Axiom compiles recurence
relations.  So one can define the following reccurence relations:

f(1, a) == 1.0 + a
f(n, a) == f(n - 1, a + 1.0/n)

and then call:

f(20000, 0.0)

\start
Date: Fri, 15 Jun 2007 21:10:09 -0400
From: Camm Maguire
To: Robert Boyer, Warren Hunt
Subject: GCL and source inlining

Greetings!  Thanks to the suggestion of R. Boyer, GCL now stores a
string containing the compressed source for each compiled function it
loads in memory.  This now allows inlining to work:
=============================================================================
>(defun foo (x) x)

FOO

>(defun bar (x) (declare (inline foo)) (foo x))

BAR

>(defun baz (x)  (foo x))

BAZ

>(compile 'foo)

;; Compiling /tmp/gazonk_22733_1.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_22733_1.o.
;; Loading /tmp/gazonk_22733_1.o
 ;; start address -T 0xa08798 ;; Finished loading /tmp/gazonk_22733_1.o
#<compiled-function FOO>
NIL
NIL

>(disassemble 'baz)
*** output flushed ***
>(disassemble 'baz nil)

;; Compiling /tmp/gazonk_22733_1.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_22733_1.o.

#include "gazonk_22733_1.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function BAZ	*/

static object LI1(V2)

object V2;
{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;
	{object V3 = (/* FOO */(*LnkLI0)((V2)));VMR1
	(V3);}
	return Cnil;
}
static object  LnkTLI0(object first,...){object V1;va_list ap;va_start(ap,first);V1=(object )call_proc_new(((object)VV[0]),0,0,(void **)(void *)&LnkLI0,1,first,ap);va_end(ap);return V1;} /* FOO */
#(#(FOO
    (%INIT
     . #((LET ((*DISABLE-RECOMPILE* T))
           (MFSFUN 'BAZ 0 1 0)
           (ADD-HASH 'BAZ '((T) T) '((FOO (T) T))
USER
LISPLAMBDA!,DECLAR,OPTIMIZ,SAFETY 	,BLOCKBAFOO-
               '/tmp/gazonk_22733_1.lsp))
         (DO-RECOMPILE)))))
static object LI1();
#define VMB1
#define VMS1
#define VMV1
#define VMR1(VMT1) return(VMT1);
#define VM1 0
static void * VVi[2]={
#define Cdata VV[1]
(void *)(LI1)
};
#define VV (VVi)
static object  LnkTLI0(object,...);
static object  (*LnkLI0)() = (object (*)()) LnkTLI0;
NIL

>(disassemble 'bar nil)

;; Compiling /tmp/gazonk_22733_1.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_22733_1.o.

#include "gazonk_22733_1.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function BAR	*/

static object LI1(V2)

object V2;
{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;
	/*(FOO X)*/
	{object V3;
	V3= (V2);
	{object V4 = (V3);VMR1
	(V4);}}
	/* END (FOO X)*/
	return Cnil;
}
#(#((%INIT
     . #((LET ((*DISABLE-RECOMPILE* T))
           (MFSFUN 'BAR 0 1 0)
           (ADD-HASH 'BAR '((T) T) '((FOO (T) T))
LISPLAMBDA!!,DECLAR,OPTIMIZ,SAFETY,INLINE!FOO	,BLOCKBA/-
               '/tmp/gazonk_22733_1.lsp))
         (DO-RECOMPILE)))))
static object LI1();
#define VMB1
#define VMS1
#define VMV1
#define VMR1(VMT1) return(VMT1);
#define VM1 0
static void * VVi[1]={
#define Cdata VV[0]
(void *)(LI1)
};
#define VV (VVi)
NIL

>(declaim (inline foo))

NIL

>(disassemble 'baz nil)

;; Compiling /tmp/gazonk_22733_1.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_22733_1.o.

#include "gazonk_22733_1.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function BAZ	*/

static object LI1(V2)

object V2;
{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;
	/*(FOO X)*/
	{object V3;
	V3= (V2);
	{object V4 = (V3);VMR1
	(V4);}}
	/* END (FOO X)*/
	return Cnil;
}
#(#((%INIT
     . #((LET ((*DISABLE-RECOMPILE* T))
           (MFSFUN 'BAZ 0 1 0)
           (ADD-HASH 'BAZ '((T) T) '((FOO (T) T))
USER
LISPLAMBDA!,DECLAR,OPTIMIZ,SAFETY 	,BLOCKBAFOO-
               '/tmp/gazonk_22733_1.lsp))
         (DO-RECOMPILE)))))
static object LI1();
#define VMB1
#define VMS1
#define VMV1
#define VMR1(VMT1) return(VMT1);
#define VM1 0
static void * VVi[1]={
#define Cdata VV[0]
(void *)(LI1)
};
#define VV (VVi)
NIL

>
============================================================================= 

This also facilitates a significant simplification in the compiler.
Instead of writing several C inlines, a type propagator, and
compiler-macro, etc. for each function, all of these can be reduced to
primitives via trial source inlining, whether such inlining is
actually used or not.  Needless to say, the compiler does not yet have
a well-defined tiny set of opaque primitives and maybe never will
have, but many performance critical compiler macros have been
replaced.  External symbols in lisp or explicitly declared declaimed
symbols are potentially inlineable.  Inlining is skipped if *speed* is
0, inlined source is computed (for type propagation purposes) but not
used if 3 minus the *space* setting exceeds some measure of the inline
size.  Type checking in the source is elided if the ambient safety is
0.  C comments delineate the action:

=============================================================================
COMPILER>(disassemble '(lambda (x) (declare (optimize (safety 1)))(endp x)) nil)

;; Compiling /tmp/gazonk_22733_3.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_22733_3.o.

#include "gazonk_22733_3.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function CMP-ANON	*/

static object LI1(V2)

object V2;
{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;
	/*(ENDP X)*/
	{register object V3;
	V3= (V2);
	if(!(listp((V3)))){
	goto T5;}
	goto T3;
	goto T5;
T5:;
	V3= (VFUN_NARGS=4,(/* CHECK-TYPE-SYMBOL */(*LnkLI2)(((object)VV[0]),(V3),((object)VV[1]),Cnil)));
	goto T3;
T3:;
	{object V4;
	V4= (V3);
	{object V5 = (((V4))==Cnil?Ct:Cnil);VMR1
	(V5);}}}
	/* END (ENDP X)*/
	return Cnil;
}
static object  LnkTLI2(object first,...){object V1;va_list ap;va_start(ap,first);V1=(object )call_vproc_new(((object)VV[2]),0,0,(void **)(void *)&LnkLI2,first,ap);va_end(ap);return V1;} /* CHECK-TYPE-SYMBOL */
#(#(X LIST CHECK-TYPE-SYMBOL
    (%INIT
     . #((LET ((*DISABLE-RECOMPILE* T))
           (MFSFUN 'CMP-ANON 0 1 0)
           (ADD-HASH 'CMP-ANON '((T) BOOLEAN) '((ENDP (LIST) BOOLEAN))COMPILER
LISPLAMBDA!,DECLAR,OPTIMIZ,SAFETY	,BLOCKCMP-ANO,ENDP-
               '/tmp/gazonk_22733_3.lsp))
         (DO-RECOMPILE)))))
static object LI1();
#define VMB1
#define VMS1
#define VMV1
#define VMR1(VMT1) return(VMT1);
#define VM1 0
static void * VVi[4]={
#define Cdata VV[3]
(void *)(LI1)
};
#define VV (VVi)
static object  LnkTLI2(object,...);
static object  (*LnkLI2)() = (object (*)()) LnkTLI2;
NIL

COMPILER>(disassemble '(lambda (x) (endp x)) nil)

;; Compiling /tmp/gazonk_22733_3.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_22733_3.o.

#include "gazonk_22733_3.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function CMP-ANON	*/

static object LI1(V2)

object V2;
{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;
	/*(ENDP X)*/
	{register object V3;
	V3= (V2);
	{object V4 = (((V3))==Cnil?Ct:Cnil);VMR1
	(V4);}}
	/* END (ENDP X)*/
	return Cnil;
}
#(#((%INIT
     . #((LET ((*DISABLE-RECOMPILE* T))
           (MFSFUN 'CMP-ANON 0 1 0)
           (ADD-HASH 'CMP-ANON '((T) BOOLEAN) '((ENDP (LIST) BOOLEAN))COMPILER
LISPLAMBDA!,DECLAR,OPTIMIZ,SAFETY 	,BLOCKCMP-ANO,ENDP-
               '/tmp/gazonk_22733_3.lsp))
         (DO-RECOMPILE)))))
static object LI1();
#define VMB1
#define VMS1
#define VMV1
#define VMR1(VMT1) return(VMT1);
#define VM1 0
static void * VVi[1]={
#define Cdata VV[0]
(void *)(LI1)
};
#define VV (VVi)
NIL

COMPILER>(disassemble '(lambda (x) (endp nil)) nil)

;; Compiling /tmp/gazonk_22733_3.lsp.
; (DEFUN CMP-ANON ...) is being compiled.
;; Warning: The variable X is not used.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_22733_3.o.

#include "gazonk_22733_3.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function CMP-ANON	*/

static object LI1(V2)

object V2;
{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;
	/*(ENDP NIL)*/
	{object V3 = Ct;VMR1
	(V3);}
	/* END (ENDP NIL)*/
	return Cnil;
}
#(#((%INIT
     . #((LET ((*DISABLE-RECOMPILE* T))
           (MFSFUN 'CMP-ANON 0 1 0)
           (ADD-HASH 'CMP-ANON '((T) BOOLEAN) '((ENDP (LIST) BOOLEAN))COMPILER
LISPLAMBDA,DECLAR,OPTIMIZ,SAFETY 	,BLOCKCMP-ANO,ENDP 
               '/tmp/gazonk_22733_3.lsp))
         (DO-RECOMPILE)))))
static object LI1();
#define VMB1
#define VMS1
#define VMV1
#define VMR1(VMT1) return(VMT1);
#define VM1 0
static void * VVi[1]={
#define Cdata VV[0]
(void *)(LI1)
};
#define VV (VVi)
NIL

>(disassemble '(lambda (x y) (member x y)) nil)

;; Compiling /tmp/gazonk_22733_1.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_22733_1.o.

#include "gazonk_22733_1.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function CMP-ANON	*/

static object LI1(V3,V4)

object V3;object V4;
{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;
	/*(MEMBER X Y)*/
	{register object V5;
	object V6;
	V5= (V3);
	V6= (V4);
	{register fixnum V7;
	if(!(eql_is_eq((V5)))){
	goto T4;}
	V7= (fixnum)0;
	goto T2;
	goto T4;
T4:;
	V7= (fixnum)2;
	goto T2;
T2:;
	{register object V8;
	V8= (V6);
	goto T7;
T7:;
	/*(ENDP LIST)*/
	{register object V9;
	V9= (V8);
	if(((V9))==Cnil){
	goto T10;}}
	/* END (ENDP LIST)*/
	{register fixnum V10;
	register object V11;
	register object V12;
	V10= V7;
	V11= (V5);
	{register object V13;
	V13= CMPcar((V8));
	V12= (V13);}switch(V10){
	case 0:
	goto T20;
T20:;
	if(!(((V11))==((V12)))){
	goto T13;}
	goto T15;
	case 2:
	goto T21;
T21:;
	if(!(eql((V11),(V12)))){
	goto T13;}
	goto T15;
	goto T13;}
	goto T13;}
	goto T15;
T15:;
	{object V14 = (V8);VMR1
	(V14);}
	goto T13;
T13:;
	{register object V15;
	V15= CMPcdr((V8));
	V8= (V15);}
	goto T7;
	goto T10;
T10:;
	{object V16 = Cnil;VMR1
	(V16);}
	{object V17 = Cnil;VMR1
	(V17);}}}}
	/* END (MEMBER X Y)*/
	return Cnil;
}

>(disassemble '(lambda (x y)(declare (optimize (safety 1))) (member x y)) nil)

;; Compiling /tmp/gazonk_22733_1.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_22733_1.o.

#include "gazonk_22733_1.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function CMP-ANON	*/

static object LI1(V3,V4)

object V3;object V4;
{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;
	/*(MEMBER X Y)*/
	{register object V5;
	register object V6;
	V5= (V3);
	V6= (V4);
	if(((/* PROPER-LISTP */(*LnkLI2)((V6))))==Cnil){
	goto T5;}
	goto T3;
	goto T5;
T5:;
	V6= (VFUN_NARGS=4,(/* CHECK-TYPE-SYMBOL */(*LnkLI3)(((object)VV[0]),(V6),((object)VV[1]),Cnil)));
	goto T3;
T3:;
	{object V7;
	V7= (V6);
	{register fixnum V8;
	if(!(eql_is_eq((V5)))){
	goto T10;}
	V8= (fixnum)0;
	goto T8;
	goto T10;
T10:;
	V8= (fixnum)2;
	goto T8;
T8:;
	{register object V9;
	V9= (V7);
	goto T13;
T13:;
	/*(ENDP LIST)*/
	{register object V10;
	V10= (V9);
	if(((V10))==Cnil){
	goto T16;}}
	/* END (ENDP LIST)*/
	{register fixnum V11;
	register object V12;
	register object V13;
	V11= V8;
	V12= (V5);
	{register object V14;
	V14= CMPcar((V9));
	V13= (V14);}switch(V11){
	case 0:
	goto T26;
T26:;
	if(!(((V12))==((V13)))){
	goto T19;}
	goto T21;
	case 2:
	goto T27;
T27:;
	if(!(eql((V12),(V13)))){
	goto T19;}
	goto T21;
	goto T19;}
	goto T19;}
	goto T21;
T21:;
	{object V15 = (V9);VMR1
	(V15);}
	goto T19;
T19:;
	{register object V16;
	V16= CMPcdr((V9));
	V9= (V16);}
	goto T13;
	goto T16;
T16:;
	{object V17 = Cnil;VMR1
	(V17);}
	{object V18 = Cnil;VMR1
	(V18);}}}}}
	/* END (MEMBER X Y)*/
	return Cnil;
}
static object  LnkTLI3(object first,...){object V1;va_list ap;va_start(ap,first);V1=(object )call_vproc_new(((object)VV[3]),0,0,(void **)(void *)&LnkLI3,first,ap);va_end(ap);return V1;} /* CHECK-TYPE-SYMBOL */
static object  LnkTLI2(object first,...){object V1;va_list ap;va_start(ap,first);V1=(object )call_proc_new(((object)VV[2]),0,0,(void **)(void *)&LnkLI2,1,first,ap);va_end(ap);return V1;} /* PROPER-LISTP */
#(#(LIST PROPER-LIST PROPER-LISTP CHECK-TYPE-SYMBOL
    (%INIT
     . #((LET ((*DISABLE-RECOMPILE* T))
           (MFSFUN 'CMP-ANON 0 2 0)
           (ADD-HASH 'CMP-ANON '((T T) PROPER-LIST)
               '((MEMBER (T PROPER-LIST *) PROPER-LIST))
USERCOMPILERCMP-ANON	,MEMBER-.
               '/tmp/gazonk_22733_1.lsp))
         (DO-RECOMPILE)))))
static object LI1();
#define VMB1
#define VMS1
#define VMV1
#define VMR1(VMT1) return(VMT1);
#define VM1 0
static void * VVi[5]={
#define Cdata VV[4]
(void *)(LI1)
};
#define VV (VVi)
static object  LnkTLI3(object,...);
static object  (*LnkLI3)() = (object (*)()) LnkTLI3;
static object  LnkTLI2(object,...);
static object  (*LnkLI2)() = (object (*)()) LnkTLI2;
NIL

>(disassemble '(lambda (x y)(declare (optimize (safety 1))) (member x y :test 'eq)) nil)

;; Compiling /tmp/gazonk_22733_1.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_22733_1.o.

#include "gazonk_22733_1.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function CMP-ANON	*/

static object LI1(V3,V4)

object V3;object V4;
{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;
	/*(MEMBER X Y TEST 'EQ)*/
	{register object V5;
	register object V6;
	V5= (V3);
	V6= (V4);
	if(((/* PROPER-LISTP */(*LnkLI6)((V6))))==Cnil){
	goto T5;}
	goto T3;
	goto T5;
T5:;
	V6= (VFUN_NARGS=4,(/* CHECK-TYPE-SYMBOL */(*LnkLI7)(((object)VV[4]),(V6),((object)VV[5]),Cnil)));
	goto T3;
T3:;
	{object V7;
	V7= (V6);
	{register object V8;
	V8= (V7);
	goto T9;
T9:;
	/*(ENDP LIST)*/
	{register object V9;
	V9= (V8);
	if(((V9))==Cnil){
	goto T12;}}
	/* END (ENDP LIST)*/
	{register object V10;
	register object V11;
	V10= (V5);
	{register object V12;
	V12= CMPcar((V8));
	V11= (V12);}
	if(!(((V10))==((V11)))){
	goto T15;}}
	{object V13 = (V8);VMR1
	(V13);}
	goto T15;
T15:;
	{register object V14;
	V14= CMPcdr((V8));
	V8= (V14);}
	goto T9;
	goto T12;
T12:;
	{object V15 = Cnil;VMR1
	(V15);}
	{object V16 = Cnil;VMR1
	(V16);}}}}
	/* END (MEMBER X Y TEST 'EQ)*/
	return Cnil;
}
static object  LnkTLI7(object first,...){object V1;va_list ap;va_start(ap,first);V1=(object )call_vproc_new(((object)VV[7]),0,0,(void **)(void *)&LnkLI7,first,ap);va_end(ap);return V1;} /* CHECK-TYPE-SYMBOL */
static object  LnkTLI6(object first,...){object V1;va_list ap;va_start(ap,first);V1=(object )call_proc_new(((object)VV[6]),0,0,(void **)(void *)&LnkLI6,1,first,ap);va_end(ap);return V1;} /* PROPER-LISTP */
#(#(TEST EQ KEY TEST-NOT LIST PROPER-LIST PROPER-LISTP
    CHECK-TYPE-SYMBOL
    (%INIT
     . #((LET ((*DISABLE-RECOMPILE* T))
           (MFSFUN 'CMP-ANON 0 2 0)
           (ADD-HASH 'CMP-ANON '((T T) PROPER-LIST)
               '((MEMBER (T PROPER-LIST *) PROPER-LIST))
USER
KEYWORDTES,QUOTE,EQ
               '/tmp/gazonk_22733_1.lsp))
         (DO-RECOMPILE)))))
static object LI1();
#define VMB1
#define VMS1
#define VMV1
#define VMR1(VMT1) return(VMT1);
#define VM1 0
static void * VVi[9]={
#define Cdata VV[8]
(void *)(LI1)
};
#define VV (VVi)
static object  LnkTLI7(object,...);
static object  (*LnkLI7)() = (object (*)()) LnkTLI7;
static object  LnkTLI6(object,...);
static object  (*LnkLI6)() = (object (*)()) LnkTLI6;
NIL

>
=============================================================================

Many of the functions are written with &rest and apply, unlike the
compiler macros which could make use of explicit argument counting.
The &rest args are mostly done with :dynamic-extent with apply binding
directly to the rest arg where appropriate.  But GCL can also count
some list lengths and change the apply to a funcall:

=============================================================================
COMPILER>(untrace)(disassemble '(lambda (x) (mapc '+ x x)) nil)

NIL

COMPILER>
;; Compiling /tmp/gazonk_22733_3.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_22733_3.o.

#include "gazonk_22733_3.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function CMP-ANON	*/

static object LI1(V2)

object V2;
{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;
	/*(MAPC '+ X X)*/
	{register object V3;
	object V4;
	register object V5;
	V3= (V2);
	V4= (V2);
	V5= 
	!1? Cnil : (alloca_val=alloca((1)*sizeof(struct cons)+sizeof(object)),
	({object _b=(void *)alloca_val;if (((unsigned long)_b)&sizeof(_b)) _b++;
	{register struct cons *_p=(void *)_b;
	_p->c_car=(V4);_p->c_cdr=(object)(_p+1);_p++;
	_p[-1].c_cdr=Cnil;}_b;}));
	{register object V6;
	register object V7;
	/*(LIST-LENGTH L)*/
	{register object V9;
	V9= (V5);
	/*(ENDP (SETQ L (CDR L)))*/
	{object V10;
	V9= CMPcdr(Cnil);
	V10= (V9);}
	/* END (ENDP (SETQ L (CDR L)))*/
	V8= (fixnum)1;}
	/* END (LIST-LENGTH L)*/
	V7= 
	!V8? Cnil : (alloca_val=alloca((V8)*sizeof(struct cons)+sizeof(object)),
	({object _b=(void *)alloca_val;if (((unsigned long)_b)&sizeof(_b)) _b++;
	{register struct cons *_p=(void *)_b;
	{struct cons *_e=_p+(V8-1);
	for (;_p<_e;_p++) {_p->c_car=Cnil;_p->c_cdr=(object)(_p+1);}} _p->c_car=_p->c_cdr=Cnil;}_b;}));
	V6= (V3);
	goto T8;
T8:;
	/*(ENDP L1)*/
	{register object V11;
	V11= (V3);
	if(((V11))==Cnil){
	goto T11;}}
	/* END (ENDP L1)*/
	/*(MEMBER-IF 'ENDP L)*/
	{register object V12;
	V12= (V5);
	/*(MEMBER ITEM LIST TEST 'FUNCALL KEY KEY)*/
	{register object V13;
	V13= (V12);
	{register object V14;
	V14= (V13);
	goto T20;
T20:;
	/*(ENDP LIST)*/
	{register object V11;
	V11= (V14);
	if(((V11))==Cnil){
	goto T23;}}
	/* END (ENDP LIST)*/
	{register object V15;
	{register object V16;
	V16= CMPcar((V14));
	V15= (V16);}
	/*(ENDP G2127)*/
	{register object V17;
	V17= (V15);
	if(!(((V17))==Cnil)){
	goto T26;}}
	/* END (ENDP G2127)*/}
	if(((V14))==Cnil){
	goto T16;}
	goto T17;
	goto T26;
T26:;
	{register object V18;
	V18= CMPcdr((V14));
	V14= (V18);}
	goto T20;
	goto T23;
T23:;
	goto T16;
	goto T16;}}
	/* END (MEMBER ITEM LIST TEST 'FUNCALL KEY KEY)*/}
	/* END (MEMBER-IF 'ENDP L)*/
	goto T17;
T17:;
	goto T11;
	goto T16;
T16:;
	{register object V19;
	register object V20;
	V19= (V7);
	V20= (V5);
	goto T38;
T38:;
	/*(ENDP L)*/
	{register object V11;
	V11= (V20);
	if(((V11))==Cnil){
	goto T41;}}
	/* END (ENDP L)*/
	{register object V21;
	register object V22;
	V21= (V19);
	{register object V23;
	register object V24;
	V23= (V20);
	V24= CMPcdr(CMPcar((V23)));
	{register object V25;
	V25= CMPcar(CMPcar((V23)));
	(void)((((V23))->c.c_car=((V24)),((V23))));
	V22= (V25);}}
	(void)((((V21))->c.c_car=((V22)),((V21))));}
	{register object V26;
	register object V27;
	V26= CMPcdr((V19));
	V27= CMPcdr((V20));
	V19= (V26);
	V20= (V27);}
	goto T38;
	goto T41;
T41:;
	goto T36;
	goto T36;}
	goto T36;
T36:;
	{register object V28;
	register object V29;
	register object V30;
	{register object V31;
	V31= CMPcar((V3));
	V3= CMPcdr((V3));
	V28= (V31);}
	V29= (V7);
	V30= CMPcar((V29));
	(void)(immnum_plus((V28),(V30)));}
	goto T8;
	goto T11;
T11:;
	{object V32 = (V6);VMR1
	(V32);}
	{object V33 = Cnil;VMR1
	(V33);}}}
	/* END (MAPC '+ X X)*/
	return Cnil;
}

COMPILER>(disassemble '(lambda (x) (mapc '+ x x x x x x)) nil)

;; Compiling /tmp/gazonk_22733_3.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_22733_3.o.

#include "gazonk_22733_3.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function CMP-ANON	*/

static object LI1(V2)

register object V2;
{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;
	/*(MAPC '+ X X X X X X)*/
	{register object V3;
	object V4;
	object V5;
	object V6;
	object V7;
	object V8;
	register object V9;
	V3= (V2);
	V4= (V2);
	V5= (V2);
	V6= (V2);
	V7= (V2);
	V8= (V2);
	V9= 
	!5? Cnil : (alloca_val=alloca((5)*sizeof(struct cons)+sizeof(object)),
	({object _b=(void *)alloca_val;if (((unsigned long)_b)&sizeof(_b)) _b++;
	{register struct cons *_p=(void *)_b;
	_p->c_car=(V4);_p->c_cdr=(object)(_p+1);_p++;
	_p->c_car=(V5);_p->c_cdr=(object)(_p+1);_p++;
	_p->c_car=(V6);_p->c_cdr=(object)(_p+1);_p++;
	_p->c_car=(V7);_p->c_cdr=(object)(_p+1);_p++;
	_p->c_car=(V8);_p->c_cdr=(object)(_p+1);_p++;
	_p[-1].c_cdr=Cnil;}_b;}));
	{register object V10;
	register object V11;
	/*(LIST-LENGTH L)*/
	{register object V13;
	V13= (V9);
	/*(ENDP (SETQ L (CDR L)))*/
	{object V14;
	V13= CMPcdr((V13));
	V14= (V13);
	if(!(((V14))==Cnil)){
	goto T5;}}
	/* END (ENDP (SETQ L (CDR L)))*/
	V12= make_fixnum(1);
	goto T3;
	goto T5;
T5:;
	/*(ENDP (SETQ L (CDR L)))*/
	{object V14;
	V13= CMPcdr((V13));
	V14= (V13);
	if(!(((V14))==Cnil)){
	goto T10;}}
	/* END (ENDP (SETQ L (CDR L)))*/
	V12= make_fixnum(2);
	goto T3;
	goto T10;
T10:;
	/*(ENDP (SETQ L (CDR L)))*/
	{object V14;
	V13= CMPcdr((V13));
	V14= (V13);
	if(!(((V14))==Cnil)){
	goto T15;}}
	/* END (ENDP (SETQ L (CDR L)))*/
	V12= make_fixnum(3);
	goto T3;
	goto T15;
T15:;
	/*(ENDP (SETQ L (CDR L)))*/
	{object V14;
	V13= CMPcdr((V13));
	V14= (V13);
	if(!(((V14))==Cnil)){
	goto T20;}}
	/* END (ENDP (SETQ L (CDR L)))*/
	V12= make_fixnum(4);
	goto T3;
	goto T20;
T20:;
	{fixnum V15;
	{object V16;
	V16= (V13);
	if(((V16))!=Cnil){
	goto T26;}
	V15= (fixnum)0;
	goto T24;
	goto T26;
T26:;
	{register fixnum V17;
	register object V18;
	register object V19;
	V17= (fixnum)1;
	V19= CMPcdr((V16));
	V18= (V16);
	goto T31;
T31:;
	V20 = V17;
	if((V20)>=((fixnum)268435455)){
	goto T34;}
	if(!(((V18))==((V19)))){
	goto T39;}
	V15= V17;
	goto T24;
	goto T39;
T39:;
	/*(ENDP F)*/
	{register object V21;
	V21= (V19);
	if(!(((V21))==Cnil)){
	goto T42;}}
	/* END (ENDP F)*/
	V22 = V17;
	V23 = V17;
	V15= (fixnum)((fixnum)-((fixnum)(V22)+(V23)))+((fixnum)1);
	goto T24;
	goto T42;
T42:;
	/*(ENDP (CDR F))*/
	{register object V21;
	V21= CMPcdr((V19));
	if(!(((V21))==Cnil)){
	goto T37;}}
	/* END (ENDP (CDR F))*/
	V24 = V17;
	V25 = V17;
	V15= (fixnum)-((fixnum)(V24)+(V25));
	goto T24;
	goto T37;
T37:;
	{register fixnum V26;
	register object V27;
	register object V28;
	V29 = V17;
	V26= (fixnum)(V29)+((fixnum)1);
	V27= CMPcdr((V18));
	V28= CMPcddr((V19));
	V17= V26;
	V18= (V27);
	V19= (V28);}
	goto T31;
	goto T34;
T34:;
	V15= (fixnum)-268435455;
	goto T24;
	V15= fix(Cnil);
	goto T24;}}
	goto T24;
T24:;
	V30 = V15;
	if(!((V30)<=((fixnum)0))){
	goto T58;}
	V31 = V15;
	V12= CMPmake_fixnum(((fixnum)4)+((fixnum)-(V31)));
	goto T3;
	goto T58;
T58:;
	V12= Cnil;}}
	/* END (LIST-LENGTH L)*/
	goto T3;
T3:;
	V11= (VFUN_NARGS=1,(/* MAKE-LIST */(*LnkLI7)(V12)));
	V10= (V3);
	goto T61;
T61:;
	/*(ENDP L1)*/
	{register object V32;
	V32= (V3);
	if(((V32))==Cnil){
	goto T64;}}
	/* END (ENDP L1)*/
	/*(MEMBER-IF 'ENDP L)*/
	{register object V33;
	V33= (V9);
	/*(MEMBER ITEM LIST TEST 'FUNCALL KEY KEY)*/
	{register object V34;
	V34= (V33);
	{register object V35;
	V35= (V34);
	goto T73;
T73:;
	/*(ENDP LIST)*/
	{register object V32;
	V32= (V35);
	if(((V32))==Cnil){
	goto T76;}}
	/* END (ENDP LIST)*/
	{register object V36;
	{register object V37;
	V37= CMPcar((V35));
	V36= (V37);}
	/*(ENDP G2127)*/
	{register object V21;
	V21= (V36);
	if(!(((V21))==Cnil)){
	goto T79;}}
	/* END (ENDP G2127)*/}
	if(((V35))==Cnil){
	goto T69;}
	goto T70;
	goto T79;
T79:;
	{register object V38;
	V38= CMPcdr((V35));
	V35= (V38);}
	goto T73;
	goto T76;
T76:;
	goto T69;
	goto T69;}}
	/* END (MEMBER ITEM LIST TEST 'FUNCALL KEY KEY)*/}
	/* END (MEMBER-IF 'ENDP L)*/
	goto T70;
T70:;
	goto T64;
	goto T69;
T69:;
	{register object V39;
	register object V40;
	V39= (V11);
	V40= (V9);
	goto T91;
T91:;
	/*(ENDP L)*/
	{register object V32;
	V32= (V40);
	if(((V32))==Cnil){
	goto T94;}}
	/* END (ENDP L)*/
	{register object V41;
	register object V42;
	V41= (V39);
	{register object V43;
	register object V44;
	V43= (V40);
	V44= CMPcdr(CMPcar((V43)));
	{register object V45;
	V45= CMPcar(CMPcar((V43)));
	(void)((((V43))->c.c_car=((V44)),((V43))));
	V42= (V45);}}
	(void)((((V41))->c.c_car=((V42)),((V41))));}
	{register object V46;
	register object V47;
	V46= CMPcdr((V39));
	V47= CMPcdr((V40));
	V39= (V46);
	V40= (V47);}
	goto T91;
	goto T94;
T94:;
	goto T89;
	goto T89;}
	goto T89;
T89:;
	base[0]= ((object)VV[0]);
	{register object V49;
	V49= CMPcar((V3));
	V3= CMPcdr((V3));
	base[1]= (V49);}
	{object V48;
	V48= (V11);
	 vs_top=base+2;
	 while(V48!=Cnil)
	 {vs_push((V48)->c.c_car);V48=(V48)->c.c_cdr;}
	vs_base=base+1;}
	super_funcall_no_event(base[0]);
	vs_top=sup;
	goto T61;
	goto T64;
T64:;
	{object V50 = (V10);VMR1
	(V50);}
	{object V51 = Cnil;VMR1
	(V51);}}}
	/* END (MAPC '+ X X X X X X)*/
	base[0]=base[0];
	return Cnil;
}

=============================================================================

The odd thing is that this inlining actually saves space, at least in
my measurements.  Still have to work out a way to elide unused
closures from the C output, etc.

There are probably many things I've forgotten to mention.  Please feel
free to ask questions if interested.

\start
Date: 15 Jun 2007 21:22:25 -0400
From: Camm Maguire
To: Waldek Hebisch
Subject: Re: [Axiom-mail] A slow summation

Greetings!  Very interesting -- needless to say, I'm very interested
in GCL performance.

Can you possible provide the raw lisp code in use here?  I'd be happy
to take a look.  

2.7.0 has immediate fixnums which doutless will make a huge difference
    here. 

Take care,

Waldek Hebisch writes:

> Bill Page wrote:
> > On 6/15/07, Waldek Hebisch wrote:
> > > On my machine, I get the following (on the second run, to
> > > exclude time for loading):
> > >
> > >                                       gcl      sbcl          sbcl
> > >                                              interpreted  compiled
> > >  reduce(+,[1.0/i for i in 1..20000])   8.70      1.76        0.17
> > >  [i for i in 1..20000];                6.23      0.78        0.01
> > >  expand(1..20000);                     0         0.004       0.01
> > >
> > > Comment: sbcl evaluator has two modes of operation: interpreted
> > > and compiled.  In compiled mode the code is first compiled and
> > > then the resulting machine code is run.  One can switch mode
> > > setting variable sb-ext:*evaluator-mode*:
> > >
> > > )lisp (setf sb-ext:*evaluator-mode* :compile)
> > >
> > > or
> > >
> > > )lisp (setf sb-ext:*evaluator-mode* :interpret)
> > >
> > > sbcl profiler showed that 98% of time were spent in Lisp evaluator,
> > > and that agrees very well with getting much higher speed using
> > > compiled mode.
> > >
> > 
> > Waldek, thank you very much for running this comparison!
> > 
> > So, the conclusion might be that I was wrong: the slowness *is*
> > because of the way that Axiom interpreter runs this code in
> > interpreted mode in GCL, right? It could still be that this interpreted
> > Lisp code is not written in an optimal manner.
> >
> 
> It seems that the code is suboptimal and probably wrong.  IIUC
> in:
> 
>  [1.0/i for i in 1..20000]
> 
> i should be local.  But Lisp code generated by Axiom accesses global
> Lisp variable i.  Making variables local may speed up this code.
> But OTOH compiled code is reasonably fast, and both sbcl and
> clisp show that the code can be interpreted few times faster.
>  
> > Maybe it is possible in GCL with some additional coding to also
> > convince GCL to compile the code first before executing it?
> > I know that Axiom includes the command:
> > 
> >   )set function compile on/off
> > 
> > that affects compilation of user defined functions in the interpreter.
> > Perhaps this can be extended to the [... for ... ] case?
> > 
> 
> Well, I think it is not hard to compile _everything_.  But compilation
> not always wins, one has to add compile time to execution time
> and especially with GCL compilation may take substantial time.
> For one-shot code (executed just once, without loops) compilation
> will almost certainly loose.  Axiom generate a lot of such
> one-shot pieces of code and evaluates them.  So it is not clear
> if compilation is better.  In fact, I switched sbcl to use
> interpreted mode, because this gives significant savings during
> bootstrap...
> 
> BTW: one can see effect of compilation in GCL using alternate
> formulation of the problem.  Namely, Axiom compiles recurence
> relations.  So one can define the following reccurence relations:
> 
> f(1, a) == 1.0 + a
> f(n, a) == f(n - 1, a + 1.0/n)
> 
> and then call:
> 
> f(20000, 0.0)

\start
Date: 15 Jun 2007 22:08:27 -0400
From: Camm Maguire
To: Robert Boyer
Subject: Re: bees for bonnets (GCL safety  definition)
Cc: Terry Parks, Richard Stallman, Warren Hunt, Henry Baker

Greetings!  In 2.7.0, I've redefined safety 3 to leave unset
*compiler-push-events*, and have fixed the code so that the ansi
tests, which assume safe code, run correctly under the new mode.  The
hook is still in the source, and might be made accessible at safety 4
if that has any meaning.  The point is that with source inlining, one
can effectively have one inline for both safe and unsafe code by
simply treating the check-type et.al. calls differently.  Type
propagation eliminates many even when safety is on.  I.e. if the
compiler is working correctly, there appears to be no need for the old
draconian catch all mode, which is actually slower than interpretation
in some cases.

More work remains in this regard.  Notably, I need to get up the
courage to do car et.al as source inlines.  Should actually be
straightforward.

Here is my speed comparison now:

=============================================================================
camm@intech19:/fix/t1/camm/debian/gcl/tmp/tmp/foo3/unixport$ ./saved_ansi_gcl
GCL (GNU Common Lisp)  2.7.0 ANSI    Jun 15 2007 19:48:03
Source License: LGPL(gcl,gmp,pargcl), GPL(unexec,bfd,xgcl)
Binary License:  GPL due to GPL'ed components: (XGCL READLINE BFD UNEXEC)
Modifications of this banner must retain notice of a compatible license
Dedicated to the memory of W. Schelter

Use (help) to get some basic information on how to use GCL.

Temporary directory for compiler files set to /tmp/

>(load "/tmp/t1.l")

;; Loading /tmp/t1.l
;; Compiling /tmp/gazonk_26334_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=2, Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_26334_0.o.
;; Loading /tmp/gazonk_26334_0.o
 ;; start address -T 0xaabcc8 ;; Finished loading /tmp/gazonk_26334_0.o
;; Compiling /tmp/gazonk_26334_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=2, Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_26334_0.o.
;; Loading /tmp/gazonk_26334_0.o
 ;; start address -T 0xaaed30 ;; Finished loading /tmp/gazonk_26334_0.o
real time       :      3.120 secs
run-gbc time    :      2.930 secs
child run time  :      0.000 secs
gbc time        :      0.000 secs
;; Finished loading /tmp/t1.l
T

>
camm@intech19:/fix/t1/camm/debian/gcl/tmp/tmp/foo3/unixport$ camm@intech19:/fix/t1/camm/debian/gcl/tmp/tmp/foo3/unixport$ 
camm@intech19:/fix/t1/camm/debian/gcl/tmp/tmp/foo3/unixport$ ./saved_ansi_gcl
GCL (GNU Common Lisp)  2.7.0 ANSI    Jun 15 2007 19:48:03
Source License: LGPL(gcl,gmp,pargcl), GPL(unexec,bfd,xgcl)
Binary License:  GPL due to GPL'ed components: (XGCL READLINE BFD UNEXEC)
Modifications of this banner must retain notice of a compatible license
Dedicated to the memory of W. Schelter

Use (help) to get some basic information on how to use GCL.

Temporary directory for compiler files set to /tmp/

>(load "/tmp/t2.l")

;; Loading /tmp/t2.l
;; Compiling /tmp/gazonk_26345_0.lsp.
; (DEFUN BAR ...) is being compiled.
;; Warning: Type declaration was found for not bound variable AR
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_26345_0.o.
;; Loading /tmp/gazonk_26345_0.o
 ;; start address -T 0xa4efc8 ;; Finished loading /tmp/gazonk_26345_0.o
;; Compiling /tmp/gazonk_26345_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_26345_0.o.
;; Loading /tmp/gazonk_26345_0.o
 ;; start address -T 0xaa7c68 ;; Finished loading /tmp/gazonk_26345_0.o
real time       :      2.290 secs
run-gbc time    :      2.120 secs
child run time  :      0.000 secs
gbc time        :      0.000 secs
;; Finished loading /tmp/t2.l
T

>
=============================================================================

ccing Walden as he asked about slow safety in GCL too.

Take care,

Robert Boyer writes:

> Hi Henry,
> 
> Thanks for the kind reply.
> 
> > so the old arguments regarding extra instructions for
> > type checking should no longer be valid.
> 
> Alas, my general experience is that tedious, careful
> declarations still make a huge, huge difference in Lisp
> if one wants the fastest code possible.  For example,
> of the four Lisps I tried just now, the best of them
> (those fastest on test2, below, the one with
> declarations) were about 8 times faster on test2 than
> on test1, the one without the declarations.
> 
> 'good' here is just under a second for test2.
> 
> -------------------------------------------------------
> 
> ; test 1
> 
> (declaim (optimize (safety 3)))
> (defvar ar (make-array 100000000))
> (defun bar (i) (setf (aref ar i) 0))
> (compile 'bar)
> (defun test () (loop for i below 100000000 do (bar i)))
> (compile 'test)
> (time (test))
> 
> ; test 2
> 
> (declaim (optimize (safety 0) (speed 3)))
> (defvar ar (make-array 100000000 :element-type 'fixnum))
> (defun bar (i)
>   (declare (fixnum i)
>            (type (simple-array fixnum (100000000)) ar))
>   (setf (aref ar i) 0))
> (compile 'bar)
> (declaim (ftype (function (fixnum) fixnum) bar))
> (defun test () (loop for i fixnum below 100000000 do (bar i)))
> (compile 'test)
> (time (test))
> 
> -------------------------------------------------------
> 
> As has been wisely said, comparisons are invidious and
> benchmarking is a dark art, so I won't refer to any
> specific Lisps.
> 
> One tests proves nothing, especially when done by a
> bumbler like me.  But referring to 'my general
> experience' proves even less.
> 
> For the little it is worth,
> 
> Bob
> 
> P. S.  Something like CDR coding is certainly still a
> super idea.  The idea of spending 128 bits on conses
> that are so almost all zeros is, well, painful.
> 
> P. S.  I am clueless about 'graph reduction'.  Will
> look into it.

\start
Date: Fri, 15 Jun 2007 22:36:54 -0500
From: Tim Daly
To: Camm Maguire
Subject: sigh

Hopefully you read the axiom-developer mailing list.
Mail sent from me to you bounces with a (550 Adminstrative prohibition).
I can set up an email account for you on axiom-developer if you wish.

Anyway the question is: Is 2.7.0 ready now?

\start
Date: Sat, 16 Jun 2007 13:45:45 +0200 (CEST)
From: Waldek Hebisch
To: Camm Maguire
Subject: Re: [Axiom-mail] A slow summation

Camm Maguire wrote:
> Waldek Hebisch writes:
> 
> > Bill Page wrote:
> > > On 6/15/07, Waldek Hebisch wrote:
> > > > On my machine, I get the following (on the second run, to
> > > > exclude time for loading):
> > > >
> > > >                                       gcl      sbcl          sbcl
> > > >                                              interpreted  compiled
> > > >  reduce(+,[1.0/i for i in 1..20000])   8.70      1.76        0.17
> > > >  [i for i in 1..20000];                6.23      0.78        0.01
> > > >  expand(1..20000);                     0         0.004       0.01
> > > >

> Can you possible provide the raw lisp code in use here?  I'd be happy
> to take a look.  

A little correction: it turned out that gcl evaluator is very fast,
faster than both clisp and sbcl interpreter.  Almost all gcl time
went into a single funtion:

(defun LIST2VEC (list) (coerce list 'vector))

This function was applied to the resulting list of length 20000 and
for some reason needed a lot of time.

\start
Date: Sat, 16 Jun 2007 22:12:35 +0200
From: Gregory Vanuxem
To: Waldek Hebisch
Subject: *read-default-float-format* in SBCL/wh-sandbox

*read-default-float-format* is set to single-float in SBCL/wh-sandbox.
The problem, I think, is that SBCL does not save the value of this
variable when creating a new Lisp image. As far as I know this happens
for other variables (not exhaustive of course) *print-escape*
*load-verbose* *compile-verbose* *load-print* *compile-print*
*print-array*.

\start
Date: 16 Jun 2007 22:21:31 +0200
From: Martin Rubey
To: list
Subject: [ANN] version 16-06-2007 of axiom.el

Again a new version of axiom.el.pamphlet, uploaded to MathAction:

http://wiki.axiom-developer.org/AxiomEmacsMode

You need to untangle the file and load it into emacs with 

  M-x load-file Ret axiom.el Ret

Changes:

* implemented repositioning of the process-mark consistently and safely,

* rearranged the defuns a little so that they are easier to locate in the
  documentation,

* axiom-reset now actually works (useful if for some reason some other process
  has written something into your *axiom* buffer.

* axiom-process is not set to nil anymore, when some buffer is killed.

> Missing:
> 
> * xemacs port
> 
> * allow lisp debugger to be entered, I.e., track when the prompt may change.
>   How does shell mode do this?
> 
> * clean up initialisation routines.

    In particular, I'd like to have the following behaviour:
    
    [[M-x axiom]] should switch to the buffer [[*axiom*]], if it exists and if
    it is an "axiom buffer".  (I guess that should be a buffer in
    [[axiom-mode]], with a running axiom process.)
     
    If there is no such buffer, it should create a new buffer and a new axiom
    process.
     
    [[(add-hook 'axiom-mode-hook (lambda () (rename-uniquely)))]] should
    rename the buffer.  I do not know what else one could use
    [[shell-mode-hook]] (and therefore [[axiom-mode-hook]]) for.

  * update the documentation and make it more concise.

\start
Date: Sun, 17 Jun 2007 00:22:22 -0500
From: Tim Daly
To: Martin Rubey
Subject: getUsersOfConstructor

Martin,

The search for the root of the Users problem continues.
There have been a couple problems so far. One was due 
to a typo which caused boot to stop translation of br-op2.
There used to be a check for a complete boot translation 
during build. That check needs to be re-implemented.

The second problem seems to be that it cannot find libdb.text.
It is not clear how this ever got broken but it needs to be fixed.

A third problem has arisen due to parsing libdb.text which will
be the next task.

So far I cannot report success.

\start
Date: Sun, 17 Jun 2007 02:15:40 -0500
From: Tim Daly
To: list
Subject: magic, religion, and pamphlets

This was in reply to a private email complaint about pamphlet files. 
These points have been made before in various contexts. They are 
summarized here so we can have a record in the mailing lists.




In reference to pamphlet files there are several points.

THE BEGINNERS MIND

You're not approaching your algebra with a "beginner's mind".

You write the spad code so it is obvious to you. And the underlying
theory is in your area of expertise so it is also obvious. However,
30 years from now someone will attempt to maintain, modify, and extend
the algebra you've written. This person will certainly have a "beginners
mind" with respect to your code. Nothing will be obvious. There will be
intermediate results (e.g. extending the field of constants in the
integration code) which are required by the algorithms but never show
up in the final result. 

If you were to write up your algorithm in a style similar to Knuth's
rather than as a technical paper you might find it easier. Knuth 
"explains" the program to the reader by introducing the decisions
about variables, data structures, efficiency issues, and other topics
before introducing the main algorithms. Thus when the reader reaches
the main algorithm description it is clear why the code is expressed
in the given form. It's the computational math equivalent of the lemma.
Now all he has left to do is explain the main theory.

There are a lot of questions for a "beginners mind". Why did you choose
to build the domain over this algebraic structure? Why are certain
functions exported and others only local? Why are certain functions
conditional? What are the limits of these algorithms? What parts of
the theory are poorly addressed? Where is there room for improvement?





COMPUTATIONAL MATH vs MATH

You even mention that "the code because of necessary data structure and
efficiency issues would not follow the theory exactly". Consider that,
while it may not follow the mathematical theory exactly, it does follow
the computational mathematical theory exactly. You're applying the wrong
metric to the problem. Computational mathematics is not traditional
mathematics. 

The difference between math and computational math is similar to
the difference between an existence proof and a constructive proof.
Both are valid but one is clearly more useful for certain purposes.

And in some sense you're applying the wrong model of documenting the
theory (mathematical papers) to the problem of documenting the
computational theory (pamphlet files).




YOU and who else?

The quaternions were documented in the latest release using a
public-domain, freely available textbook by Tait in the 1850s.  The
file contains hand converted text to Latex and then the pamphlet file
was decorated with command line examples from axiom sessions.  Tait
could have done a better job and given much better and more insightful
examples. However, he's dead. But its a start which we can now shape,
reshape, and improve for our needs.

We do have the good fortune that his work is in the public domain so
we can freely use it. We have the bad fortune of being unable to get
feedback directly from him. Do you want your work to be documented by
a 3rd string mathematician 150 years from now? Or would you rather do
a quality job yourself? If we're lucky axiom will outlive all of us.




PAMPHLETS ARE HARD

And pamphlet files are probably the wrong way to capture this information.
But currently there is no other mechanism. Suppose one writes up an algebra
package of only algebra files and puts it in the system. Suppose there is no
documentation and no test cases. We have no idea if it works and no way
to figure out what it might do, not to mention how to test boundary cases
or unit test the functions. There are no literature references so we
can't even look up the theory.

If all else fails use the "big staple" theory and just attach papers.

Writing pamphlet files, and convincing people that pamphlet files are
a good format and medium for computational mathematics seems to be
about as hard as convincing a student that there are certain
acceptable forms of technical papers and dissertations. Part of their
training as a mathematician is learning to publish according to form.
Part of the training of a computational mathematician is learning to
write literate documentation of algorithms. 



PAMPHLETS CARRY THE "NOW"

Writing computational mathematics documentation as published journal 
articles suffers from the problem of time. All of the algorithms in
Axiom will drift over time as more people make changes. If we don't
document the algorithms and keep the documentation with the code 
we certainly won't document the changes. So the algorithms will come
to represent the collective mindset of several authors, none of whom
spoke to each other, in a multi-generational non-conversation. There
will eventually be no correct reference sources and no clue how this
code actually works. That path leads to code-death.



PAMPHLETS ARE PROBABLY WRONG BUT...

Without SOME documentation the algebra code is magic.
As long as we allow magic we might as well allow religion (pamphlets) :-)

\start
Date: Sun, 17 Jun 2007 00:56:36 -0700 (PDT)
From: Cliff Yapp
To: Tim Daly
Subject: Re: magic, religion, and pamphlets

I'm not sure pamphlet are the wrong idea - they may not be the best of
all possible ideas, but that's something different.

Pamphlets are an expression of the "write for humans" model of
programming and documentation, and when the goal is long term usability
I think that model is correct.

"Write for humans" treats the most probable situation for someone
looking at the code - they don't know what they are looking at.  Even
as code is being written the numbers who can understand it directly are
few - this number drops sharply the older the code gets.  From this
standpoint, writing for humans (beginners if you prefer) is an obvious
default.

What has NOT been obvious, up until recently, is the need for code to
last indefinitely.  Early systems were bootstrapped using throwaway
code written once to get the machine running - most systems that
followed were so closely tied to the machines that they lived and died
with the hardware.  Abstracting the code beyond the architecture is
only a reasonable idea when the hardware resources are not the limiting
factor, and that is a recent development (historically).  Indeed, there
is a "new is better" philosophy in software that still runs strong even
today, in part because systems being replaced were not designed to last
- there was no point.

Now, with the benefit of hindsight, we see how much effort has been
spent and lost to posterity.  We see the costs of having to deal with
poor design decisions (or decisions dictated by hardware - I'm sure
both happened).  Re-inventing the wheel happens FAR too often.  Every
time a wheel is re-invented it means effort was spent which could have
been spent to solve some other, new problem.

TeX has shown us what happens when software is written to last.  TeX is
used (and unsurpassed) decades after its original conception.  No
serious competitor is in sight.  The initial investment put into the
TeX system has benefited countless people over the decades.

Axiom is converting to pamphlets because it intends to be to computer
algebra what TeX is to typesetting.  Not just a program to be thrown
away or rewritten after a few decades, but a repository of knowledge
and design that will stand the test of time.  It will evolve, like any
system, but the goal should be that changes should reflect developments
in mathematics.  There are many extensions to TeX, but they reflect
extensions to the core.  Likewise, Axiom should be a solid core on
which mathematical extensions can be built.  THAT is why pamphlet files
are important - because they serve as the detailed knowledge repository
behind the software.  They force us to consider what we are doing, and
explain it.  

Perhaps one thing that should be stressed - most of Axiom's pamphlet
files as they exist in the distribution today do not represent the
intended final form.  They are syntactically valid pamphlet files, but
they are not (with a few exceptions) literate documents.  A proper
documentation of the Axiom system should also be a working introduction
to the foundations of mathematics - as Axiom is a mathematical system,
this context is integral to its functionality and design.  The goal is
a long term one, but with any luck the benefits will be as well. 

There exists a wide variety of motivations among Axiom developers -
speaking for myself, I work on it because I see in it the best chance
for the Final CAS - a system sufficiently capable, extensible and well
designed that updating it and extending it will always be easier and
more desirable than replacing it.  It may even be possible to interface
it with formal proof systems to provide a level of rigor to rival or
exceed human correctness checking, at which point computer algebra will
assume a new importance in the research world.

Cheers,
CY

P.S.  Two unstated assumptions in the Axiom literate system are
functioning computers and understanding of the English language.  While
both almost HAVE to be assumed for the project to move forward, if we
look beyond 30 years to hundreds of years or more it becomes an
interesting question.  Will we still speak and understand English? 
Will we have functioning computers?  Outside the scope of the Axiom
project, but fascinating questions none the less.

\start
Date: Mon, 18 Jun 2007 13:35:26 +1000
From: Alasdair McAndrew
To: list
Subject: Two hyperdoc questions

I haven't been following the discussions as closely as I should, so I
apologize if these questions are jejune:

1)  What is the current state of using HyperDoc (or any other sort of help
browser) under windows - in particular with Axiom-0.1.4?

2)  If I inadvertently quit HyperDoc while running Axiom, I can restart it
with )hd.  But )hd doesn't provide a socket connection; this new HyperDoc is
"not connected to Axiom".  Is there any way of starting a "connected"
HyperDoc from an already-running Axiom?

\start
Date: 18 Jun 2007 08:24:33 +0200
From: Martin Rubey
To: Alasdair McAndrew
Subject: Re: Two hyperdoc questions

Alasdair McAndrew writes:

> 1) What is the current state of using HyperDoc (or any other sort of help
> browser) under windows - in particular with Axiom-0.1.4?

* Out of the box there is nothing.

* There is an experimental port by Tim Daly, with the important drawback that
  there is no connection to Axiom, i.e., browse does *not* work

* There is the possibility of running axiom within a virtual machine, as
  proposed by Bill Page and Alfredo Portes.  I'd recommend that one.  This is
  also the only way to get graphics on windows.  Furthermore, if you are
  interested in combinatorics, Polymake and therefore my Polymake-wrapper only
  works on linux, too.  Together with axiom.el and SPADEDIT for gnu emacs this
  makes quite a usable environment even for windows users.  (After clicking on
  gnu emacs, they just need to press "Alt" then "x", type "axiom" and
  everything should work.

* There is the possibly half working hyperdoc replacement by myself, which
  needs an axiom process dedicated for documentation -- but which you can run
  in the background, so you won't even notice.  So far it only can browse
  operations, and it's not really tested on windows.  Even if it is not that
  much interesting for production work at the moment, I'd urge you to try it
  and send me your experiences.

> 2) If I inadvertently quit HyperDoc while running Axiom, I can restart it
> with )hd.  But )hd doesn't provide a socket connection; this new HyperDoc is
> "not connected to Axiom".  Is there any way of starting a "connected"
> HyperDoc from an already-running Axiom?

No, but I'd love to see a fix for that bug, too.

\start
Date: Mon, 18 Jun 2007 03:15:19 -0400
From: Bill Page
To: Waldek Hebisch
Subject: problem compiling wh-sandbox revision 571 on Windows

Waldek,

The following change in revsion 571:

http://axiom.svn.sourceforge.net/viewvc/axiom/branches/wh-sandbox/src/lisp/Makefile.pamphlet?view=diff&r1=570&r2=571

seems to cause problems building wh-sandbox on Windows:

...
Finished compiling axiom-lisp.lisp.
#p"axiom-lisp.o"

>echo '(compiler::link (quote ("axiom-package.lisp" "axiom-lisp.o")) "lisp" ' \
              ' (format nil "(progn (let ((*load-path* (cons ~S *load-path*))'\
                                        ' (si::*load-types* ~S))' \
                                       ' (compiler::emit-fn t))' \
                                  ' (when (fboundp (quote si::sgc-on))' \
                                        ' (si::sgc-on t))' \
                                  ' (setq compiler::*default-system-p* t))"' \
                      ' si::*system-directory* (quote (list ".lsp")))' \
               '
"C:/msys/1.0/home/Administrator/axiom-sandbox/src/lisp/../.././src/lib/bsdsignal.o
C:/msys/1.0/home/Administrator/axiom-sandbox/src/lisp/../.././src/lib/cfuns-c.o
C:/msys/1.0/home/Administrator/axiom-sandbox/src/lisp/../.././src/lib/sockio-c.o
-lwsock32")' \
            | /usr/local/bin/gcl
GCL (GNU Common Lisp)  2.6.8 CLtL1    Apr 16 2007 00:20:36
Source License: LGPL(gcl,gmp), GPL(unexec,bfd,xgcl)
Binary License:  GPL due to GPL'ed components: (UNEXEC)
Modifications of this banner must retain notice of a compatible license
Dedicated to the memory of W. Schelter

Use (help) to get some basic information on how to use GCL.
Temporary directory for compiler files set to
C:/msys/1.0/home/Administrator/axiom-sandbox/build/i686-pc-mingw32/

>
Error: Unsupported on Windows platforms
Fast links are on: do (si::use-fast-links nil) for debugging
Error signalled by SYSTEM:FIND-INIT-NAME.
Broken at SYSTEM:FIND-INIT-NAME.  Type :H for Help.
>>/bin/install -c lisp.exe
/home/Administrator/axiom-sandbox/build/i686-pc-mingw32/bin
/bin/install: cannot stat `lisp.exe': No such file or directory
make[2]: *** [do_it.gcl] Error 1
make[2]: Leaving directory `/home/Administrator/axiom-sandbox/src/lisp'
make[1]: *** [all-lisp] Error 2
make[1]: Leaving directory `/home/Administrator/axiom-sandbox/src'
make: *** [all-src] Error 2

---------

Apparently GCL is complaining about "axiom-lisp.o". The following
patch allowed the build to proceed further:

--- src/lisp/Makefile.pamphlet  (revision 613)
+++ src/lisp/Makefile.pamphlet  (working copy)
@@ -81,7 +81,7 @@
        echo '(load "axiom-package.lisp")' \
             '(setq compiler::*default-system-p* t)' \
             '(compile-file "axiom-lisp.lisp")' | $(AXIOM_LISP)
-       echo '(compiler::link (quote ("axiom-package.lisp"
"axiom-lisp.$(OBJEXT)")) "lisp" ' \
+       echo '(compiler::link (quote ("axiom-package.lisp"
"axiom-lisp.lisp")) "lisp" ' \
               ' (format nil "(progn (let ((*load-path* (cons ~S *load-path*))'\
                                         ' (si::*load-types* ~S))' \
                                        ' (compiler::emit-fn t))' \

-----------

But then it stops at:

Finished compiling g-util.o.
Loading g-util.o
start address -T 117fc000 Finished loading g-util.o
Finished loading makedep.lisp
T

>Dumping from C:/msys/1.0/home/Administrator/axiom-sandbox/build/i686-pc-mingw32/bin/lisp.exe
          to /home/Administrator/axiom-sandbox/build/i686-pc-mingw32/bin/depsys.exe
Failed to open /home/Administrator/axiom-sandbox/build/i686-pc-mingw32/bin/depsys.exe
(3)...bailing.
make[2]: *** [/home/Administrator/axiom-sandbox/build/i686-pc-mingw32/bin/depsys]
Error 1
make[2]: Leaving directory `/home/Administrator/axiom-sandbox/src/interp'
make[1]: *** [all-interpsys] Error 2
make[1]: Leaving directory `/home/Administrator/axiom-sandbox/src'
make: *** [all-src] Error 2

----------

I am not sure what is the problem here.

What is the last know revision of wh-sandbox that compiled on Windows?

\start
Date: Mon, 18 Jun 2007 17:09:04 +0200
From: Gregory Vanuxem
To: Martin Rubey
Subject: Re: testing hyperdoc package on Windows

Hello Martin,

Le mardi 12 juin 2007 =E0 01:06 +0200, Gregory Vanuxem a =E9crit :
> Hello Martin,
>
> Here are my tests:
>
> gcl-2.6.8pre just checked out today : fails in 'accept' with error:
>
>   "not such file or directory"

[...]

> Will try to know why 2.6.8pre from cvs
> fails in accept (windows only).

It was a problem with my MingW configuration, more precisely I had to
downgrade GCC to version 3.3.1 to compile old fortran 77 code. Reverting
to gcc-3.4.2 fixes this issue. In other words your socket code works on
gcl-2.6.8pre (Windows and Linux).

\start
Date: Mon, 18 Jun 2007 11:11:16 -0400
From: Bill Page
To: Waldek Hebisch
Subject: Re: problem compiling wh-sandbox revision 571 on Windows

Waldek,

To continue the build of revision 607 of wh-sandbox, in addition to
the patch below I also needed the following patch:

===================================================================
--- src/interp/Makefile.pamphlet        (revision 613)
+++ src/interp/Makefile.pamphlet        (working copy)
@@ -940,7 +940,7 @@
                  >> makedep.lisp ; \
          echo '(load "'$$B'")' >> makedep.lisp ; \
        done
-       echo '(load "makedep.lisp") (BOOT::spad-save "$@" nil)' | ${LISPSYS}
+       echo '(load "makedep.lisp") (BOOT::spad-save "$(BASE)$@" nil)'
| ${LISPSYS}
        @ echo 4 ${DEPSYS} created
 @

----------

Now the build proceeds up to the Stage 1 bootstrap but fails with the error:

   Error: The function AXIOM-LISP::FILE_KIND is undefined.

-------

Stage 1 object bootstrap (bootStrapMode)
GCL (GNU Common Lisp)  2.6.8 CLtL1    Apr 16 2007 00:20:36
Source License: LGPL(gcl,gmp), GPL(unexec,bfd,xgcl)
Binary License:  GPL due to GPL'ed components: (UNEXEC)
Modifications of this banner must retain notice of a compatible license
Dedicated to the memory of W. Schelter

Use (help) to get some basic information on how to use GCL.
Temporary directory for compiler files set to
C:/msys/1.0/home/Administrator/wh-test/build/i686-pc-mingw32/
                        AXIOM Computer Algebra System
                 Version: Axiom wh-sandbox branch 2007-05-31
                           Timestamp: no timestamp
-----------------------------------------------------------------------------
   Issue )copyright to view copyright notices.
   Issue )summary for a summary of useful system commands.
   Issue )quit to leave AXIOM and return to shell.
-----------------------------------------------------------------------------

   Using local database
C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/compress.daase..
  Using local database
C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/interp.daase..
   Using local database
C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/operation.daase..
   Using local database
C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/category.daase..
   Using local database
C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/browse.daase..

Error: The function AXIOM-LISP::FILE_KIND is undefined.
Fast links are on: do (si::use-fast-links nil) for debugging
Error signalled by FILE-KIND.
Broken at APPLY.  Type :H for Help.
BOOT>>
Error: The variable READ is unbound.
Fast links are on: do (si::use-fast-links nil) for debugging
Error signalled by EVALHOOK.
Backtrace: system:universal-error-handler > evalhook > lambda >
lambda-closure > block > apply > APPLY

Broken at APPLY.
BOOT>>
"boo1.input"
BOOT>>Stage 1 copy
cp: cannot stat `AHYP.NRLIB/code.o': No such file or directory
make[2]: *** [stamp-bootstrap] Error 1
make[2]: Leaving directory `/home/Administrator/wh-test/src/algebra'
make[1]: *** [all-algebra] Error 2
make[1]: Leaving directory `/home/Administrator/wh-test/src'
make: *** [all-src] Error 2

----------

Perhaps this is related to my patch to 'src/lisp/Makefile.pamphlet'
below. Maybe that is not the correct way to solve the "Unsupported on
Windows platforms" error?

BTW, I checked that the last revision of wh-sandbox that I
successfully compiled was revision # 526. Do you know if anyone has
built a windows version of Axiom from a later revision of wh-sandbox?

Regards,
Bill Page.

On 6/18/07, Bill Page wrote:
> Waldek,
>
> The following change in revsion 571:
>
> http://axiom.svn.sourceforge.net/viewvc/axiom/branches/wh-sandbox/src/lisp/Makefile.pamphlet?view=diff&r1=570&r2=571
>
> seems to cause problems building wh-sandbox on Windows:
>
> ...
> Finished compiling axiom-lisp.lisp.
> #p"axiom-lisp.o"
>
> >echo '(compiler::link (quote ("axiom-package.lisp" "axiom-lisp.o")) "lisp" ' \
>               ' (format nil "(progn (let ((*load-path* (cons ~S *load-path*))'\
>                                         ' (si::*load-types* ~S))' \
>                                        ' (compiler::emit-fn t))' \
>                                   ' (when (fboundp (quote si::sgc-on))' \
>                                         ' (si::sgc-on t))' \
>                                   ' (setq compiler::*default-system-p* t))"' \
>                       ' si::*system-directory* (quote (list ".lsp")))' \
>                '
> "C:/msys/1.0/home/Administrator/axiom-sandbox/src/lisp/../.././src/lib/bsdsignal.o
> C:/msys/1.0/home/Administrator/axiom-sandbox/src/lisp/../.././src/lib/cfuns-c.o
> C:/msys/1.0/home/Administrator/axiom-sandbox/src/lisp/../.././src/lib/sockio-c.o
> -lwsock32")' \
>             | /usr/local/bin/gcl
> GCL (GNU Common Lisp)  2.6.8 CLtL1    Apr 16 2007 00:20:36
> Source License: LGPL(gcl,gmp), GPL(unexec,bfd,xgcl)
> Binary License:  GPL due to GPL'ed components: (UNEXEC)
> Modifications of this banner must retain notice of a compatible license
> Dedicated to the memory of W. Schelter
>
> Use (help) to get some basic information on how to use GCL.
> Temporary directory for compiler files set to
> C:/msys/1.0/home/Administrator/axiom-sandbox/build/i686-pc-mingw32/
>
> >
> Error: Unsupported on Windows platforms
> Fast links are on: do (si::use-fast-links nil) for debugging
> Error signalled by SYSTEM:FIND-INIT-NAME.
> Broken at SYSTEM:FIND-INIT-NAME.  Type :H for Help.
> >>/bin/install -c lisp.exe
> /home/Administrator/axiom-sandbox/build/i686-pc-mingw32/bin
> /bin/install: cannot stat `lisp.exe': No such file or directory
> make[2]: *** [do_it.gcl] Error 1
> make[2]: Leaving directory `/home/Administrator/axiom-sandbox/src/lisp'
> make[1]: *** [all-lisp] Error 2
> make[1]: Leaving directory `/home/Administrator/axiom-sandbox/src'
> make: *** [all-src] Error 2
>
> ---------
>
> Apparently GCL is complaining about "axiom-lisp.o". The following
> patch allowed the build to proceed further:
>
> ===================================================================
> --- src/lisp/Makefile.pamphlet  (revision 613)
> +++ src/lisp/Makefile.pamphlet  (working copy)
> @@ -81,7 +81,7 @@
>         echo '(load "axiom-package.lisp")' \
>              '(setq compiler::*default-system-p* t)' \
>              '(compile-file "axiom-lisp.lisp")' | $(AXIOM_LISP)
> -       echo '(compiler::link (quote ("axiom-package.lisp"
> "axiom-lisp.$(OBJEXT)")) "lisp" ' \
> +       echo '(compiler::link (quote ("axiom-package.lisp"
> "axiom-lisp.lisp")) "lisp" ' \
>                ' (format nil "(progn (let ((*load-path* (cons ~S *load-path*))'\
>                                          ' (si::*load-types* ~S))' \
>                                         ' (compiler::emit-fn t))' \
>
> -----------
>
> But then it stops at:
>
> Finished compiling g-util.o.
> Loading g-util.o
> start address -T 117fc000 Finished loading g-util.o
> Finished loading makedep.lisp
> T
>
> >Dumping from C:/msys/1.0/home/Administrator/axiom-sandbox/build/i686-pc-mingw32/bin/lisp.exe
>           to /home/Administrator/axiom-sandbox/build/i686-pc-mingw32/bin/depsys.exe
> Failed to open /home/Administrator/axiom-sandbox/build/i686-pc-mingw32/bin/depsys.exe
> (3)...bailing.
> make[2]: *** [/home/Administrator/axiom-sandbox/build/i686-pc-mingw32/bin/depsys]
> Error 1
> make[2]: Leaving directory `/home/Administrator/axiom-sandbox/src/interp'
> make[1]: *** [all-interpsys] Error 2
> make[1]: Leaving directory `/home/Administrator/axiom-sandbox/src'
> make: *** [all-src] Error 2
>
> ----------
>
> I am not sure what is the problem here.
>
> What is the last know revision of wh-sandbox that compiled on Windows?
>

\start
Date: 18 Jun 2007 17:13:36 +0200
From: Martin Rubey
To: Gregory Vanuxem
Subject: Re: testing hyperdoc package on Windows

Gregory Vanuxem writes:

> Hello Martin,
>
> Le mardi 12 juin 2007 =C3=A0 01:06 +0200, Gregory Vanuxem a =C3=A9crit :
> > Hello Martin,
> >
> > Here are my tests:
> >
> > gcl-2.6.8pre just checked out today : fails in 'accept' with error:
> >
> >   "not such file or directory"
>
> [...]
>
> > Will try to know why 2.6.8pre from cvs
> > fails in accept (windows only).
>
> It was a problem with my MingW configuration, more precisely I had to
> downgrade GCC to version 3.3.1 to compile old fortran 77 code. Reverting
> to gcc-3.4.2 fixes this issue. In other words your socket code works on
> gcl-2.6.8pre (Windows and Linux).

Great!  Time permitting, I'll put together some more functionality and a user
interface.

\start
Date: Mon, 18 Jun 2007 11:18:50 -0400
From: Bill Page
To: Gregory Vanuxem
Subject: re: testing hyperdoc package on Windows

Have you tried this in Axiom built with gcl-2.6.8pre? If so what
source version? More specifically have you actually tried Martin's
hyperdoc browser based on this socket code?

Regards,
Bill Page.

On 6/18/07, Gregory Vanuxem wrote:
> ...
> > Will try to know why 2.6.8pre from cvs
> > fails in accept (windows only).
>
> It was a problem with my MingW configuration, more precisely I had to
> downgrade GCC to version 3.3.1 to compile old fortran 77 code. Reverting
> to gcc-3.4.2 fixes this issue. In other words your socket code works on
> gcl-2.6.8pre (Windows and Linux).

\start
Date: 18 Jun 2007 12:41:34 -0400
From: Stephen Wilson
To: list
Subject: Axiom and GCL ANSI

I have need for an Axiom which compiles under GCL-2.6.8pre in ANSI
mode. 

>From what I understand wh-sandbox compiles with an ANSI GCL.

I have a local version of Silver which appears to be working too.

Has anyone else managed to compile a GCL ANSI Silver?


I would like to see the changes required for ANSI support included in
Silver in the short term.  I would be happy to work with anyone who is
interested and/or has their own changes they would like to merge.

\start
Date: Mon, 18 Jun 2007 19:19:08 +0200
From: Gregory Vanuxem
To: Bill Page
Subject: re: testing hyperdoc package on Windows

Le lundi 18 juin 2007 =E0 11:18 -0400, Bill Page a =E9crit :
> Greg,
>
> Have you tried this in Axiom built with gcl-2.6.8pre? If so what
> source version?

No, I tried this with gcl-2.6.8pre just checked out from cvs.

> More specifically have you actually tried Martin's
>  hyperdoc browser based on this socket code?

No, I only tested the lisp socket code, Martin wanted to know if the
socket code was usable on Windows. This is the piece of code I tested
(parts of Martin's code):

==========================
==========================
=================
(defun mysocket (port docfun)
  (let ((s (si::socket port :server #'server)))
    (tagbody l
	     (when (si::listen s)
	       (let ((w (si::accept s)))
		 (server w)))
	     (sleep 0.1)
	     (go l))))


(defun server (s)
  (let* ((get (read s nil 'eof))
         (fn (and (eq get 'get)
		  (let* ((s1 (subseq (string (read s nil 'eof)) 1))
			 (n (length s1))
			 (s2 (make-string n)))
		    (do ((i 0 (incf i))
			 (j 0 (incf j)))
			((= i n) (subseq s2 0 j))
		      (if (char= (char s1 i) #\%)
			  (setf (char s2 j)
				(code-char (read-from-string
					    (concat "#x"
						    (subseq s1 (incf i)
							    (1+ (incf i)))))))
			(setf (char s2 j) (char s1 i))))))))



    (format t "Got ~S~%~%" fn) ; server side
    (format s "hello~%") ; client side
    (close s)))
==========================
==========================
======================


Using telnet I was able to connect to the server ask a page and receive
the "hello". The rest of the job to support Windows should be
straightforward (if not already done). In fact the first thing to do is
to have a version of Axiom with correct databases that build on Windows.
This require some other tests, hmm... apparently this is what you're
doing Bill :-). I think that build-improvements produces correct
databases too but it has the probe-file problem (probe-file no longer
works on directory).

Greg



> Regards,
> Bill Page.
>
> On 6/18/07, Gregory Vanuxem wrote:
> > ...
> > > Will try to know why 2.6.8pre from cvs
> > > fails in accept (windows only).
> >
> > It was a problem with my MingW configuration, more precisely I had to
> > downgrade GCC to version 3.3.1 to compile old fortran 77 code. Reverting
> > to gcc-3.4.2 fixes this issue. In other words your socket code works on
> > gcl-2.6.8pre (Windows and Linux).
> >
>

\start
Date: Mon, 18 Jun 2007 14:27:01 -0400
From: Bill Page
To: Gregory Vanuxem
Subject: re: testing hyperdoc package on Windows

On 6/18/07, Gregory Vanuxem wrote:
>
> No, I only tested the lisp socket code, Martin wanted to know if the
> socket code was usable on Windows. This is the piece of code
> I tested (parts of Martin's code):
>
> ===================================================================
> (defun mysocket (port docfun)
>   (let ((s (si::socket port :server #'server)))
>     (tagbody l
>              (when (si::listen s)
>                (let ((w (si::accept s)))
>                  (server w)))
>              (sleep 0.1)
>              (go l))))
>
>
> (defun server (s)
>   (let* ((get (read s nil 'eof))
>          (fn (and (eq get 'get)
>                   (let* ((s1 (subseq (string (read s nil 'eof)) 1))
>                          (n (length s1))
>                          (s2 (make-string n)))
>                     (do ((i 0 (incf i))
>                          (j 0 (incf j)))
>                         ((= i n) (subseq s2 0 j))
>                       (if (char= (char s1 i) #\%)
>                           (setf (char s2 j)
>                                 (code-char (read-from-string
>                                             (concat "#x"
>                                                     (subseq s1 (incf i)
>                                                             (1+ (incf i)))))))
>                         (setf (char s2 j) (char s1 i))))))))
>
>
>
>     (format t "Got ~S~%~%" fn) ; server side
>     (format s "hello~%") ; client side
>     (close s)))
> ========================================================================
>

Oh, ok. In fact the first version of this code was actually developed
using Axiom on Windows, so I am glad that it still works. :-)

>
> Using telnet I was able to connect to the server ask a page and
> receive the "hello". The rest of the job to support Windows should
> be straightforward (if not already done). In fact the first thing to do is
> to have a version of Axiom with correct databases that build on
> Windows. This require some other tests, hmm... apparently this is
> what you're doing Bill :-). I think that build-improvements produces
> correct databases too but it has the probe-file problem (probe-file
> no longer works on directory).
>

I think wh-sandbox has the most complete and consistent system of
building the axiom databases. Revison 526 (and perhaps some more
recent but not more recent than revision than 570) build on Windows.
Some windows incompatible changes were made to wh-sandbox at 571 and
perhaps later. Revisioni 526 includes patches so that the Windows
version can run natively outside of the MSYS environment, but Martin's
spad code that is part of his mini-hyperdoc browser apparently still
requires that some version of 'grep' be present in the PATH.

I will continue with trying Martin's code with the most recent version
 wh-sandbox that compiles on Windows. If you have some time to try
this with build-improvements that would
be great.

\start
Date: Mon, 18 Jun 2007 22:07:19 +0200 (CEST)
From: Waldek Hebisch
To: Bill Page
Subject: Re: problem compiling wh-sandbox revision 571 on Windows
Cc: Camm Maguire

CC-ing Camm, as the problem depends on very specific GCL behavoiur.

Bill Page wrote:
> Waldek,
> 
> The following change in revsion 571:
> 
> http://axiom.svn.sourceforge.net/viewvc/axiom/branches/wh-sandbox/src/lisp/Makefile.pamphlet?view=diff&r1=570&r2=571
> 
> seems to cause problems building wh-sandbox on Windows:
> 
> ...
> Finished compiling axiom-lisp.lisp.
> #p"axiom-lisp.o"
> 
> >echo '(compiler::link (quote ("axiom-package.lisp" "axiom-lisp.o")) "lisp" ' \
>               ' (format nil "(progn (let ((*load-path* (cons ~S *load-path*))'\
>                                         ' (si::*load-types* ~S))' \
>                                        ' (compiler::emit-fn t))' \
>                                   ' (when (fboundp (quote si::sgc-on))' \
>                                         ' (si::sgc-on t))' \
>                                   ' (setq compiler::*default-system-p* t))"' \
>                       ' si::*system-directory* (quote (list ".lsp")))' \
>                '
> "C:/msys/1.0/home/Administrator/axiom-sandbox/src/lisp/../.././src/lib/bsdsignal.o
> C:/msys/1.0/home/Administrator/axiom-sandbox/src/lisp/../.././src/lib/cfuns-c.o
> C:/msys/1.0/home/Administrator/axiom-sandbox/src/lisp/../.././src/lib/sockio-c.o
> -lwsock32")' \
>             | /usr/local/bin/gcl
> GCL (GNU Common Lisp)  2.6.8 CLtL1    Apr 16 2007 00:20:36
> Source License: LGPL(gcl,gmp), GPL(unexec,bfd,xgcl)
> Binary License:  GPL due to GPL'ed components: (UNEXEC)
> Modifications of this banner must retain notice of a compatible license
> Dedicated to the memory of W. Schelter
> 
> Use (help) to get some basic information on how to use GCL.
> Temporary directory for compiler files set to
> C:/msys/1.0/home/Administrator/axiom-sandbox/build/i686-pc-mingw32/
> 
> >
> Error: Unsupported on Windows platforms
> Fast links are on: do (si::use-fast-links nil) for debugging
> Error signalled by SYSTEM:FIND-INIT-NAME.
> Broken at SYSTEM:FIND-INIT-NAME.  Type :H for Help.
> >>/bin/install -c lisp.exe
> /home/Administrator/axiom-sandbox/build/i686-pc-mingw32/bin
> /bin/install: cannot stat `lisp.exe': No such file or directory
> make[2]: *** [do_it.gcl] Error 1
> make[2]: Leaving directory `/home/Administrator/axiom-sandbox/src/lisp'
> make[1]: *** [all-lisp] Error 2
> make[1]: Leaving directory `/home/Administrator/axiom-sandbox/src'
> make: *** [all-src] Error 2
> 
> ---------
> 
> Apparently GCL is complaining about "axiom-lisp.o". The following
> patch allowed the build to proceed further:
> 
> --- src/lisp/Makefile.pamphlet  (revision 613)
> +++ src/lisp/Makefile.pamphlet  (working copy)
> @@ -81,7 +81,7 @@
>         echo '(load "axiom-package.lisp")' \
>              '(setq compiler::*default-system-p* t)' \
>              '(compile-file "axiom-lisp.lisp")' | $(AXIOM_LISP)
> -       echo '(compiler::link (quote ("axiom-package.lisp"
> "axiom-lisp.$(OBJEXT)")) "lisp" ' \
> +       echo '(compiler::link (quote ("axiom-package.lisp"
> "axiom-lisp.lisp")) "lisp" ' \
>                ' (format nil "(progn (let ((*load-path* (cons ~S *load-path*))'\
>                                          ' (si::*load-types* ~S))' \
>                                         ' (compiler::emit-fn t))' \
> 
> -----------
> 

Using 'axiom-lisp.lisp' is certainly wrong: 'axiom-lisp.lisp' contains
'clines' constuct which to work must be compiled.  I think that the
following procedure should work:

- first produce an auxilary image linking in the compiled C files, but no
  Lisp files (essentially what revisions earlier than 571 did).
- than start this image, load lisp files and use save-system to
  dump proper image.

Question to Camm:  I want to make an executable image which contains
a package and a few functions in this package.  Some functions call
extra C code.  What is the proper way to make such an executable?
In particular, how to do this in a way that works on all systems
supported by GCL?

My impression was that COMPILER:LINK was the way.  Namely, compile.texi
says:

On systems where dlopen is used for relocations, one cannot make custom
images containing loaded binary object files simply by loading the files
and executing save-system.  This function is provided for such cases.

IIUC save-system will not work if I want to load compiled Lisp code
and the platform uses dlopen.  However, messages in source code seem
to say that COMPILER:LINK does not really work on Windows -- namely
that it can not link Lisp code.


Bill, you may try the following. Camm, is this correct?

diff -u wh-sandbox.bb2/src/lisp/Makefile.pamphlet wh-sandbox/src/lisp/Makefile.pamphlet
--- wh-sandbox.bb2/src/lisp/Makefile.pamphlet	2007-06-18 21:47:51.000000000 +0200
+++ wh-sandbox/src/lisp/Makefile.pamphlet	2007-06-18 22:03:50.000000000 +0200
@@ -81,7 +81,7 @@
 	echo '(load "axiom-package.lisp")' \
 	     '(setq compiler::*default-system-p* t)' \
 	     '(compile-file "axiom-lisp.lisp")' | $(AXIOM_LISP)
-	echo '(compiler::link (quote ("axiom-package.lisp" "axiom-lisp.$(OBJEXT)")) "lisp" ' \
+	echo '(compiler::link nil "prelisp" ' \
               ' (format nil "(progn (let ((*load-path* (cons ~S *load-path*))'\
                                         ' (si::*load-types* ~S))' \
                                        ' (compiler::emit-fn t))' \
@@ -91,6 +91,9 @@
                       ' si::*system-directory* (quote (list ".lsp")))' \
                '  "$(lisp_c_objects) @axiom_c_runtime_extra@")' \
             | $(AXIOM_LISP)
+	echo '(load "axiom-package.lisp") (load "axiom-lisp.$(OBJEXT)")' \
+	     '(in-package "AXIOM-LISP") (save-core "lisp$(EXEEXT)")' \
+	    | ./prelisp$(EXEEXT)
 	$(INSTALL_PROGRAM) lisp$(EXEEXT) $(OUT)
 	$(STAMP) $@
 
\start
Date: Mon, 18 Jun 2007 16:49:53 -0400
From: Bill Page
To: Waldek Hebisch
Subject: Re: problem compiling wh-sandbox revision 571 on Windows
Cc: Camm Maguire

On 6/18/07, Waldek Hebisch wrote:
> ...
> Bill, you may try the following. Camm, is this correct?
>
> diff -u wh-sandbox.bb2/src/lisp/Makefile.pamphlet wh-sandbox/src/lisp/Makefile.pamphlet
> --- wh-sandbox.bb2/src/lisp/Makefile.pamphlet   2007-06-18 21:47:51.000000000 +0200
> +++ wh-sandbox/src/lisp/Makefile.pamphlet       2007-06-18 22:03:50.000000000 +0200
> @@ -81,7 +81,7 @@
>         echo '(load "axiom-package.lisp")' \
>              '(setq compiler::*default-system-p* t)' \
>              '(compile-file "axiom-lisp.lisp")' | $(AXIOM_LISP)
> -       echo '(compiler::link (quote ("axiom-package.lisp" "axiom-lisp.$(OBJEXT)")) "lisp" ' \
> +       echo '(compiler::link nil "prelisp" ' \
>                ' (format nil "(progn (let ((*load-path* (cons ~S *load-path*))'\
>                                          ' (si::*load-types* ~S))' \
>                                         ' (compiler::emit-fn t))' \
> @@ -91,6 +91,9 @@
>                        ' si::*system-directory* (quote (list ".lsp")))' \
>                 '  "$(lisp_c_objects) @axiom_c_runtime_extra@")' \
>              | $(AXIOM_LISP)
> +       echo '(load "axiom-package.lisp") (load "axiom-lisp.$(OBJEXT)")' \
> +            '(in-package "AXIOM-LISP") (save-core "lisp$(EXEEXT)")' \
> +           | ./prelisp$(EXEEXT)
>         $(INSTALL_PROGRAM) lisp$(EXEEXT) $(OUT)
>         $(STAMP) $@
>

Ok, thanks Waldek. That patch appears to have worked. The build just
started stage 2 and is continuing. I will let you know when/if it
completes normally.

\start
Date: 18 Jun 2007 16:50:40 -0400
From: Camm Maguire
To: Waldek Hebisch
Subject: Re: problem compiling wh-sandbox revision 571 on Windows

Greetings!  And thanks for finding this bug.  compiler::link did once
work on Windows -- apparently subsequent development coupled with our
current lack of a Windows maintainer has resulted in this temporary
breakage.


Here is the function in question:

object
find_init_name1(char *s,unsigned len) {
#ifdef _WIN32
  FEerror("Not supported on Windows",0);
#else    
  struct stat ss;
  char *tmp,*q;
  FILE *f;

  if (len) {
    tmp=alloca(len+1);
    memcpy(tmp,s,len);
    tmp[len]=0;
  } else
    tmp=s;
  if (stat(tmp,&ss))
    FEerror("File ~a does not exist",1,make_simple_string(tmp));
  if (!(f=fopen(tmp,"rb")))
    FEerror("Cannot open ~a for binary reading",1,make_simple_string(tmp));
  tmp=alloca(ss.st_size+1);
  if (fread(tmp,1,ss.st_size,f)!=ss.st_size)
    FEerror("Error reading binary file",0);
  fclose(f);
  for (s=tmp;s<tmp+ss.st_size && strncmp(s,"init_",5);q=strstr(s+1,"init_"),s=q ? q : s+strlen(s)+1);
  if (strncmp(s,"init_",5))
    FEerror("Init name not found",0);
  return make_simple_string(s);
#endif  

}

Admittedly this is a rather stupid function.  Traditionally, GCL uses
"init_code" as the name of the initializing function for compiled
source, except when the :system-p flag is set (i.e. for linking with
ld), in which case the name is "init_filename" to prevent multiple
symbol errors from ld.  compiler::link needs to have the name to
properly write user_init.  Before find_init_name was written, we used
some even more fragile heuristic.

Surely something like the above can be made to work on Windows.  Or a
piped call to nm?  I'd be most appreciative for a suggested patch,
which should be rather simple.

Take care,


Waldek Hebisch writes:

> CC-ing Camm, as the problem depends on very specific GCL behavoiur.
> 
> Bill Page wrote:
> > Waldek,
> > 
> > The following change in revsion 571:
> > 
> > http://axiom.svn.sourceforge.net/viewvc/axiom/branches/wh-sandbox/src/lisp/Makefile.pamphlet?view=diff&r1=570&r2=571
> > 
> > seems to cause problems building wh-sandbox on Windows:
> > 
> > ...
> > Finished compiling axiom-lisp.lisp.
> > #p"axiom-lisp.o"
> > 
> > >echo '(compiler::link (quote ("axiom-package.lisp" "axiom-lisp.o")) "lisp" ' \
> >               ' (format nil "(progn (let ((*load-path* (cons ~S *load-path*))'\
> >                                         ' (si::*load-types* ~S))' \
> >                                        ' (compiler::emit-fn t))' \
> >                                   ' (when (fboundp (quote si::sgc-on))' \
> >                                         ' (si::sgc-on t))' \
> >                                   ' (setq compiler::*default-system-p* t))"' \
> >                       ' si::*system-directory* (quote (list ".lsp")))' \
> >                '
> > "C:/msys/1.0/home/Administrator/axiom-sandbox/src/lisp/../.././src/lib/bsdsignal.o
> > C:/msys/1.0/home/Administrator/axiom-sandbox/src/lisp/../.././src/lib/cfuns-c.o
> > C:/msys/1.0/home/Administrator/axiom-sandbox/src/lisp/../.././src/lib/sockio-c.o
> > -lwsock32")' \
> >             | /usr/local/bin/gcl
> > GCL (GNU Common Lisp)  2.6.8 CLtL1    Apr 16 2007 00:20:36
> > Source License: LGPL(gcl,gmp), GPL(unexec,bfd,xgcl)
> > Binary License:  GPL due to GPL'ed components: (UNEXEC)
> > Modifications of this banner must retain notice of a compatible license
> > Dedicated to the memory of W. Schelter
> > 
> > Use (help) to get some basic information on how to use GCL.
> > Temporary directory for compiler files set to
> > C:/msys/1.0/home/Administrator/axiom-sandbox/build/i686-pc-mingw32/
> > 
> > >
> > Error: Unsupported on Windows platforms
> > Fast links are on: do (si::use-fast-links nil) for debugging
> > Error signalled by SYSTEM:FIND-INIT-NAME.
> > Broken at SYSTEM:FIND-INIT-NAME.  Type :H for Help.
> > >>/bin/install -c lisp.exe
> > /home/Administrator/axiom-sandbox/build/i686-pc-mingw32/bin
> > /bin/install: cannot stat `lisp.exe': No such file or directory
> > make[2]: *** [do_it.gcl] Error 1
> > make[2]: Leaving directory `/home/Administrator/axiom-sandbox/src/lisp'
> > make[1]: *** [all-lisp] Error 2
> > make[1]: Leaving directory `/home/Administrator/axiom-sandbox/src'
> > make: *** [all-src] Error 2
> > 
> > ---------
> > 
> > Apparently GCL is complaining about "axiom-lisp.o". The following
> > patch allowed the build to proceed further:
> > 
> > --- src/lisp/Makefile.pamphlet  (revision 613)
> > +++ src/lisp/Makefile.pamphlet  (working copy)
> > @@ -81,7 +81,7 @@
> >         echo '(load "axiom-package.lisp")' \
> >              '(setq compiler::*default-system-p* t)' \
> >              '(compile-file "axiom-lisp.lisp")' | $(AXIOM_LISP)
> > -       echo '(compiler::link (quote ("axiom-package.lisp"
> > "axiom-lisp.$(OBJEXT)")) "lisp" ' \
> > +       echo '(compiler::link (quote ("axiom-package.lisp"
> > "axiom-lisp.lisp")) "lisp" ' \
> >                ' (format nil "(progn (let ((*load-path* (cons ~S *load-path*))'\
> >                                          ' (si::*load-types* ~S))' \
> >                                         ' (compiler::emit-fn t))' \
> > 
> > -----------
> > 
> 
> Using 'axiom-lisp.lisp' is certainly wrong: 'axiom-lisp.lisp' contains
> 'clines' constuct which to work must be compiled.  I think that the
> following procedure should work:
> 
> - first produce an auxilary image linking in the compiled C files, but no
>   Lisp files (essentially what revisions earlier than 571 did).
> - than start this image, load lisp files and use save-system to
>   dump proper image.
> 
> Question to Camm:  I want to make an executable image which contains
> a package and a few functions in this package.  Some functions call
> extra C code.  What is the proper way to make such an executable?
> In particular, how to do this in a way that works on all systems
> supported by GCL?
> 
> My impression was that COMPILER:LINK was the way.  Namely, compile.texi
> says:
> 
> On systems where dlopen is used for relocations, one cannot make custom
> images containing loaded binary object files simply by loading the files
> and executing save-system.  This function is provided for such cases.
> 
> IIUC save-system will not work if I want to load compiled Lisp code
> and the platform uses dlopen.  However, messages in source code seem
> to say that COMPILER:LINK does not really work on Windows -- namely
> that it can not link Lisp code.
> 
> 
> Bill, you may try the following. Camm, is this correct?
> 
> diff -u wh-sandbox.bb2/src/lisp/Makefile.pamphlet wh-sandbox/src/lisp/Makefile.pamphlet
> --- wh-sandbox.bb2/src/lisp/Makefile.pamphlet	2007-06-18 21:47:51.000000000 +0200
> +++ wh-sandbox/src/lisp/Makefile.pamphlet	2007-06-18 22:03:50.000000000 +0200
> @@ -81,7 +81,7 @@
>  	echo '(load "axiom-package.lisp")' \
>  	     '(setq compiler::*default-system-p* t)' \
>  	     '(compile-file "axiom-lisp.lisp")' | $(AXIOM_LISP)
> -	echo '(compiler::link (quote ("axiom-package.lisp" "axiom-lisp.$(OBJEXT)")) "lisp" ' \
> +	echo '(compiler::link nil "prelisp" ' \
>                ' (format nil "(progn (let ((*load-path* (cons ~S *load-path*))'\
>                                          ' (si::*load-types* ~S))' \
>                                         ' (compiler::emit-fn t))' \
> @@ -91,6 +91,9 @@
>                        ' si::*system-directory* (quote (list ".lsp")))' \
>                 '  "$(lisp_c_objects) @axiom_c_runtime_extra@")' \
>              | $(AXIOM_LISP)
> +	echo '(load "axiom-package.lisp") (load "axiom-lisp.$(OBJEXT)")' \
> +	     '(in-package "AXIOM-LISP") (save-core "lisp$(EXEEXT)")' \
> +	    | ./prelisp$(EXEEXT)
>  	$(INSTALL_PROGRAM) lisp$(EXEEXT) $(OUT)
>  	$(STAMP) $@

\start
Date: Mon, 18 Jun 2007 18:53:51 -0400
From: Bill Page
To: Waldek Hebisch
Subject: Re: problem compiling wh-sandbox revision 571 on Windows
Cc: Camm Maguire

On 6/18/07, Bill Page wrote:
> ...
> Ok, thanks Waldek. That patch appears to have worked. The build just
> started stage 2 and is continuing. I will let you know when/if it
> completes normally.
>

Well here we are nearly at the end of the algebra build but a problem
occurs while re-building the databases:

...

   Cumulative Statistics for Constructor GuessFinite
      Time: 0.09 seconds

   finalizing NRLIB GUESSF
   Processing GuessFinite for Browser database:
--------constructor---------
------------------------------------------------------------------------
   GuessFinite is now explicitly exposed in frame initial
   GuessFinite will be automatically loaded when needed from
      /msys/1.0/home/Administrator/wh-test/src/algebra/GUESSF.NRLIB/code

(1) -> touch guess-pkg
/home/Administrator/wh-test/src/algebra/../.././build/scripts/document
--tangle='TEST INTHEORY' --output=../input/INTHEORY.input
../../../wh-sandbox/src/algebra/numtheor.spad.pamphlet
/home/Administrator/wh-test/src/algebra/../.././build/scripts/document
--tangle='TEST VIEW2D' --output=../input/VIEW2D.input
../../../wh-sandbox/src/algebra/view2D.spad.pamphlet
/home/Administrator/wh-test/src/algebra/../.././build/scripts/document
--tangle='TEST FR' --output=../input/TESTFR.input
../../../wh-sandbox/src/algebra/fr.spad.pamphlet
rm -f stamp
echo timestamp > stamp
finished .
make[2]: Entering directory `/home/Administrator/wh-test/src/etc'
4 rebuilding databases...
GCL (GNU Common Lisp)  2.6.8 CLtL1    Apr 16 2007 00:20:36
Source License: LGPL(gcl,gmp), GPL(unexec,bfd,xgcl)
Binary License:  GPL due to GPL'ed components: (UNEXEC)
Modifications of this banner must retain notice of a compatible license
Dedicated to the memory of W. Schelter

Use (help) to get some basic information on how to use GCL.
Temporary directory for compiler files set to
C:/msys/1.0/home/Administrator/wh-test/build/i686-pc-mingw32/
                        AXIOM Computer Algebra System
                 Version: Axiom wh-sandbox branch 2007-05-31
                           Timestamp: no timestamp
-----------------------------------------------------------------------------
   Issue )copyright to view copyright notices.
   Issue )summary for a summary of useful system commands.
   Issue )quit to leave AXIOM and return to shell.
-----------------------------------------------------------------------------

   Using local database
C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/compress.daase..
  Using local database
C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/interp.daase..
   Using local database
C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/operation.daase..
   Using local database
C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/category.daase..
   Using local database
C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/browse.daase..
(1) ->    Loading
C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/apply.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/c-doc.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/c-util.

...

   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-prof.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-saturn.

"building browse.daase"
"building operation.daase"
"building category.daase"
   >> System error:
   The function |SetCategory| is undefined.

(1) -> /bin/install: cannot stat `../algebra/*.daase': No such file or directory
make[2]: *** [/home/Administrator/wh-test/target/i686-pc-mingw32/algebra/compress.daase]
Error 1
make[2]: Leaving directory `/home/Administrator/wh-test/src/etc'
make[1]: *** [all-asq] Error 2
make[1]: Leaving directory `/home/Administrator/wh-test/src'
make: *** [all-src] Error 2

------------

But something goes wrong building 'compress.daase'. This error:

     The function |SetCategory| is undefined.

seems strange to appear at this late stage in the build process. It
looks like the failure occurred in 'make-databases'.

 I did not notice any earlier failures in the build but I will check again.

Can you think of anything that might cause this?

\start
Date: Tue, 19 Jun 2007 01:40:23 +0200 (CEST)
From: Waldek Hebisch
To: Bill Page
Subject: Re: problem compiling wh-sandbox revision 571 on Windows
Cc: Camm Maguire

Bill Page wrote:
> Well here we are nearly at the end of the algebra build but a problem
> occurs while re-building the databases:
> 
> ...
> 
>    Cumulative Statistics for Constructor GuessFinite
>       Time: 0.09 seconds
> 
>    finalizing NRLIB GUESSF
>    Processing GuessFinite for Browser database:
> --------constructor---------
> ------------------------------------------------------------------------
>    GuessFinite is now explicitly exposed in frame initial
>    GuessFinite will be automatically loaded when needed from
>       /msys/1.0/home/Administrator/wh-test/src/algebra/GUESSF.NRLIB/code
> 
> (1) -> touch guess-pkg
> /home/Administrator/wh-test/src/algebra/../.././build/scripts/document
> --tangle='TEST INTHEORY' --output=../input/INTHEORY.input
> ../../../wh-sandbox/src/algebra/numtheor.spad.pamphlet
> /home/Administrator/wh-test/src/algebra/../.././build/scripts/document
> --tangle='TEST VIEW2D' --output=../input/VIEW2D.input
> ../../../wh-sandbox/src/algebra/view2D.spad.pamphlet
> /home/Administrator/wh-test/src/algebra/../.././build/scripts/document
> --tangle='TEST FR' --output=../input/TESTFR.input
> ../../../wh-sandbox/src/algebra/fr.spad.pamphlet
> rm -f stamp
> echo timestamp > stamp
> finished .
> make[2]: Entering directory `/home/Administrator/wh-test/src/etc'
> 4 rebuilding databases...
> GCL (GNU Common Lisp)  2.6.8 CLtL1    Apr 16 2007 00:20:36
> Source License: LGPL(gcl,gmp), GPL(unexec,bfd,xgcl)
> Binary License:  GPL due to GPL'ed components: (UNEXEC)
> Modifications of this banner must retain notice of a compatible license
> Dedicated to the memory of W. Schelter
> 
> Use (help) to get some basic information on how to use GCL.
> Temporary directory for compiler files set to
> C:/msys/1.0/home/Administrator/wh-test/build/i686-pc-mingw32/
>                         AXIOM Computer Algebra System
>                  Version: Axiom wh-sandbox branch 2007-05-31
>                            Timestamp: no timestamp
> -----------------------------------------------------------------------------
>    Issue )copyright to view copyright notices.
>    Issue )summary for a summary of useful system commands.
>    Issue )quit to leave AXIOM and return to shell.
> -----------------------------------------------------------------------------
> 
>    Using local database
> C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/compress.daase..
>   Using local database
> C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/interp.daase..
>    Using local database
> C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/operation.daase..
>    Using local database
> C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/category.daase..
>    Using local database
> C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/browse.daase..
> (1) ->    Loading
> C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/apply.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/c-doc.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/c-util.
> 
> ...
> 
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-prof.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-saturn.
> 
> "building browse.daase"
> "building operation.daase"
> "building category.daase"
>    >> System error:
>    The function |SetCategory| is undefined.
> 
> (1) -> /bin/install: cannot stat `../algebra/*.daase': No such file or directory
> make[2]: *** [/home/Administrator/wh-test/target/i686-pc-mingw32/algebra/compress.daase]
> Error 1
> make[2]: Leaving directory `/home/Administrator/wh-test/src/etc'
> make[1]: *** [all-asq] Error 2
> make[1]: Leaving directory `/home/Administrator/wh-test/src'
> make: *** [all-src] Error 2
> 
> ------------
> 
> But something goes wrong building 'compress.daase'. This error:
> 
>      The function |SetCategory| is undefined.
> 
> seems strange to appear at this late stage in the build process. It
> looks like the failure occurred in 'make-databases'.
> 
>  I did not notice any earlier failures in the build but I will check again.
> 
> Can you think of anything that might cause this?
> 

I belive that have met this error several times.  Typically, however
I saw a crash.   Namely, during database build Axiom has to load
all constructors (categories, domains and packages) from *.NRLIB
directories.  If something goes wrong with paths or file searches
Axiom finds no files to load -- the result is an essentially empty
database.  But such database stil contains a few positions which
reference SetCategory.  If SetCategory is missing Axiom can not
dump the database...

During normal build one sees a lot of messages of form:

  IntegerMod will be automatically loaded when needed from
      /var/tmp/hebisch/axp22/ax-build2/src/algebra/ZMOD.NRLIB/code

and later:
 
  Loading
      /var/tmp/hebisch/axp22/ax-build2/src/algebra/A1AGG-.NRLIB/code
      for domain OneDimensionalArrayAggregate&

I would first try to build databases by hand: set AXIOM variable to

C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32

and DAASE to

C:/msys/1.0/home/Administrator/wh-sandbox/src/share

and at Axiom prompt type:

)lisp (make-databases "" nil)

\start
Date: Tue, 19 Jun 2007 14:43:00 +1000
From: Alasdair McAndrew
To: Martin Rubey
Subject: Re: Two hyperdoc questions

Thanks Martin, as always, for your unstinting and generous help.  What then,
in your estimation, are the minimal requirements (virtual machine, X server,
whatever) to run a complete Axiom - including graphics and HyperDoc - on
windows?

Thanks,
Alasdair

On 18 Jun 2007 08:24:33 +0200, Martin Rubey
wrote:
>
> Alasdair McAndrew writes:
>
> > 1) What is the current state of using HyperDoc (or any other sort of
> help
> > browser) under windows - in particular with Axiom-0.1.4?
>
> * Out of the box there is nothing.
>
> * There is an experimental port by Tim Daly, with the important drawback
> that
>   there is no connection to Axiom, i.e., browse does *not* work
>
> * There is the possibility of running axiom within a virtual machine, as
>   proposed by Bill Page and Alfredo Portes.  I'd recommend that one.  This
> is
>   also the only way to get graphics on windows.  Furthermore, if you are
>   interested in combinatorics, Polymake and therefore my Polymake-wrapper
> only
>   works on linux, too.  Together with axiom.el and SPADEDIT for gnu emacs
> this
>   makes quite a usable environment even for windows users.  (After
> clicking on
>   gnu emacs, they just need to press "Alt" then "x", type "axiom" and
>   everything should work.
>
> * There is the possibly half working hyperdoc replacement by myself, which
>   needs an axiom process dedicated for documentation -- but which you can
> run
>   in the background, so you won't even notice.  So far it only can browse
>   operations, and it's not really tested on windows.  Even if it is not
> that
>   much interesting for production work at the moment, I'd urge you to try
> it
>   and send me your experiences.
>
> > 2) If I inadvertently quit HyperDoc while running Axiom, I can restart
> it
> > with )hd.  But )hd doesn't provide a socket connection; this new
> HyperDoc is
> > "not connected to Axiom".  Is there any way of starting a "connected"
> > HyperDoc from an already-running Axiom?
>
> No, but I'd love to see a fix for that bug, too.

\start
Date: Mon, 18 Jun 2007 21:46:24 -0700
From: Alfredo Portes
To: Alasdair McAndrew
Subject: Re: Two hyperdoc questions

Virtual Machine:

http://wiki.axiom-developer.org/DoyenCD (Axiom Gold)

On 6/18/07, Alasdair McAndrew wrote:
> Thanks Martin, as always, for your unstinting and generous help.  What then,
> in your estimation, are the minimal requirements (virtual machine, X server,
> whatever) to run a complete Axiom - including graphics and HyperDoc - on
> windows?
>
> Thanks,
> Alasdair
>
>
> On 18 Jun 2007 08:24:33 +0200, Martin Rubey
> wrote:
> > "Alasdair McAndrew" <Alasdair McAndrew > writes:
> >
> > > 1) What is the current state of using HyperDoc (or any other sort of
> help
> > > browser) under windows - in particular with Axiom-0.1.4?
> >
> > * Out of the box there is nothing.
> >
> > * There is an experimental port by Tim Daly, with the important drawback
> that
> >   there is no connection to Axiom, i.e., browse does *not* work
> >
> > * There is the possibility of running axiom within a virtual machine, as
> >   proposed by Bill Page and Alfredo Portes.  I'd recommend that one.  This
> is
> >   also the only way to get graphics on windows.  Furthermore, if you are
> >   interested in combinatorics, Polymake and therefore my Polymake-wrapper
> only
> >   works on linux, too.  Together with axiom.el and SPADEDIT for gnu emacs
> this
> >   makes quite a usable environment even for windows users.  (After
> clicking on
> >   gnu emacs, they just need to press "Alt" then "x", type "axiom" and
> >   everything should work.
> >
> > * There is the possibly half working hyperdoc replacement by myself, which
> >   needs an axiom process dedicated for documentation -- but which you can
> run
> >   in the background, so you won't even notice.  So far it only can browse
> >   operations, and it's not really tested on windows.  Even if it is not
> that
> >   much interesting for production work at the moment, I'd urge you to try
> it
> >   and send me your experiences.
> >
> > > 2) If I inadvertently quit HyperDoc while running Axiom, I can restart
> it
> > > with )hd.  But )hd doesn't provide a socket connection; this new
> HyperDoc is
> > > "not connected to Axiom".  Is there any way of starting a "connected"
> > > HyperDoc from an already-running Axiom?
> >
> > No, but I'd love to see a fix for that bug, too.

\start
Date: Tue, 19 Jun 2007 01:02:11 -0400
From: Bill Page
To: Waldek Hebisch
Subject: Re: problem compiling wh-sandbox revision 571 on Windows

On 6/18/07, Waldek Hebisch wrote:
> Bill Page wrote:
> > Well here we are nearly at the end of the algebra build but a problem
> > occurs while re-building the databases:
> >
> > ...
> >
> >    Cumulative Statistics for Constructor GuessFinite
> >       Time: 0.09 seconds
> >
> >    finalizing NRLIB GUESSF
> >    Processing GuessFinite for Browser database:
> > --------constructor---------
> > ------------------------------------------------------------------------
> >    GuessFinite is now explicitly exposed in frame initial
> >    GuessFinite will be automatically loaded when needed from
> >       /msys/1.0/home/Administrator/wh-test/src/algebra/GUESSF.NRLIB/code
> >
> > (1) -> touch guess-pkg
> > /home/Administrator/wh-test/src/algebra/../.././build/scripts/document
> > --tangle='TEST INTHEORY' --output=../input/INTHEORY.input
> > ../../../wh-sandbox/src/algebra/numtheor.spad.pamphlet
> > /home/Administrator/wh-test/src/algebra/../.././build/scripts/document
> > --tangle='TEST VIEW2D' --output=../input/VIEW2D.input
> > ../../../wh-sandbox/src/algebra/view2D.spad.pamphlet
> > /home/Administrator/wh-test/src/algebra/../.././build/scripts/document
> > --tangle='TEST FR' --output=../input/TESTFR.input
> > ../../../wh-sandbox/src/algebra/fr.spad.pamphlet
> > rm -f stamp
> > echo timestamp > stamp
> > finished .
> > make[2]: Entering directory `/home/Administrator/wh-test/src/etc'
> > 4 rebuilding databases...
> > GCL (GNU Common Lisp)  2.6.8 CLtL1    Apr 16 2007 00:20:36
> > Source License: LGPL(gcl,gmp), GPL(unexec,bfd,xgcl)
> > Binary License:  GPL due to GPL'ed components: (UNEXEC)
> > Modifications of this banner must retain notice of a compatible license
> > Dedicated to the memory of W. Schelter
> >
> > Use (help) to get some basic information on how to use GCL.
> > Temporary directory for compiler files set to
> > C:/msys/1.0/home/Administrator/wh-test/build/i686-pc-mingw32/
> >                         AXIOM Computer Algebra System
> >                  Version: Axiom wh-sandbox branch 2007-05-31
> >                            Timestamp: no timestamp
> > -----------------------------------------------------------------------------
> >    Issue )copyright to view copyright notices.
> >    Issue )summary for a summary of useful system commands.
> >    Issue )quit to leave AXIOM and return to shell.
> > -----------------------------------------------------------------------------
> >
> >    Using local database
> > C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/compress.daase..
> >   Using local database
> > C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/interp.daase..
> >    Using local database
> > C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/operation.daase..
> >    Using local database
> > C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/category.daase..
> >    Using local database
> > C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/browse.daase..
> > (1) ->    Loading
> > C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/apply.
> >    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/c-doc.
> >    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/c-util.
> >
> > ...
> >
> >    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-prof.
> >    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-saturn.
> >
> > "building browse.daase"
> > "building operation.daase"
> > "building category.daase"
> >    >> System error:
> >    The function |SetCategory| is undefined.
> >
> > (1) -> /bin/install: cannot stat `../algebra/*.daase': No such file or directory
> > make[2]: *** [/home/Administrator/wh-test/target/i686-pc-mingw32/algebra/compress.daase]
> > Error 1
> > make[2]: Leaving directory `/home/Administrator/wh-test/src/etc'
> > make[1]: *** [all-asq] Error 2
> > make[1]: Leaving directory `/home/Administrator/wh-test/src'
> > make: *** [all-src] Error 2
> >
> > ------------
> >
> > But something goes wrong building 'compress.daase'. This error:
> >
> >      The function |SetCategory| is undefined.
> >
> > seems strange to appear at this late stage in the build process. It
> > looks like the failure occurred in 'make-databases'.
> >
> >  I did not notice any earlier failures in the build but I will check again.
> >
> > Can you think of anything that might cause this?
> >
>
> I belive that have met this error several times.  Typically, however
> I saw a crash.   Namely, during database build Axiom has to load
> all constructors (categories, domains and packages) from *.NRLIB
> directories.  If something goes wrong with paths or file searches
> Axiom finds no files to load -- the result is an essentially empty
> database.  But such database stil contains a few positions which
> reference SetCategory.  If SetCategory is missing Axiom can not
> dump the database...
>
> During normal build one sees a lot of messages of form:
>
>   IntegerMod will be automatically loaded when needed from
>       /var/tmp/hebisch/axp22/ax-build2/src/algebra/ZMOD.NRLIB/code
>
> and later:
>
>   Loading
>       /var/tmp/hebisch/axp22/ax-build2/src/algebra/A1AGG-.NRLIB/code
>       for domain OneDimensionalArrayAggregate&
>
> I would first try to build databases by hand: set AXIOM variable to
>
> C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32
>
> and DAASE to
>
> C:/msys/1.0/home/Administrator/wh-sandbox/src/share
>
> and at Axiom prompt type:
>
> )lisp (make-databases "" nil)
>
>

Here is the result of the test. It seems, as you say, that for some
reason 'make-databases' is not loading any of the *.NRLIB. But oddly,
I can load them manually by the ')lib' command and if I do, then the
error message shifts to the next *.NRLIB. For example:


-------

Administrator@ASUS ~/wh-test/src/algebra
$ export AXIOM=C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32

Administrator@ASUS ~/wh-test/src/algebra
$ ls $AXIOM
algebra  autoload  bin  doc  lib  share  src  timestamp

Administrator@ASUS ~/wh-test/src/algebra
$ export DAASE=C:/msys/1.0/home/Administrator/wh-sandbox/src/share

Administrator@ASUS ~/wh-test/src/algebra
$ ../../build/i686-pc-mingw32/bin/interpsys.exe
GCL (GNU Common Lisp)  2.6.8 CLtL1    Apr 16 2007 00:20:36
Source License: LGPL(gcl,gmp), GPL(unexec,bfd,xgcl)
Binary License:  GPL due to GPL'ed components: (UNEXEC)
Modifications of this banner must retain notice of a compatible license
Dedicated to the memory of W. Schelter

Use (help) to get some basic information on how to use GCL.
Temporary directory for compiler files set to
C:/DOCUME~1/ADMINI~1.ASU/LOCALS~1/Temp/
                        AXIOM Computer Algebra System
                 Version: Axiom wh-sandbox branch 2007-05-31
                           Timestamp: no timestamp
-----------------------------------------------------------------------------
   Issue )copyright to view copyright notices.
   Issue )summary for a summary of useful system commands.
   Issue )quit to leave AXIOM and return to shell.
-----------------------------------------------------------------------------

   Using local database
C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/compress.daase..
  Using local database
C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/interp.daase..
   Using local database
C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/operation.daase..
   Using local database
C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/category.daase..
   Using local database
C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/browse.daase..
(1) -> )lisp (make-databases "" nil)
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/apply.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/c-doc.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/c-util.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/profile.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/category.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/compiler.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/define.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/functor.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/info.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/iterator.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/modemap.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/nruncomp.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/package.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/htcheck.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/bc-matrix.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/bc-misc.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/bc-solve.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/bc-util.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/ht-util.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/htsetvar.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/ht-root.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-con.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-data.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/showimp.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-op1.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-op2.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-search.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-util.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/topics.
(1) ->

   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-prof.
   Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-saturn.

"building browse.daase"
"building operation.daase"
"building category.daase"
   >> System error:
   The function |SetCategory| is undefined.

(1) -> )sh SetCategory
 SetCategory  is a category constructor
 Abbreviation for SetCategory is SETCAT
 This constructor is exposed in this frame.
 Issue )edit NIL to see algebra source code for SETCAT

------------------------------- Operations --------------------------------
 ?=? : (%,%) -> Boolean                coerce : % -> OutputForm

(1) -> )lib SETCAT
   SetCategory is now explicitly exposed in frame initial
   SetCategory will be automatically loaded when needed from
      /msys/1.0/home/Administrator/wh-test/src/algebra/SETCAT.NRLIB/code

...

(1) -> )lisp (make-databases "" nil)
   Loading ...

"building browse.daase"
"building operation.daase"
"building category.daase"    Loading
      /msys/1.0/home/Administrator/wh-test/src/algebra/SETCAT.NRLIB/code
      for  SetCategory

   >> System error:
   The function |BasicType| is undefined.

(1) -> )lib BASTYPE
   BasicType is now explicitly exposed in frame initial
   BasicType will be automatically loaded when needed from
      /msys/1.0/home/Administrator/wh-test/src/algebra/BASTYPE.NRLIB/code
(1) -> )lisp (make-databases "" nil)

"building browse.daase"
"building operation.daase"
"building category.daase"    Loading
      /msys/1.0/home/Administrator/wh-test/src/algebra/BASTYPE.NRLIB/code
      for  BasicType

   >> System error:
   The function |CoercibleTo| is undefined.

etc.

---------------

So, it seems like some crucial initialization if missing that prevents
'make-databases' from finding and loading all the *.NRLIB. I have
looked at the Lisp code in 'daase.lisp.pamphlet' but how this is
supposed to work remains completely obscure to me. What changes when I
issue the ')lib' command that allows 'make-databases' to then find and
load the modules?

\start
Date: 19 Jun 2007 09:23:18 +0200
From: Martin Rubey
To: Alfredo Portes
Subject: Re: Two hyperdoc questions

Alfredo Portes writes:

> Virtual Machine:
> 
> http://wiki.axiom-developer.org/DoyenCD (Axiom Gold)

Hm, but didn't you have a live cd of wh-sandbox also?  See

http://www.mail-archive.com/axiom-developer%40nongnu.org/msg10528.html

That's much better than Gold, since HyperDoc doesn't really work in
Gold. (dependents, users, etc. crash.)


(You didn't manage to add the Aldor connection also, did you? Is it easy to add
files and programs after having it installed on the windows box, like emacs,
and my axiom mode for emacs?)

\start
Date: Tue, 19 Jun 2007 12:01:10 +0200 (CEST)
From: Waldek Hebisch
To: Bill Page
Subject: Re: problem compiling wh-sandbox revision 571 on Windows

Bill Page wrote:
> Here is the result of the test. It seems, as you say, that for some
> reason 'make-databases' is not loading any of the *.NRLIB. But oddly,
> I can load them manually by the ')lib' command and if I do, then the
> error message shifts to the next *.NRLIB. For example:
> 
> 
> -------
> 
> Administrator@ASUS ~/wh-test/src/algebra
> $ export AXIOM=C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32
> 
> Administrator@ASUS ~/wh-test/src/algebra
> $ ls $AXIOM
> algebra  autoload  bin  doc  lib  share  src  timestamp
> 
> Administrator@ASUS ~/wh-test/src/algebra
> $ export DAASE=C:/msys/1.0/home/Administrator/wh-sandbox/src/share
> 
> Administrator@ASUS ~/wh-test/src/algebra
> $ ../../build/i686-pc-mingw32/bin/interpsys.exe
> GCL (GNU Common Lisp)  2.6.8 CLtL1    Apr 16 2007 00:20:36
> Source License: LGPL(gcl,gmp), GPL(unexec,bfd,xgcl)
> Binary License:  GPL due to GPL'ed components: (UNEXEC)
> Modifications of this banner must retain notice of a compatible license
> Dedicated to the memory of W. Schelter
> 
> Use (help) to get some basic information on how to use GCL.
> Temporary directory for compiler files set to
> C:/DOCUME~1/ADMINI~1.ASU/LOCALS~1/Temp/
>                         AXIOM Computer Algebra System
>                  Version: Axiom wh-sandbox branch 2007-05-31
>                            Timestamp: no timestamp
> -----------------------------------------------------------------------------
>    Issue )copyright to view copyright notices.
>    Issue )summary for a summary of useful system commands.
>    Issue )quit to leave AXIOM and return to shell.
> -----------------------------------------------------------------------------
> 
>    Using local database
> C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/compress.daase..
>   Using local database
> C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/interp.daase..
>    Using local database
> C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/operation.daase..
>    Using local database
> C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/category.daase..
>    Using local database
> C:/msys/1.0/home/Administrator/wh-sandbox/src/share/algebra/browse.daase..
> (1) -> )lisp (make-databases "" nil)
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/apply.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/c-doc.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/c-util.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/profile.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/category.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/compiler.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/define.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/functor.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/info.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/iterator.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/modemap.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/nruncomp.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/package.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/htcheck.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/bc-matrix.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/bc-misc.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/bc-solve.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/bc-util.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/ht-util.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/htsetvar.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/ht-root.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-con.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-data.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/showimp.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-op1.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-op2.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-search.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-util.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/topics.
> (1) ->
> 
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-prof.
>    Loading C:/msys/1.0/home/Administrator/wh-test/target/i686-pc-mingw32/autoload/br-saturn.
> 
> "building browse.daase"
> "building operation.daase"
> "building category.daase"
>    >> System error:
>    The function |SetCategory| is undefined.
> 
> (1) -> )sh SetCategory
>  SetCategory  is a category constructor
>  Abbreviation for SetCategory is SETCAT
>  This constructor is exposed in this frame.
>  Issue )edit NIL to see algebra source code for SETCAT
> 
> ------------------------------- Operations --------------------------------
>  ?=? : (%,%) -> Boolean                coerce : % -> OutputForm
> 
> (1) -> )lib SETCAT
>    SetCategory is now explicitly exposed in frame initial
>    SetCategory will be automatically loaded when needed from
>       /msys/1.0/home/Administrator/wh-test/src/algebra/SETCAT.NRLIB/code
> 
> ...
> 
> (1) -> )lisp (make-databases "" nil)
>    Loading ...
> 
> "building browse.daase"
> "building operation.daase"
> "building category.daase"    Loading
>       /msys/1.0/home/Administrator/wh-test/src/algebra/SETCAT.NRLIB/code
>       for  SetCategory
> 
>    >> System error:
>    The function |BasicType| is undefined.
> 
> (1) -> )lib BASTYPE
>    BasicType is now explicitly exposed in frame initial
>    BasicType will be automatically loaded when needed from
>       /msys/1.0/home/Administrator/wh-test/src/algebra/BASTYPE.NRLIB/code
> (1) -> )lisp (make-databases "" nil)
> 
> "building browse.daase"
> "building operation.daase"
> "building category.daase"    Loading
>       /msys/1.0/home/Administrator/wh-test/src/algebra/BASTYPE.NRLIB/code
>       for  BasicType
> 
>    >> System error:
>    The function |CoercibleTo| is undefined.
> 
> etc.
> 
> ---------------
> 
> So, it seems like some crucial initialization if missing that prevents
> 'make-databases' from finding and loading all the *.NRLIB. I have
> looked at the Lisp code in 'daase.lisp.pamphlet' but how this is
> supposed to work remains completely obscure to me. What changes when I
> issue the ')lib' command that allows 'make-databases' to then find and
> load the modules?
> 

The fact that ')lib' helps is unintended side effect (bug).  'make-databases'
should clean all old information and use only new one, but currently it
does not clean autoload info.  Usually this is not a big problem, but
is showed up during database bootstrap.

Concerning code in 'daase.lisp.pamphlet':  the 'localdatabase' function
is supposed to read information from files.  More preciely,
'localdatabase' computes list of files and calls 'localnrlib' (or
other functions) to process each of the files.  'localdatabase'
is used in two ways:  
1) from ')lib' command, in this mode explicit list of constructors is
   given
2) form make-databases, in this mode the arguments contain list of
   directories containing *.NRLIB subdirectories

Since apparently ')lib' command works (however the paths printed lack
drive part, which may be a problem), I would suspect that the problem
is in building list of *.NRLIB subdirectories.  I changed this part
to make it work in sbcl and clisp...

As a sanity check I will first check what '(truename "./")' gives
(we want patchname to the current directory).  Than I would look
what '(directory "*.NRLIB/index.KAF")' in algebra directory gives
-- it should produce list of pathnames to index.KAF files.
The exact result vary from Lisp to Lisp, but the form above was
the only one which gave what we want in all Lisps...

You may also try '(directory "*.NRLIB\\index.KAF")', to check
for possible bug handling slashes.

\start
Date: 19 Jun 2007 14:35:05 +0200
From: Francois Maltey
To: list
Subject: A multi-line mode for Emacs.

Hello,

I'm looking at the AxiomEmacsMode.pamphlet and try to allow emacs to 
send to axiom to multi-lines command in an *.input file.

I'll go to use the comint mode in order to improve the actual 
axiom.el mode. 

Are there others prompts in axiom ?

   ^(nn) -> 
or Please enter y or yes if you really want to leave the interactive
   environment and return to the operating system:
or [...] Please confirm your request to have these listed by
   typing y or yes and then pressing Enter :
or BOOT>> 
or BOOT>>>>

How can I go out BOOT>> prompt ?

Can Axiom evaluate every command in a *.input file after the 
usual prompt (nn) -> ?

Have a nice day !

\start
Date: 19 Jun 2007 14:44:30 +0200
From: Martin Rubey
To: Francois Maltey
Subject: Re: A multi-line mode for Emacs.

Francois Maltey writes:

> I'm looking at the AxiomEmacsMode.pamphlet and try to allow emacs to 
> send to axiom to multi-lines command in an *.input file.

great!

> I'll go to use the comint mode in order to improve the actual axiom.el mode.

Haeh? axiom.el already derives from comint mode.

> Are there others prompts in axiom ?
> 
>    ^(nn) -> 
> or Please enter y or yes if you really want to leave the interactive
>    environment and return to the operating system:
> or [...] Please confirm your request to have these listed by
>    typing y or yes and then pressing Enter :
> or BOOT>> 
> or BOOT>>>>

If you change to another lisp package, BOOT will change to be the name of this
package, as far as I know.

It would not surprise me at all if there were other prompts, too.

> How can I go out BOOT>> prompt ?

:qt


But really, the functionality you want to provide should be nearly independent
of axiom.el:

> Can Axiom evaluate every command in a *.input file after the 
> usual prompt (nn) -> ?

no, not at all. You have to put the command into a temporary input file, for
example "tmp.input" and then say

)re tmp.input

in the axiom buffer.  I think it would be OK to assume that the "*axiom*"
buffer is in the right state, i.e., that it has the "^(nn) ->" prompt.

Thus, I suggest you write a function

(defun axiom-send-input (str)
  (interactive)
  ...
)

that puts str into a temporary file tmp.input (best located in the /tmp
directory or the windows equivalent), then writes ")re /tmp/tmp.input" into the
"*axiom*" buffer and calls axiom-eval.

\start
Date: Tue, 19 Jun 2007 08:50:58 -0400
From: Alfredo Portes
To: Martin Rubey
Subject: Re: Two hyperdoc questions

On 19 Jun 2007 09:23:18 +0200, Martin Rubey wrote:
> Alfredo Portes writes:
>
> > Virtual Machine:
> >
> > http://wiki.axiom-developer.org/DoyenCD (Axiom Gold)
>
> Hm, but didn't you have a live cd of wh-sandbox also?  See
>
> http://www.mail-archive.com/axiom-developer%40nongnu.org/msg10528.html
>
> That's much better than Gold, since HyperDoc doesn't really work in
> Gold. (dependents, users, etc. crash.)

Yes. http://alfredo.axiom-developer.org/axiom.zip

> (You didn't manage to add the Aldor connection also, did you? Is it easy to add
> files and programs after having it installed on the windows box, like emacs,
> and my axiom mode for emacs?)

No sorry :-(. I was having similar problems to those described on the
list. I will
give it another try.

\start
Date: 19 Jun 2007 14:58:39 +0200
From: Martin Rubey
To: axiom-developer <list>
Subject: exact quotient

I am currently trying to correct a performance bug of my guessing package, and
found out that exquo is in general not extremely intelligent.

In axiom, what exquo really does is to perform division and return "failed" if
it's not exact.  (I.e., it is in fact slower than quo.quotient)

What I need is a fast algorithm, that simply assumes that the division is
exact, and should benefit from that assumption.  (If the assumption is not
true, the computer may crash, if necessary...) As far as I know, using some
tricks performance even better than n^2 (n being the size of the input) is
achievable.

Most important would be such an implementation for the polynomial rings.

\start
Date: Tue, 19 Jun 2007 09:13:41 -0400
From: Bill Page
To: Waldek Hebisch
Subject: Re: problem compiling wh-sandbox revision 571 on Windows

On 6/19/07, Waldek Hebisch wrote:
> ...
> Concerning code in 'daase.lisp.pamphlet':  the 'localdatabase' function
> is supposed to read information from files.  More preciely,
> 'localdatabase' computes list of files and calls 'localnrlib' (or
> other functions) to process each of the files.  'localdatabase'
> is used in two ways:
> 1) from ')lib' command, in this mode explicit list of constructors is
>    given
> 2) form make-databases, in this mode the arguments contain list of
>    directories containing *.NRLIB subdirectories
>

Thanks for this explanation.

> Since apparently ')lib' command works (however the paths printed
> lack drive part, which may be a problem), I would suspect that the
> problem is in building list of *.NRLIB subdirectories.  I changed this
> part to make it work in sbcl and clisp...
>
> As a sanity check I will first check what '(truename "./")' gives
> (we want patchname to the current directory).

Ok, this result looks sane:

(1) -> )lisp (truename "./")

Value = #p"C:/msys/1.0/home/Administrator/wh-test/src/algebra/"

> Than I would look what '(directory "*.NRLIB/index.KAF")' in algebra
> directory gives
> -- it should produce list of pathnames to index.KAF files.
> The exact result vary from Lisp to Lisp, but the form above was
> the only one which gave what we want in all Lisps...
>
> You may also try '(directory "*.NRLIB\\index.KAF")', to check
> for possible bug handling slashes.
>

All of these functions fail!

(1) -> )lisp (directory "*.NRLIB/index.KAF")

Value = NIL

(1) -> )lisp (directory "*.NRLIB\index.KAF")

Value = NIL
(1) -> )lisp (directory "*.NRLIB\\index.KAF")

Value = NIL

But the following works:

(1) -> )sys ls *.NRLIB/index.KAF
A1AGG-.NRLIB/index.KAF
A1AGG.NRLIB/index.KAF
...

and this works:

(1) -> )lisp (directory "*.NRLIB")

Value = (#p"A1AGG-.NRLIB" #p"A1AGG.NRLIB" #p"ABELGRP-.NRLIB"
         #p"ABELGRP.NRLIB" #p"ABELMON-.NRLIB" #p"ABELMON.NRLIB"
         #p"ABELSG-.NRLIB" #p"ABELSG.NRLIB" #p"ACF-.NRLIB"
...

So I guess we can blame some limitation in the wildcard handling in
paths on Windows. Do you think that it is not safe just to use '
(directory "*.NRLIB")' ? I will change 'make-databases' to omit the
'/index.KAF' part and try the build again.

\start
Date: Tue, 19 Jun 2007 15:23:51 +0200
From: Ralf Hemmecke
To: list
Subject: Re: A multi-line mode for Emacs.

Hi Martin, hello Francois,

maybe you want to look at

http://www.risc.uni-linz.ac.at/people/hemmecke/aldor/aldor.el.nw
\subsection{Sending Command String to an Aldor Process}

That sends a line to the Aldor window and executes it but leaves the 
cursor in the window that contains the list of commands.

I think, Martin, that makes it faster to demonstrate Axiom commands 
since you don't have to go back and forth between the two emacs windows.

\start
Date: Tue, 19 Jun 2007 15:33:42 +0200
From: Ralf Hemmecke
To: Martin Rubey
Subject: Re: exact quotient

On 06/19/2007 02:58 PM, Martin Rubey wrote:
> I am currently trying to correct a performance bug of my guessing package, and
> found out that exquo is in general not extremely intelligent.

> In axiom, what exquo really does is to perform division and return "failed" if
> it's not exact.  (I.e., it is in fact slower than quo.quotient)
> 
> What I need is a fast algorithm, that simply assumes that the division is
> exact, and should benefit from that assumption.  (If the assumption is not
> true, the computer may crash, if necessary...) As far as I know, using some
> tricks performance even better than n^2 (n being the size of the input) is
> achievable.

For integers that algorithm is due to Tudor Jebelean and implemented in GMP.

http://info2html.sourceforge.net/cgi-bin/info2html-demo/info2html?(gmp.info.gz)References

     * Tudor Jebelean, "An algorithm for exact division", Journal of
       Symbolic Computation, volume 15, 1993, pp. 169-180.  Research
       report version available
       `ftp://ftp.risc.uni-linz.ac.at/pub/techreports/1992/92-35.ps.gz'

     * Tudor Jebelean, "Exact Division with Karatsuba Complexity -
       Extended Abstract", RISC-Linz technical report 96-31,
       `ftp://ftp.risc.uni-linz.ac.at/pub/techreports/1996/96-31.ps.gz'

     * Tudor Jebelean, "Practical Integer Division with Karatsuba
       Complexity", ISSAC 97, pp. 339-341.  Technical report available
       `ftp://ftp.risc.uni-linz.ac.at/pub/techreports/1996/96-29.ps.gz'

     * Tudor Jebelean, "A Generalization of the Binary GCD Algorithm",
       ISSAC 93, pp. 111-116.  Technical report version available
       `ftp://ftp.risc.uni-linz.ac.at/pub/techreports/1993/93-01.ps.gz'

     * Tudor Jebelean, "A Double-Digit Lehmer-Euclid Algorithm for
       Finding the GCD of Long Integers", Journal of Symbolic
       Computation, volume 19, 1995, pp. 145-157.  Technical report
       version also available
       `ftp://ftp.risc.uni-linz.ac.at/pub/techreports/1992/92-69.ps.gz'

     * Werner Krandick and Tudor Jebelean, "Bidirectional Exact Integer
       Division", Journal of Symbolic Computation, volume 21, 1996, pp.
       441-455.  Early technical report version also available
       `ftp://ftp.risc.uni-linz.ac.at/pub/techreports/1994/94-50.ps.gz'

But also in Aldor one is out of luck since AldorInteger builds on FOAM 
and exact division is (as far as I know) not available through FOAM.

http://info2html.sourceforge.net/cgi-bin/info2html-demo/info2html?(gmp.info.gz)References

BTW, does Axiom build on GMP? Or does it implement its own large integer 
package?

\start
Date: Tue, 19 Jun 2007 15:51:20 +0200 (CEST)
From: Waldek Hebisch
To: Bill Page
Subject: Re: problem compiling wh-sandbox revision 571 on Windows
Cc: Camm Maguire

Hmm, it looks like we have another GCL problem.
Bill Page wrote:
> On 6/19/07, Waldek Hebisch wrote:
> > ...
> > Concerning code in 'daase.lisp.pamphlet':  the 'localdatabase' function
> > is supposed to read information from files.  More preciely,
> > 'localdatabase' computes list of files and calls 'localnrlib' (or
> > other functions) to process each of the files.  'localdatabase'
> > is used in two ways:
> > 1) from ')lib' command, in this mode explicit list of constructors is
> >    given
> > 2) form make-databases, in this mode the arguments contain list of
> >    directories containing *.NRLIB subdirectories
> >
> 
> Thanks for this explanation.
> 
> > Since apparently ')lib' command works (however the paths printed
> > lack drive part, which may be a problem), I would suspect that the
> > problem is in building list of *.NRLIB subdirectories.  I changed this
> > part to make it work in sbcl and clisp...
> >
> > As a sanity check I will first check what '(truename "./")' gives
> > (we want patchname to the current directory).
> 
> Ok, this result looks sane:
> 
> (1) -> )lisp (truename "./")
> 
> Value = #p"C:/msys/1.0/home/Administrator/wh-test/src/algebra/"
> 
> > Than I would look what '(directory "*.NRLIB/index.KAF")' in algebra
> > directory gives
> > -- it should produce list of pathnames to index.KAF files.
> > The exact result vary from Lisp to Lisp, but the form above was
> > the only one which gave what we want in all Lisps...
> >
> > You may also try '(directory "*.NRLIB\\index.KAF")', to check
> > for possible bug handling slashes.
> >
> 
> All of these functions fail!
> 
> (1) -> )lisp (directory "*.NRLIB/index.KAF")
> 
> Value = NIL
> 
> (1) -> )lisp (directory "*.NRLIB\index.KAF")
> 
> Value = NIL
> (1) -> )lisp (directory "*.NRLIB\\index.KAF")
> 
> Value = NIL
> 
> But the following works:
> 
> (1) -> )sys ls *.NRLIB/index.KAF
> A1AGG-.NRLIB/index.KAF
> A1AGG.NRLIB/index.KAF
> ...
> 
> and this works:
> 
> (1) -> )lisp (directory "*.NRLIB")
> 
> Value = (#p"A1AGG-.NRLIB" #p"A1AGG.NRLIB" #p"ABELGRP-.NRLIB"
>          #p"ABELGRP.NRLIB" #p"ABELMON-.NRLIB" #p"ABELMON.NRLIB"
>          #p"ABELSG-.NRLIB" #p"ABELSG.NRLIB" #p"ACF-.NRLIB"
> ...
> 
> So I guess we can blame some limitation in the wildcard handling in
> paths on Windows. Do you think that it is not safe just to use '
> (directory "*.NRLIB")' ? I will change 'make-databases' to omit the
> '/index.KAF' part and try the build again.
> 

Just using '(directory "*.NRLIB")' will not work: you need to add
'index.KAF' part.  Basically, you would need to use the old
version of code.  But the old version was not portable between Lisp
implementations: some Lisps want '(directory "*.NRLIB/")' (with
final slash) and the results also vary widely.  Since we do want
to access 'index.KAF' file in the '.NRLIB' directory the
version '(directory "*.NRLIB/index.KAF")' exactly matches our
intent.  IMHO Windows version of GCL should also support such
names.

\start
Date: Tue, 19 Jun 2007 10:19:52 -0400
From: Bill Page
To: Ralf Hemmecke
Subject: Re: exact quotient

On 6/19/07, Ralf Hemmecke wrote:
> ...
> BTW, does Axiom build on GMP? Or does it implement its own large integer
> package?
>

To the best of my knowledge Axiom always depends on the underlying
Lisp to provide large integer support. GCL (and most other Lisp
packages?) use GMP.

\start
Date: Tue, 19 Jun 2007 16:31:30 +0200
From: Ralf Hemmecke
To: Bill Page
Subject: Re: exact quotient

> To the best of my knowledge Axiom always depends on the underlying
> Lisp to provide large integer support. GCL (and most other Lisp
> packages?) use GMP.

Well, then exquo of GMP would be available. The question is how to 
access it via SPAD?

\start
Date: Tue, 19 Jun 2007 16:34:50 +0200 (CEST)
From: Waldek Hebisch
To: Martin Rubey
Subject: Re: exact quotient

Martin Rubey wrote:
> I am currently trying to correct a performance bug of my guessing package, and
> found out that exquo is in general not extremely intelligent.
> 
> In axiom, what exquo really does is to perform division and return "failed" if
> it's not exact.  (I.e., it is in fact slower than quo.quotient)
> 
> What I need is a fast algorithm, that simply assumes that the division is
> exact, and should benefit from that assumption.  (If the assumption is not
> true, the computer may crash, if necessary...) As far as I know, using some
> tricks performance even better than n^2 (n being the size of the input) is
> achievable.
> 
> Most important would be such an implementation for the polynomial rings.
> 
> Anybody interested?
> 

I am interested in Axiom performance.  But do you have reasons to
supect exquo?  I mean, did you look at profile of some problematic
run?   While I agree that perfroming division and checking that
remainder is zero is not very smart, it should not matter much for
polynomials (at least for polynomials in single variable, for
multivariate polynomials division is not defined, so you must do
something smarter anyway).

Concerning complexity: for dense univariate polynomials with coefficients
in small finite fields both multiplication and division have complexity
of n times logarithmic terms.  For practical problem sizes logarithmic
terms behave like constants, and you end up comparing your "constants"
with n.  For dense multivariate polynomials one have similar 
results, but complexity grows exponentially with dimension (for
fixed dimension you have some constat coefficent, but it grows
exponentially with dimension).  Unbouded integer coefficents
essentially add one dimension to the problem (so one variable
integer problem have similar complexity like two variable
modular one).  Sparse problems have some similarity to multidimensional
ones.

I was thinking about adding fast operations on dense polynomials
with coefficients in small finite fields -- such operations are
key to many fast algorithms.  Unfortunatly, they fit rather
poorly into existing algebra.  More precisely, to be fast such
operations would have to work directly at Lisp level (or maybe
even at C level).  But that would require building a new set
of domains and adding calls to them from various places in
algebra.  In particular that would change import relations
in the algebra.  Currently (before database bootstrap is
integrated) such changes are likely to cause bootstrap failure...
-- 

\start
Date: 19 Jun 2007 23:07:31 -0400
From: Camm Maguire
To: list
Subject: gcl 2.7.0 and "ready"

Tim -- my apologies for the mail problems.  If you could post the
headers, that would help.

I'm trying to release in September.  What is really needed right now
are testers which can understand and deal with some transient
breakage, but still provide useful feedback as to the general
direction and needs of the release.

\start
Date: 19 Jun 2007 23:39:17 -0400
From: Stephen Wilson
To: Camm Maguire
Subject: Re: gcl 2.7.0 and "ready"

Camm Maguire writes:

> I'm trying to release in September.  What is really needed right now
> are testers which can understand and deal with some transient
> breakage, but still provide useful feedback as to the general
> direction and needs of the release.

Hello Camm,

I have been working as of late with the ansi build of gcl-2.6.8pre.
Without reservation, I must say I am impressed.  This is truly
excellent work!

I would be very happy to contribute to GCL, and in particular to its
advance towards ANSI compliance.

I have noticed several issues which I feel I could address, but do not
understand the priorities of the GCL team for purposes of releasing
2.7.0.  Could you provide a brief description of what you mean by
`general direction and needs of the release'?

\start
Date: Wed, 20 Jun 2007 16:40:33 +0200 (CEST)
From: Waldek Hebisch
To: Bill Page
Subject: Re: problem compiling wh-sandbox revision 571 on Windows

Bill Page wrote:
> On 6/19/07, Waldek Hebisch wrote:
> > Than I would look what '(directory "*.NRLIB/index.KAF")' in algebra
> > directory gives
> > -- it should produce list of pathnames to index.KAF files.
> > The exact result vary from Lisp to Lisp, but the form above was
> > the only one which gave what we want in all Lisps...
> >
> > You may also try '(directory "*.NRLIB\\index.KAF")', to check
> > for possible bug handling slashes.
> >
> 
> All of these functions fail!
> 
> (1) -> )lisp (directory "*.NRLIB/index.KAF")
> 
> Value = NIL
> 
> (1) -> )lisp (directory "*.NRLIB\index.KAF")
> 
> Value = NIL
> (1) -> )lisp (directory "*.NRLIB\\index.KAF")
> 
> Value = NIL
> 
> But the following works:
> 
> (1) -> )sys ls *.NRLIB/index.KAF
> A1AGG-.NRLIB/index.KAF
> A1AGG.NRLIB/index.KAF
> ...
> 
> and this works:
> 
> (1) -> )lisp (directory "*.NRLIB")
> 
> Value = (#p"A1AGG-.NRLIB" #p"A1AGG.NRLIB" #p"ABELGRP-.NRLIB"
>          #p"ABELGRP.NRLIB" #p"ABELMON-.NRLIB" #p"ABELMON.NRLIB"
>          #p"ABELSG-.NRLIB" #p"ABELSG.NRLIB" #p"ACF-.NRLIB"
> ...
> 
> So I guess we can blame some limitation in the wildcard handling in
> paths on Windows. Do you think that it is not safe just to use '
> (directory "*.NRLIB")' ? I will change 'make-databases' to omit the
> '/index.KAF' part and try the build again.
> 

It looks that 'directory' implementation in GCL is rather messy, so
I will not try to fix it.  However, you can try the following (which
works like the old code):

--- wh-sandbox.bb3/src/interp/daase.lisp.pamphlet	2007-06-20 15:59:32.000000000 +0200
+++ wh-sandbox/src/interp/daase.lisp.pamphlet	2007-06-20 16:32:24.000000000 +0200
@@ -900,7 +900,19 @@
       (let (nrlibdirs asos skipasos aos)
 
       (chdir (string dirarg))
+      #-:GCL
       (setq nrlibdirs (directory "*.NRLIB/index.KAF"))
+
+      #| directory in GCL (at least gcl-2.6.8) on Windows is buggy,
+      it can not handle pathnames having wildcards in the middle,
+      so we need a workaround.  |#
+      #+:GCL
+      (setq nrlibdirs
+           (mapcar #'(lambda (f)
+                          (concatenate 'string (namestring f)
+                                         "/index.KAF"))
+                   (directory "*.NRLIB")))
+
       (setq asys (directory "*.asy"))
       (setq asos (directory "*.ao"))
 
\start
Date: 20 Jun 2007 11:47:11 -0400
From: Camm Maguire
To: Stephen Wilson
Subject: Re: gcl 2.7.0 and "ready"

Greetings, and thanks for the interest and the kind words.

As far as 2.6.8pre goes, this will be released when 

1) We can satisfy Vadim/read-char-nohang on windows:
http://lists.gnu.org/archive/html/gcl-devel/2007-05/msg00036.html
2) We port to intel mac

I'd like to refrain from ansi work on 2.6.x if possible, though I will
put in ensure-directories-exist for the people who've requested it.

2.7.0 has much, much more work behind it, and is where the bulk of my
    effort on GCL is spent.  The basic changes:

1) two word cons -- 50% more cons space at the expense of extra
   overhead in type_of
2) immediate fixnums and vastly accelerated fixnum arithmetic in a
   range determined at compile time ((INTEGER -268435456 268435455) on
   32bit x86 Linux), again at the expense of more type_of overhead.
3) gmp random numbers, gcd functions, and many more bignum
   accelerations. 
4) src inlining.  GCL keeps a compesssed src string of every loaded
   compiled function, and uses source inlining to improve
   type-propagation and branch-elimination, as well as simplifying the
   compiler significantly.
5) auto proclamation/recompilation -- no more need for sys-proclaims
6) mutual recursion detection and tail-recursion implementation
7) many, many ansi fixes
8) apply optimization
9) unboxed complex arithmetic
10) dynamically-generated persistent 1 instruction calls to external
   shared C library functions 
11) libm function integration
12) faster safety mode
13) fork-based parallel processing, p-and, p-or and p-let

The changelog in debian/changelog contains the details.

In general, I'd like to release 2.7 when (hopefully by September):

1) Paul's ansi suite passes without error.  There are many more tests
   in the 2.7.0 branch.  This suite effectively defines ansi
   compliance for me.
2) performance is at or better than 2.6.x for all applications
3) The extra compile time induced by autorecompilation is under
   control. 

Things I would like to do:

0) centralize on Schelter's funcall descriptor
0a)call closures with the same semantics as normal functions
0b)decide on a complex thread-safe call or a simple call using globals  
1) support slime
2) improve native debugging, including Schelter's dbl.el emacs mode
3) complex short-float and complex double-float array types
4) optional blas interface
5) robustify parallel processing
6) build the mpi extension by default in the Debian package
7) support apply/&rest -> funcall list elimination
8) extend the src-inlining coverage to car et.al. and aref et.al. (One
   can define safe source which when inlined at safety 0 has the
   checks automatically removed.  Ask me if interested in the details.)
9) provide lisp implementations for as many functions now written in C
   as is practical.
10) clean up dead C code written into .c source files
11) refine source inlining algorithm
12) compile top-level closures
13) get a simple useable bechmark suite in place to quickly spot
    performance degradation.
14) re-liberate the dpans info documentation

As you are interested in ansi there really are only a few fundamental
issues left:

1) (setf foo) function descriptors need implementing as
   'setf::package_foo
2) symbols in common-lisp package
3) print/format
4) special declarations

Paul had summarized a todo in the BUGS file.  His contributions have
been immeasurable.  I haven't heard from him in some time, and hope he
is OK.

Take care,


Stephen Wilson writes:

> Camm Maguire writes:
> 
> > I'm trying to release in September.  What is really needed right now
> > are testers which can understand and deal with some transient
> > breakage, but still provide useful feedback as to the general
> > direction and needs of the release.
> 
> Hello Camm,
> 
> I have been working as of late with the ansi build of gcl-2.6.8pre.
> Without reservation, I must say I am impressed.  This is truly
> excellent work!
> 
> I would be very happy to contribute to GCL, and in particular to its
> advance towards ANSI compliance.
> 
> I have noticed several issues which I feel I could address, but do not
> understand the priorities of the GCL team for purposes of releasing
> 2.7.0.  Could you provide a brief description of what you mean by
> `general direction and needs of the release'?

\start
Date: Wed, 20 Jun 2007 12:08:41 -0400
From: Camm Maguire
To: list,Tim Daly
Subject: TIM .. (was CAMM.... the bounce message headers)

Greetings!

The host

lincoln.rosehosting.com

has my ISP

mail.eticomm.net

on some sort of blacklist, as does mailman@gnu.org or whatever, as I
can't get gcl-devel nor axiom-developer mail without checking the web.

Could you try Camm Maguire?  This might get around things.

What humanity has done to the once Promethean gift of email leaves me
speechless. 

\start
Date: 20 Jun 2007 12:18:55 -0400
From: Camm Maguire
To: Waldek Hebisch
Subject: GCL gprof profiling

Greetings!  Just wanted to point out a facility for investigating
performance issues to anyone interested in the axiom community.

If gcl is build with profiling,

--enable-gprof

and axiom is built using compiler::link (as you all know how to do),
then one can profile any function by bracketing it between
(si::gprof-start) and (si::gprof-quit).

\start
Date: 20 Jun 2007 13:16:14 -0400
From: Stephen Wilson
To: Tim Daly
Subject: Small patch to silver.

--=-=-=

Tim,

Last commit ebe5edc5 w.r.t DeveloperNotes had a simple typo.

Please try:

    git-pull ssh://Tim Daly/~swilson/axisp axisp-silver-release

Ive attached a patch as well.

Thanks,
Steve


--=-=-=
	filename=0001-Small-typo-fix-introduced-in-commit-ebe5edc.patch

diff --git a/src/doc/DeveloperNotes.pamphlet b/src/doc/DeveloperNotes.pamphlet
index 4fefd66..2afa16d 100755
--- a/src/doc/DeveloperNotes.pamphlet
+++ b/src/doc/DeveloperNotes.pamphlet
@@ -38,7 +38,7 @@ maintained in a git archive. This can be pulled from:
 \begin{verbatim}
 git-clone ssh://git@axiom-developer.org/home/git/silver
 \end{verbatim}
-the password for the userid git is linux.
+the password for the userid git is linus.
 
 \subsection{cvs}
 \begin{verbatim}

--=-=-=--

\start
Date: 20 Jun 2007 23:08:49 +0200
From: Martin Rubey
To: Waldek Hebisch
Subject: Re: exact quotient

Waldek Hebisch writes:

> I am interested in Axiom performance.  But do you have reasons to supect
> exquo?  I mean, did you look at profile of some problematic run?  While I
> agree that perfroming division and checking that remainder is zero is not
> very smart, it should not matter much for polynomials (at least for
> polynomials in single variable, for multivariate polynomials division is not
> defined, so you must do something smarter anyway).

Well, I'm not so sure - I just don't know.  To fix things: I am really only
(for the moment) interested in the case where we are dealing with multivariate
polynomials.

As far as I can see, the poor performance is due to poor multiplication and
exquo, but I cannot be sure.  I find it a bit hard to measure.

[one day later...]

OK, the situation is worse than I would have thought.  I did the following
rather simple test, which is, however, very realistic for my application: (Note
that in my application, for certain reasons, I also have to use the POLY
constructor.)

-------------------------------------------------------------------------------
-- define a bivariate polynomial of "size" (= number of coefficients) n+1
mon(n,k) == (random k * x + random k * y)^n

l(kappa, m) == [mon(kappa, 10000) for i in 1..m]

-- test performance of multiplication
test(kappa, m, n) ==
    ls1 := l(kappa, m)
    ls2 := l(kappa, m)
    res: List List Integer := []
    for trial in 1..n repeat
        GBC(t)$Lisp
        tim1 := integer GET_-UNIVERSAL_-TIME()$Lisp
        for i in ls1 for j in ls2 repeat i*j;
        tim2 := integer GET_-UNIVERSAL_-TIME()$Lisp
        res := cons([kappa, tim2-tim1], res)
    output res
    res

reduce(append, [test(kappa, 500, 5) for kappa in 10..100 by 10])
-------------------------------------------------------------------------------

On my machine, I get the following output

   [[10,1],[10,0],[10,1],[10,1],[10,1]]
   [[20,2],[20,2],[20,3],[20,2],[20,2]]
   [[30,6],[30,6],[30,5],[30,6],[30,6]]
   [[40,11],[40,12],[40,12],[40,12],[40,12]]
   [[50,19],[50,20],[50,19],[50,20],[50,20]]
   [[60,32],[60,32],[60,35],[60,35],[60,35]]
   [[70,52],[70,52],[70,52],[70,55],[70,51]]
   [[80,77],[80,77],[80,76],[80,76],[80,76]]
   [[90,102],[90,102],[90,108],[90,103],[90,103]]

This really looks like complexity between O(k^2.5) and O(k^3.0) for me, where k
is the number of monomials of the input.  I expected something like O(k^2)
though:

(a1*x1 + a2*x2+...+ak*xk)*(b1*x1 + b2*x2+...+bk*xk)
= (a1*x1 + a2*x2+...+ak*xk)*B
= a1*B*x1 + a2*B*x2...+ak*B*xk

which makes k^2 coefficient multiplications.  The cost of multiplying variables
should really be negligible, I believe.

Reducing this and exquo to O(k^2) would be a *huge* speedup for my guessing
package.  For example, it would reduce the time needed for a certain example in
my article from 5 hours down to 45 minutes.

Unfortunately, I have no idea how to go about this.

\start
Date: Thu, 21 Jun 2007 01:26:57 +0200 (CEST)
From: Waldek Hebisch
To: Martin Rubey
Subject: Re: exact quotient

Martin Rubey wrote:
> Waldek Hebisch writes:
> 
> > I am interested in Axiom performance.  But do you have reasons to supect
> > exquo?  I mean, did you look at profile of some problematic run?  While I
> > agree that perfroming division and checking that remainder is zero is not
> > very smart, it should not matter much for polynomials (at least for
> > polynomials in single variable, for multivariate polynomials division is not
> > defined, so you must do something smarter anyway).
> 
> Well, I'm not so sure - I just don't know.  To fix things: I am really only
> (for the moment) interested in the case where we are dealing with multivariate
> polynomials.
> 
> As far as I can see, the poor performance is due to poor multiplication and
> exquo, but I cannot be sure.  I find it a bit hard to measure.
> 
> [one day later...]
> 
> OK, the situation is worse than I would have thought.  I did the following
> rather simple test, which is, however, very realistic for my application: (Note
> that in my application, for certain reasons, I also have to use the POLY
> constructor.)
> 
> -------------------------------------------------------------------------------
> -- define a bivariate polynomial of "size" (= number of coefficients) n+1
> mon(n,k) == (random k * x + random k * y)^n
> 
> l(kappa, m) == [mon(kappa, 10000) for i in 1..m]
> 
> -- test performance of multiplication
> test(kappa, m, n) ==
>     ls1 := l(kappa, m)
>     ls2 := l(kappa, m)
>     res: List List Integer := []
>     for trial in 1..n repeat
>         GBC(t)$Lisp
>         tim1 := integer GET_-UNIVERSAL_-TIME()$Lisp
>         for i in ls1 for j in ls2 repeat i*j;
>         tim2 := integer GET_-UNIVERSAL_-TIME()$Lisp
>         res := cons([kappa, tim2-tim1], res)
>     output res
>     res
> 
> reduce(append, [test(kappa, 500, 5) for kappa in 10..100 by 10])
> -------------------------------------------------------------------------------
> 
> On my machine, I get the following output
> 
>    [[10,1],[10,0],[10,1],[10,1],[10,1]]
>    [[20,2],[20,2],[20,3],[20,2],[20,2]]
>    [[30,6],[30,6],[30,5],[30,6],[30,6]]
>    [[40,11],[40,12],[40,12],[40,12],[40,12]]
>    [[50,19],[50,20],[50,19],[50,20],[50,20]]
>    [[60,32],[60,32],[60,35],[60,35],[60,35]]
>    [[70,52],[70,52],[70,52],[70,55],[70,51]]
>    [[80,77],[80,77],[80,76],[80,76],[80,76]]
>    [[90,102],[90,102],[90,108],[90,103],[90,103]]
> 
> This really looks like complexity between O(k^2.5) and O(k^3.0) for me, where k
> is the number of monomials of the input.  I expected something like O(k^2)
> though:
> 
> (a1*x1 + a2*x2+...+ak*xk)*(b1*x1 + b2*x2+...+bk*xk)
> = (a1*x1 + a2*x2+...+ak*xk)*B
> = a1*B*x1 + a2*B*x2...+ak*B*xk
> 
> which makes k^2 coefficient multiplications.  The cost of multiplying variables
> should really be negligible, I believe.
> 

Well, naive complexity is k^4: you have k^2 mutiplications of 4-k digit
numbers.  Naive algorithm multiplication algorithm nees k^2 operations
to multipy two k-digint numbers...

A little estimate: for k=100 we have about 400 digits.  400 digits
require something like 21 machine words on amd64.  So we get about
100^2*21^2*500 = 2205000000 ~= 2*10^9 multiplications.  The calcularion
takes 37 seconds on my amd64, while in theory could be few times faster.
However, there are various overheads so the result is reasonable.

Note that both Axiom and gmp contain faster algorithms (Axiom
uses Karatsuba method and gmp is smarter), however for numbers
having 21 digits smart methods are likely to work just as fast
as a naive one. 

There is another factor: your polynomials are homogeneous, so
essentially behave like one-dimensional ones, if your real data
is inhomogeneous you have much more work to do.  For one
dimensional polynomials of degree 100 Karatsuba gives substantial
win and FFT method may be applicable.  If you have two variable
polynomials of degree 100 with 100 nonzero terms smart methods
are unlikely to win.

If your intermediate polynomials have large coefficients, but
the final answer has moderate size it may be wort look at modular
methods.  In Axiom modular arithmetic is unreasonably expensive,
but still may give some win.  For example, replacing first three
lines in your script by:

MP := Polynomial PrimeField(87654337)
-- define a bivariate polynomial of "size" (= number of coefficients) n+1
mon(n,k) == ((random k * x + random k * y)::MP)^n

for k = 100 I need 26 seconds (compared to 37 in integer case).
This is way too much, because modular case needs about 100 times less
arithmetic operations at machine level (note that the modulus is
chosen in such a way that the intermedate numbers should stay in the
range of machine integers), but still shows possibility for gain.

BTW:  sbcl needs 12 seconds for k = 100 in modular case and 25
seconds in integer case, so gain is bigger. 

\start
Date: 21 Jun 2007 06:50:26 +0200
From: Martin Rubey
To: Waldek Hebisch
Subject: Re: exact quotient

Waldek Hebisch writes:

> > On my machine, I get the following output
> > 
> >    [[10,1],[10,0],[10,1],[10,1],[10,1]]
> >    [[20,2],[20,2],[20,3],[20,2],[20,2]]
> >    [[30,6],[30,6],[30,5],[30,6],[30,6]]
> >    [[40,11],[40,12],[40,12],[40,12],[40,12]]
> >    [[50,19],[50,20],[50,19],[50,20],[50,20]]
> >    [[60,32],[60,32],[60,35],[60,35],[60,35]]
> >    [[70,52],[70,52],[70,52],[70,55],[70,51]]
> >    [[80,77],[80,77],[80,76],[80,76],[80,76]]
> >    [[90,102],[90,102],[90,108],[90,103],[90,103]]
> > 
> > This really looks like complexity between O(k^2.5) and O(k^3.0) for me,
> > where k is the number of monomials of the input.  I expected something like
> > O(k^2) though:
> > 
> > (a1*x1 + a2*x2+...+ak*xk)*(b1*x1 + b2*x2+...+bk*xk)
> > = (a1*x1 + a2*x2+...+ak*xk)*B
> > = a1*B*x1 + a2*B*x2...+ak*B*xk
> > 
> > which makes k^2 coefficient multiplications.  The cost of multiplying
> > variables should really be negligible, I believe.
> 
> Well, naive complexity is k^4: you have k^2 mutiplications of 4-k digit
> numbers.  Naive algorithm multiplication algorithm nees k^2 operations to
> multipy two k-digint numbers...

Why?  k is the number of monomials in A = (a1*x1 + a2*x2+...+ak*xk) and B (b1*x1 + b2*x2+...+bk*xk).  a_i is random(10000), b_i is random(10000), so I
think that a1*B should by k multiplications of two random(10000) numbers?  I'd
hope that the cost of multiplying the variable x_i = X^i * Y^(k-i-1) with yi is
negligible.

> There is another factor: your polynomials are homogeneous, so essentially
> behave like one-dimensional ones,

No, the model above is realistic.

\start
Date: Thu, 21 Jun 2007 04:05:38 -0400
From: William Sit
To: Martin Rubey
Subject: Re: exact quotient

Martin:

Regarding your test for multivariate polynomial
multiplication:

On my machine (Windows), I got:
   [[10,1], [10,0], [10,1], [10,0], [10,1],
    [20,2], [20,2], [20,1], [20,1],[20,2],
    [30,4], [30,4], [30,3], [30,4], [30,4],
    [40,8], [40,7], [40,7],[40,8], [40,7],
    [50,12], [50,12], [50,13], [50,13], [50,12],
    [60,22],[60,21], [60,21], [60,22], [60,22],
    [70,33], [70,33], [70,33], [70,34],[70,34],
    [80,47], [80,47], [80,48], [80,48], [80,48],
    [90,67], [90,67], [90,67], [90,67], [90,67],
    [100,90], [100,90], [100,92], [100,94],[100,93]]

which is painfully slow. Using DMP instead of POLY INT is
slightly faster:
 [[10,1], [10,0], [10,0], [10,0], [10,0],
[20,1], [20,1], [20,1], [20,1],[20,1],
[30,2], [30,3], [30,2], [30,3], [30,3],
[40,5], [40,6], [40,5], [40,5], [40,5],
[50,9], [50,9], [50,9], [50,9], [50,10],
[60,16], [60,16], [60,17], [60,16], [60,16],
[70,25], [70,25], [70,25], [70,26], [70,25],
[80,37], [80,37], [80,38], [80,38], [80,38],
[90,55], [90,55], [90,55], [90,55], [90,55],
[100,76], [100,75], [100,75], [100,77], [100,78]]


Compare this with Mathematica 5.2 (output reformatted; 0
timing means less than 10^(-7)):

{{10, 0. }, {10, 0. }, {10, 0. }, {10, 0. }, {10,
0.0156250},
{20, 0. }, {20, 0. }, {20, 0. }, {20, 0.0156250}, {20, 0. },

{30, 0. }, {30, 0.0156250}, {30, 0. }, {30, 0. }, {30,
0.0156250},
{40, 0.0156250}, {40, 0. }, {40, 0. }, {40, 0.0156250}, {40,
0.0312500},
{50, 0.0156250}, {50, 0. }, {50, 0. }, {50, 0. }, {50,
0.0312500},
{60, 0. }, {60, 0.0156250}, {60, 0. 10  }, {60, 0. }, {60,
0.0468750},
{70, 0. }, {70, 0. }, {70, 0.0156250}, {70, 0. }, {70,
0.0468750},
{80, 0. }, {80, 0.0156250}, {80, 0. }, {80, 0. }, {80,
0.0625000},
{90, 0. }, {90, 0. }, {90, 0.0156250}, {90, 0. }, {90,
0.0625000},
{100, 0.0156250}, {100, 0.   }, {100, 0. }, {100, 0. },
{100, 0.0781250}}

I even changed the polynomials to use n+1 random
coefficients and random exponents. The result is similar to
above.  See the code below.
{{10, 0. }, {10, 0.0156250}, {10, 0. }, {10, 0.0156250},
{10, 0.},
{20, 0.0156250}, {20, 0.0156250}, {20, 0.0156250}, {20,
0.0156250}, {20,0.0156250},
{30, 0.0156250}, {30, 0.0156250}, {30, 0.0312500},
{30,0.0156250}, {30, 0.0156250},
{40, 0.0312500}, {40, 0.0312500}, {40,0.0156250}, {40,
0.0312500}, {40, 0.0312500},
{50, 0.0468750}, {50,0.0468750}, {50, 0.0312500}, {50,
0.0468750}, {50, 0.0312500},
{60,0.0312500}, {60, 0.0468750}, {60, 0.0312500}, {60,
0.0312500}, {60,0.0312500},
{70, 0.0625000}, {70, 0.0468750}, {70, 0.0312500},
{70,0.0468750}, {70, 0.0312500},
{80, 0.0468750}, {80, 0.0468750}, {80,0.0468750}, {80,
0.0625000}, {80, 0.0312500},
{90, 0.0625000}, {90, 0.0468750}, {90, 0.0468750}, {90,
0.0625000}, {90, 0.0468750},
{100, 0.0625000}, {100, 0.0625000}, {100, 0.0781250}, {100,
0.0625000}, {100, 0.0625000}}

This is three orders of magnitude faster than Axiom.

William
---
In[1]:mon[n_,k_]:= Expand[(Random[Integer,k] x + Random[Integer,
k]y)^n]

In[2]:list[kappa_,m_]:=Table[mon[kappa, 10000], {i,1,m}]

In[3]:test[kappa_,m_,n_]:=Module[{list1, list2, t1, t2, res},
    list1=list[kappa, m];
    list2=list[kappa,m];
    res = {};
    Do[t1 = AbsoluteTime[];
           Do[list1[[i]] list2[[i]], {i,m}];
           t2 = AbsoluteTime[];
           res = Join[{{kappa, t2-t1}}, res],
      {n}]; res]


In[4]:Flatten[Table[test[10 kappa, 500,5], {kappa, 1,10}],1]

In[5]:mon2[n_,k_]:= Module[{},
  coefs = Table[Random[Integer, k],{i,0,n}];
  exps = Table[{Random[Integer,n], Random[Integer, n]},
{i,0,n}];
  Apply[Plus, MapThread[#1 x^First[#2] y^#2[[2]]
&,{coefs,exps}]]]

In[6]:listTwo[kappa_,m_]:=Table[mon2[kappa,10000],{i,1,m}]

In[7]:test2[kappa_,m_,n_]:=Module[{list1, list2, t1, t2, res},
    list1=listTwo[kappa, m];
    list2=listTwo[kappa,m];
    res = {};
    Do[t1 = AbsoluteTime[];
           Do[list1[[i]] list2[[i]], {i,m}];
           t2 = AbsoluteTime[];
           res = Join[{{kappa, t2-t1}}, res],
      {n}]; res]

In[8]:Flatten[Table[test2[10 kappa, 500,5], {kappa, 1,10}],1]

\start
Date: 21 Jun 2007 10:15:51 +0200
From: Martin Rubey
To: Waldek Hebisch
Subject: Re: exact quotient

Martin Rubey writes:

> Waldek Hebisch writes:
> 
> > > On my machine, I get the following output
> > > 
> > >    [[10,1],[10,0],[10,1],[10,1],[10,1]]
> > >    [[20,2],[20,2],[20,3],[20,2],[20,2]]
> > >    [[30,6],[30,6],[30,5],[30,6],[30,6]]
> > >    [[40,11],[40,12],[40,12],[40,12],[40,12]]
> > >    [[50,19],[50,20],[50,19],[50,20],[50,20]]
> > >    [[60,32],[60,32],[60,35],[60,35],[60,35]]
> > >    [[70,52],[70,52],[70,52],[70,55],[70,51]]
> > >    [[80,77],[80,77],[80,76],[80,76],[80,76]]
> > >    [[90,102],[90,102],[90,108],[90,103],[90,103]]
> > > 
> > > This really looks like complexity between O(k^2.5) and O(k^3.0) for me,
> > > where k is the number of monomials of the input.  I expected something like
> > > O(k^2) though:
> > > 
> > > (a1*x1 + a2*x2+...+ak*xk)*(b1*x1 + b2*x2+...+bk*xk)
> > > = (a1*x1 + a2*x2+...+ak*xk)*B
> > > = a1*B*x1 + a2*B*x2...+ak*B*xk
> > > 
> > > which makes k^2 coefficient multiplications.  The cost of multiplying
> > > variables should really be negligible, I believe.
> > 
> > Well, naive complexity is k^4: you have k^2 mutiplications of 4-k digit
> > numbers.  Naive algorithm multiplication algorithm nees k^2 operations to
> > multipy two k-digint numbers...
> 
> Why?  k is the number of monomials in A = (a1*x1 + a2*x2+...+ak*xk) and B > (b1*x1 + b2*x2+...+bk*xk).  a_i is random(10000), b_i is random(10000), so I
> think that a1*B should by k multiplications of two random(10000) numbers?  I'd
> hope that the cost of multiplying the variable x_i = X^i * Y^(k-i-1) with yi is
> negligible.

Oh, I think I made a stupid mistake.  I defined 

mon(n,k) == (random k * x + random k * y)^n

which makes the coefficients not of size log k, but rather of size 

log(binomial(n,j)* k^j).  Stupid me.

\start
Date: 21 Jun 2007 10:18:04 +0200
From: Martin Rubey
To: William Sit
Subject: Re: exact quotient

Dear William,

> In[1]:=
> mon[n_,k_]:= Expand[(Random[Integer,k] x + Random[Integer,
> k]y)^n]
> 
> In[2]:=
> list[kappa_,m_]:=Table[mon[kappa, 10000], {i,1,m}]
> 
> In[3]:=
> test[kappa_,m_,n_]:=Module[{list1, list2, t1, t2, res},
>     list1=list[kappa, m];
>     list2=list[kappa,m];
>     res = {};
>     Do[t1 = AbsoluteTime[];
>            Do[list1[[i]] list2[[i]], {i,m}];
>            t2 = AbsoluteTime[];
>            res = Join[{{kappa, t2-t1}}, res],
>       {n}]; res]

When you write list1[[i]] list2[[i]] I'm not so sure whether the result is
actually computed.  Maybe you could retry with Expand[list1[[i]] list2[[i]]],
and maybe you should also store the result somewhere, so that the calculation
cannot be optimized away.

\start
Date: 21 Jun 2007 11:59:09 +0200
From: Martin Rubey
To: Waldek Hebisch, William Sit
Subject: Re: exact quotient

Dear Waldek,

just to make sure:

> Oh, I think I made a stupid mistake.  I defined 
> 
> mon(n,k) == (random k * x + random k * y)^n
> 
> which makes the coefficients not of size log k, but rather of size 
> 
> log(binomial(n,j)* k^j).  Stupid me.

I just ran the test with

mon(n,k) == reduce(+, [random k * x^i*y^(n-i) for i in 0..n])

instead, and get the "expected" O(k^2) output:

(6) -> [test(kappa, 500, 5) for kappa in 10..100 by 10]

   [[10,1],[10,0],[10,1],[10,0],[10,1]]
   [[20,2],[20,2],[20,2],[20,2],[20,2]]
   [[30,4],[30,4],[30,3],[30,3],[30,5]]
   [[40,7],[40,7],[40,7],[40,7],[40,6]]
   [[50,11],[50,10],[50,11],[50,10],[50,11]]
   [[60,18],[60,15],[60,14],[60,15],[60,15]]
   [[70,19],[70,20],[70,20],[70,20],[70,22]]
 
I also modified William Sit's test (using Expand), and obtained

Out[11]= {{10, 0.272878}, {10, 0.273776}, {10, 0.273362}, {20, 0.902124}, 
 
>    {20, 0.899902}, {20, 0.899222}, {30, 1.920647}, {30, 1.922753}, 
 
>    {30, 1.916153}, {40, 3.617779}, {40, 3.708420}, {40, 3.608447}, 
 
>    {50, 6.507658}, {50, 6.525488}, {50, 6.509765}, {60, 10.755069}, 
 
>    {60, 10.809554}, {60, 10.868204}, {70, 16.384399}, {70, 16.461227}, 
 
>    {70, 16.337861}}

(on a much faster machine) which corresponds to Axiom's performance.

So, it remains to check, what situation is realistic for my problem, and
whether I can do anything about it...

\start
Date: Thu, 21 Jun 2007 22:19:44 +1000
From: Alasdair McAndrew
To: list
Subject: Incorporating other GPL software into Axiom?

------=_Part_3628_19698901.1182428384811

The particular instance here is integer factorization.  A quick look through
intfact.spad reveals that integer factorization is implemented by trial
division, followed by Pollard's rho method - nothing very sophisticated.
The file itself claims: "We should also employ Lenstra's elliptic curve
method."  Yes, we should.  And the various modern sieving methods (quadratic
sieve, number field sieve, and so on).  Now, I'm no expert in this, and I
doubt I could program such things myself, but they do exist, either
stand-alone (as in Zimmermann et al's GMP-ECM), or as part of GPL software
such as LiDIA or Pari/GP.

Is there any system for importing such things into Axiom?  It seems to me
that if we have integer factorization, we should use the best methods
available, so how can it be done?

-Alasdair

P.S. I've decided for the coming semester to trial Axiom with my
cryptography students; it seems that Axiom is admirably suited for the
number theory, and string and list handling which cryptography (at least as
I teach it) requires.  So I'm having fun developing worksheets.

------=_Part_3628_19698901.1182428384811

The particular instance here is integer factorization.&nbsp; A quick
look through intfact.spad reveals that integer factorization is
implemented by trial division, followed by Pollard&#39;s rho method -
nothing very sophisticated.&nbsp; The file itself claims: &quot;We
should also employ Lenstra&#39;s elliptic curve method.&quot;&nbsp;
Yes, we should.&nbsp; And the various modern sieving methods
(quadratic sieve, number field sieve, and so on).&nbsp; Now, I&#39;m
no expert in this, and I doubt I could program such things myself, but
they do exist, either stand-alone (as in Zimmermann et al&#39;s
GMP-ECM), or as part of GPL software such as LiDIA or Pari/GP.

Is there any system for importing such things into Axiom?&nbsp; It
seems to me that if we have integer factorization, we should use the
best methods available, so how can it be done?

-Alasdair

P.S. I've decided for the coming semester to trial Axiom with my
cryptography students; it seems that Axiom is admirably suited for the
number theory, and string and list handling which cryptography (at
least as I teach it) requires.

So I'm having fun developing worksheets.

------=_Part_3628_19698901.1182428384811--

\start
Date: 21 Jun 2007 14:48:10 +0200
From: Martin Rubey
To: Alasdair McAndrew
Subject: Re: Incorporating other GPL software into Axiom?

Alasdair McAndrew writes:

> Now, I'm no expert in this, and I doubt I could program such things myself,
> but they do exist, either stand-alone (as in Zimmermann et al's GMP-ECM), or
> as part of GPL software such as LiDIA or Pari/GP.

A colleague of mine who is an expert in number theory tested various such
systems and found pari to be very well suited for general purpose tasks.

I think it would be a great shame and quite stupid not to use such well tested
and researched packages, especially given our very limited number.  In Aldor it
is fairly trivial to import fun from Foreign C, but I do not know how to do
this from Axiom.  I guess we should have a simple package that uses the
underlying lisp functionality and provides a interface for the average user.

> P.S. I've decided for the coming semester to trial Axiom with my cryptography
> students; it seems that Axiom is admirably suited for the number theory, and
> string and list handling which cryptography (at least as I teach it)
> requires.  So I'm having fun developing worksheets.

That's wonderful news.  Suggestions to make my axiom.el emacs mode more
accessible are very welcome.

\start
Date: Thu, 21 Jun 2007 12:36:11 -0400
From: William Sit
To: Martin Rubey
Subject: Re: exact quotient

Hi Martin:

Thanks, Martin, for catching the missing Expand (I caught
the one in mon, but not the one in the loop!). Yes, it takes
much longer now and the results are, using your revised
version of mon:
mon3[n_,k_]:= Module[{},
  coefs = Table[Random[Integer, k],{i,0,n}];
  exps = Table[i,{i,0,n}];
  Apply[Plus, MapThread[#1 x^#2 y^(n-#2) &,{coefs,exps}]]]

{{10, 0.3125000}, {10, 0.2812500}, {10, 0.2812500}, {10,
0.2656250}, {10, 0.2812500},
{20, 0.7968750}, {20, 0.7812500}, {20, 0.8281250}, {20,
0.8750000}, {20, 0.7968750},
{30, 1.6406250}, {30, 1.6093750}, {30, 1.6718750}, {30,
1.6250000}, {30, 1.6250000},
{40, 2.9687500}, {40, 2.9375000}, {40, 2.9218750}, {40,
2.8750000}, {40, 2.9531250},
{50, 4.4843750}, {50, 4.3593750}, {50, 4.2968750}, {50,
4.5000000}, {50, 4.6250000},
{60, 6.0625000}, {60, 6.0625000}, {60, 6.1093750}, {60,
6.1093750}, {60, 5.9687500},
{70, 12.1875000}, {70, 8.9843750}, {70, 8.9062500}, {70,
9.3125000}, {70, 9.2031250},
{80, 24.0000000}, {80, 24.4375000}, {80, 24.5937500}, {80,
24.5781250}, {80, 24.6718750},
{90, 30.6875000}, {90, 29.8125000}, {90, 30.3593750}, {90,
30.2968750}, {90, 30.6562500},
{100, 36.2500000}, {100, 36.1250000}, {100, 36.1875000},
{100, 36.1250000}, {100, 35.9531250}}

On the same machine on Axiom, using:
mon(n,k) == reduce(+, [(random k *
x^i*y^(n-i))::DMP([x,y],Integer) for i in 0..n])
reduce(append, [test(kappa, 500, 5) for kappa in 10..100 by
10])

   Compiling function mon with type
(PositiveInteger,PositiveInteger)
       -> DistributedMultivariatePolynomial([x,y],Integer)
   Compiling function l with type
(PositiveInteger,PositiveInteger) ->
      List DistributedMultivariatePolynomial([x,y],Integer)
   Compiling function test with type
(PositiveInteger,PositiveInteger,
      PositiveInteger) -> List List Integer
 [[10,1], [10,0], [10,0], [10,0], [10,1], [20,0], [20,1],
[20,1], [20,1],
  [20,1], [30,2], [30,2], [30,2], [30,2], [30,2], [40,3],
[40,3], [40,3],
  [40,3], [40,3], [50,5], [50,5], [50,5], [50,6], [50,5],
[60,6], [60,7],
  [60,7], [60,7], [60,7], [70,9], [70,9], [70,9], [70,9],
[70,9], [80,12],
  [80,12], [80,12], [80,12], [80,12], [90,16], [90,15],
[90,16], [90,17],
  [90,17], [100,18], [100,19], [100,18], [100,18], [100,19]]

This is much faster than both Mathematica and using default
(which timing is compatible with Mathematica):
(12) -> mon(n,k) == reduce(+, [random k * x^i*y^(n-i) for i
in 0..n])
   Compiled code for mon has been cleared.
   Compiled code for l has been cleared.
   Compiled code for test has been cleared.
   1 old definition(s) deleted for function or rule mon

Type: Void
(13) -> reduce(append, [test(kappa, 500, 5) for kappa in
10..100 by 10])
   Compiling function mon with type
(PositiveInteger,PositiveInteger)
       -> Fraction Polynomial Integer
   Compiling function l with type
(PositiveInteger,PositiveInteger) ->
      List Fraction Polynomial Integer
   Compiling function test with type
(PositiveInteger,PositiveInteger,
      PositiveInteger) -> List List Integer
[[10,1], [10,1], [10,0], [10,0], [10,1], [20,2], [20,2],
[20,2], [20,2],
   [20,3], [30,5], [30,5], [30,5], [30,5], [30,5], [40,9],
[40,9], [40,9],
   [40,9], [40,9], [50,15], [50,14], [50,15], [50,14],
[50,14], [60,20],
   [60,20], [60,21], [60,20], [60,21], [70,30], [70,28],
[70,29], [70,28],
   [70,29], [80,19], [80,23], [80,21], [80,20], [80,21],
[90,28], [90,25],
   [90,29], [90,27], [90,25], [100,33], [100,34], [100,35],
[100,36],
  [100,31]]

I also noted that the function mon was compiled differently,
where using default  the function mon compiles to FRAC POLY
INT, not POLY INT, even though the times for kappa >= 80 are
about the same in both cases:

(14) -> mon(n,k) == reduce(+, [(random k *
x^i*y^(n-i))::POLY INT for i in 0..n]
)
   Compiled code for mon has been cleared.
   Compiled code for l has been cleared.
   Compiled code for test has been cleared.
   1 old definition(s) deleted for function or rule mon

Type: Void
(15) -> reduce(append, [test(kappa, 500, 5) for kappa in
10..100 by 10])
   Compiling function mon with type
(PositiveInteger,PositiveInteger)
       -> Polynomial Integer
   Compiling function l with type
(PositiveInteger,PositiveInteger) ->
      List Polynomial Integer
   Compiling function test with type
(PositiveInteger,PositiveInteger,
      PositiveInteger) -> List List Integer
    (15)
   [[10,0], [10,0], [10,0], [10,0], [10,1], [20,1], [20,1],
[20,1], [20,1],
    [20,1], [30,2], [30,3], [30,3], [30,3], [30,3], [40,5],
[40,6], [40,4],
    [40,4], [40,4], [50,8], [50,8], [50,8], [50,8], [50,7],
[60,11], [60,11],
    [60,12], [60,11], [60,11], [70,15], [70,15], [70,15],
[70,16], [70,15],
    [80,21], [80,20], [80,20], [80,20], [80,20], [90,26],
[90,25], [90,26],
    [90,26], [90,26], [100,32], [100,33], [100,32],
[100,32], [100,32]]

So the data-structure comes into play. Not sure if
converting your computation to DMP and back would save time.

\start
Date: Thu, 21 Jun 2007 15:10:43 -0700 (PDT)
From: Cliff Yapp
To: list
Subject: Root chunk naming conventions

I'm making a little progress on ASDF-Literate, and as I'm doing so a
question question has arisen about naming of chunks intended to be
"root" chunks - i.e. chunks that are points of extraction for the build
process.

Right now, those chunks have names corresponding to source file names,
as far as I can tell.  This is OK, but I'm attempting to auto-generate
names for the tangle and compile steps based on the chunk name and
source file - these names result in some pretty strange file names.  It
doesn't matter particularly on Linux (and after all anything except the
pamphlet file may be regarded as machine generated) but I'm concerned
something like foo-bar.lisp.lisp may cause some operating systems to
gag.

There are three solutions I can see right now:

1.  Assume all root chunks (except the known "*" default case) will
have valid filenames as chunk names, and don't generate any name - use
the chunk string itself.

2.  Give root chunks names like any other chunk and trust the build
routines to generate file names. 

3.  Mangle the chunk name - strip off any .*** ending and work with
that string.  Might have unintended consequences if a non-file chunk
name wants to use a "."

Does anyone else have opinions on this issue?  As I'm doing a lot of
pathname related mangling anyway I'm up for any of the three, if there
is any concensus as to what the preferred direction is.

\start
Date: Thu, 21 Jun 2007 18:41:43 -0500
From: Tim Daly
To: Camm Maguire
Subject: literate programming

Camm,

Do you have any interest in making a literate form of GCL?

\start
Date: Thu, 21 Jun 2007 19:02:17 -0500
From: Tim Daly
To: Cliff Yapp
Subject: root chunks

Besides the argument that the algebra files contain more than one root
chunk there is another difficulty with choosing a connection between
filenames and root chunk names. At the present time I'm walking the
system downcase all of the filenames. If there was a tight coupling
between file and root chunk it would require that I also modify each
file.

In general I feel that there should be no correspondence between 
filenames and contents. The namespace and organization of files is
not related to the namespace and organization of information.

\start
Date: 21 Jun 2007 20:18:37 -0400
From: Camm Maguire
To: Tim Daly
Subject: Re: literate programming

Greetings!  Very much so, as I think we need to diversify my knowledge
of the internals into more brains.  Of course, I find myself pressed
for time....

Take care,

Tim Daly writes:

> Camm,
> 
> Do you have any interest in making a literate form of GCL?

\start
Date: 21 Jun 2007 20:22:13 -0400
From: Camm Maguire
To: Gabriel Dos Reis
Subject: 2.7.0 reports

Greetings, and thanks for the reports!

1) gcl self compile time is  deliberately slower, but may be
   mitigatable somewhat.  Most of the core functions are now
   implemented in lisp rather than C, which allows for automatic
   source inlining.  Unfortunately, this makes bootstrapping much
   slower.   Ideas welcome.  Might be better to use the old C as a
   boot strap accelerator, but then we have to maintain two versions
   of each function in two different languages.

2) x64 failure -- could you please post the full log?

\start
Date: Thu, 21 Jun 2007 19:48:12 -0700 (PDT)
From: Cliff Yapp
To: Tim Daly
Subject: Re: root chunks

--- Tim Daly wrote:

> Besides the argument that the algebra files contain more than one
> root chunk there is another difficulty with choosing a connection 
> between filenames and root chunk names. At the present time I'm
> walking the system downcase all of the filenames. If there was a
> tight coupling between file and root chunk it would require that I
> also modify each file.

The only difficulty comes when extracting something other than the "*"
chunk - several files unique to that one chunk of code must be
generated by the tangle and compile routines.  I suppose I could have
the lisps generate completely random file names for these cases but I
would prefer to have the generated files relate back to the chunk they
came from for debugging purposes.  To illustrate the difficulty, let's
say I have two chunks:  "bootstrap1.clisp" and "startup"   Suppose I
need to tangle both of these out of the same pamphlet.  I know how to
specify them, but I must tangle them to a destination file for
compiling.  What name should I select?  In the case of bootstrap1.clisp
the obvious choice is the chunk name, but in the case of startup it's
not so clear.  Is it a lisp file, boot file, or what?  If I see that
file lying around in the directory, where did it come from?  On the
other hand, if I generate bootstrap1-startup.lisp, that works for
startup but makes a mess out of bootstrap1.clisp.  If I tangle them to
randomfoo1.lisp and randomfoo2.lisp that solves the problem but makes
tracing a given file back to its pamphlet origins a bit harder.

I would prefer to have the target files for the tangle process chosen
automatically rather than being user or developer specified - that's a
detail no one should have to care about.  The tangled source file is a
generated file.  I would like to have a sensible rule for doing so, if
one can be found.

> In general I feel that there should be no correspondence between 
> filenames and contents. The namespace and organization of files is
> not related to the namespace and organization of information.

In general, I agree.  In the specific case of intermediate generated
files, I would like the filenames to retain some relationship to their
origin to aid debugging.

\start
Date: Fri, 22 Jun 2007 10:53:10 +0200
From: Ralf Hemmecke
To: Tim Daly
Subject: Re: root chunks

 > In general I feel that there should be no correspondence between
 > filenames and contents. The namespace and organization of files is
 > not related to the namespace and organization of information.

Tim, I am happy that you share my opinion. Chunk names should be 
considered like section titles: they should tell you something about the 
content. A filename usually will not do this.

It is true that there is some relation between the content of the files 
and the build order, but the content is for humans (and would describe 
the algebra) and so the description of the build process (which is also 
for humans but describes a different topic) should better be 
concentrated in Makefiles (or rather pamphlets of Makefiles).

In my opinion, we still have to come up with a good definition of what a 
pamphlet actually is. I tend to favour something like the way OpenOffice 
stores a file (eg a worksheet). That is a zip file of a whole directory. 
Internally OO certainly sees all the different files, but as a user you 
would have one file to deal with. I would rather call such a zip file a 
pamphlet. But the term "pamphlet" is already in use so another name 
would probably cause less confusion.

\start
Date: Fri, 22 Jun 2007 11:08:15 +0200
From: Ralf Hemmecke
To: Cliff Yapp
Subject: re: root chunks

> In general, I agree.  In the specific case of intermediate generated
> files, I would like the filenames to retain some relationship to their
> origin to aid debugging.

Again, look at ALLPROSE. The idea is that while generating the .as files 
you also generate line information into that file. Something like

#line 56 "myalps/prtype.as.nw"

that gives the compiler a hint where it should look for the original 
source. Of course, you need a smart compiler to deal with #line 
directives. The same applies for a debugger. The compiler should forward 
the #line information into the executable so that the debugger can deal 
with that information.

There is simply no need to have chunk names corresponding to filenames.

\start
Date: Fri, 22 Jun 2007 04:11:44 -0700 (PDT)
From: Cliff Yapp
To: Ralf Hemmecke
Subject: re: root chunks

--- Ralf Hemmecke wrote:

> > In general, I agree.  In the specific case of intermediate
> > generated files, I would like the filenames to retain some 
> > relationship to their origin to aid debugging.
> 
> Again, look at ALLPROSE. The idea is that while generating the .as
> files you also generate line information into that file. Something 
> like
> 
> #line 56 "myalps/prtype.as.nw"
> 
> that gives the compiler a hint where it should look for the original 
> source. Of course, you need a smart compiler to deal with #line 
> directives. The same applies for a debugger. The compiler should
> forward the #line information into the executable so that the 
> debugger can deal with that information.

Yes, that is the best case.  However, I don't know that there is a
general way to have the Lisp compiler preserve that information in
useful form in the binary.  We can preserve it when we translate to
Lisp (or C or whatever - regardless of language) but when that final
file is compiled by a compiler we didn't write I'm not sure how to make
it preserve the information for the debugger.  I'm even less sure how
to do this portably - we might be able to talk to the GCL and SBCL
devs, I guess.

> There is simply no need to have chunk names corresponding to
> filenames.

At some point I think the Algebra code needs to dictate file names
(unless the build somehow records what it needs for loading), in order
to be able to load the correct binary files corresponding to various
bits of functionality later.  However until that point random filenames
(e.g. (defvar filename (format nil "~a.lisp" (gensym))) are probably
the most robust for cross-platform filename legality and avoidance of
unintended name collisions.
 
Well, this being Lisp, I could just program in more power, set working
defaults, and let the user deside.  Default Lisp and boot files to one
behavior, spad to whatever the algebra needs, and have some variables
to switch behavior around if anyone needs it :-).

\start
Date: Fri, 22 Jun 2007 13:47:16 +0200
From: Ralf Hemmecke
To: Cliff Yapp
Subject: re: root chunks

>> #line 56 "myalps/prtype.as.nw"

> Yes, that is the best case.  However, I don't know that there is a 
> general way to have the Lisp compiler preserve that information in 
> useful form in the binary.  We can preserve it when we translate to 
> Lisp (or C or whatever - regardless of language) but when that final 
> file is compiled by a compiler we didn't write I'm not sure how to
> make it preserve the information for the debugger.  I'm even less
> sure how to do this portably - we might be able to talk to the GCL
> and SBCL devs, I guess.

I am pretty sure that someone can confirm that gcc has an option that
compiles the #line information into the executable. I am not so sure 
about gcl. Camm?

You don't need to debug with sbcl. If a bug happens via SBCL and not via 
GCL then that is a bug in the compiler and not in the algebra code. So 
you would not be interested in debugging unless you are a compiler writer.

>> There is simply no need to have chunk names corresponding to 
>> filenames.

> At some point I think the Algebra code needs to dictate file names 
> (unless the build somehow records what it needs for loading), in
> order to be able to load the correct binary files corresponding to
> various bits of functionality later.

I don't know what problem you want to solve, but all I can see it that 
there should be a way that the system knows that for domain/category X 
it must load the file Y. To me it looks like a simple translation table 
is sufficient and a user never needs to know about the filename where X 
is defined. We should have a system where you just click on X and your 
editor opens and shows you the right place in file Y. That the compiled 
binary of Y is in Z is only important for the loading mechanism. Why 
would you want to bother the writer of X with specifying a filename for Z?

Ideally the writer of X should not even need to know the name of Y.

\start
Date: Fri, 22 Jun 2007 12:41:24 -0400
From: Bill Page
To: Gabriel Dos Reis
Subject: Re: [Axiom-commit] SF.net SVN: axiom: [632] branches/build-improvements

On 6/20/07you wrote:
> Revision: 632
>           http://svn.sourceforge.net/axiom/?rev=632&view=rev
> Author:   dos-reis
> Date:     2007-06-20 14:28:50 -0700 (Wed, 20 Jun 2007)
>
> Log Message:
> -----------
> Dissociate HyperDoc component build from X11 availability.
> In particular, itis now possible to build HyperTex macros
> even when X11 is absent.  This is required for clean builds
> of the Algebra component on all systems, including Windows.
> ...

Could you explain what HyperTex macros are required for building the
algebra on Windows (and why)?

\start
Date: 22 Jun 2007 13:28:58 -0400
From: Stephen Wilson
To: Cliff Yapp
Subject: re: root chunks

Hi Cliff,

Cliff Yapp writes:
> Well, this being Lisp, I could just program in more power, set working
> defaults, and let the user deside.  Default Lisp and boot files to one
> behavior, spad to whatever the algebra needs, and have some variables
> to switch behavior around if anyone needs it :-).

This is basicly the approach I would take.  The system should have a
surface simplicity for the user which needs no more,  but facilities
available for the developer who needs fine grained control.
Apologies that this comment does not help much in achieving that
goal.  However, I do have plans to look at your work in detail once a
few moer items get taken care of.

BTW, have you tried ASDF with GCL lately?  I have a slightly hacked
version which basicly works with 2.6.8pre in ANSI mode.  In the sort
term I hope to be switching my work to be based on 2.7.0 cvs, and I
expect ASDF to be a fair bit more comfortable there.  The notion of
integrating cl-web with asdf is fantastic.

\start
Date: Fri, 22 Jun 2007 19:56:41 +0200 (CEST)
From: Waldek Hebisch
To: Ralf Hemmecke
Subject: re: root chunks

Ralf Hemmecke wrote:
> I am pretty sure that someone can confirm that gcc has an option that
> compiles the #line information into the executable. I am not so sure 
> about gcl. Camm?
> 
> You don't need to debug with sbcl. If a bug happens via SBCL and not via 
> GCL then that is a bug in the compiler and not in the algebra code. So 
> you would not be interested in debugging unless you are a compiler writer.
> 

Sorry, that very naive:  Axiom in many places makes unportable
assumptions.   So, in most cases when code works in one Lisp but
fails in another the code is wrong.  FYI SBCL caught a number
of bugs that were hidden when running under gcl (some of them
were likely to give you "memory may be damaged" message).

Do not take this message personally, but I am concerned by
general attitude presented on this list: people here frequently 
ignore important practical problems.

\start
Date: Fri, 22 Jun 2007 11:28:04 -0700 (PDT)
From: Cliff Yapp
To: Stephen Wilson
Subject: re: root chunks

--- Stephen Wilson wrote:

> Hi Cliff,
> 
> Cliff Yapp writes:
> > Well, this being Lisp, I could just program in more power, set
> > working defaults, and let the user deside.  Default Lisp and boot
> > files to one behavior, spad to whatever the algebra needs, and
> > have some variables to switch behavior around if anyone needs 
> > it :-).
> 
> This is basicly the approach I would take.  The system should have a
> surface simplicity for the user which needs no more,  but facilities
> available for the developer who needs fine grained control.

Can do.

> Apologies that this comment does not help much in achieving that
> goal.

No problem.  It's not in a working state yet - I think my position at
this stage is basically that I know how to achieve pretty much what I
want, but I need to wade through the nitty gritty of doing it.  The
most vexing annoyance is probably the bootstrapping of the boot
language - that will probably take some special operations and tricks
to do the way I want to.  I'm doing something a bit different from
"normal" asdf asd files - there are a couple commands other than system
definitions (I can't do literate defsystem definitions without
asdf-literate loaded) and I'm defining all the "systems" in one
pamphlet file - that's because I think it is logical that
axiom-system.asd.pamphlet discuss the overall system design and
component interactions for the human as well as asdf.

> However, I do have plans to look at your work in detail once a
> few more items get taken care of.

I plan to show it to the world once I reach the point where I can
successfully handle lisp, boot and spad pamphlets.  Other goodies like
the hyperdoc system and c files for sman and friends will have to come
later.  I'd like to look at alternate solutions to some of that anyway
but that's down the road (might as well not annoy folks with more Lisp
talk.)

> BTW, have you tried ASDF with GCL lately?  I have a slightly hacked
> version which basicly works with 2.6.8pre in ANSI mode.  In the sort
> term I hope to be switching my work to be based on 2.7.0 cvs, and I
> expect ASDF to be a fair bit more comfortable there.  The notion of
> integrating cl-web with asdf is fantastic.

:-).  I've got just enough working that it's getting fun.  I'm working
in SBCL at the moment - once I have something working we can look at
porting it to GCL et. al.  I'm not too interested in supporting the
legacy GCL - 2.7.0 makes more sense to me.  It's enough effort to do
all this without having to worry about backwards compatibility - I
would suggest we release a gold version soon and make that the last
gold version based on a non ANSI lisp.  Based on attempts so far I'm
afraid merging the ANSI changes into Silver may be an ordeal, but it is
a necessary step.

I'm using files from wh-sandbox right now since a) its got the most
stuff working and b) it works with sbcl.  Probably a necessary step
will be to find the changes relative to the Silver branch that make
ANSI work and submit them as an offering to Silver - without that
folding this back into Silver probably won't be possible (or at least,
a big pain).

\start
Date: 22 Jun 2007 14:39:07 -0400
From: Camm Maguire
To: Ralf Hemmecke
Subject: re: root chunks

Greetings!

Ralf Hemmecke writes:

> >> #line 56 "myalps/prtype.as.nw"
> 
> > Yes, that is the best case.  However, I don't know that there is a
> > general way to have the Lisp compiler preserve that information in
> > useful form in the binary.  We can preserve it when we translate to
> > Lisp (or C or whatever - regardless of language) but when that final
> > file is compiled by a compiler we didn't write I'm not sure how to
> > make it preserve the information for the debugger.  I'm even less
> > sure how to do this portably - we might be able to talk to the GCL
> > and SBCL devs, I guess.
> 
> I am pretty sure that someone can confirm that gcc has an option that
> compiles the #line information into the executable. I am not so sure
> about gcl. Camm?
> 

Here is one idea:


COMPILER>(defun c1clines (args)
  (list 'clines (make-info :type nil) (with-output-to-string (s) (princ (car args) s))))
(defun c2clines (clines)
  (wt-nl clines))
(si::putprop 'clines 'c1clines 'c1)
(si::putprop 'clines 'c2clines 'c2)


C1CLINES

COMPILER>
C2CLINES

COMPILER>
C1CLINES

COMPILER>
C2CLINES

COMPILER>(disassemble '(lambda nil (clines "#line __LINE__") (+ 1 1)) nil)

;; Compiling /tmp/gazonk_13883_1.lsp.
  1> (C1CLINES ("#line __LINE__"))
  <1 (C1CLINES
         (CLINES
           #S(INFO TYPE NIL SP-CHANGE 0 VOLATILE 0 UNUSED 0 UNUSED1 0
                   CHANGED-ARRAY #() REFERRED-ARRAY #())
           "#line __LINE__"))
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_13883_1.o.

#include "gazonk_13883_1.h"
void init_code(){do_init((void *)VV);}
/*	local entry for function CMP-ANON	*/

static fixnum LI1()

{	 VMB1 VMS1 VMV1
	goto TTL;
TTL:;
	#line __LINE__
	{fixnum V1 = (fixnum)2;VMR1
	(V1);}
}

\start
Date: 22 Jun 2007 15:07:01 -0400
From: Stephen Wilson
To: Cliff Yapp
Subject: re: root chunks

Cliff Yapp writes:
[...]
> I plan to show it to the world once I reach the point where I can
> successfully handle lisp, boot and spad pamphlets.  Other goodies like
> the hyperdoc system and c files for sman and friends will have to come
> later.  I'd like to look at alternate solutions to some of that anyway
> but that's down the road (might as well not annoy folks with more Lisp
> talk.)

Great, I look forward to seeing the prototype.

[...]
> :-).  I've got just enough working that it's getting fun.  I'm working
> in SBCL at the moment - once I have something working we can look at
> porting it to GCL et. al.  I'm not too interested in supporting the
> legacy GCL - 2.7.0 makes more sense to me.  

If your working exclusively with SBCL, you /may/ be surprised when you
try with an ANSI 2.6.8pre.  It certainly has missing features, but is
quite usable as a near-ansi lisp.  I used to work with SBCL
exclusively. But the strides GCL has made recently towards ansi and
the amazing resource we have with Camm willing and able to tailor GCL
to our needs is very close to convincing me that GCL should be our
primary Lisp target (as opposed to investing effort in supporting
other lisps, and finding generic solutions to problems which require
compiler support).  I do miss Slime though :(

Hey, while your at it, could you teach Slime how to handle pamphlets?
:)

> It's enough effort to do all this without having to worry about
> backwards compatibility - I would suggest we release a gold version
> soon and make that the last gold version based on a non ANSI lisp.
> Based on attempts so far I'm afraid merging the ANSI changes into
> Silver may be an ordeal, but it is a necessary step.

I agree.  Have thought about this too.  We should have some notion of
when development on Silver will be frozen and when it will get
promoted to Gold.

\start
Date: Fri, 22 Jun 2007 21:08:04 +0200
From: Ralf Hemmecke
To: Waldek Hebisch
Subject: re: root chunks

Hello Waldek

On 06/22/2007 07:56 PM, Waldek Hebisch wrote:
> Ralf Hemmecke wrote:
>> I am pretty sure that someone can confirm that gcc has an option 
>> that compiles the #line information into the executable. I am not 
>> so sure about gcl. Camm?
>> 
>> You don't need to debug with sbcl. If a bug happens via SBCL and 
>> not via GCL then that is a bug in the compiler and not in the 
>> algebra code. So you would not be interested in debugging unless 
>> you are a compiler writer.

> Sorry, that very naive:  Axiom in many places makes unportable 
> assumptions.   So, in most cases when code works in one Lisp but 
> fails in another the code is wrong.  FYI SBCL caught a number of bugs
>  that were hidden when running under gcl (some of them were likely to
>  give you "memory may be damaged" message).

Do you really mean that you had to change the *algebra* code? I did not
speak of anything else. That the lisp/boot/shoe code is something else,
I completely understand. And I also understand that for such issues
different compilers are good. (Sorry for the gap that I left in my
statement.)

I cannot much help with the LISP part of Axiom and so I am only 
interested that whoever works on it should do a good job.

> Do not take this message personally,

I don't consider your message as an offence.

> but I am concerned by general attitude presented on this list: people
> here frequently ignore important practical problems.

I understand your point.

\start
Date: Fri, 22 Jun 2007 12:35:00 -0700 (PDT)
From: Cliff Yapp
To: Stephen Wilson
Subject: re: root chunks

--- Stephen Wilson wrote:

> If your working exclusively with SBCL, you /may/ be surprised when
> you try with an ANSI 2.6.8pre.  It certainly has missing features,
> but is quite usable as a near-ansi lisp.  I used to work with SBCL
> exclusively. But the strides GCL has made recently towards ansi and

I thought most of those strides were in the 2.7.0 branch?  I guess I
need to check the ANSI build of 2.6.8pre again.

> the amazing resource we have with Camm willing and able to tailor GCL
> to our needs

No question there :-).  (Note to self, don't scare Camm away with dpANS
talk...)

> is very close to convincing me that GCL should be our
> primary Lisp target (as opposed to investing effort in supporting
> other lisps, and finding generic solutions to problems which require
> compiler support).  I do miss Slime though :(

A long time back there were some efforts to get Slime working on GCL -
I don't know if anyone has revisited the issue lately.

One trick I was able to pull with Maxima once was to have two Emacs
connections to the same Maxima session - one talking to the Lisp REPL
and the other talking to the command prompt.  This allowed one to
perform normal commands in the command line and work inside the Slime
environment at the Lisp level at the same time :-).  It needed threads
though - the swank server in one and the normal Maxima session in the
other - and some special startup was required to trigger swank, IIRC. 
Once the asdf work is set up it might be worth trying to do that again
for Axiom.  Does GCL have threads?

> Hey, while your at it, could you teach Slime how to handle pamphlets?
> :)

Erm. :-).  I suppose its possible...

> > It's enough effort to do all this without having to worry about
> > backwards compatibility - I would suggest we release a gold version
> > soon and make that the last gold version based on a non ANSI lisp.
> > Based on attempts so far I'm afraid merging the ANSI changes into
> > Silver may be an ordeal, but it is a necessary step.
> 
> I agree.  Have thought about this too.  We should have some notion of
> when development on Silver will be frozen and when it will get
> promoted to Gold.

That would be nice.

\start
Date: Fri, 22 Jun 2007 21:55:09 +0200 (CEST)
From: Waldek Hebisch
To: Camm Maguire
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

Camm Maguire wrote:
> 2) x64 failure -- could you please post the full log?
> 

I tried cvs gcl on two different machines (both 64-bit), one
runnimng Gentoo, the other one Debian etch.  On both build
failed.  The output from configure on Debian is at:

http://www.math.uni.wroc.pl/~hebisch/prog/clogg

the output from make (also on Debian) at:

http://www.math.uni.wroc.pl/~hebisch/prog/mlogg

\start
Date: Fri, 22 Jun 2007 16:02:54 -0400
From: Bill Page
To: Waldek Hebisch
Subject: Re: problem compiling wh-sandbox revision 571 on Windows

On 6/20/07, Waldek Hebisch wrote:
> ...
> It looks that 'directory' implementation in GCL is rather messy, so
> I will not try to fix it.  However, you can try the following (which
> works like the old code):
> ...

Thanks! That patch (together with two other previous patches) worked
fine. wh-sandbox now builds properly on Windows again. Here are the
three patches:

$ svn diff src/interp/*.pamphlet
Index: src/interp/Makefile.pamphlet
===================================================================
--- src/interp/Makefile.pamphlet        (revision 613)
+++ src/interp/Makefile.pamphlet        (working copy)
@@ -940,7 +940,7 @@
                  >> makedep.lisp ; \
          echo '(load "'$$B'")' >> makedep.lisp ; \
        done
-       echo '(load "makedep.lisp") (BOOT::spad-save "$@" nil)' | ${LISPSYS}
+       echo '(load "makedep.lisp") (BOOT::spad-save "$(BASE)$@" nil)'
| ${LISPSYS}
        @ echo 4 ${DEPSYS} created
 @

Index: src/interp/daase.lisp.pamphlet
===================================================================
--- src/interp/daase.lisp.pamphlet      (revision 613)
+++ src/interp/daase.lisp.pamphlet      (working copy)
@@ -900,7 +900,19 @@
       (let (nrlibdirs asos skipasos aos)

       (chdir (string dirarg))
+      #-:GCL
       (setq nrlibdirs (directory "*.NRLIB/index.KAF"))
+
+      #| directory in GCL (at least gcl-2.6.8) on Windows is buggy,
+      it can not handle pathnames having wildcards in the middle,
+      so we need a workaround.  |#
+      #+:GCL
+      (setq nrlibdirs
+           (mapcar #'(lambda (f)
+                          (concatenate 'string (namestring f)
+                                         "/index.KAF"))
+                   (directory "*.NRLIB")))
+
       (setq asys (directory "*.asy"))
       (setq asos (directory "*.ao"))

$ svn diff src/lisp/*.pamphlet
Index: src/lisp/Makefile.pamphlet
===================================================================
--- src/lisp/Makefile.pamphlet  (revision 613)
+++ src/lisp/Makefile.pamphlet  (working copy)
@@ -81,7 +81,7 @@
        echo '(load "axiom-package.lisp")' \
             '(setq compiler::*default-system-p* t)' \
             '(compile-file "axiom-lisp.lisp")' | $(AXIOM_LISP)
-       echo '(compiler::link (quote ("axiom-package.lisp"
"axiom-lisp.$(OBJEXT)")) "lisp" ' \
+       echo '(compiler::link nil "prelisp" ' \
               ' (format nil "(progn (let ((*load-path* (cons ~S *load-path*))'\
                                         ' (si::*load-types* ~S))' \
                                        ' (compiler::emit-fn t))' \
@@ -91,6 +91,9 @@
                       ' si::*system-directory* (quote (list ".lsp")))' \
                '  "$(lisp_c_objects) @axiom_c_runtime_extra@")' \
             | $(AXIOM_LISP)
+       echo '(load "axiom-package.lisp") (load "axiom-lisp.$(OBJEXT)")' \
+            '(in-package "AXIOM-LISP") (save-core "lisp$(EXEEXT)")' \
+           | ./prelisp$(EXEEXT)
        $(INSTALL_PROGRAM) lisp$(EXEEXT) $(OUT)
        $(STAMP) $@

---------

Would you like me to commit this to wh-sandbox?

\start
Date: Fri, 22 Jun 2007 22:30:40 +0200 (CEST)
From: Waldek Hebisch
To: Bill Page
Subject: Re: problem compiling wh-sandbox revision 571 on Windows

Bill Page wrote:
> On 6/20/07, Waldek Hebisch wrote:
> > ...
> > It looks that 'directory' implementation in GCL is rather messy, so
> > I will not try to fix it.  However, you can try the following (which
> > works like the old code):
> > ...
> 
> Thanks! That patch (together with two other previous patches) worked
> fine. wh-sandbox now builds properly on Windows again. Here are the
> three patches:
> 

Thanks for checking this.

> $ svn diff src/interp/*.pamphlet
> Index: src/interp/Makefile.pamphlet
> ===================================================================
> --- src/interp/Makefile.pamphlet        (revision 613)
> +++ src/interp/Makefile.pamphlet        (working copy)
> @@ -940,7 +940,7 @@
>                   >> makedep.lisp ; \
>           echo '(load "'$$B'")' >> makedep.lisp ; \
>         done
> -       echo '(load "makedep.lisp") (BOOT::spad-save "$@" nil)' | ${LISPSYS}
> +       echo '(load "makedep.lisp") (BOOT::spad-save "$(BASE)$@" nil)'
> | ${LISPSYS}
>         @ echo 4 ${DEPSYS} created
>  @
> 
> Index: src/interp/daase.lisp.pamphlet
> ===================================================================
> --- src/interp/daase.lisp.pamphlet      (revision 613)
> +++ src/interp/daase.lisp.pamphlet      (working copy)
> @@ -900,7 +900,19 @@
>        (let (nrlibdirs asos skipasos aos)
> 
>        (chdir (string dirarg))
> +      #-:GCL
>        (setq nrlibdirs (directory "*.NRLIB/index.KAF"))
> +
> +      #| directory in GCL (at least gcl-2.6.8) on Windows is buggy,
> +      it can not handle pathnames having wildcards in the middle,
> +      so we need a workaround.  |#
> +      #+:GCL
> +      (setq nrlibdirs
> +           (mapcar #'(lambda (f)
> +                          (concatenate 'string (namestring f)
> +                                         "/index.KAF"))
> +                   (directory "*.NRLIB")))
> +
>        (setq asys (directory "*.asy"))
>        (setq asos (directory "*.ao"))
> 
> $ svn diff src/lisp/*.pamphlet
> Index: src/lisp/Makefile.pamphlet
> ===================================================================
> --- src/lisp/Makefile.pamphlet  (revision 613)
> +++ src/lisp/Makefile.pamphlet  (working copy)
> @@ -81,7 +81,7 @@
>         echo '(load "axiom-package.lisp")' \
>              '(setq compiler::*default-system-p* t)' \
>              '(compile-file "axiom-lisp.lisp")' | $(AXIOM_LISP)
> -       echo '(compiler::link (quote ("axiom-package.lisp"
> "axiom-lisp.$(OBJEXT)")) "lisp" ' \
> +       echo '(compiler::link nil "prelisp" ' \
>                ' (format nil "(progn (let ((*load-path* (cons ~S *load-path*))'\
>                                          ' (si::*load-types* ~S))' \
>                                         ' (compiler::emit-fn t))' \
> @@ -91,6 +91,9 @@
>                        ' si::*system-directory* (quote (list ".lsp")))' \
>                 '  "$(lisp_c_objects) @axiom_c_runtime_extra@")' \
>              | $(AXIOM_LISP)
> +       echo '(load "axiom-package.lisp") (load "axiom-lisp.$(OBJEXT)")' \
> +            '(in-package "AXIOM-LISP") (save-core "lisp$(EXEEXT)")' \
> +           | ./prelisp$(EXEEXT)
>         $(INSTALL_PROGRAM) lisp$(EXEEXT) $(OUT)
>         $(STAMP) $@
> 
> ---------
> 
> Would you like me to commit this to wh-sandbox?
> 

Yes, please do.

\start
Date: 22 Jun 2007 16:32:59 -0400
From: Stephen Wilson
To: Cliff Yapp
Subject: re: root chunks

Cliff Yapp writes:
> --- Stephen Wilson wrote:
> 
> > If your working exclusively with SBCL, you /may/ be surprised when
> > you try with an ANSI 2.6.8pre.  It certainly has missing features,
> > but is quite usable as a near-ansi lisp.  I used to work with SBCL
> > exclusively. But the strides GCL has made recently towards ansi and
> 
> I thought most of those strides were in the 2.7.0 branch?  I guess I
> need to check the ANSI build of 2.6.8pre again.

AFAIK, yes.  Main effort is w.r.t 2.7.0, however 2.6.8pre (latest cvs
snapshot) even has enough to give you a working MOP (some
difficulties, but relatively minor).  Its certainly not CLtL1.

[...]
> A long time back there were some efforts to get Slime working on GCL -
> I don't know if anyone has revisited the issue lately.
> 
> One trick I was able to pull with Maxima once was to have two Emacs
> connections to the same Maxima session - one talking to the Lisp REPL
> and the other talking to the command prompt.  This allowed one to
> perform normal commands in the command line and work inside the Slime
> environment at the Lisp level at the same time :-).  It needed threads
> though - the swank server in one and the normal Maxima session in the
> other - and some special startup was required to trigger swank, IIRC. 
> Once the asdf work is set up it might be worth trying to do that again
> for Axiom.  Does GCL have threads?

Im not one to ask as I have never done any work along these lines with
GCL.  I do know GCL has multiprocessing support via an MPI interface.
I have not come across an interface to something like NPTL or the
like.

\start
Date: Fri, 22 Jun 2007 16:34:11 -0400
From: Bill Page
To: Waldek Hebisch
Subject: Re: problem compiling wh-sandbox revision 571 on Windows

BTW, I did not time it carefully but I think this build of wh-sandbox
on Windows, including running the test scripts, took significantly
less than half the time of previous versions. Great work. Thanks
again.

I guess it's time I planned on creating an 'axiom-0.2' binary install file...

\start
Date: 22 Jun 2007 16:45:19 -0400
From: Camm Maguire
To: Waldek Hebisch
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

Greetings, and thanks so much for the feedback/report!  This should be
fixed now.  Releasing snapshot -70 to the Debian autobuilders...
Take care,

\start
Date: 22 Jun 2007 17:41:25 -0400
From: Camm Maguire
To: Robert Boyer
Subject: Re: 2.7.0 nqthm compile times
Cc: Matt Kaufmann

Greetings!

[ cc'ed to the maxima and axiom lists, as I would greatly appreciate
any user feedback on what they would like (that is practical) in the
forthcoming gcl release.  If this is unwelcome traffic, please let me
know.]

Robert Boyer writes:

> Fantastic.  Thanks so much!
> 

The above is most appreciated, but I was hoping for a bit more of an
opinion as to where GCL should be heading in this direction, to wit:

Code calling compiled functions of known signature can be rendered
incorrect if the callee is subsequently compiled to produce a
different signature:

=============================================================================
COMPILER>(defun foo (x y z) (list x y z))

FOO

COMPILER>(compile 'foo)

;; Compiling /tmp/gazonk_13883_1.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_13883_1.o.
;; Loading /tmp/gazonk_13883_1.o
 ;; start address -T 0xaa2f80 ;; Finished loading /tmp/gazonk_13883_1.o
#<compiled-function FOO>
NIL
NIL

COMPILER>(defun bar (x y z zz) (remove zz (foo x y z)))

BAR

COMPILER>(compile 'bar)

;; Compiling /tmp/gazonk_13883_1.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_13883_1.o.
;; Loading /tmp/gazonk_13883_1.o
;; start address -T 0x87b2b0 ;; Finished loading /tmp/gazonk_13883_1.o
#<compiled-function BAR>
NIL
NIL

COMPILER>(bar 1 2 3 1)

(2 3)

COMPILER>(setq si::*disable-recompile* t)

T

COMPILER>(defun foo (x y z) (coerce (list x y z) 'vector))

FOO

COMPILER>(compile 'foo)

;; Compiling /tmp/gazonk_13883_1.lsp.
; (DEFUN FOO ...) is being compiled.
;; Warning: ret type mismatch in auto-proclamation (CONS T
                                                    (CONS T
                                                     (CONS T NULL)))(NIL) -> *

;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_13883_1.o.
;; Loading /tmp/gazonk_13883_1.o
 ;; start address -T 0x87b540 ;; Finished loading /tmp/gazonk_13883_1.o
#<compiled-function FOO>
NIL
NIL

COMPILER>(bar 1 2 3 1)
Segmentation violation: c stack ok:signalling error
Error: ERROR "Caught fatal error [memory may be damaged]: Segmentation violation."
Fast links are on: do (si::use-fast-links nil) for debugging
Signalled by BAR.
ERROR "Caught fatal error [memory may be damaged]: Segmentation violation."

Broken at BAR.  Type :H for Help.
COMPILER>>:q

Top level.
COMPILER>(setq si::*disable-recompile* nil)

NIL

COMPILER>(si::do-recompile)
Pass1 signature discovery on 1 functions ...
Compiling and loading new source in #<output stream "/tmp/gazonk_13883_jvaAQ9.lsp">
;; Compiling /tmp/gazonk_13883_jvaAQ9.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_13883_jvaAQ9.o.
;; Loading /tmp/gazonk_13883_jvaAQ9.o
 ;; start address -T 0x87ff40 ;; Finished loading /tmp/gazonk_13883_jvaAQ9.o
done
NIL

COMPILER>(bar 1 2 3 1)

#(2 3)

COMPILER>(defun foo (x y z) (list x y z))

FOO

COMPILER>(compile 'foo)

;; Compiling /tmp/gazonk_13883_1.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_13883_1.o.
;; Loading /tmp/gazonk_13883_1.o
Pass1 signature discovery on 1 functions ...
Compiling and loading new source in #<output stream "/tmp/gazonk_13883_XL6AKh.lsp">
;; Compiling /tmp/gazonk_13883_XL6AKh.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_13883_XL6AKh.o.
;; Loading /tmp/gazonk_13883_XL6AKh.o
 ;; start address -T 0x880a20 ;; Finished loading /tmp/gazonk_13883_XL6AKh.o
 ;; start address -T 0x887320 ;; Finished loading /tmp/gazonk_13883_1.o
#<compiled-function FOO>
NIL
NIL

COMPILER>(bar 1 2 3 1)

(2 3)

COMPILER>
=============================================================================

The existing philosophy is therefore not to let the load of the new
foo complete without executing the recompile.  This has the
disadvantage of compiling functions possibly multiple times, and
fragmenting the contiguous memory space.

'si::do-recompile has the following behavior at the moment:

        a) if called without an argument, as is done in every loaded
        .o file, will 1) do a fast pass1-only signature discovery run
        on the out of date functions, 2) will write the necessary
        functions to a temporary file, compile and then load it.  Each
        function passes through gcc once, but possibly multiple times
        only through pass1.  System is left in a safe state, but code
        can be recompiled multiple times on subsequent multiple loads.

        b) if called with a non-nil argument, will do the above, but
        write the new source to the filespec provided in the argument,
        which is compiled but not loaded.  The system is left in an
        unsafe state, and implicitly leaves to the user the job of
        integrating the freshly compiled source.

        c) if called with a nil argument, will do the pass1 signature
        discovery, and collect a list of original source files
        containing the recompiled functions.  These files are then
        probed for and recompiled if found.  The system is left in an
        unsafe state, and implicitly leaves to the user the job of
        integrating the freshly recompiled code.  (These files cannot
        be automatically reloaded, as they may contain other top-level
        forms which are only intended to be executed once.  Given
        this, the load was also skipped for the non-nil argument case
        in b) by way of symmetry.  A third recompile for automatic
        loading purposes (as in a)) is ommitted to save compile time.)

'with-compilation-unit is as follows:

(defmacro with-compilation-unit (opt &rest body)   
  (declare (optimize (safety 1)))
  (declare (ignore opt)) 
  `(progn
     (let ((*disable-recompile* t))
       ,@body)
     (do-recompile nil)))

So at present it leaves the system in an unsafe state to avoid a
second pass through gcc and load for every recompiled function.  If
there are only compile-files and no loads in the unit, no signature
conflict is detected and no recompilation is done.  Only loaded
functions within the unit trigger recompilation at unit end.  This is
somewhat counter to what one might expect from the ansi-doc
definition, given its emphasis on compile-file item deferral.

Here are some alternatives:

1) do another pass through gcc followed by a load when passing the nil
   argument (or a just a load when passing the non-nil argument) to
   leave the system in a safe state at the expense of more compile
   time.

2) Never automatically recompile at load, leaving the safety < 3 user
   to the whims of random segfaults, but provide a safety 3 which
   eliminates all branch elimination depending on known return
   signatures.

3) Defer auto recompiles to a re-entry of top-level, minimizing the
   window of unsafe code execution.

...

Thoughts most appreciated.  Please help me make this serve the needs
of the community.  For those new to this thread, this mechanism
obviates the need for ftype declaims.  A final question remains of
whether or not to actually use ftype declaims if provided.

\start
Date: 22 Jun 2007 17:46:17 -0400
From: Camm Maguire
To: Stephen Wilson
Subject: re: root chunks

Greetings!

> compiler support).  I do miss Slime though :(
> 

Slime is on the medium term radar.

\start
Date: 22 Jun 2007 17:59:52 -0400
From: Camm Maguire
To: Cliff Yapp
Subject: re: root chunks

Greetings!

Cliff Yapp writes:

> --- Stephen Wilson wrote:
> 
> > If your working exclusively with SBCL, you /may/ be surprised when
> > you try with an ANSI 2.6.8pre.  It certainly has missing features,
> > but is quite usable as a near-ansi lisp.  I used to work with SBCL
> > exclusively. But the strides GCL has made recently towards ansi and
> 
> I thought most of those strides were in the 2.7.0 branch?  I guess I
> need to check the ANSI build of 2.6.8pre again.
> 

Though this statement is obviously ill-defined, I think 2.6.8pre is ~
75% the way there, and 2.7.0 ~90%.

> No question there :-).  (Note to self, don't scare Camm away with dpANS
> talk...)
> 

Please accept my humblest apologies for my repeated silence here --
time management you know.

Here is the last I have on this -- I think the point of the
distinction of the public draft was partially missed -- there may
still be hope.

=============================================================================
From: Joe Corneli <jcorneli@planetmath.org>
Subject: RE: ansi common lisp standard?
To: Camm Maguire, Richard Stallman
Date: Wed, 26 Oct 2005 19:28:31 -0400 (EDT)

Please advise.

From: "Barra, Lynn" <lbarra@itic.org>
Subject: RE: FW: ansi common lisp standard?
To: "Joe Corneli" <jcorneli@math.utexas.edu>
Date: Wed, 26 Oct 2005 16:33:55 -0400

Dear Joe -

I have submitted your request to the appropriate people within INCITS.
Unfortunately, INCITS does not allow its standards to be published
online or elsewhere for public distribution.  

INCITS standards are priced at $18 per copy; however, INCITS does work
with many organizations to develop license agreements (with discounted
rates).  We would be happy to discuss this with you.

In addition, if the INCITS LISP standard is used in other documentation,
the appropriate copyright approvals from INCITS need to be obtained.


Regards-
Lynn

Lynn Barra
Associate Director, Standards Operations
INCITS/Information Technology Industry Council
1250 Eye Street NW - Suite 200
Washington, DC  20005
202-626-5739
e-mail: Lbarra@itic.org
website: www.incits.org
 

- -----Original Message-----
From: Joe Corneli [mailto:jcorneli@math.utexas.edu] 
Sent: Sunday, September 04, 2005 2:32 PM
To: Barra, Lynn
Subject: Re: FW: ansi common lisp standard?


Yes, you bet!  We're still very interested.  Looking forward to
hearing more.
Thanks,
Joe

   Dear Joe,

   Your email was forwarded to me by Jennifer Garner.  I do not recall
   seeing your request.  Is this something you are still interested in?

   Regards
   Lynn

   Lynn Barra
   Associate Director, Standards Operations
   INCITS/Information Technology Industry Council
   1250 Eye Street NW - Suite 200
   Washington, DC  20005
   202-626-5739
   e-mail: Lbarra@itic.org
   website: www.incits.org

   -----Original Message-----
   From: Joe Corneli [mailto:jcorneli@math.utexas.edu] 
   Sent: Thursday, June 16, 2005 4:40 PM
   To: Garner, Jennifer
   Subject: ansi common lisp standard?


   Hi Jennifer,

   in October or November of last year, we sent the appended request,
   concerning the ANSI common lisp standard, to you, in hopes that you
   could communicate the request to the ANSI J13 management committee.
   Our aim was to obtain a copy of the Common Lisp standard with
   permissions that would enable us to use it as the basis of new Lisp
   documentation.  Can you tell me what the status of this request is
   currently?

   Thank you,

   Joe Corneli


     To the members of the ANSI J13 management committee:

     We wish to file a request on the behalf of Lisp users world wide
     that ANSI release the text of the Common Lisp standard in a way
     that would make it legal to use the standard as the foundation
     for a system of documentation which adequately describes Common
     Lisp as a living language.

     We recommend the use of the GNU Free Documentation License, which
     was specifically designed to apply to documentation and standards
     documents.  Using the GFDL, the copyright holder grants anyone
     permission to publish both changed and unchanged versions of the
     document, but requires that they all be distributed under the
     same license.

     The GFDL has a special feature intended for standards documents.
     The document can have an Endorsements section which must be
     removed from any modified version; ANSI's endorsement could say
     that the document contains the official definition of ANSI Common
     Lisp.  Other provisions of the license require giving credit to
     the authors of earlier versions.  Thus, modified versions would
     give credit to ANSI but could not claim to be the standard.

     We would be glad to explore ways to resolve any issues or
     uncertainties that may arise as you consider this request.

      Joseph Corneli
      jcorneli@math.utexas.edu

      Richard Stallman
      Richard Stallman

      Camm McGuire
      Camm Maguire

      Richard Gabriel
      rpg@dreamsongs.com

      Bruno Haible
      bruno@clisp.org

      Sam Steingold
      sds@gnu.org
----------





=============================================================================

> for Axiom.  Does GCL have threads?
> 

I'll try to post on this separately, as it deals with two other
"direction for GCL" questions, 1) parallelism, and 2) function calling
semantics.  The short answer is no, not at present, but we have a
quite effective fork-based parallelism (in addition to the MPI
support) at the lisp level: p-let, p-and, and p-or.  I'll try to
describe the advantages of fork vs. threads for lisp in a post soon.

\start
Date: Sat, 23 Jun 2007 00:40:36 +0200 (CEST)
From: Waldek Hebisch
To: Ralf Hemmecke
Subject: re: root chunks

Ralf Hemmecke wrote:
> On 06/22/2007 07:56 PM, Waldek Hebisch wrote:
> > Ralf Hemmecke wrote:
> >> I am pretty sure that someone can confirm that gcc has an option 
> >> that compiles the #line information into the executable. I am not 
> >> so sure about gcl. Camm?
> >> 
> >> You don't need to debug with sbcl. If a bug happens via SBCL and 
> >> not via GCL then that is a bug in the compiler and not in the 
> >> algebra code. So you would not be interested in debugging unless 
> >> you are a compiler writer.
> 
> > Sorry, that very naive:  Axiom in many places makes unportable 
> > assumptions.   So, in most cases when code works in one Lisp but 
> > fails in another the code is wrong.  FYI SBCL caught a number of bugs
> >  that were hidden when running under gcl (some of them were likely to
> >  give you "memory may be damaged" message).
> 
> Do you really mean that you had to change the *algebra* code? I did not
> speak of anything else. That the lisp/boot/shoe code is something else,
> I completely understand. And I also understand that for such issues
> different compilers are good. (Sorry for the gap that I left in my
> statement.)
> 

I was thinking mostly about boot code.  But SBCL helped also debugging
algebra -- because ATM "safe" gcl build takes much longer than safe
SBCL build.  In case of issue 359 it seems that SBCL catches
error earlier than "safe" gcl.  Issue 359 seem to be at boot
level, but already illustrates that it is hard to separate algebra
from the rest of the system.  And while I do not have example
of algebra problem that shows in SBCL but do not show in 
"safe" gcl I belive that such problems are possible and we
will hit such problem sooner or later.

\start
Date: 22 Jun 2007 18:49:12 -0400
From: Camm Maguire
To: list
Subject: GCL Fork based parallelism

Greetings!  Just committed a quick fix to get this working again in
the new dlopen access to external libs mechanism.  More discussion
later if desired.

Warning: at present there is no limit to the number of forks -- this
is forthcoming.

Take care,

>(in-package 'si)

#<"SYSTEM" package>

SYSTEM>(defun fib (x) (cond ((= x 1) 1) ((= x 2) 1) ((+ (fib (1- x)) (fib (- x 2))))))

FIB

SYSTEM>(defun fib1 (x) (si::p-let ((w (fib (1- x)))(z (fib (- x 2)))) (+ w z)))

FIB1

SYSTEM>(compile 'fib)

;; Compiling /tmp/gazonk_20137_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_20137_0.o.
;; Loading /tmp/gazonk_20137_0.o
 ;; start address -T 0x84f170 ;; Finished loading /tmp/gazonk_20137_0.o
#<compiled-function FIB>
NIL
NIL

SYSTEM>(compile 'fib1)

;; Compiling /tmp/gazonk_20137_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_20137_0.o.
;; Loading /tmp/gazonk_20137_0.o
 ;; start address -T 0x86cbc0 ;; Finished loading /tmp/gazonk_20137_0.o
#<compiled-function FIB1>
NIL
NIL

SYSTEM>(time (fib 30))

real time       :      0.020 secs
run-gbc time    :      0.020 secs
child run time  :      0.000 secs
gbc time        :      0.000 secs
832040

SYSTEM>(time (fib 40))

real time       :      2.550 secs
run-gbc time    :      2.550 secs
child run time  :      0.000 secs
gbc time        :      0.000 secs
102334155

SYSTEM>(time (fib1 40))

real time       :      1.590 secs
run-gbc time    :      0.000 secs
child run time  :      2.540 secs
gbc time        :      0.000 secs
102334155

SYSTEM>

\start
Date: Fri, 22 Jun 2007 18:05:48 -0500 (CDT)
From: Gabriel Dos Reis
To: Waldek Hebisch
Subject: Re: 2.7.0 reports
Cc: Camm Maguire

On Fri, 22 Jun 2007, Waldek Hebisch wrote:

| Camm Maguire wrote:
| > 2) x64 failure -- could you please post the full log?
| > 
| 
| I tried cvs gcl on two different machines (both 64-bit), one
| runnimng Gentoo, the other one Debian etch.  On both build
| failed.  The output from configure on Debian is at:
| 
| http://www.math.uni.wroc.pl/~hebisch/prog/clogg
| 
| the output from make (also on Debian) at:
| 
| http://www.math.uni.wroc.pl/~hebisch/prog/mlogg


Hi Waldek,

   Thanks for supplying the info.

Camm -- sorry for the delay.  I've been away from computers for all day.

\start
Date: Fri, 22 Jun 2007 16:14:29 -0700
From: Richard Fateman
To: Camm Maguire, Robert Boyer
Subject: RE: [Maxima] 2.7.0 nqthm compile times
Cc: Matt Kaufmann

The Franz Lisp system (on the VAX) had a file-compiler feature which
allowed you to group functions that were (in today's nomenclature)
private, and could only be called from functions in that file.  It was
not possible to redefine such internal functions without recompiling
the file.  The external functions (i.e. public) could be recompiled
and their signatures could be changed.

The code locality is, I think, a red herring. Caches are huge now.

\start
Date: Sat, 23 Jun 2007 01:50:19 +0200 (CEST)
From: Waldek Hebisch
To: Camm Maguire
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

Camm Maguire wtote:
> Greetings, and thanks so much for the feedback/report!  This should be
> fixed now.  Releasing snapshot -70 to the Debian autobuilders...

Thanks, CLtL1 have build file, ANSI build is in progress.  I have
noticed two little problems. One is that 'make install' did not install
the actual gcl command.  The second one is that 'defpackage' is
now absent from "LISP" package -- is this intentional?  Axiom
uses 'defpackage' and its lack breaks Axiom build.  It looks that
'defpackage' is now only available in the "COMPILER" package.
As long as 'defpackage' is available somewere I can easily
import it, but I would like to know what is supported.

\start
Date: Sat, 23 Jun 2007 02:20:14 +0200 (CEST)
From: Waldek Hebisch
To: Camm Maguire
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

> Greetings, and thanks so much for the feedback/report!  This should be
> fixed now.  Releasing snapshot -70 to the Debian autobuilders...
> Take care,

ANSI version have build file, but it did not install the gcl command.
Also, during 'compiler:link' I got error about missing 
'/var/tmp/hebisch/usrm/lib/gcl-2.7.0/unixport/../clcs/package.lisp'
('/var/tmp/hebisch/usrm/' is my prefix).  It looks that copying
'gcl/clcs/package.lisp' by hand solved that problem.  

But later I hit another one: I am getting messages like:

;; Compiling stage0/ptyout.clisp.
Segmentation violation: c stack ok:signalling errorError in error:
ERROR TYPE-ERROR (DATUM #<FREE OBJECT 0000000001b5c888> EXPECTED-TYPE
                        (OR METHOD-CALL FUNCTION)) NIL

Backtrace:

This is the first thing that the freshly linked image should do...

\start
Date: Fri, 22 Jun 2007 19:00:39 -0700 (PDT)
From: Cliff Yapp
To: Camm Maguire
Subject: ANSI documentation
 
> Please accept my humblest apologies for my repeated silence here --
> time management you know.

No problem - your work on GCL proper is both more important and more
likely to bear fruit.  A literate Lisp may still be possible without
the direct inclusion of text copied from ANSI standard documents,
although it would be considerably more difficult.
 
> Here is the last I have on this -- I think the point of the
> distinction of the public draft was partially missed -- there may
> still be hope.

Yes, the distinction between public draft and official text may be
important.  I don't know if they can say anything official about a
draft, but the digging I did on freespec
http://wiki.alu.org/Project_FreeSpec seems to suggest that any other
possibility of coherent copyright response is minimal.

Looking at that response, two points jump out at me - one is that they
don't allow their standards to be published "for public distribution". 
That's not surprising, but this part is:  "if the INCITS LISP standard
is used in other documentation, the appropriate copyright approvals
from INCITS need to be obtained."  That seems to suggest there is a
distinction between publishing the standard as THE INCITS standard and
using the content of the standard. 

I suspect at least one of our intended uses of the text of the standard
(source level documentation in literate form) has probably never come
up before as a proposed use of the text of a standard.  If there is no
intent to claim any official status with the text, it would seem to me
the primary focus of the INCITS wouldn't be impacted - particularly
given the 10 year availability history of the drafts.  People get the
official text from INCITS because it's OFFICIAL.  Anything non-official
isn't really in direct competition, even if freely distributed and
modifiable.

I myself have never contacted INCITS directly, since a) I don't
officially represent any Lisp distribution or project and b) I didn't
want to gum up the works if you were already doing so.  (Judging by the
names listed on the original appeal, that was a wise move.)  There was
some question raised during the freespec investigation as to what
official copyright ownership the INCITS has on the text, but the above
makes it sound like they DO have copyright control.  If that's true, a
renewed effort to contact them may be of interest, particularly if the
goals are explained in more detail.  (I.e. here's why what we're
interested in doing wouldn't hurt your status as the distributor of the
official Lisp standard.)

Camm, is there any continued interest in this from the other heavy
hitters?  Both a follow-up on the inclusion of INCITS text in "other
documentation" and a focused question on the dpANS documentation (as
opposed to the official published text) may be worthwhile, particularly
if we stress that no claim will be made that the documents that result
are in any sense official copies.

Camm I can certainly understand if you don't want to spend cycles on
this, but a direct appeal by me alone will likely accomplish exactly
zilch.  Are any of the other co-signers of the original appeal still
actively interested?  The hints in those communications give rise to
some hope I didn't have for INCITS itself being of aid, and based on my
current knowledge of the situation they may be the only practical hope.

\start
Date: Sat, 23 Jun 2007 08:11:42 +0200
From: Ralf Hemmecke
To: Bill Page
Subject: re: problem compiling wh-sandbox revision 571 on Windows

> I guess it's time I planned on creating an 'axiom-0.2' binary install 
> file...

I am a bit confused about the version number. NAG released 2.3. Didn't 
we once say that the current gold version is Axiom 3.0? What versioning 
scheme does OpenAxiom now actually have? Does somebody know? Where is 
this written down?

\start
Date: 23 Jun 2007 09:16:23 +0200
From: Martin Rubey
To: Ralf Hemmecke
Subject: Version numbers
Cc: Waldek Hebisch

Ralf Hemmecke writes:

> > I guess it's time I planned on creating an 'axiom-0.2' binary install file...
> 
> I am a bit confused about the version number. NAG released 2.3. Didn't we once
> say that the current gold version is Axiom 3.0? What versioning scheme does
> OpenAxiom now actually have? Does somebody know? Where is this written down?

Since Axiom is and very likely will be for a long time rapidly evolving, I
suggest to use yymm versioning.  I was hoping that trunk would become usable
(i.e., very close to wh-sandbox) soon, but that doesn't seem to be happening.

Gold is currently completely uninteresting for me and my math colleagues: no
working HyperDoc, many important algebra fixes are missing, etc., etc.

I have the feeling that "trunk" and "branches" is somewhat unfitting for the
Axiom project.  Currently, wh-sandbox seems most useable to me.

(Waldek: the only remaining thing on my wishlist is to have out of the box
aldor support)

\start
Date: Sat, 23 Jun 2007 02:30:45 -0500 (CDT)
From: Gabriel Dos Reis
To: Waldek Hebisch
Subject: Re: 2.7.0 reports
Cc: Camm Maguire

On Sat, 23 Jun 2007, Waldek Hebisch wrote:

| Camm Maguire wtote:
| > Greetings, and thanks so much for the feedback/report!  This should be
| > fixed now.  Releasing snapshot -70 to the Debian autobuilders...
| 
| Thanks, CLtL1 have build file, ANSI build is in progress.  I have
| noticed two little problems. One is that 'make install' did not install
| the actual gcl command. 

I concur that ANSI builds fine, and indeed maks insteall does
not install the gcl command.  Please find attached the "transcript"
of "make install"

-- Gaby
--8323584-334976469-1182583845=:31510
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--8323584-334976469-1182583845=:31510--

\start
Date: Sat, 23 Jun 2007 13:09:44 -0500
From: Tim Daly
To: Ralf Hemmecke
Subject: Axiom version numbering

There have been long discussions of the version naming scheme
which are journaled in the mailing list.

The Axiom version is printed as part of the banner when you start:

                 AXIOM Computer Algebra System
                   Version: Axiom (May 2007)
          Timestamp: Friday May 18, 2007 at 00:44:15


This gives information about what version of source was used to build
the system (May 2007). It gives information about what day and time
the system was built (nearly 1AM on May 18th).  And the first line of
CHANGELOG gives an exact version in yyyymmdd format. CHANGELOG is a
stack. Thus:

20070617 tpd src/interp/inpter-proclaims remove unused arg from $FCOPY

This gives far more information than version 3.1.4.1.5.9
The drive for random numbers seems to have started from RSC or CVS.
Telling me that GCL is 2.6.8pre tells me nothing as that version
contains many, many changes.

We could also print the git ref which is an md5 hash code and
will guarantee which source tree was used to build. However we
aren't usually in the business of chasing such fine-grained bugs.

\start
Date: Sat, 23 Jun 2007 13:13:21 -0500
From: Tim Daly
To: Martin Rubey
Subject: Axiom version numbering

> ... I was hoping that trunk would become usable (i.e., very close to
> wh-sandbox) soon, but that doesn't seem to be happening.

Why aren't they becoming close?

\start
Date: Sat, 23 Jun 2007 21:08:58 +0200 (CEST)
From: Waldek Hebisch
To: Gregory Vanuxem
Subject: Re: *read-default-float-format* in SBCL/wh-sandbox

> Hello Waldek,
> 
> *read-default-float-format* is set to single-float in SBCL/wh-sandbox.
> The problem, I think, is that SBCL does not save the value of this
> variable when creating a new Lisp image. As far as I know this happens
> for other variables (not exhaustive of course) *print-escape*
> *load-verbose* *compile-verbose* *load-print* *compile-print*
> *print-array*.
> 

AFAICS in open source Axiom *read-default-float-format* always was
set to single-float.  CCL based Axiom set *read-default-float-format*
to double-float.  GCL uses the same precision for single and
double floats (and also for long float), so for GCL it does not
matter very much.  Do you think we should set *read-default-float-format*
to T?  I must admit that in Lisp/boot sources I would prefer to
explicitly specify double precision (when needed), while for
Spad/input we are (or should be) using our own routines anyway.

Concerning *load-verbose*: in my sbcl-based Axiom it is set
to nil (the intended value) -- the same as in GCL or clisp
based version.  I am not sure if we care about other special
variables: we I think set them to required value during affected
operations.

BTW: If you want to have quiet compilation/loading it is not
enough to set *load-verbose* and *compile-verbose* to nil.
One also have to handle various conditions (see for example
|load_quietly| in axiom-lisp.lisp.pamphlet).

\start
Date: 23 Jun 2007 21:23:53 +0200
From: Martin Rubey
To: Sumant Oemrawsingh
Subject: Re: [Axiom-mail] Defining piece-wise functions	and drawing, integrating, ...

Dear Sumant,

Sumant Oemrawsingh writes:


> (1) -> h(k,x)==1/2 + 1/%pi * atan(k*x)

> (2) -> f(k,x)==x**2 * (h(k,x)-h(k,-x))

> (4) -> g(x)==limit(f(k,x),k=%plusInfinity)

> What I would think is that, since g(x) is a sum of two functions, the
> integral would split up into a sum of integrals as well.

Hm, why should g(x) be a sum of two functions? My axiom gives me upon issueing
g x

 x abs(x)

> (6) -> integrate(g(x),x=-1..1,"noPole")
> integrate(g(x),x=-1..1,"noPole")
> (6) -> 
>    (6)  "failed"
>                                                 Type: Union(fail: failed,...)

This just says that axiom couldn't do the integral.  In particular, bugs aside,
it is a "proof" that it not expressible as an elementary function.  (The Risch
algorithm is more or less completely implemented in axiom, and axiom will spit
out an error message if you hit an unimplemented branch.)

> So I've been looking a bit into how this could be done in spad. But I've not
> been able to understand where and how the functionality of such special
> functions is or can be implemented, or if I somehow would have to extend the
> definition or workings of the integrate function itself.

For a start, I'd think it is easier to split up integration boundaries
semi-automatically, as I indicated in a previous email.

If you are really interested in the internals, I think that intpm.spad is for
you, it tells axiom some pattern matching rules.  In my opinion, we should go
the mupad way here, the source of axiom is a horror, while the one of mupad is
extremely easy to grasp and to extend.

But that's way beyond my (computer algebra) skills.

\start
Date: Sat, 23 Jun 2007 23:20:57 +0200 (CEST)
From: Waldek Hebisch
To: Martin Rubey
Subject: re: [Axiom-mail] Defining piece-wise functions	and drawing, integrating, ...
Cc: Sumant Oemrawsingh

Martin Rubey wrote:
> Dear Sumant,
> 
> Sumant Oemrawsingh writes:
> 
> 
> > (1) -> h(k,x)==1/2 + 1/%pi * atan(k*x)
> 
> > (2) -> f(k,x)==x**2 * (h(k,x)-h(k,-x))
> 
> > (4) -> g(x)==limit(f(k,x),k=%plusInfinity)
> 
> > What I would think is that, since g(x) is a sum of two functions, the
> > integral would split up into a sum of integrals as well.
> 
> Hm, why should g(x) be a sum of two functions? My axiom gives me upon issueing
> g x
> 
>  x abs(x)
> 
> > (6) -> integrate(g(x),x=-1..1,"noPole")
> > integrate(g(x),x=-1..1,"noPole")
> > (6) -> 
> >    (6)  "failed"
> >                                                 Type: Union(fail: failed,...)
> 
> This just says that axiom couldn't do the integral.  In particular, bugs aside,
> it is a "proof" that it not expressible as an elementary function.  (The Risch
> algorithm is more or less completely implemented in axiom, and axiom will spit
> out an error message if you hit an unimplemented branch.)
> 

Note, that from Axiom point of view x*abs(x) is _not_ an elementary
function, so Risch algorithm immediatly gives up.

> > So I've been looking a bit into how this could be done in spad. But I've not
> > been able to understand where and how the functionality of such special
> > functions is or can be implemented, or if I somehow would have to extend the
> > definition or workings of the integrate function itself.
> 
> For a start, I'd think it is easier to split up integration boundaries
> semi-automatically, as I indicated in a previous email.
> 
> If you are really interested in the internals, I think that intpm.spad is for
> you, it tells axiom some pattern matching rules.  In my opinion, we should go
> the mupad way here, the source of axiom is a horror, while the one of mupad is
> extremely easy to grasp and to extend.
> 

I do not understand the comment about mupad.  I did not see mupad code,
but source of Axiom integrator is very clear: it implements Risch
algorithm very much as described in research articles.  Basically
the only extra difficulty is due to use of overloading: somethimes
one have to spend some time to discover domain from which given
operation comes.  The algorithm (and expecially math behind it) is
complex, so anybody who does not know the algorithm may easily get
lost.  But given complexity of math I doubt that that it can be
written much clearer.

Concerning integration of piecewise functions: there is an
algorithm which handles a buch of interesting cases. See:

D. J. Jeffrey,  G. Labahn,  M. v. Mohrenschildt,  A. D. Rich,
Integration of the signum, piecewise and related Functions
http://citeseer.ist.psu.edu/jeffrey97integration.html

and

D. J. Jeffrey,  A. D. Rich,   Recursive integration  of
piecewise-continuous functions
http://citeseer.ist.psu.edu/jeffrey97recursive.html

If one wants to implement something similar in Axiom the
first thing to do is to define a domain of piecewise
continuous functions.  Why?  Normal Axiom expressions form
a field, piecewise continuous functions have zero divisors,
so they only form a ring.  Zero divisors, if unhandled
will cause various nonsense results.

In general I belive that people who want to change Axiom
should quickly define their own category/domain/package
and work there.  Once such code is mature we will try
to integrate it.  It would be good to have some
examples for such extensions.  While defining new domains
looks easy one can hit problems very quickly.  For
example, a little package that tries to model adding
special functions:

)abbrev package EPAK MiscFunctions
MiscFunctions() : Exports == Implementation where
  F == Expression Integer
  Exports ==> with
     HypergeomF : (List F, List F, F) -> F
  Implementation ==> add
     ophypergeom := operator("HypergomF"::Symbol)$CommonOperators
     oplist := operator("%list"::Symbol)$CommonOperators
     HypergeomF(a, b, z) == ophypergeom [oplist a, oplist b, z]


One problem is that Axiom operats want expressions as arguments.
But here is natural to allow lists -- othewise one would be
forced to put arbitrary limit on the number of parameters and
define bunch of functions which differ only in the number
of paramters they accept.  Above I "solved" this using
atificial "%list" operator, but this has a drawback that
when I type:

HypergeomF([0, 1, 2], [2, 3], 3)

I get back:

HypergomF(%list(0,1,2),%list(2,3),3)

(and I would prefer list in square brackets).  It also seems
that this definitions will cause problems with derivatives
with respect to parameters...

\start
Date: Sat, 23 Jun 2007 19:52:06 -0400
From: Bill Page
To: Martin Rubey
Subject: Re: Version numbers
Cc: Waldek Hebisch

> Ralf Hemmecke writes:
>
> > Bill Page wrote:
> > > I guess it's time I planned on creating an 'axiom-0.2' binary install file...
> >
> > I am a bit confused about the version number. NAG released 2.3. Didn't we
> > once say that the current gold version is Axiom 3.0? What versioning
> > scheme does OpenAxiom now actually have? Does somebody know?
> > Where is this written down?
>

Yes, I think this was tentatively agreed upon and it appears in at
least one "released" version of open source Axiom (maybe the first?),
but it seems that this was promptly forgotten or re-defined by Tim as
he issued subsequent releases. Since defining new releases has so far
only been the job of one person - Tim - then I guess it remains up to
him until/if someone else wants to take on the job.

On 23 Jun 2007 09:16:23 +0200, Martin Rubey wrote:
> Since Axiom is and very likely will be for a long time rapidly evolving, I suggest
> to use yymm versioning.  I was hoping that trunk would become usable (i.e.,
> very close to wh-sandbox) soon, but that doesn't seem to be happening.
>

It seems the contrary to stated intentions, the update of the Gold and
Silver versions of Axiom effectively remains under the control of only
one person - Tim. So again as I see it, Tim remains the primary
bottleneck for getting these changes done. Perhaps this is not his
intention however I think his approach of using a separate repository
(based on git) and insisting on doing all updates via manual patches,
effectively discourages other developers from contributing directly to
the Gold or Silver versions. (See for example recent revisions
submitted by Gaby which he was asked to revert pending something
similar to be done by Tim.)  I do not see much incentive contribute to
these older "official" versions of Axiom versus continuing changes to
the build-improvements and wh-sandbox branches even though they remain
essentially only "experimental".

> Gold is currently completely uninteresting for me and my math colleagues: no
> working HyperDoc, many important algebra fixes are missing, etc., etc.
>

I agree completely. Gold does not even build on Windows.

> I have the feeling that "trunk" and "branches" is somewhat unfitting for the
> Axiom project.  Currently, wh-sandbox seems most useable to me.
>

Although no one has named it as such, I think effectively we have the
situation of a "fork" in the Axiom sources.

> (Waldek: the only remaining thing on my wishlist is to have out of the box
> aldor support)
>

Does this still have to wait until we have Aldor as open source?

\start
Date: Sun, 24 Jun 2007 14:03:35 +0200 (CEST)
From: Waldek Hebisch
To: Gregory Vanuxem
Subject: Re: Axiom under Windows

Greg, thanks for your comments, they are very helpful.
Gregory Vanuxem wrote:
> Le mardi 12 juin 2007 ? 14:54 +0200, Waldek Hebisch a =E9crit :
> > Could you be more specific about file handling in Windows SBCL?  AFAIK
> > makedir is problematic (but I hoped that it would work if you have mkdir
> > program in correct place) also chdir does not do much (but IIRC it is
> > taken verbatim from your Windows version).
>
> No, I was speaking about SBCL wh-sandbox built on Linux, sorry I was not
> clear. Your version misses writablep and consort (try to read the
> fname.input file). Attached is the file that I use (I think you already
> have it), it's a literal translation of the C code in
> Build-improvements. This code is not satisfactory and file/directory
> handling should be reworked I think. For Windows it's a real pain to
> work on file or directory, as a matter of fact the code here returns
> always true (readablep, writablep etc..). I quickly looked at your code
> and you seem to assume a unix environment, why not using obey.bat ? That
> gives you a "shell" which provides some file related functions (after
> all this is Windows...).
>

Concerning writablep: I looked at your code.  But AFAICS we would
need a separate version for each Lisp system.  And the code is
actually more complicated than C version.  So I think it is better
to call C version.  I still have to work out some details, but
for writablep it seem to work.  To say the truth I would like
to limit use writablep/readable just to (rare) sitations when
one really needs them and eliminate them from other places.

Attached you will find a little Lisp file "ffi-tst.lisp" and a
patch.  After applying the patch compiling Axiom will build
a shared library "libspad.so" in the src subdirectory.  ATM one
has to copy it by hand to "target/x86_64-unknown-linux/lib/" directory.
Before installing "libspad.so" one has to compile "ffi-tst.lisp"
(for Axiom, as it uses "BOOT" package) and copy resulting fasl
to "target/x86_64-unknown-linux/lib/".  Once both are installed
writablep should work OK.  Also some socket functions will work
(but I have to work out "sock_get_string_buf" and fix various
portablity problems including console handling before socket
code will have any visible effect).

readble? had a bug which should be fixed in revision 635.


Concerning 'obey.bat':  I did not notice that it is included
in your version.

> >
> > Do you have problems with
> > other functions?
>
> (Do not take me wrong, consider what I'm saying with the tonality of a
> joke). Yes a lot! I would like to be able to (Windows and Linux):
>
>   )cd Something (a namestring is missing apparently)
>

I just wrongly copied your version: I did not notice that 'sb-ext:chdir'
only changes directory at C level and one still have to change
*default-pathname-defaults*... Fixed now.

>   )fin (a problem here, some Lisp implementations do not fall in a
> read-eval-print loop when a "main" function is provided)
>

Yes, one has to figure out how to get repl in sbcl.  I have found
some functions that should help, but there are still details to work
out.

>   )trace INT )op + )break after
>

That should be fixed by a patch that I commited shorty before
your message :)

>   have better error message (using (format nil "%a" ...) ?)
>

Yes, using "~a" in 'error-format' (in 'spaderror.lisp.pamphlet')
seem to give better message.

>   Suppress the warnings, particularly when you compile a Spad file
>   since it's a pain to find the Spad error (even if the error is
>   NoValueMode is an Unknown mode  :-)
>

Just suppressing warnings is easy, but during build they point out
to real problems.  So ATM I am trying to find out a good compromise.

\start
Date: 24 Jun 2007 11:19:46 -0400
From: Camm Maguire
To: Waldek Hebisch
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

Greetings, and thanks so much for the report!

Will attend to the installation issues ASAP.

The other is of course more serious.  Since you have it all setup,
would you mind running with (si::use-fast-links nil)(trace (error
:entry (break))) and then do a :bt at the lisp prompt?  For really low
level, build gcl with --enable-debug and catch the segfault under gdb.
If you do not have time, I understand.  How do I get the source you
are working on?

Take care,

Waldek Hebisch writes:

> > Greetings, and thanks so much for the feedback/report!  This should be
> > fixed now.  Releasing snapshot -70 to the Debian autobuilders...
> > Take care,
> 
> ANSI version have build file, but it did not install the gcl command.
> Also, during 'compiler:link' I got error about missing 
> '/var/tmp/hebisch/usrm/lib/gcl-2.7.0/unixport/../clcs/package.lisp'
> ('/var/tmp/hebisch/usrm/' is my prefix).  It looks that copying
> 'gcl/clcs/package.lisp' by hand solved that problem.  
> 
> But later I hit another one: I am getting messages like:
> 
> ;; Compiling stage0/ptyout.clisp.
> Segmentation violation: c stack ok:signalling errorError in error:
> ERROR TYPE-ERROR (DATUM #<FREE OBJECT 0000000001b5c888> EXPECTED-TYPE
>                         (OR METHOD-CALL FUNCTION)) NIL
> 
> Backtrace:
> 
> This is the first thing that the freshly linked image should do...

\start
Date: 24 Jun 2007 18:49:48 +0200
From: Francois Maltey
To: Martin Rubey
Subject: Re: A multi-line mode for Emacs.

Hi Martin,

Thanks to your axiom.pamphlet and axiom.el files,
Now I better understand how the comint mode is running...

In your previous mail you write about :

clean up initialisation routines.
---------------------------------
I don't understand what you should like :

>  [[M-x axiom]] should switch to the buffer [[*axiom*]], if it exists and if
>  it is an "axiom buffer".  (I guess that should be a buffer in
>  [[axiom-mode]], with a running axiom process.)
  
>  If there is no such buffer, it should create a new buffer and a new axiom
>  process.

The axiom command in axiom.el file works so.

Do you want to run several axiom in several buffers ?

Nicolas Thery did it in mupad-run.el.
I hope I can to use this way for axiom.

I'll try to propose :

M-x axiom        goes to the *axiom* buffer in which axiom is running.
M-x axiom-other  goes to a new *axiom<n>* buffer in which axiom is running.
M-x axiom-mode   remains in the same buffer and runs axiom.
M-x axiom-buffer switchs from one axiom buffer to the next one.

Do you have an other idea ?

Then the buffer is seen as an *.input file which will be run after [return]

For this use all variables must be local. It's a curious trick...

And M-x axiom is defined by (switch-to-buffer *axiom*)(axiom-mode).

write another mode which allows input to be sent to the axiom buffer.
---------------------------------------------------------------------
I think I'll use the same mode axiom-mode with a new
variable axiom-multi-lines.

If axiom-multi-lines is false :
[return] sends a line which ends with ...._
and emacs waits for the new line as now.

If axiom-multi-lines is true :
[return] doesn't look at underscore _ at the end of the lines.

For this I think I must change the code arround the prompt

About prompt
------------
In axiom-output-filter
I'll add a complex function of tests arround prompt
and add a variable axiom-state :
axiom-state is 'running
            or 'usualPrompt    (nn) ->
            or 'quitPrompt     after )q
            or 'displayPrompt  after )d ...
            or 'debugPrompt    when UPPERCASE>> or UPPERCASE>>>>

In this function I destroy the double prompt (1)-> if necessary.
Then I use this variable in order to lock or to send the next input
after the [return]=A0command.

If axiom-multi-line is true I add a newline command after the prompt.
So the emacs-buffer begins with a new line.

\start
Date: Sun, 24 Jun 2007 18:58:18 +0200 (CEST)
From: Waldek Hebisch
To: Camm Maguire
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

> Greetings, and thanks so much for the report!
> 
> Will attend to the installation issues ASAP.
> 
> The other is of course more serious.  Since you have it all setup,
> would you mind running with (si::use-fast-links nil)(trace (error
> :entry (break))) and then do a :bt at the lisp prompt?  For really low
> level, build gcl with --enable-debug and catch the segfault under gdb.
> If you do not have time, I understand.  How do I get the source you
> are working on?
> 

The source is at (the revision probably does not matter much, but just
in case I add '-r 636' option):

svn checkout https://axiom.svn.sourceforge.net/svnroot/axiom/branches/wh-sandbox -r 636 wh-sandbox

I have tried to enable debugging.  However, the image seem to be badly
damaged, because alredy the second command give me error.  To give
more context: we build one image using 'compiler:link'.  This image
is used to build the second one using 'save-system'.  The second
image gives me:

$ ./local-lisp
GCL (GNU Common Lisp)  2.7.0 ANSI    Jun 23 2007 01:35:47
Source License: LGPL(gcl,gmp,pargcl), GPL(unexec,bfd,xgcl)
Binary License:  GPL due to GPL'ed components: (READLINE BFD UNEXEC)
Modifications of this banner must retain notice of a compatible license
Dedicated to the memory of W. Schelter

Use (help) to get some basic information on how to use GCL.

Temporary directory for compiler files set to /tmp/

>(si::use-fast-links nil)

NIL

>(trace (error :entry (break)))
Segmentation violation: c stack ok:signalling error
Error:
Signalled by PCL::FREE-CACHE.
Condition in PCL::FREE-CACHE [or a callee]: INTERNAL-SIMPLE-ERROR: Segmentation
violation: c stack ok:signalling errorError in error:
UNIVERSAL-ERROR-HANDLER ERROR (FORMAT-CONTROL
                                  Caught fatal error [memory may be damaged]: ~a                                  FORMAT-ARGUMENTS
                                  (Segmentation violation.)) (FREE-CACHE
                                                               )

Backtrace: system:universal-error-handler > system::break-level > format > pcl::print-std-instance > print-object > pcl::caching-miss > pcl::invoke-emf > simple-condition-format-control > pcl::accessor-miss > pcl::update-dfun > PCL::FREE-CACHE

Newly traced functions:  NIL
>

I will try '--enable-debug'...  

\start
Date: 24 Jun 2007 19:45:43 +0200
From: Martin Rubey
To: Francois Maltey
Subject: Re: A multi-line mode for Emacs.

Francois Maltey writes:

> In your previous mail you write about :
> 
> clean up initialisation routines.
> ---------------------------------
> I don't understand what you should like :
> 
> >  [[M-x axiom]] should switch to the buffer [[*axiom*]], if it exists and if
> >  it is an "axiom buffer".  (I guess that should be a buffer in
> >  [[axiom-mode]], with a running axiom process.)
>    
> >  If there is no such buffer, it should create a new buffer and a new axiom
> >  process.
> 
> The axiom command in axiom.el file works so.

Not for me.

> Do you want to run several axiom in several buffers ?

Yes.  I'd like behaviour as with shell mode.  M-x axiom switches to *axiom* if
present and if it is a buffer in axiom-mode, otherwise it creates such a
buffer.

Setting

(add-hook 'axiom-mode-hook (lambda () (rename-uniquely)))

in my .emacs should give me a new axiom buffer whenever I do M-x axiom.

But with clean up I also meant: clean up, i.e., make it tidy.  Currently, the
code is a mess, at least for me.

> I'll try to propose :
> 
> M-x axiom        goes to the *axiom* buffer in which axiom is running.
> M-x axiom-other  goes to a new *axiom<n>* buffer in which axiom is running.
> M-x axiom-mode   remains in the same buffer and runs axiom.
> M-x axiom-buffer switchs from one axiom buffer to the next one.
> 
> Do you have an other idea ?

Yes, the above looks far too complicated for me.  I'd like the way shell mode
works far better, i.e., only one command, which works "the emacs way", though.

> Then the buffer is seen as an *.input file which will be run after [return]

That doesn't look very useful for me.  If I want to read a whole input file, I
just )read it.  What I need however is to mark parts of an input file and send
it to axiom.

> I think I'll use the same mode axiom-mode with a new 
> variable axiom-multi-lines. 
> 
> If axiom-multi-lines is false :
> [return] sends a line which ends with ...._ 
> and emacs waits for the new line as now.
> 
> If axiom-multi-lines is true :
> [return] doesn't look at underscore _ at the end of the lines.

So, how do you determine end of input then?

> About prompt
> ------------
> In axiom-output-filter 
> I'll add a complex function of tests arround prompt 
> and add a variable axiom-state :
> axiom-state is 'running
>             or 'usualPrompt    (nn) -> 
>             or 'quitPrompt     after )q
>             or 'displayPrompt  after )d ...
>             or 'debugPrompt    when UPPERCASE>> or UPPERCASE>>>>

I doubt that you'll catch all situations with that, but I don't know.  I think
we should try to stay as flexible as possible.

Really, I think the best thing would be a mode axiom-input.el, which allows
sending the region to axiom, via saving it into a temporary file and )read ing
it in the axiom buffer.  This would also allow us to do some syntax
highlighting and possibly even some indentation features for input files.

Another good feature would be tab completion, by the way.  This works if you
start axiom in a terminal, so it should be possible...

\start
Date: 24 Jun 2007 21:15:32 +0200
From: Francois Maltey
To: Martin Rubey
Subject: Re: A multi-line mode for Emacs.

Dear Martin,

> > > [[M-x axiom]] should switch to the buffer [[*axiom*]], 
> > > if it exists and if it is an "axiom buffer".  

> > > If there is no such buffer, 
> > > it should create a new buffer and a new axiom process.
> > 
> > The axiom command in axiom.el file works so.
> 
> Not for me.

What do you get when you type ?

   [[M-x axiom]]         the first time.
   [[C-x b return]]      to switch to an other buffer
   [[M-x axiom]]         a second time

I switch to the first axiom buffer, as in shell mode.

Could you send me your axiom.el please ?
Do you have any line about axiom.el in your .emacs ?
In my .emacs I have only : 
  
(load "~/Configuration/emacs/axiom.el")

for this axiom.el file that I extract from june 16th. *.pamphlet file.

> > Do you want to run several axiom in several buffers ?

> Yes.  I'd like behaviour as with shell mode. 
All right, I test... 
But it seem today impossible to do this with axiom because
variables in axiom.el are global for all axiom-process, 
and it's necessary to create local variable for each axiom buffer.

> M-x axiom switches to *axiom* if present and 
> if it is a buffer in axiom-mode, otherwise it creates such a buffer.

Perhaps [[M-x axiom]] will be right if you delete this line from 
your .emacs...

> (add-hook 'axiom-mode-hook (lambda () (rename-uniquely)))

This hook'll works right after we transform global variables to local ones. 

> Yes, the above looks far too complicated for me.  I'd like the way
> shell mode works far better, i.e., only one command, which works
> "the emacs way", though.
All right...

I only look for an axiom-run mode, not for an axiom-input mode
with font lock and so...

> > If axiom-multi-lines is true :
> > [return] doesn't look at underscore _ at the end of the lines.
> 
> So, how do you determine end of input then?

The end of the buffer or 2 empty lines or a line with ---- or others.

1> Really, I think the best thing would be a mode axiom-input.el, 
1> This would also allow us to do some syntax highlighting and possibly
1> even some indentation features for input files.

2> which
2> allows sending the region to axiom, via saving it into a temporary
2> file and )read ing it in the axiom buffer.  

3> Another good feature would be tab completion, by the way.  This works if you
3> start axiom in a terminal, so it should be possible...

I keep theses three wishes in my memory.

My first want is an axiom interface in emacs, not really an axiom-input mode.
What do you know about emacs fontification and indentation.
I'm very dull about it...

The second one is very easy.

I keep the third one in my mind.
It seem possible to send the tab key to axiom and get the reponse.
(even if axiom is running)
This completion ignore the new variables of a session, 
I only get system keyword.

But it'll be more easy to generate the complete list only one time
and browse it in an emacs list. But how can I get this complete list ?

About axiom.el code :

> But with clean up I also meant: clean up, i.e., make it tidy.  
> Currently, the code is a mess, at least for me.

I began to play with this very small file.

F. 

---------------------------------------------------------------------
(require 'comint)
(setq comint-highlight-prompt nil)

(defvar axiom-mode-map nil "Keyboard for axiom mode.")
(define-derived-mode axiom-mode comint-mode "AXIOM")

(defvar axiom-state nil)
(defvar axiom-process nil)
(defvar axiom-last-output nil)

(defun axiom-local ()
   "Run axiom in a terminal environment"
  (interactive)
  ;; Run that command and switch to the new buffer
  (switch-to-buffer (make-comint "axiom" "axiom" nil "-noclef" "-noht"))
  (add-hook 'comint-output-filter-functions 'axiom-output-filter nil t)
  (add-hook 'comint-preoutput-filter-functions 'axiom-preoutput-filter)
  ;; and identify the process as well:
  (setq axiom-process (get-buffer-process (current-buffer)))
  (axiom-mode))

(defface axiom-output-face '((t (:background "lightgrey")))
  "Face used for output."
  :group 'axiom)

(defun axiom-preoutput-filter (str) 
  (setq axiom-last-output (marker-position (process-mark axiom-process)))
  str)

(defun axiom-output-filter (str)
  (let ((inhibit-read-only t)
        (beg axiom-last-output) (end (process-mark axiom-process)))
    (put-text-property beg end 'front-sticky t)
    (put-text-property beg end 'rear-nonsticky t)
    (put-text-property beg end 'read-only t)
    (put-text-property beg end 'face 'axiom-output-face))
  str)

(defun axiom-eval ()
  "Evaluate the current input and append output."
  (interactive)
  (goto-char (point-max))
  (insert "\n")
  (comint-send-string 
    axiom-process
    (buffer-substring (process-mark axiom-process) (point-max)))
  (goto-char (point-max))
  (comint-set-process-mark))

(define-key axiom-mode-map "\C-m" 'axiom-eval)
(define-key axiom-mode-map "\C-j" 'newline)
----------------------------------------------------------------------------

\start
Date: Sun, 24 Jun 2007 17:51:51 -0500 (CDT)
From: Gabriel Dos Reis
To: list
Subject: Lille

Hi,

  I'm currently in Lille; I visited the computer algebra group (headed by
Michel Petitot) at LIFL last thursday.  Michel Petitot was an Axiom user and
contributor in the late '80 and beginning '90 -- pieces of his contributions
to the Axiom algebra are still there.  

  I'll be giving a talk on Axiom next wednesday to the group.  Most of it
will be update on the state of the project, current architcture, and possible 
future (technical) directions.

\start
Date: Sun, 24 Jun 2007 18:40:28 -0500 (CDT)
From: Gabriel Dos Reis
To: list
Subject: HyperDoc macros

Bill --

   When replying, please CC: me using my address at TAMU as I cannot
currently access my usual dev machine which has all Axiom mails.

   If you build Axiom.build-improvements prior to version 632, you
notice that when compiling the algebra files, AXIOMsys will spit out
noise saying "Unexpected HT command" on all files that
are properly documented.  That is because AXIOMsys cannot find
the HyperDoc macro table -- the path to the macro table is wrong, and that
is a long standing fallout from my initial build-improvement work; I meant
to fix it but never get around to do it.

   Now, what is the relation with Windows?  Well, currently Axiom (both 
Gold, Silver, and all branches I tested a few days ago) will
build the hyperdoc component only if X11 is available.  If that component
is not built, then we will not set up the macro table path correctly.  
And we will see the noise mentioned above.

   As it turns out, only a fraction of the HyperDoc component really needs
X11 (mainly the terrible graphic interface).  Other parts (e.g. htadd) of
HyperDoc will do just fine.  So my patch to Axiom.build-improvemnt
builds those parts that really do not need X11.  And we set up the path
to macro table correctly.

   My long term viewd would be to reogranize the Axiom structure in logical,
indpendent units, but I've given up on having long term views for
Axiom, so you should not waste much time on this.

\start
Date: Sun, 24 Jun 2007 19:13:24 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: Axiom version numbering

Hi,

   Giving a conventional version numbering x.y.z is not
exclusing of giving the build time.  In fact none of them
is completely accurate and unambiguous for all purposes. They can 
be seen complimentary.  It can also be checked that several
software out there give both types of versioning.  They are
each useful for specific kinds of investigations.  X.Y.Z. helps quikcly
identify the flavor of a release.  The finer grained version giving time of
build serves different purpose.

  Modern Axiom releases should have  X.Y.Z version numbering
in addition of the the more verbose and imprecise 'May 2007'
scheme.

\start
Date: Mon, 25 Jun 2007 02:51:44 +0200 (CEST)
From: Waldek Hebisch
To: Camm Maguire
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

I wrote:
> > But later I hit another one: I am getting messages like:
> > 
> > ;; Compiling stage0/ptyout.clisp.
> > Segmentation violation: c stack ok:signalling errorError in error:
> > ERROR TYPE-ERROR (DATUM #<FREE OBJECT 0000000001b5c888> EXPECTED-TYPE
> >                         (OR METHOD-CALL FUNCTION)) NIL
> > 

I have noticed that this error goes away if I change parameters to
compiler link:  normally axiom has '(si::sgc-on t)' as part of init
form, if I this to '(si::sgc-on nil)' I can proceed further.

Later I hit problem with setting memory parameters, gcl complained:

Condition in APPLY [or a callee]: INTERNAL-SIMPLE-ERROR: Can't set the limit for relocatable blocks to 1000.

This error went away when I commented Axiom code which tried to
set memory parameteres.

Later I met another error. Relevant (part of) log is below:

;; Compiling def.lisp.
; (DEFUN B-MDEF ...) is being compiled.
;; Warning: The variable X is not used.
; (DEFUN DEF-INNER ...) is being compiled.
;; Warning: The variable SIGNATURE is not used.
;; End of Pass 1.
;; End of Pass 2.
;; OPTIMIZE levels: Safety=1 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling def.o.
;; Loading def.o
Pass1 signature discovery on 86 functions ...
; (DEFUN B-MDEF ...) is being compiled.
;; Warning: The variable X is not used.
; (DEFUN DEF-INNER ...) is being compiled.
;; Warning: The variable SIGNATURE is not used.
Pass1 signature discovery on 1 functions ...
Mutual recursion detected: (|new2OldDefForm| |new2OldTran| |newDef2Def|
                               LET_ERROR), recompiling |new2OldDefForm159046|
Mutual recursion detected: (DEF-PROCESS B-MDEF DEF), recompiling DEF-PROCESS159056
Mutual recursion detected: (DEFTRAN MKPROGN DEF-INNER ERRHUH DEF-LET
                                    MK_LEFORM MK_LEFORM-CONS DEF-WHERE), recompiling DEF-WHERE159049
Mutual recursion detected: (DEF-IS-REV DEF-IS-EQLIST), recompiling DEF-IS-EQLIST159053
Pass1 signature discovery on 4 functions ...
; (DEFUN DEF-PROCESS159056 ...) is being compiled.
;; Warning: The variable X is not used.
; (DEFUN DEF-WHERE159049 ...) is being compiled.
;;; The declaration (DECLARE (OPTIMIZE (SAFETY 1))) was found in a bad place.
;;; The declaration (DECLARE (OPTIMIZE (SAFETY 1))) was found in a bad place.;;
Warning: The variable SIGNATURE is not used.
Pass1 signature discovery on 17 functions ...
Compiling and loading new source in #<output stream "/tmp/gazonk_20011_4qT07D.lsp">
;; Compiling /tmp/gazonk_20011_4qT07D.lsp.
;; End of Pass 1.
;; End of Pass 2.
;; OPTIMIZE levels: Safety=1 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_20011_4qT07D0.o.
;; Compiling /tmp/gazonk_20011_4qT07D.lsp.
; (DEFUN DEF-PROCESS159056 ...) is being compiled.
;; Warning: The variable X is not used.
; (DEFUN DEF-WHERE159049 ...) is being compiled.
;;; The declaration (DECLARE (OPTIMIZE (SAFETY 1))) was found in a bad place.
;;; The declaration (DECLARE (OPTIMIZE (SAFETY 1))) was found in a bad place.;;
Warning: The variable SIGNATURE is not used.
No FASL generated.
;; Compiling /tmp/gazonk0.lsp.
;; End of Pass 1.
;; End of Pass 2.
;; OPTIMIZE levels: Safety=1 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_20011_4qT07D.o.
;; Loading /tmp/gazonk_20011_4qT07D.o
;; Loading /tmp/gazonk_20011_4qT07D0.o
 ;; start address -T 0x10fd600 ;; Finished loading /tmp/gazonk_20011_4qT07D0.o
;; Loading /tmp/gazonk_20011_4qT07D1.o

Error:
Fast links are on: do (si::use-fast-links nil) for debugging
Signalled by LOAD.
Condition in APPLY [or a callee]: INTERNAL-SIMPLE-ERROR: Unknown bfd format

Broken at APPLY.  Type :H for Help.


/tmp/gazonk_20011_4qT07D1.o is empty, so no wonder that gcl can not
load it.  I see no other files with name of form '/tmp/gazonk_20011_4qT07D1.*'
(no .lsp file, no .c file).

BTW: it looks that at that stage I have 167 gazonk* files in the
/tmp directory -- it looks that gcl is leaving trash files there. 

\start
Date: 24 Jun 2007 21:02:24 -0400
From: Stephen Wilson
To: Waldek Hebisch
Subject: Re: 2.7.0 reports
Cc: Camm Maguire, Gabriel Dos Reis

Waldek Hebisch writes:

> Later I hit problem with setting memory parameters, gcl complained:
> 
> Condition in APPLY [or a callee]: INTERNAL-SIMPLE-ERROR: Can't set the limit for relocatable blocks to 1000.
> 
> This error went away when I commented Axiom code which tried to
> set memory parameteres.

Unsure if its related, but I have hit similar problems after doing
extensive wrok at the REPL then issuing (sys:top-level) which, IIFC,
winds up in the calls to sys:allocate. 

Explicit call to gc in all cases so far has enabled me to continue.

\start
Date: Mon, 25 Jun 2007 01:21:17 -0400
From: Bill Page
To: list
Subject: Re: Version numbers
Cc: Gabriel Dos Reis, Waldek Hebisch

Axiom Developers,

On 6/24/07 Tim Daly sent me a private email on the subjects discussed
by me in this thread on June 23, 2007 7:52 PM. He claimed that I had
published several emails that disparage him in an unjust personal
manner and that he thought that it was highly unprofessional of me to
make such libelous remarks. He said that I had misrepresented his
motives in a negative manner without giving exact quotations from his
public emails to the list. He then asked that I "take some
professional responsibility and publicly apologize to me".

Since Tim thinks that I have done these things it is my intention in
this email to present such an apology in as professional a manner as
possible.

To other people reading this thread, if this disagreement is of no
interest to you and seems off topic, then I apologize for wasting your
inbox space and suggest that you hit the delete key now. But if you
have enough patience, please do continue reading. I think open source
projects are a lot different than traditional computer software
projects because in many cases *all* of the effort and the resources
available are *volunteer*. This means among other things that it is
not possible simply to pay someone a salary as compensation for
"putting up with" the difficulties of working together with other
people. Instead we must be prepared to devote at least some of our
time trying to making sure that everyone involved feels like they are
being treated fairly.

Needless to say, I was somewhat surprised and taken-a-back by Tim's
email. In a personal reply to him I explained that this certainly was
not the intention of my email and I believed that I had made only
factual statements and no statements about his motives. I did not
intend or expect to make anyone angry. I am sorry if what I wrote had
that result.

In his email Tim pointed out to me that every decision he has made
regarding Axiom was with the explicit goal of improving Axiom and that
he had put both massive amounts of time and an ongoing sizable amount
of money into building up Axiom, raising the quality, and promoting
its use. I do in fact realize this is the case and have previously
pointed out Tim's large personal contributions to other people both
privately and on these email lists.

Tim's email to me went on to quote specific parts of this thread and
made additional comments intended to support his claims. Although I do
not have his permission to quote directly from his private email to
me, I would like to summarize these points and my replies below since
they also partly address concerns expressed by other people on this
list.

On the subject which started this thread:

>
> >> Bill Page wrote:
> >>> I guess it's time I planned on creating an 'axiom-0.2' binary install file
>
> > Ralf Hemmecke wrote:
> >> I am a bit confused about the version number. NAG release 2.3. Didn't we
> >> once say that the current gold version is Axiom 3.0? What versioning
> >> scheme does OpenAxiom now actually have? Does someone know?
> >> Where is this written down?
>

Tim said that he was confused about my use of the name "axiom-0.2". He
pointed out that there were no patches against Gold for this version
of Axom and so it would difficult to relate "axiom-0.2" back to
anything for debugging purposes.

Concerning naming conventions Tim suggested that I check the mailing
lists, e.g, from January:

http://lists.gnu.org/archive/html/axiom-developer/2007-02/msg00076.html

He said that this is same version scheme that we've been using all
along. And that it is the same approach that was used in the original
Scratchpad project and by NAG when Axiom was a commerical product.
This scheme is embodied in the *yearweek* variable in the original
Axiom source code.

Tim said that I could call it anything I like, for example "axiom-0.2"
but it would be most *useful* if it was a name that is actually being
used in the releases and meaningfully identified the actual source
code.

I believe that what Ralf was pointing out in his original reply to me
was that my use of "axiom-0.2" did not seem consistent and that we had
previously used version 3.0. I think he is right. For example see
Tim's email to the mailing list of Thu, 30 Dec 2004 15:30:25:

http://lists.gnu.org/archive/html/axiom-developer/2004-12/msg00534.html

In that email Tim wrote:

"Axiom 3.0 Beta sources are now in savannah.
You can tell that it is the 3.0 Beta because it prints this in the header:

    Axiom 3.0 Beta (January 2005)"

In fact there are at least 45 emails in the axiom-developer list
referring to Axiom "3.0
Beta" dating from 16 Dec 2004 to 17 Oct 2006.

I agree that the name axiom-0.2 is not consistent with this. Really
what I am talking about is the name given to the Axiom installation
program for windows.  I posted the first "Axiom on Windows" installer
program on the Axiom wiki in early December 2004. It was labeled
"axiom-windows-0.1.1.exe" and was based on patches done by Mike Thomas
that November. Mike sent all of these patches to Tim and the reset of
the email list at that time. The current Axiom Gold sources do not
compile on windows. The most recent Axiom for Windows version 0.1.4
(no more than two years out of date) was based on the same
modifications made to the Axiom sources by Mike Thomas and are
available in the tla (arch) respository axiom--windows--1.

On contrast, what I was (incorrectly) thinking of calling "axiom-0.2"
would be based entirely on unmodified source code of the current
revision (613 or later) of wh-sandbox. The relationship of wh-sandbox
to Gold is rather complex, but when we solve the problem of how to
merge wh-sandbox (and build-improvements) back into Gold, then the
problem of merging windows with Gold will also be solved.

I think Ralf and Tim are right and that I should probably call this
new Axiom for Windows installer by a name something like:

  axiom-windows-wh-rev613.exe

> > Martin Rubey wrote:
> >> I was hoping that trunk would be usable (i.e., very close to wh-sandbox) soon, ...

Tim points out that in fact he has committed to number of changes to
Silver that originated from build-improvements (labeled "gdr" in the
Silver change log) and wh-sandbox (labeled "wxh" in the Silver change
log). He admits that not everything has been merged because: 1) he has
had to read the code from build-improvements and wh-sandbox to create
the diff-Naur from Gold himself because no one else made any effort to
merge changes back to gold. Further, that some changes were not
included because either: 2) they were unstable or 3)  because he did
not understand them.

I think that what Tim says is true but I believe that Martin is
concerned about higher level functionality like the fixes to Hyperdoc
and the ability to compile his "guess" package. Personally I find that
both build-improvements and wh-sandbox are much more stable than Gold
and that they build on more platforms, so they seem like a natural
choice for Martin.

I am not sure why Tim does not understand the changes that where made
in these branches. Most (all?) of the changes made by Gaby and Waldek
were announced on axiom-developer email list and the detailed patches
are sent to axiom-commit. I think that if anyone has questions about
the changes it would be best to ask the authors via the
axiom-developer list.

>> Martin Rubey wrote:
> >> but that doesn't seem to be happening.
>

As an explanation of why this is not happening Tim said that we should
consider the two ways that people generally contribute changes to open
source projects. The first is to create a branch, make a series of
modifications, merge those modifications into a local copy, test those
changes, package up the changes into a changeset, and post those
diff-Naur changes against the trunk. He says that his is the way it is
done in linux, gcc, apache and SBCL. For example:
 http://sourceforge.net/mailarchive/message.php?msg_name=75cb50350706181211g1740af8dg155a401

The second method is to create a fork: take the main body of code and
make your own competing branch, marketing it with new features. You do
not make an effort to contribute your code back to the trunk. You
simply "walk off" with the collective effort and promote your own
private version.

I would prefer the first method but as I said in my previous email, I
am afraid that we are closed to the second method right now.

Although it is true that they are not *exactly* diff-Naur patches, all
of the posts to axiom-commit are in fact diffs against the original
trunk of SVN at SourceForge which corresponded to patch-50 which is
what "Silver" used to be. I there must be at least 500 of these emails
in the axiom-commit archive. It seems to me  that both Gaby and Waldek
originally believed that Tim (or anyone else motivated to update Gold
and Silver would use these diffs.

Tim explains why there has been no conversion of Gold to using
autoconf by pointing out that there is no diff-Naur, there is no
documentation, there is no effort to promote any changes back to the
main line of code by anyone else. He says that since he doesn't
understand the autoconf code, he personally can not merge it. All of
this seems clear to me  and it is not my intention to suggest that
this should be Tim's responsiblity. I agree that the documentation of
the autoconf changes is minimal but I believe that both Gaby and
Waldek have made some effort to update both the code and the
documentation parts of the pamphlet files they have modified. The
modified makefile.pamhlet files do contain a lot of details about the
new autoconf build process - enough at least for me to make some very
simple changes.

Since I have been promoting the autoconf style of build process for
Axiom to Tim for several years, Tim asked me why I did not do this
work myself. I replied that I was very glad when someone came along
(Gaby) who was motivated and obviously knew enough about how to do it
- much more than me! The situation is that really I do not want to be
doing this kind of development. Since I am not very good at it, it
wastes my time and there is never enough time. I would very much
prefer to be an Axiom user/developer who discusses mathematics and
writes new algebra code for example in category theory and in
applications to physics. But here I have been stuck for nearly 5 years
now - just getting to the point where this is becoming possible.

As I see it, my main contribution to the Axiom project so far has been
the attempt to attract other people (and hopefully some talented
developers) to the project so that I personally wouldn't have to be
trying to do those things for which I don't have much talent. So far I
am a little disappointed with the results since the axiom-developer
list has not grown nearly so mcuh as I would have liked, however we do
have both Gaby and Waldek, and I think that counts as some a
significant measure of success at attracting new talent. Of course I
can not claim that it was specifically my efforts that resulted in
this but I like to think that I contributed in some manner. :-)

> > Bill Page wrote:
> >> It seems the contrary to stated intentions, the update of the Gold and
> >> Silver versions of Axiom effectively remains under the control of only
> >> one person -- Tim.
>

Tim says that this is a "lie" and referred me to his email:

http://lists.gnu.org/archive/html/axiom-developer/2006-11/msg00282.html

He says that history shows that no one stepped up to build a new
version of Axiom and no one committed any changes to Axiom over the
period of 3 months from November to January even though everyone
(inculding me) had write access. During that time Gaby and Waldek
continued working on their own branches.

I agree that that this history is correct. In fact I have had write
access to the archives since the very  beginning. My first and only
critical submission was way back in the stone age when I submitted a
patch to update the database files that had been generated by Jergen
Weiss. I also committed some changes to the build scripts to simplify
the algebra makefile (after a lot of discussion with Tim).

Tim said that it is clear that I can't take responsibility for the
main branch of Axiom because given the complete freedom to do the
task, that I did nothing. But I never said I wanted to take
responsibility for any branch. I was happy to let Tim do that. But
when Tim stopped I was at least happy that Gaby and Waldek continued
to work on the build-improvements and wh-sandbox branches.

> > Bill Page wrote:
> >> Tim remains the primary bottleneck for getting these changes done.
> ...
> >> Perhaps this is not his intention however I think his approach of using
> >> a separate repostory (based on git) and insisting on doing all updates
> >> via manual patches, effectively discourages other developers from
> >> contributing directly to Gold or Silver versions.
>

What Tim wrote in reply seemed to indicate that he was angry that I
should make this sort of claim. He said that it was equivalent to
claiming that he personally should decode how autoconf works,  how the
new boot is supposed to work, and how the ansi version is supposed to
be merged. Tim repeated that no one besides him makes any effort to
ensure that the main trunk is updated.

So I explained that what I meant was that I thought his (Tim's)
actions have discouraged other people who potentially could contribute
to Axiom Gold in parallel with Tim. I pointed out that he has not
convinced anyone else to "play by your rules" and he has not
compromised enough to allow them to change their own approach to be
compatible with his. So, the consequence is that Tim is still the only
one doing it. I easily be wrong about other people's motivations here,
but I do not think that this is a "lie".

In fact I doubt that anyone besides Tim feels confident enough to do
update trunk. The manual process that Tim has described for how he
does it is very unlike the process used by anyone else that I know.

About the Windows version Tim said that it seems to him that I am the
primary bottleneck since I build it, I run it and I package it, but I
have not posted any changes. But I have never made any significant
changes. Those were all done by Mike Thomas. In any case these were
made obsolete when Gaby generalized the build system to autoconf so
that it could properly detect the differences between the linux and
windows/MSYS build environments. Most recently I have submitted a few
small changes and tested other changes proposed by Waldek so that
wh-sandbox can also be built on Windows.

> >> Bill Page wrote:
> >> (See for example recent revisions submitted by Gaby which he asked
> >> to revert pending something similar to be done by Tim.)
>

I think Tim's reply to this is very important.

He said that he had planned to work with the change that Gaby had
submitted and the
fact that Gaby later withdrew it was *not* based on his request.
(Check the mailing list). He said that I should get your facts
straight when you are making disparaging remarks about him in public.

I am very sorry about this. I do hereby state publicly that I was
wrong about that. I also get the impression that there were more
people than me who may have gotten the wrong impression about that
interchange so I am glad that Tim has set the record straight.

> > Martin Ruber wrote:
> >> I have the feeling that "trunk" and "branches" is somewhat unfitting
> >> for the Axiom project. Currently, wh-sandbox seems most useable to me.
>
> Bill Page wrote:
> > Although no one has named it as such, I think effectively we have the
> > situation of a "fork" in the Axiom sources.

Tim pointed out to me that he has previously written to the email list
about this. He says that when one joins an open source project and
wants to "contribute" then it it is your responsibility to make sure
that your work gets merged into the main line (first Method above).
But no one has done this. And we now see 3 different things being
called "axiom"... Gold, build-Improvements and wh-sandbox. He says
this is a "fork" because there is no acknowledgment that this work
should go back into the main line.

I am afraid that Tim might be right about this, although I do think
there has been *some* acknowledgment that these changes *should* go
back into the main line.

>From his email it is clear that Tim is concerned the work of a many
developers is being simply being "taken away". But from my point of
view even if Axiom was to fork (I don't think anyone is actually
claiming that is has yet) then I think that it is hard to claim that
anyone has "walked off" with anything since everything remains
completely public. One should not accuse anyone of doing anything
illegal or unethical because this sort of thing happens often in open
source projects. Still, I am *not* saying that this would be a good
thing.  I think there is still time and resources that can be devoted
to keeping Axiom together as a single open source project. And I am
*very happy* that we have so much progress in the last year in spite
of all of this uncertainty and confusion.

Regards,
Bill Page.


On 6/23/07, Bill Page wrote:
> > Ralf Hemmecke writes:
> >
> > > Bill Page wrote:
> > > > I guess it's time I planned on creating an 'axiom-0.2' binary install file...
> > >
> > > I am a bit confused about the version number. NAG released 2.3. Didn't we
> > > once say that the current gold version is Axiom 3.0? What versioning
> > > scheme does OpenAxiom now actually have? Does somebody know?
> > > Where is this written down?
> >
>
> Yes, I think this was tentatively agreed upon and it appears in at
> least one "released" version of open source Axiom (maybe the first?),
> but it seems that this was promptly forgotten or re-defined by Tim as
> he issued subsequent releases. Since defining new releases has so far
> only been the job of one person - Tim - then I guess it remains up to
> him until/if someone else wants to take on the job.
>
> On 23 Jun 2007 09:16:23 +0200, Martin Rubey wrote:
> > Since Axiom is and very likely will be for a long time rapidly evolving, I suggest
> > to use yymm versioning.  I was hoping that trunk would become usable (i.e.,
> > very close to wh-sandbox) soon, but that doesn't seem to be happening.
> >
>
> It seems the contrary to stated intentions, the update of the Gold and
> Silver versions of Axiom effectively remains under the control of only
> one person - Tim. So again as I see it, Tim remains the primary
> bottleneck for getting these changes done. Perhaps this is not his
> intention however I think his approach of using a separate repository
> (based on git) and insisting on doing all updates via manual patches,
> effectively discourages other developers from contributing directly to
> the Gold or Silver versions. (See for example recent revisions
> submitted by Gaby which he was asked to revert pending something
> similar to be done by Tim.)  I do not see much incentive contribute to
> these older "official" versions of Axiom versus continuing changes to
> the build-improvements and wh-sandbox branches even though they remain
> essentially only "experimental".
>
> > Gold is currently completely uninteresting for me and my math colleagues: no
> > working HyperDoc, many important algebra fixes are missing, etc., etc.
> >
>
> I agree completely. Gold does not even build on Windows.
>
> > I have the feeling that "trunk" and "branches" is somewhat unfitting for the
> > Axiom project.  Currently, wh-sandbox seems most useable to me.
> >
>
> Although no one has named it as such, I think effectively we have the
> situation of a "fork" in the Axiom sources.
>
> > (Waldek: the only remaining thing on my wishlist is to have out of the box
> > aldor support)
> >
>
> Does this still have to wait until we have Aldor as open source?

\start
Date: Sun, 24 Jun 2007 22:19:56 -0500
From: Matt Kaufmann
To: Camm Maguire
Subject: Re: 2.7.0 nqthm compile times
Cc: Robert Boyer

Hi, Camm --

Here is some feedback with respect to the use of ACL2 on top of GCL,
as I see it.

>>    A final question remains of
>>    whether or not to actually use ftype declaims if provided.

As you know, in ACL2 we do our own auto-proclaiming of function types.
Just to be safe, I think it would be good if there were a way to turn
off the auto-proclamation capability, as a way to work around any
problems we might encounter, using our own proclaiming instead.  That
said, I can imagine you do a signficantly better job than we do, and
I'm looking forward to using this new GCL feature!

I imagine that we might avoid 'si::do-recompile entirely with ACL2.
Here are some (potentially confused) thoughts:

Regarding leaving things in a safe state: For many years we have told
ACL2 users that they redefine functions at their own peril (and, they
have to set a flag even to be able to do any redefinition).  So in a
sense, that justifies leaving things in an unsafe state when there is
redefinition.  But I think that for ACL2, it would be a nice default
to leave things in a safe state, even if this means expensive
recompilation (presumably by leaving si::*disable-recompile* at nil,
if I understand correctly).  As for with-compilation-unit, I think
that the important thing is that it leaves things in a safe state
provided there is no redefinition.

Thanks --
-- Matt
   Sender: camm@intech19.enhanced.com
   cc: list, maxima@math.utexas.edu,
	   Matt Kaufmann, gcl-devel@gnu.org
   From: Camm Maguire
   Date: 22 Jun 2007 17:41:25 -0400
   X-SpamAssassin-Status: No, hits=-2.3 required=5.0
   X-UTCS-Spam-Status: No, hits=-315 required0

   Greetings!

   [ cc'ed to the maxima and axiom lists, as I would greatly appreciate
   any user feedback on what they would like (that is practical) in the
   forthcoming gcl release.  If this is unwelcome traffic, please let me
   know.]

   Robert Boyer writes:

   > Fantastic.  Thanks so much!
   > 

   The above is most appreciated, but I was hoping for a bit more of an
   opinion as to where GCL should be heading in this direction, to wit:

   Code calling compiled functions of known signature can be rendered
   incorrect if the callee is subsequently compiled to produce a
   different signature:

   ============================================================================   COMPILER>(defun foo (x y z) (list x y z))

   FOO

   COMPILER>(compile 'foo)

   ;; Compiling /tmp/gazonk_13883_1.lsp.
   ;; End of Pass 1.  
   ;; End of Pass 2.  
   ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
   ;; Finished compiling /tmp/gazonk_13883_1.o.
   ;; Loading /tmp/gazonk_13883_1.o
    ;; start address -T 0xaa2f80 ;; Finished loading /tmp/gazonk_13883_1.o
   #<compiled-function FOO>
   NIL
   NIL

   COMPILER>(defun bar (x y z zz) (remove zz (foo x y z)))

   BAR

   COMPILER>(compile 'bar)

   ;; Compiling /tmp/gazonk_13883_1.lsp.
   ;; End of Pass 1.  
   ;; End of Pass 2.  
   ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
   ;; Finished compiling /tmp/gazonk_13883_1.o.
   ;; Loading /tmp/gazonk_13883_1.o
   ;; start address -T 0x87b2b0 ;; Finished loading /tmp/gazonk_13883_1.o
   #<compiled-function BAR>
   NIL
   NIL

   COMPILER>(bar 1 2 3 1)

   (2 3)

   COMPILER>(setq si::*disable-recompile* t)

   T

   COMPILER>(defun foo (x y z) (coerce (list x y z) 'vector))

   FOO

   COMPILER>(compile 'foo)

   ;; Compiling /tmp/gazonk_13883_1.lsp.
   ; (DEFUN FOO ...) is being compiled.
   ;; Warning: ret type mismatch in auto-proclamation (CONS T
						       (CONS T
							(CONS T NULL)))(NIL) -> *

   ;; End of Pass 1.  
   ;; End of Pass 2.  
   ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
   ;; Finished compiling /tmp/gazonk_13883_1.o.
   ;; Loading /tmp/gazonk_13883_1.o
    ;; start address -T 0x87b540 ;; Finished loading /tmp/gazonk_13883_1.o
   #<compiled-function FOO>
   NIL
   NIL

   COMPILER>(bar 1 2 3 1)
   Segmentation violation: c stack ok:signalling error
   Error: ERROR "Caught fatal error [memory may be damaged]: Segmentation violation."
   Fast links are on: do (si::use-fast-links nil) for debugging
   Signalled by BAR.
   ERROR "Caught fatal error [memory may be damaged]: Segmentation violation."

   Broken at BAR.  Type :H for Help.
   COMPILER>>:q

   Top level.
   COMPILER>(setq si::*disable-recompile* nil)

   NIL

   COMPILER>(si::do-recompile)
   Pass1 signature discovery on 1 functions ...
   Compiling and loading new source in #<output stream "/tmp/gazonk_13883_jvaAQ9.lsp">
   ;; Compiling /tmp/gazonk_13883_jvaAQ9.lsp.
   ;; End of Pass 1.  
   ;; End of Pass 2.  
   ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
   ;; Finished compiling /tmp/gazonk_13883_jvaAQ9.o.
   ;; Loading /tmp/gazonk_13883_jvaAQ9.o
    ;; start address -T 0x87ff40 ;; Finished loading /tmp/gazonk_13883_jvaAQ9.o
   done
   NIL

   COMPILER>(bar 1 2 3 1)

   #(2 3)

   COMPILER>(defun foo (x y z) (list x y z))

   FOO

   COMPILER>(compile 'foo)

   ;; Compiling /tmp/gazonk_13883_1.lsp.
   ;; End of Pass 1.  
   ;; End of Pass 2.  
   ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
   ;; Finished compiling /tmp/gazonk_13883_1.o.
   ;; Loading /tmp/gazonk_13883_1.o
   Pass1 signature discovery on 1 functions ...
   Compiling and loading new source in #<output stream "/tmp/gazonk_13883_XL6AKh.lsp">
   ;; Compiling /tmp/gazonk_13883_XL6AKh.lsp.
   ;; End of Pass 1.  
   ;; End of Pass 2.  
   ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
   ;; Finished compiling /tmp/gazonk_13883_XL6AKh.o.
   ;; Loading /tmp/gazonk_13883_XL6AKh.o
    ;; start address -T 0x880a20 ;; Finished loading /tmp/gazonk_13883_XL6AKh.o
    ;; start address -T 0x887320 ;; Finished loading /tmp/gazonk_13883_1.o
   #<compiled-function FOO>
   NIL
   NIL

   COMPILER>(bar 1 2 3 1)

   (2 3)

   COMPILER>
   ============================================================================
   The existing philosophy is therefore not to let the load of the new
   foo complete without executing the recompile.  This has the
   disadvantage of compiling functions possibly multiple times, and
   fragmenting the contiguous memory space.

   'si::do-recompile has the following behavior at the moment:

	   a) if called without an argument, as is done in every loaded
	   .o file, will 1) do a fast pass1-only signature discovery run
	   on the out of date functions, 2) will write the necessary
	   functions to a temporary file, compile and then load it.  Each
	   function passes through gcc once, but possibly multiple times
	   only through pass1.  System is left in a safe state, but code
	   can be recompiled multiple times on subsequent multiple loads.

	   b) if called with a non-nil argument, will do the above, but
	   write the new source to the filespec provided in the argument,
	   which is compiled but not loaded.  The system is left in an
	   unsafe state, and implicitly leaves to the user the job of
	   integrating the freshly compiled source.

	   c) if called with a nil argument, will do the pass1 signature
	   discovery, and collect a list of original source files
	   containing the recompiled functions.  These files are then
	   probed for and recompiled if found.  The system is left in an
	   unsafe state, and implicitly leaves to the user the job of
	   integrating the freshly recompiled code.  (These files cannot
	   be automatically reloaded, as they may contain other top-level
	   forms which are only intended to be executed once.  Given
	   this, the load was also skipped for the non-nil argument case
	   in b) by way of symmetry.  A third recompile for automatic
	   loading purposes (as in a)) is ommitted to save compile time.)

   'with-compilation-unit is as follows:

   (defmacro with-compilation-unit (opt &rest body)   
     (declare (optimize (safety 1)))
     (declare (ignore opt)) 
     `(progn
	(let ((*disable-recompile* t))
	  ,@body)
	(do-recompile nil)))

   So at present it leaves the system in an unsafe state to avoid a
   second pass through gcc and load for every recompiled function.  If
   there are only compile-files and no loads in the unit, no signature
   conflict is detected and no recompilation is done.  Only loaded
   functions within the unit trigger recompilation at unit end.  This is
   somewhat counter to what one might expect from the ansi-doc
   definition, given its emphasis on compile-file item deferral.

   Here are some alternatives:

   1) do another pass through gcc followed by a load when passing the nil
      argument (or a just a load when passing the non-nil argument) to
      leave the system in a safe state at the expense of more compile
      time.

   2) Never automatically recompile at load, leaving the safety < 3 user
      to the whims of random segfaults, but provide a safety 3 which
      eliminates all branch elimination depending on known return
      signatures.

   3) Defer auto recompiles to a re-entry of top-level, minimizing the
      window of unsafe code execution.

   ...

   Thoughts most appreciated.  Please help me make this serve the needs
   of the community.  For those new to this thread, this mechanism
   obviates the need for ftype declaims.  A final question remains of
   whether or not to actually use ftype declaims if provided.

\start
Date: 25 Jun 2007 01:51:13 -0400
From: Camm Maguire
To: Waldek Hebisch
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

Greetings!  There is something wrong with sgc, I think minor.  One can
trigger and help debug if desired using the simple command (typep 0
'standard-object) in a fresh compiler::link'ed image interspersed with
calls to (si::gbc t) This is the lisp in build/i686.../bin/

I'll try to fix this soon.  In the meantime, the build appears to
progress with (si:sgc-on nil).  May I also suggest (setq
si::*disable-recompile* t) in the initial image for the time being.

Take care,

Waldek Hebisch writes:

> > Greetings, and thanks so much for the report!
> > 
> > Will attend to the installation issues ASAP.
> > 
> > The other is of course more serious.  Since you have it all setup,
> > would you mind running with (si::use-fast-links nil)(trace (error
> > :entry (break))) and then do a :bt at the lisp prompt?  For really low
> > level, build gcl with --enable-debug and catch the segfault under gdb.
> > If you do not have time, I understand.  How do I get the source you
> > are working on?
> > 
> 
> The source is at (the revision probably does not matter much, but just
> in case I add '-r 636' option):
> 
> svn checkout https://axiom.svn.sourceforge.net/svnroot/axiom/branches/wh-sandbox -r 636 wh-sandbox
> 
> I have tried to enable debugging.  However, the image seem to be badly
> damaged, because alredy the second command give me error.  To give
> more context: we build one image using 'compiler:link'.  This image
> is used to build the second one using 'save-system'.  The second
> image gives me:
> 
> $ ./local-lisp
> GCL (GNU Common Lisp)  2.7.0 ANSI    Jun 23 2007 01:35:47
> Source License: LGPL(gcl,gmp,pargcl), GPL(unexec,bfd,xgcl)
> Binary License:  GPL due to GPL'ed components: (READLINE BFD UNEXEC)
> Modifications of this banner must retain notice of a compatible license
> Dedicated to the memory of W. Schelter
> 
> Use (help) to get some basic information on how to use GCL.
> 
> Temporary directory for compiler files set to /tmp/
> 
> >(si::use-fast-links nil)
> 
> NIL
> 
> >(trace (error :entry (break)))
> Segmentation violation: c stack ok:signalling error
> Error:
> Signalled by PCL::FREE-CACHE.
> Condition in PCL::FREE-CACHE [or a callee]: INTERNAL-SIMPLE-ERROR: Segmentation
> violation: c stack ok:signalling errorError in error:
> UNIVERSAL-ERROR-HANDLER ERROR (FORMAT-CONTROL
>                                   Caught fatal error [memory may be damaged]: ~a                                  FORMAT-ARGUMENTS
>                                   (Segmentation violation.)) (FREE-CACHE
>                                                                )
> 
> Backtrace: system:universal-error-handler > system::break-level > format > pcl::print-std-instance > print-object > pcl::caching-miss > pcl::invoke-emf > simple-condition-format-control > pcl::accessor-miss > pcl::update-dfun > PCL::FREE-CACHE
> 
> Newly traced functions:  NIL
> >
> 
> I will try '--enable-debug'...  

\start
Date: 25 Jun 2007 08:56:36 +0200
From: Martin Rubey
To: Francois Maltey
Subject: Re: A multi-line mode for Emacs.

Francois Maltey writes:

> Dear Martin,
> 
> > > > [[M-x axiom]] should switch to the buffer [[*axiom*]], 
> > > > if it exists and if it is an "axiom buffer".  
> 
> > > > If there is no such buffer, 
> > > > it should create a new buffer and a new axiom process.
> > > 
> > > The axiom command in axiom.el file works so.
> > 
> > Not for me.
> 
> What do you get when you type ?
> 
>    [[M-x axiom]]         the first time.
>    [[C-x b return]]      to switch to an other buffer
>    [[M-x axiom]]         a second time

Sorry, I was wrong here, this one works.

> Could you send me your axiom.el please ?

I just uploaded my version to MathAction, the only modification is a correction
to axiom-reset.

> Do you have any line about axiom.el in your .emacs ?
> In my .emacs I have only : 
>   
> (load "~/Configuration/emacs/axiom.el")

same thing.

> > > Do you want to run several axiom in several buffers ?
> 
> > Yes.  I'd like behaviour as with shell mode. 

> All right, I test... 

> But it seem today impossible to do this with axiom because variables in
> axiom.el are global for all axiom-process, and it's necessary to create local
> variable for each axiom buffer.

I asked on gnu.emacs.help recently:

http://groups.google.at/group/gnu.emacs.help/browse_thread/thread/7ac4361f78c0e5a3/fdf0e3cebe263990?lnk=st&q=axiom+mode&rnum=1&hl=de#fdf0e3cebe263990

> > M-x axiom switches to *axiom* if present and 
> > if it is a buffer in axiom-mode, otherwise it creates such a buffer.
> 
> Perhaps [[M-x axiom]] will be right if you delete this line from 
> your .emacs...
> 
> > (add-hook 'axiom-mode-hook (lambda () (rename-uniquely)))

Don't worry, that's the line I would *like* to have in my .emacs.  I know that
it won't work at the moment.

> I only look for an axiom-run mode, not for an axiom-input mode
> with font lock and so...

So, what is axiom-run mode supposed to do?

> 1> Really, I think the best thing would be a mode axiom-input.el, This would
> 1> also allow us to do some syntax highlighting and possibly even some
> 1> indentation features for input files.
> 
> 2> which allows sending the region to axiom, via saving it into a temporary
> 2> file and )read ing it in the axiom buffer.
> 
> 3> Another good feature would be tab completion, by the way.  This works if
> 3> you start axiom in a terminal, so it should be possible...

[...] 

> The second one is very easy.

Great.  So please create a mode that does this -- and I suggest that you *name*
it axiom-input.

I.e., it should be a mode separate from axiom-mode -- and in a different file
-- that provides two commands:

axiom-send-line

axiom-send-region

Both check whether there is an *axiom* buffer.  If not, error, or perhaps
create one.

Otherwise:

* axiom-send-line copies the current line into the *axiom* buffer, and calls
  axiom-eval.

* axiom-send-region saves the current region into a temporary file
  /tmp/tmp.input, inserts )read /tmp/tmp.input into the *axiom* buffer and
  calls axiom-eval.

> About axiom.el code :
> 
> > But with clean up I also meant: clean up, i.e., make it tidy.  Currently,
> > the code is a mess, at least for me.
> 
> I began to play with this very small file.

Do you understand shell.el?

\start
Date: 25 Jun 2007 09:06:05 +0200
From: Martin Rubey
To: Tim Daly, Waldek Hebisch, Gabriel Dos Reis
Subject: Re: Axiom version numbering

Tim Daly writes:

> The Axiom version is printed as part of the banner when you start:
> 
>                  AXIOM Computer Algebra System
>                    Version: Axiom (May 2007)
>           Timestamp: Friday May 18, 2007 at 00:44:15
> 
> 
> This gives information about what version of source was used to build the
> system (May 2007). It gives information about what day and time the system
> was built (nearly 1AM on May 18th).  And the first line of CHANGELOG gives an
> exact version in yyyymmdd format. CHANGELOG is a stack. Thus:
> 
> 20070617 tpd src/interp/inpter-proclaims remove unused arg from $FCOPY

Only, the CHANGELOG is not installed.  Since I often say svn up, to see what
happened recently, but sometimes decide not to build a new axiom, I do not know
anymore what exact version of axiom I am using.

People installing a binary of axiom from MathAction or via debian  have even
less possibility to tell us what version they are using.

So, maybe we could use

YY.MM.branch.revision-number

For example,

                     Version: 7.06.wh-sandbox.607

or perhaps

                     Version: June 2007, wh-sandbox 607

instead of

>                    Version: Axiom (May 2007)

(I don't see a point in repeating "Axiom")

Curiously, my wh-sandbox gives

Version: Axiom build-improvements branch 2006-11-26

which is nonsense.

\start
Date: Mon, 25 Jun 2007 03:41:49 -0500
From: Tim Daly
To: Martin Rubey
Subject: Axiom version numbering

> Only, the CHANGELOG is not installed.

Eh? <http://axiom.svn.sourceforge.net/viewvc/axiom/trunk/axiom>
shows CHANGELOG in revision 631 of the trunk. Why is CHANGELOG
not installed? Can you SVN get the file?

> People installing a binary of axiom from Mathaction or via debian
> have even less possibility to tell us what version they are using.

Why? Are these versions suppressing the banner? Is CHANGELOG missing?



Question: When was this image built? Has it been rebuilt?

When Axiom builds it creates a file called lastBuildDate in the home
directory of the Axiom build. The date and time stamp from this file
identifies the exact date and time of the build. The date and time
stamp is 
 (a) set as the value of the *yearweek* variable in the image. Try:
       )lisp *yearweek*
       Value = "Friday May 18, 2007 at 00:44:15 "
     Thus you can write programs which depend in the date and time
     of the current build image.

 (b) The *yearweek* variable is printed in the banner.
     Thus you know when or if the image has been rebuilt.

In a binary distribution you can tell when the image was built and
you can tell if the user rebuilt it after receiving the binary image.



Question: What "Axiom" sources were used to build the image?

Distributions are only updated on a reasonably infrequent basis.  Thus
the finest grain of change need only identify the month and year of
the sources.  (Scratchpad was "released" weekly, hence the name
"yearweek")

When you get a distribution the month and year of the source tree
is encoded into the top level Makefile as the first line:
  head -1 Makefile
  VERSION="Axiom (May 2007)"
This information is also printed in the banner.

For exact details of the changes the top line of CHANGELOG suffices:
  head -1 CHANGELOG
  20070617 tpd src/interp/inpter-proclaims remove unused arg from $FCOPY
since the CHANGELOG is updated for every change since August 30, 2003.



Question: Which "Axiom Distribution" is this?

In rereading your post I think I understand the confusion. We are not
talking about the same thing when we say "Axiom". The above information
suffices to identify the exact version of an "Axiom distribution". By the
term "Axiom Distribution" I mean one intended for the outside world
which was built from either Arch, CVS@Sourceforge, or CVS@Savannah.
"Distributions" intended for world use should be buit from these places.


By "Axiom distribution" you appear to mean something that came from
SVN or git or your local, non-isomorphic version. I fully agree that
these do not have "version numbers". But the versions are easy to find.

If you feel the need to identify specific SVN sources the SVN revision 
number seems appropriate. 
   svn log --revision COMMITTED

If you use git the whole source tree is exactly identified by an MD5 hash
which is the name of the current HEAD, e.g.
  cat .git/refs/heads/master
  7385d9f77d25d5ca71d76d89b21118d9e3d73fb5

If you want the ARCH version it is given by the directory name:
  Axiom--main--1--patch-50

If you have a local, non-isomorphic version I don't know.



Question: When posting a bug which "version" should I use?

That depends on where you root your sources. If you're using Gold
use the banner. If you're using Silver use the SVN revision number.
If you're using wh-sandbox use the SVN revision number. If you're
using Arch use the --patch number. If you're using git use the MD5 ref.
Since SVN and git are the same either the SVN revison or git ref is ok.



Question: When posting a diff which "version" should I use?

Posted diffs depend on what you intend to patch. 

Changes that are intended to go into the "Axiom distribution" should
be posted as a diff against either the Arch version (currently
--patch-50) or the SVN trunk (currently 637). Simply use one of the
methods below to identify your "version".

Posted diffs against branches are completely up to the branch maintainers.




Question: How should we identify "versions"?

For an "Axiom Distribution" use the banner.

For development, any way you'd like. You point out that build-improvements
prints the banner:
  Version: Axiom build-improvements branch 2006-11-26
but BI uses SVN. I'm not an SVN expert but I believe you can use the
date/time stamp against SVN. Probably something like:
  svn log --revision (2006-11-26)



As for the "version number" controvery my advice is to use any name
scheme you wish. 

I'll add this as a FAQ.

\start
Date: Mon, 25 Jun 2007 11:40:10 +0200
From: Ralf Hemmecke
To: Tim Daly
Subject: Re: Axiom version numbering

On 06/25/2007 10:41 AM, Tim Daly wrote:
>> Only, the CHANGELOG is not installed.

> Eh? <http://axiom.svn.sourceforge.net/viewvc/axiom/trunk/axiom>
> shows CHANGELOG in revision 631 of the trunk. Why is CHANGELOG
> not installed? Can you SVN get the file?

Would you like the end user (who does not want to bother with 
compilation) require to issue an svn/git/darc/cvs (or whatever) command?
No. It should be easy to get an exact reference to the version someone 
is using by typing

   axiom --version

Whatever comes out from that should be in one-to-one correspondence to 
the branch+revision number (or if you like git so much the md5sum that 
identifies the version).

As Gaby pointed out, a x.y.z form is advantageous for package managers 
at Debian/Red Hat etc. But that would probably only apply to Gold. We 
have many more versions around an they should identify themselves 
uniquely. The build timestamp is not necessarily referring to the 
version, since I can roll back in the history and build a version from 
last year.

> Why? Are these versions suppressing the banner? Is CHANGELOG missing?

Banner is OK, but axiom --version should also work (without actually 
starting AXIOMsys).

> Question: When was this image built? Has it been rebuilt?
> 
> When Axiom builds it creates a file called lastBuildDate in the home
> directory of the Axiom build. The date and time stamp from this file
> identifies the exact date and time of the build. The date and time
> stamp is 
>  (a) set as the value of the *yearweek* variable in the image. Try:
>        )lisp *yearweek*
>        Value = "Friday May 18, 2007 at 00:44:15 "
>      Thus you can write programs which depend in the date and time
>      of the current build image.
> 
>  (b) The *yearweek* variable is printed in the banner.
>      Thus you know when or if the image has been rebuilt.
> 
> In a binary distribution you can tell when the image was built and
> you can tell if the user rebuilt it after receiving the binary image.

It would not hurt if we have a x.y.z scheme and add the date on the 
banner when this Gold version was released. (We never release Silver to 
an ordinary user. Such versions (and the experimental branches) have to 
be fetched from the repositories.

> Question: What "Axiom" sources were used to build the image?
> 
> Distributions are only updated on a reasonably infrequent basis.  Thus
> the finest grain of change need only identify the month and year of
> the sources.  (Scratchpad was "released" weekly, hence the name
> "yearweek")

Note that it would be perfectly possible that Debian people do little 
tweaks that are not in any of our repositories. You would want to see 
whether something like that happened so that you don't chase a bug that 
you will be unable to find since it is in the code introduced by 
somebody else.

> When you get a distribution the month and year of the source tree
> is encoded into the top level Makefile as the first line:
>   head -1 Makefile
>   VERSION="Axiom (May 2007)"
> This information is also printed in the banner.

Tim, I use Linux, but why should I bother to install the sources, if I 
don't want to look at them and if I am happy what Debian produced for me?

   head -1 Makefile

is totally helpless, since I would not have the sources. Some users of 
Axiom would be happy with a binary version of Axiom, so the binary 
should identify the exact origin.

> Question: Which "Axiom Distribution" is this?
> 
> In rereading your post I think I understand the confusion. We are not
> talking about the same thing when we say "Axiom". The above information
> suffices to identify the exact version of an "Axiom distribution". By the
> term "Axiom Distribution" I mean one intended for the outside world
> which was built from either Arch, CVS@Sourceforge, or CVS@Savannah.
> "Distributions" intended for world use should be buit from these places.

Of course. Axiom Distribution = Gold. But for development we also need a 
binary that identifies itself. That is just to make life easier. See 
Martin suffering...

\start
Date: Mon, 25 Jun 2007 05:05:33 -0500 (CDT)
From: Gabriel Dos Reis
To: Bill Page
Subject: Re: Version numbers
Cc: Waldek Hebisch

On Mon, 25 Jun 2007, Bill Page wrote:

[...]

| To other people reading this thread, if this disagreement is of no
| interest to you and seems off topic, then I apologize for wasting your
| inbox space and suggest that you hit the delete key now. But if you
| have enough patience, please do continue reading. 

I do not believe your posting was a waste -- although a patch to
Axiom with equialvent size would have been nice :-) :-)

More seriously, it looks like several people are "suffering" in silence.
Since, obviously, I'm part of the concerns I believe I must straight
out some points and voice some of my own concerns.

This email and the situation reminds me of the pre-EGCS stage of gcc, before
the fork was done: too much resources were spent discussing politics, not
actual technical work, and the weight of just one person ruling everything.
In the end, EGCS forked from gcc, got successful, and later reunited with
original gcc under several conditions, the most important being that the
project is collaborative, and technical decisions are made collectively by GCC
developers. 

I do not suggest Axiom to take a fork route -- it is not something I like,
but I cannot recommend people ignore that possibility.  Again, I'm not
suggesting a fork.

| [...] I think open source
| projects are a lot different than traditional computer software
| projects because in many cases *all* of the effort and the resources
| available are *volunteer*. This means among other things that it is
| not possible simply to pay someone a salary as compensation for
| "putting up with" the difficulties of working together with other
| people. Instead we must be prepared to devote at least some of our
| time trying to making sure that everyone involved feels like they are
| being treated fairly.

Yes, open source development is very different from what can been seen in some
commercial companies or a long time ago.

[...]

| In his email Tim pointed out to me that every decision he has made
| regarding Axiom was with the explicit goal of improving Axiom and that
| he had put both massive amounts of time and an ongoing sizable amount
| of money into building up Axiom, raising the quality, and promoting
| its use. I do in fact realize this is the case and have previously
| pointed out Tim's large personal contributions to other people both
| privately and on these email lists.

I acknowledge that. Furthermore, I believe that can be said of any
Axiom contributor on this list I know of, although the resources
vary in nature.

Personally, I've risked more resources into Axiom than advisable since I've
started.  It remains unclear to me at this moment whether I should continue
or just go on with my own project.  Part of this is due to resources being
spent talking more about politics than technical work.  Part of this is due to
unfocused view.  I'm not blaming anyone.

[...]

| I think Ralf and Tim are right and that I should probably call this
| new Axiom for Windows installer by a name something like:
| 
|  axiom-windows-wh-rev613.exe

I agree.

| > > Martin Rubey wrote:
| > > > I was hoping that trunk would be usable (i.e., very close to wh-sandbox)
| > > > soon, ...
| 
| Tim points out that in fact he has committed to number of changes to
| Silver that originated from build-improvements (labeled "gdr" in the
| Silver change log) and wh-sandbox (labeled "wxh" in the Silver change
| log). He admits that not everything has been merged because: 1) he has
| had to read the code from build-improvements and wh-sandbox to create
| the diff-Naur from Gold himself because no one else made any effort to
| merge changes back to gold. Further, that some changes were not
| included because either: 2) they were unstable or 3)  because he did
| not understand them.

Yes, Tim had hand cherry picked changes to both build-improvements and
wh-sandbox.  That is both good and painful.  That is good because some
changes found their way into silver, where they are supposed to
eventual end up.  It is painful for some of us because it was carefully done
so that both automated revision trackers and ChangeLog entries are
worked around, avoided.  Therefore it requires more effort to figure out
what is done than if no merge was done in the first place.  I'm not
here to blame.

>From your mail, I've sensed that some people on this list would be
thinking that I want to promote my product and contribute nothing back.  That
would be pure nonsense, because it goes against the *facts*.

Notice that I took responsability in syncing silver with Tim's private 
branches that contained the merges [in preparation of future merge from
build-improvements to silver].  I've attempted to merge some
changes to silver but I backed off when some vocal people complained.
More on this below.

| I think that what Tim says is true but I believe that Martin is
| concerned about higher level functionality like the fixes to Hyperdoc
| and the ability to compile his "guess" package. Personally I find that
| both build-improvements and wh-sandbox are much more stable than Gold
| and that they build on more platforms, so they seem like a natural
| choice for Martin.

That is perfectly sensible to me.  For everybody, except a few tiny
minority, wh-sandbox as it stands is a natural choice.  The reason is simply
because most people will be users and they are interested in high level
functionalities and less bugs.  People concerned with possible competition
between silver and wh-sandbox should be working together with both wh-sandbox
and silver maintainers to move forward.

| I am not sure why Tim does not understand the changes that where made
| in these branches. Most (all?) of the changes made by Gaby and Waldek
| were announced on axiom-developer email list and the detailed patches
| are sent to axiom-commit. I think that if anyone has questions about
| the changes it would be best to ask the authors via the
| axiom-developer list.

All the changes made to the SVN repository can be retrieved or viewed as
patches.  The mails sent to axiom-commit are just informative, and sometimes
they are truncated because of size limit.  However, they do indeed
contain most information.  I would expect that anyone who has looked
at build-improvements who does not understand a specific part would ask
his specific questions that I'd try to address. Just saying "I don't
understand the autoconf change" is not specific enough, sorry.
Although the documentation is not perfect, I've tried to explain what is going
on so that others can make changes.  I know of at least two Axiom
contributors who have changed the Autoconf-based build machinery -- I'm not
claiming that is a proof that it is good enough for all purposes.

| > > Martin Rubey wrote:
| > > > but that doesn't seem to be happening.
| >
| 
| As an explanation of why this is not happening Tim said that we should
| consider the two ways that people generally contribute changes to open
| source projects. The first is to create a branch, make a series of
| modifications, merge those modifications into a local copy, test those
| changes, package up the changes into a changeset, and post those
| diff-Naur changes against the trunk. He says that his is the way it is
| done in linux, gcc, apache and SBCL. For example:
| http://sourceforge.net/mailarchive/message.php?msg_name=75cb50350706181211g1740af8dg155a401
| 
| The second method is to create a fork: take the main body of code and
| make your own competing branch, marketing it with new features. You do
| not make an effort to contribute your code back to the trunk. You
| simply "walk off" with the collective effort and promote your own
| private version.
| 
| I would prefer the first method but as I said in my previous email, I
| am afraid that we are closed to the second method right now.

In fact, I have a different opinion:
  (1) the above dichotomy is overly simplifying.
  (2) I don't believe anyone is taking the second approach, at least, I know
      I'm not taking the second approach.

| Although it is true that they are not *exactly* diff-Naur patches, all
| of the posts to axiom-commit are in fact diffs against the original
| trunk of SVN at SourceForge which corresponded to patch-50 which is
| what "Silver" used to be. I there must be at least 500 of these emails
| in the axiom-commit archive. It seems to me  that both Gaby and Waldek
| originally believed that Tim (or anyone else motivated to update Gold
| and Silver would use these diffs.

I strongly believe that the requirement of manually applying someone else
patch which is already present in the repository is curious and
backward.  The task can be automated with far less risk of errors
by using the tools we already have:  I've merges trunk to build-improvements,
build-improvements to gdr-sandbox, gdr-sandbox to build-improvements,
build-improvements to silver, daly to silver with one single command.
Furthermore, I have the assistance of the source version system to undo any
changes at anytime without errors.  People who take the merge from the active
branches to trunk/silver seriously should give serious thought to
automated merges.  That said, however, there must be a requirement
of sending patched to the list for consideration.
As a matter of fact, I did propose such policy a year and half ago.

| Tim explains why there has been no conversion of Gold to using
| autoconf by pointing out that there is no diff-Naur, there is no
| documentation, there is no effort to promote any changes back to the
| main line of code by anyone else.

If that is Tim's explanation, then that explanation can be safely ignored as a
non-explanation. To my view, it is closer to fantasm than anything else.

On this list, I've stated several times that when build-improvements
is ready for merge to silver, I'll announce it and request review.
It came as a surprise to me when I realized that Tim had privately
hand cherry picked changes from both build-improvements and wh-sandbox.
While, the documentation is not perfect, it is untrue that there is
no documentation.  And I would expect that if Tim does not understand a
specific part of the changes I made, he would ask a specific question.

In fact, when I started working on the Axiom source code, I was asking
many questions about parts of the code not documented that I did not
understand.  I stopped because I had the sense that most of the answers I got
were not useful to me.  I don't think we have reached that point with
build-improvements yet :-)

[...]

| Since I have been promoting the autoconf style of build process for
| Axiom to Tim for several years, Tim asked me why I did not do this
| work myself. I replied that I was very glad when someone came along
| (Gaby) who was motivated and obviously knew enough about how to do it
| - much more than me! The situation is that really I do not want to be
| doing this kind of development. Since I am not very good at it, it
| wastes my time and there is never enough time. I would very much
| prefer to be an Axiom user/developer who discusses mathematics and
| writes new algebra code for example in category theory and in
| applications to physics. But here I have been stuck for nearly 5 years
| now - just getting to the point where this is becoming possible.


I very much disagree with that view. I too would very much perfer to be
an Axiom user/developer who discusses mathematics and write algebra code for
example in category theory and applications to various fields of 
computational science.  However, I also realize that I cannot just wish
someone else come and does the dirty job for me so that I can theorize without 
getting my hands dirt.  I'm not a developer.  I'm a mathematician.
I earned my degree in Differential Geometry.  I'm highly interested
in computational mathematics.  Since *I need tools* and they are lacking, I
have to build them.  That is why I have my hands dirt with C++, GCC, Axiom,
etc. 

[...]

| > > Bill Page wrote:
| > > > It seems the contrary to stated intentions, the update of the Gold and
| > > > Silver versions of Axiom effectively remains under the control of only
| > > > one person -- Tim.
| >
| 
| Tim says that this is a "lie" and referred me to his email:
| 
| http://lists.gnu.org/archive/html/axiom-developer/2006-11/msg00282.html
| 
| He says that history shows that no one stepped up to build a new
| version of Axiom and no one committed any changes to Axiom over the
| period of 3 months from November to January even though everyone
| (inculding me) had write access. During that time Gaby and Waldek
| continued working on their own branches.

If that is the explanation, then I believe Tim is oversimplifying
the actual facts and that *helps nobody*.

[...]

| > > Bill Page wrote:
| > > > Tim remains the primary bottleneck for getting these changes done.
| > ...
| > > > Perhaps this is not his intention however I think his approach of using
| > > > a separate repostory (based on git) and insisting on doing all updates
| > > > via manual patches, effectively discourages other developers from
| > > > contributing directly to Gold or Silver versions.
| >
| 
| What Tim wrote in reply seemed to indicate that he was angry that I
| should make this sort of claim. He said that it was equivalent to
| claiming that he personally should decode how autoconf works,  how the
| new boot is supposed to work, and how the ansi version is supposed to
| be merged. Tim repeated that no one besides him makes any effort to
| ensure that the main trunk is updated.

That is untrue, and I'm disappointed that Tim is reported to make that claim. 

My personal view on this matter is that many people here don't seem to
appreciate the notion of approximation and incremental improvements.  I seem
to be living in the imperfect world of practical needs and I have the sense of
talking with people who lives in perfect world.  I have ideals but I also 
know that I can only approximate them, and incrementally tend to that ideal
limits.

The build-improvements and wh-sandbox are the results of approximations and
incremental improvements.  People who would like to discuss them are invited
to reflect on the notion of approximation and incremental improvements.

| So I explained that what I meant was that I thought his (Tim's)
| actions have discouraged other people who potentially could contribute
| to Axiom Gold in parallel with Tim. I pointed out that he has not
| convinced anyone else to "play by your rules" and he has not
| compromised enough to allow them to change their own approach to be
| compatible with his. So, the consequence is that Tim is still the only
| one doing it. I easily be wrong about other people's motivations here,
| but I do not think that this is a "lie".

I've said it many times and I'll repeat it again: having many "main"
repositories is a good recipe for confusion.  That does not mean we should not
have mirrors -- we just need one main repository.

| In fact I doubt that anyone besides Tim feels confident enough to do
| update trunk. The manual process that Tim has described for how he
| does it is very unlike the process used by anyone else that I know.

In fact, I can update trunk (and I have done so many times), but:
  (1) between the period where Tim semi-retired, I deliberately did
      nothing to silver/trunk because last messages from Tim on the matter
      was clearly based on mis-communication and I would surely not going
      to do anything that would be construed as evidence to the
      misinterpretation.  And I was glad it came back.

  (2) I've recently updated trunk so that I can continue work on my
      (windows) machine and contribute code.  But some vocal people
      have complained and I backed out my changes.  I based my decision
      to back off the basis that if people have such strong opinions
      and are so vocal about modifying trunk then they surely have
      the resources to do the work I was trying to do.  

      No, Tim did not ask me to back off, but he did not say "no" either
      when I offered to back off.  He has plans for a giga patch that would
      solve everything so I've rather waited.  

[...]

| > > > Bill Page wrote:
| > > > (See for example recent revisions submitted by Gaby which he asked
| > > > to revert pending something similar to be done by Tim.)
| >
| 
| I think Tim's reply to this is very important.
| 
| He said that he had planned to work with the change that Gaby had
| submitted and the
| fact that Gaby later withdrew it was *not* based on his request.

That is true: Tim never asked me to back off the change I made.
The complain came from more vocal people who did not take any step in 
solving the problem I was attempting to solve.  I guess solving the problem
they thought I erroneously solved would have been against the law.

| (Check the mailing list). He said that I should get your facts
| straight when you are making disparaging remarks about him in public.

Is "you" referring to me (Gaby)?

| I am very sorry about this. I do hereby state publicly that I was
| wrong about that. I also get the impression that there were more
| people than me who may have gotten the wrong impression about that
| interchange so I am glad that Tim has set the record straight.

Again, Tim never asked me to back off.  I first offered the reversion, but got
no answer.  and since some people felt strongly about it, I reverted
to the state the branch was.  I suspended any work on silver until 
the problem I was trying to solved get solved by people with more
resources than me and those people who have strong opinion about how it should
be solved.  It does not mean I'm not going to contribute anything
back to silver.

| > > Martin Ruber wrote:
| > > > I have the feeling that "trunk" and "branches" is somewhat unfitting
| > > > for the Axiom project. Currently, wh-sandbox seems most useable to me.
| >
| > Bill Page wrote:
| > > Although no one has named it as such, I think effectively we have the
| > > situation of a "fork" in the Axiom sources.
| 
| Tim pointed out to me that he has previously written to the email list
| about this. He says that when one joins an open source project and
| wants to "contribute" then it it is your responsibility to make sure
| that your work gets merged into the main line (first Method above).

Obviously that remark is addressed to Waldek and me.  If Tim believes
that none of us is willing to contribute changes back, then I believe Tim is
seriously wrong about us.  I would not ask for a public apology, but I would
like to invite him to refrain from such statements in the future.

| But no one has done this. And we now see 3 different things being
| called "axiom"... Gold, build-Improvements and wh-sandbox. He says
| this is a "fork" because there is no acknowledgment that this work
| should go back into the main line.

That is simply contrary to any facts that can be found about both
build-improvements and wh-sandbox.  I've stated repeatedly 
that I would like build-improvements to eventually get merged to
silver.  Waldek has even outlined components that would be merged
to build-improvements branch, and later up to silver.  Statements
like the above are just plain gratuitous injustified insults to people 
with interest in contributing to the whole Axiom project.  I don't see how
that is a help. :-(

\start
Date: Mon, 25 Jun 2007 05:09:44 -0500 (CDT)
From: Gabriel Dos Reis
To: Martin Rubey
Subject: Re: Axiom version numbering
Cc: Waldek Hebisch

On Mon, 25 Jun 2007, Martin Rubey wrote:

[...]

| > exact version in yyyymmdd format. CHANGELOG is a stack. Thus:
| > 
| > 20070617 tpd src/interp/inpter-proclaims remove unused arg from $FCOPY
| 
| Only, the CHANGELOG is not installed.  Since I often say svn up, to see what
| happened recently, but sometimes decide not to build a new axiom, I do not know
| anymore what exact version of axiom I am using.
| 
| People installing a binary of axiom from MathAction or via debian  have even
| less possibility to tell us what version they are using.

I fully agree.  It does not make sense to me to say that people can 
look at the top of ChangeLog.  What would be your reaction if I said that 
the Axiom sources code should not be documented because its implementation
has a far more precise information about what it actually does?

| So, maybe we could use
| 
| YY.MM.branch.revision-number

That makes sense to me.

\start
Date: Mon, 25 Jun 2007 12:11:14 +0200
From: Ralf Hemmecke
To: Bill Page
Subject: Re: Version numbers
Cc: Gabriel Dos Reis, Waldek Hebisch

>> > Martin Ruber wrote:
>> >> I have the feeling that "trunk" and "branches" is somewhat unfitting
>> >> for the Axiom project. Currently, wh-sandbox seems most useable to me.
>>
>> Bill Page wrote:
>> > Although no one has named it as such, I think effectively we have the
>> > situation of a "fork" in the Axiom sources.
> 
> Tim pointed out to me that he has previously written to the email list
> about this. He says that when one joins an open source project and
> wants to "contribute" then it it is your responsibility to make sure
> that your work gets merged into the main line (first Method above).
> But no one has done this. And we now see 3 different things being
> called "axiom"... Gold, build-Improvements and wh-sandbox. He says
> this is a "fork" because there is no acknowledgment that this work
> should go back into the main line.
> 
> I am afraid that Tim might be right about this, although I do think
> there has been *some* acknowledgment that these changes *should* go
> back into the main line.

I am too lazy now to search the archives, but hasn't Gaby once said that 
he would like to merge BI and trunk? The only problem was that there are 
now some patches that have been made on BI that are also picked up by 
Tim and applied to trunk. (Gaby, please correct me if I am wrong.)
Unfortunately SVN does not track which patches have been applied already 
so a simple

svn merge or svk emerge

will result of a lot of conflicts since some (already applied) patches 
would be unnecessary. Without a record of the svn revision numbers that 
merging is a terribly hard task.

Nevertheless, to go forward, I'd like to ask Tim: Do you allow Gaby to 
merge his autoconf code into trunk even if you don't understand it?

\start
Date: Mon, 25 Jun 2007 05:22:34 -0500 (CDT)
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Re: Version numbers
Cc: Waldek Hebisch

On Mon, 25 Jun 2007, Ralf Hemmecke wrote:

| I am too lazy now to search the archives, but hasn't Gaby once said that he
| would like to merge BI and trunk? The only problem was that there are now some
| patches that have been made on BI that are also picked up by Tim and applied
| to trunk. (Gaby, please correct me if I am wrong.)

Ralf --

  You are correct on all counts.  I've said many times that I would
like to merge build-improvements to silver and that people would have
to accept the notion of approximation and incremental improvements.

| Unfortunately SVN does not track which patches have been applied already so a
| simple

As you know, I'm using SVK to do merges (in particular smerge) so I 
get some help from there.  But the manual changes done by tim was 
indeed not tracet.

[...]

| Nevertheless, to go forward, I'd like to ask Tim: Do you allow Gaby to merge
| his autoconf code into trunk even if you don't understand it?


Thanks for your support, Ralf.  I would first ask Tim to be more specific
about which parts he does not understand so that I can improve the
documentation in that respect.  Also, I cannot merge
to the GIT repo and I suspect that is going to be a problem...  But I can
definitely merge to the SVN repo.

\start
Date: Mon, 25 Jun 2007 05:41:18 -0700 (PDT)
From: Cliff Yapp
To: list
Subject: Version numbers and merging improvements

I'm not quite sure if I should risk muddying the waters further, but I
have (sort of) an idea and perhaps it would make sense to other people.

If we step back and take a look at the requirements driving various
aspects of this debate, I think the main points are:

1.  Most open source software uses a numerical X.Y.Z style numbering
system for released versions of software.  This is common enough that
package management systems (Gentoo for example) are best suited to work
with such arrangements.

2.  When debugging Axiom, the most useful information is the branch and
revision used to build the binary - we want to preserve this
information in a form that can be easily accessed at need.  The current
banner report reflects this.

3.  The branches build-improvements and wh-sandbox have many fixes and
pieces working that the "official" Silver and Gold do not - reasons for
this are complex.


For the first and second points, we want to both make Axiom a good fit
with packaging systems and preserve the useful information we need.  I
would suggest the following, a minor variation on some existing
proposals:

1.  We establish two fields to hold version numbers - the current
mechanism and a "release version" slot specifically for use when
updating Gold.  The "release version" would use X.Y.Z style numbering,
and would correspond exactly to a particular branch of Gold.  When the
banner of a Gold release is run, it would find the release version set
and print that as opposed to the more detailed (and confusing, to the
casual user) branch and revision information

2.  In any branch other than gold, the release version is nonsensical
and would remain unset.  Because it is unset, the current mechanism
would take over and print branch and revision information - exactly
what a developer needs.

This has the merit of simplicity - it should be borderline trivial to
code - and returning the appropriate information for a given situation.
 Developers get development information, Gold users get something
simple they can understand.  If we need to relate it to a branch and
revision, the branch is Gold and the revision is the revision tagged
for release X.Y.Z.  If that sounds good to everyone I'll volunteer to
cook up a patch that can be merged into both Gold and Silver to
implement it.

OK, well and good, but proposing such a scheme doesn't make it so.  I
think most of the practical problems relate to #3 above:

Merging build-improvements and wh-sandbox.

There are a great many changes in these branches, and making sure they
are understood is important.  First an observation, and then I have a
suggestion for handling this that ties in with the above numbering
scheme.

Observation:  If I understand correctly Tim (please correct me if I'm
wrong) you are being careful about introducing changes into Gold
because you want to avoid regression of functionality and ensure that
changes included in Gold are correct?  This is one of the motivations
for the new regression testing system, IIRC - to make testing these
changes faster.  I certainly agree that such a system is needed, but
I'm not sure if we need it for all the changes being considered at this
current point.  I could be wrong, but this is my thinking:

1.  At the current state in the design and development of Axiom, we
have no more reason to be sure Axiom is correct than any other CAS,
except for the modes of thinking and programming encouraged by its
strong type system.  There is no formal verification system backing the
current codebase or builds.

2.  Regression testing will identify unintended consequences of changes
in the code, but it will not identify correct vs. incorrect results. 
For that we need the CATS effort, and probably some formal correctness
proof systems mixed in there.

3.  Given these facts, it might be of slightly less importance to do
exhaustive regression testing for every change until we risk not just
side effects but undermining trusted results.  Or, stated another way,
what is our loss in confidence in the correctness of an algebra result
as a consequence of changes in the current codebase?  Do we have
confidence to begin with?

Obviously in some situations (like the algebra bootstrap) we have to
check.  Others (ANSI compatibility changes, hyperdoc) I personally am
less nervous about - I think there is enough work to do at all levels
of the system that any problems introduced by those changes will be
rooted out in the gradual literate programming process - particularly
at the levels below the algebra, which I think will need extensive work
before we're done.  Given that work will need to be done regardless,
I'd much rather be working from an ANSI foundation.

Proposed merge and release scheme:

1.  Take the current Gold CVS tree, fix any truly obvious and trivially
fixable problems and assign it the version number 3.0.0.  This should
be the last version not based on ANSI Common Lisp.  

2.  Identify the changes needed in wh-sandbox to enable building on
ANSI, and merge them.  This may not be separable from fixing some bugs
in things like the database bootstrap, but we will see.  The next goal
should be getting Silver up to the point of running on ANSI lisps,
IMHO.  Once that is accomplished, merge Silver into Gold and release
the new Gold as 4.0.0 - the first stable ANSI based Axiom.

(Note:  If a Lisp based build of the core Axiom code is possible in
4.0.0, it should be possible (give or take some filesystem quirks) to
build an AXIOMsys Windows release with nothing but a working ANSI Lisp
as the bootstrap requirement - if that's the case a first Windows
release needn't wait on the autoconf machinery and GCL.  Eventually I
would like both, but any ANSI should work for that first release while
we hammer out the issues, and that would mean a Windows binary actually
based on the main trunk would be available.)

3.  Once ANSI merge is accomplished, work on merging the build
machinery.  It should be possible, like Maxima, to build in different
ways depending on what tools one wants to use - autoconf has undeniable
advantages when it comes to integrating and managing things like the
gcl build and the sman and graphics.  Once we have autoconf working in
Silver, release 4.1.0 in Gold.

(If autoconf in Axiom is anything like autoconf in Maxima, autoconf
handles all the non-lisp-based details and triggers the Lisp build
system for the core system.  It may also handle dumping the core
images, which (of course) can't be done from inside the lisp build
process.)

4.  Then, we can introduce the fixes that get hyperdoc working.  This
would be version 4.2.0 in Gold.

Algebra fixes can be scattered throughout - if they rely on core level
fixes like the new database bootstrap procedure we will need to sort
that out at the 4.0 stage, but I think that should be doable.  It would
be really nice to be able to include Martin's working Guess package in
4.0.

This of course still leaves us with the hard work of getting the ANSI
changes into Silver (I'm working on learning GIT, and once I get
something other than this old laptop running I can make a more serious
stab at it).  Does this plan look like it makes sense, Tim? 
(Everybody?)  We may find that after 4.0 we release 4.1 quickly and 4.2
on the heels of 4.1, but that's fine.  Hopefully by 4.2 we will have
Gold up to the current wh-sandbox functionality level, and the
motivation for the different branches will disappear.

Tim, Gaby, Waldek, all - opinions?

\start
Date: Mon, 25 Jun 2007 15:27:05 +0200
From: Ralf Hemmecke
To: Cliff Yapp
Subject: Re: Version numbers and merging improvements

Just a side remark Cliff.

> If that sounds good to everyone I'll volunteer to cook up a patch
> that can be merged into both Gold and Silver to implement it.

Nothing will ever be merged into Gold. We have Silver which is SF:trunk 
(always in sync with Tim's git archive) and at some point in time we 
simply *call* it Gold, it gets a version number, time stamp, etc. And 
then we continue working on (the same) trunk as usual. Actually, we 
should have a freeze time, but for the moment let's not complicate 
things more than they are already.

We should just make a note in the archive that this particular revision 
is the release revision. That's it.

\start
Date: Mon, 25 Jun 2007 08:41:56 -0500
From: Tim Daly
To: Gabriel Dos Reis
Subject: Autoconf change

I invite you to create a diff-Naur patch that creates ONLY the
autoconf facility as a changeset. Do the diff-Naur against the current
silver. I'll withhold changes to silver until you're ready. Please try
to make the changeset specific to autoconf, not to other features.

Please make sure that the new regression works.

I have a pending downcase change which is complete and ready to
undergo testing. Since it is guaranteed to make your changeset
incompatible I'll withhold it until your changeset is ready to
apply. Then I'll refit the downcase change.

\start
Date: Mon, 25 Jun 2007 08:46:28 -0500
From: Tim Daly
To: Cliff Yapp
Subject: Version Numbering

I invite you to create a diff-Naur patch that creates ONLY the
version numbering as a changeset.

\start
Date: Mon, 25 Jun 2007 09:04:51 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: Re: Autoconf change

On Mon, 25 Jun 2007, Tim Daly wrote:

| I invite you to create a diff-Naur patch that creates ONLY the
| autoconf facility as a changeset.

As I explained a few days ago, the build machinery will be broken
into a few installments -- incremental improvements:

  (1) configure
  (2) Makefiles in several pieces.

I would like to get the configure change in first, then attack
the Makefile modification seperately in separate changes.  Yes, the
new configure is not that all useful without the Makefiles, but 
in its own it is not entirely useless either and it is certainly
an improvement over Silver's configure.  All of this woul have to wait
until I get back to my primary development machine.

} Do the diff-Naur against the current
| silver. I'll withhold changes to silver until you're ready. Please try
| to make the changeset specific to autoconf, not to other features.
| 
| Please make sure that the new regression works.
| 
| I have a pending downcase change which is complete and ready to
| undergo testing. Since it is guaranteed to make your changeset
| incompatible I'll withhold it until your changeset is ready to
| apply. Then I'll refit the downcase change.

Please don't hold your downcasing changes on the Autoconf machinery.
As I explained two weeks ago (or so), I'm on travel and my main machine at
this moment is a windows based system.  I'm not fully back to home
untill August 2-3.  we will most certainly meet at ISSAC, 
July 29-August 1, and try to resolve other issues in a face-to-face
meeting.

\start
Date: Mon, 25 Jun 2007 09:06:28 -0500
From: Tim Daly
To: Cliff Yapp
Subject: confidence in the correctness

> what is our loss in confidence in the correctness of an algebra result
> as a consequence of changes in the current codebase? Do we have
> confidence to begin with?

re: Algebra change confidence

After initial merge failures creating silver, a new facility was
created to check what changes occur in any file when a change is made
(see src/regress/REGRESS). Then, starting with Gold, each change was 
applied,  one at a time, and a complete system build per change was done.

The REGRESS script computes an MD5 hashcode for each file and remembers 
the results. After each change is checked, the new results file replaces
the prior one.

The MD5 hash will be the same if no change occurs.
We can see whether a change has had any effect on the algebra.
Indeed we can now see every file that a patch affects.
All patches were applied that did not affect the algebra.
Changes that affected the algebra were not yet applied.

This gives us great confidence that nothing in the algebra is broken
(any worse than it was in Gold).


re: Algebra correctness.

To look at actual computation results there is a new regress function
that does a line-by-line compare against prior results cached in the
comments.  This has uncovered interesting problems going from platform
to platform which we need to think about. More tests are being added
as well as documentation about each test. 

The src/input subdir will eventually contain CATS-like test cases for
the range of algebra along with associated documentation. Prior to
this the input files were simple test scripts. After this the expected
results are explained mathematically and then the results from Axiom
are given and tested.

\start
Date: Mon, 25 Jun 2007 09:16:40 -0500
From: Tim Daly
To: Cliff Yapp
Subject: other diff-Naur changesets

So you're proposing:

4.0 ANSI lisp
4.1 Autoconf
4.2 Hyperdoc

Frankly, I'm happy to merge changesets that add any SINGLE facility.
Or changesets that fix any SINGLE bug. We can increment any number 
in any field you like. Perhaps we need a "schedule" of changesets?


I invite anyone who has a changeset to post a diff-Naur of the changeset.

\start
Date: Mon, 25 Jun 2007 09:36:09 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: Re: Autoconf change

On Mon, 25 Jun 2007, Tim Daly wrote:

| I invite you to create a diff-Naur patch that creates ONLY the
| autoconf facility as a changeset. Do the diff-Naur against the current
| silver. I'll withhold changes to silver until you're ready. Please try
| to make the changeset specific to autoconf, not to other features.

This is impractical:  Given windows filesystem characteristic, it is
not possible to check out silver source codes in a meaningful way
on windows, because of the case insensitive issues.  The net result
is that I will not be able to check out trunk and test whether any
merge from build-improvements to trunk works.  I do consider the fact
that build-improvements can build on windows essential.  

There are several ways to solve this:

  (1) you check in your mega change that solves that problem, or
  (2) you check in only the changes that are needed for successful
      check out on windows.  Personally, I don't see why that change
      useful in its own should be put on hold for a much bigger
      change.  Incremental improvements!

\start
Date: Mon, 25 Jun 2007 07:40:53 -0700 (PDT)
From: Cliff Yapp
To: Tim Daly
Subject: Re: other diff-Naur changesets


Well, I proposed that but the order was more from a "what needs what"
kind of thinking than anything.  If Autoconf is simpler to put in than
ANSI as a changeset, I would suggest the Autoconf version be 3.1.0.

I would like the first fully ANSI version to be 4.0 because I think
this will be a turning point for a variety of development directions,
but the particular numbering around that should be what makes sense,
and if we can plug in autoconf we should do it and not wait for the
ANSI changeset just to keep the version numbers in my (more or less
arbitrary) order.

Waldek, does the hyperdoc fix require the ANSI modifications as well? 
(or changes that can't be easily untangled from the ANSI work?)  I was
assuming yes, but that was just an assumption.

Cheers,
CY 

--- Tim Daly wrote:

> So you're proposing:
> 
> 4.0 ANSI lisp
> 4.1 Autoconf
> 4.2 Hyperdoc
> 
> Frankly, I'm happy to merge changesets that add any SINGLE facility.
> Or changesets that fix any SINGLE bug. We can increment any number 
> in any field you like. Perhaps we need a "schedule" of changesets?
> 
> 
> I invite anyone who has a changeset to post a diff-Naur of the
> changeset.

\start
Date: Mon, 25 Jun 2007 07:44:30 -0700 (PDT)
From: Cliff Yapp
To: Tim Daly
Subject: Re: Version Numbering

Will do.  I'll take a stab at it tonight.  I'm not sure offhand, but if
the file containing the relevant info has changed from Gold to silver
should I make a diff for both?

--- Tim Daly wrote:

> I invite you to create a diff-Naur patch that creates ONLY the
> version numbering as a changeset.
> 
> Tim

\start
Date: Mon, 25 Jun 2007 09:52:26 -0500
From: Tim Daly
To: Gabriel Dos Reis
Subject: changeset order

So you're proposing that I finish testing and post my global downcase
changeset (which will fix the Windows/MAC/bug#353 issue) before you
post your autoconf changeset?

\start
Date: Mon, 25 Jun 2007 09:55:51 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: Re: changeset order

On Mon, 25 Jun 2007, Tim Daly wrote:

| So you're proposing that I finish testing and post my global downcase
| changeset (which will fix the Windows/MAC/bug#353 issue) before you
| post your autoconf changeset?

If you cannot fix the Windows/MAC bug separately, yes.

I would like to be able to check out silver on windows machine, so that
I can work on the build issue on my spare time.

\start
Date: Mon, 25 Jun 2007 08:03:38 -0700 (PDT)
From: Cliff Yapp
To: Ralf Hemmecke
Subject: Re: Version numbers and merging improvements

> Just a side remark Cliff.
> 
> > If that sounds good to everyone I'll volunteer to cook up a patch
> > that can be merged into both Gold and Silver to implement it.
> 
> Nothing will ever be merged into Gold. We have Silver which is
> SF:trunk (always in sync with Tim's git archive) and at some point
> in time we simply *call* it Gold, it gets a version number, time
> stamp, etc. And then we continue working on (the same) trunk as
> usual. Actually, we should have a freeze time, but for the moment
> let's not complicate things more than they are already.

Well, the cvs and arch trees currently represent the Gold archive.  I
agree that normal procedure would be to "tag" the release and generate
tarballs from that, but my understanding was that we were going to
maintain the arch archive as "the" gold archive and the cvs mirror in
sync with the arch archive.  Has that changed?

> We should just make a note in the archive that this particular
> revision is the release revision. That's it.

Well, I suppose the function that prints the Axiom header could be made
to check if the branch and build used to make the binary correspond to
a known release, and if so print the release number.  Maybe store the
release<->revision information in a hash table or something.  That
would be future proof if we ever switch to tagging the Silver branch
for releases.  Hmm...

\start
Date: Mon, 25 Jun 2007 09:03:49 -0600
From: Robert Dodier
To: Camm Maguire
Subject: Re: [Maxima] 2.7.0 nqthm compile times
Cc: Robert Boyer, Matt Kaufmann

Camm,

Thanks a lot for your work on GCL.

My only comment about recompiling policy is that I hope that
the system remains in a safe state by default.

About this,

> A final question remains of
> whether or not to actually use ftype declaims if provided.

My advice: ignore user-supplied ftype declaims.

All the best, & keep up the good work.

\start
Date: Mon, 25 Jun 2007 10:31:53 -0500
From: Tim Daly
To: Cliff Yapp
Subject: sourceforge
Cc: Bill Page, Gabriel Dos Reis

You have world privs on sourceforge.

\start
Date: Mon, 25 Jun 2007 11:32:07 -0400
From: Bill Page
To: Gabriel Dos Reis
Subject: Re: Lille

On 6/24/07, Gabriel Dos Reis wrote:
>
>    I'm currently in Lille; I visited the computer algebra group (headed by
> Michel Petitot) at LIFL last thursday.  Michel Petitot was an Axiom user and
> contributor in the late '80 and beginning '90 -- pieces of his contributions
> to the Axiom algebra are still there.
>
>   I'll be giving a talk on Axiom next wednesday to the group.  Most of it
> will be update on the state of the project, current architcture, and possible
> future (technical) directions.
>

That's excellent, Gaby. I think such presentations about Axiom are
very important. If it is technically possible, I think it is a very
good thing to record such presentations so that other people can
download and listen. This approach is very popular with the Sage
project.

\start
Date: Mon, 25 Jun 2007 08:39:01 -0700 (PDT)
From: Cliff Yapp
To: Tim Daly
Subject: Re: sourceforge

Thanks!

Cliff

--- Tim Daly wrote:

> You have world privs on sourceforge.

\start
Date: Mon, 25 Jun 2007 08:40:34 -0700 (PDT)
From: Cliff Yapp
To: list
Subject: Gold vs. Sept. 2005 tarball

I suppose I can find out the hard way, but in case anyone knows:

Is the source currently in the Gold tree the same as that in the Sept.
2005 tarball that already exists?

\start
Date: Mon, 25 Jun 2007 11:42:28 -0400
From: Bill Page
To: Gabriel Dos Reis
Subject: Re: HyperDoc macros

Gaby,

Thank you very much for the detailed explanation.

Regards,
Bill Page.

On 6/24/07, Gabriel Dos Reis wrote:
>
>    When replying, please CC: me using my address at TAMU as I cannot
> currently access my usual dev machine which has all Axiom mails.
>

Ok.

> ...
>    As it turns out, only a fraction of the HyperDoc component really needs
> X11 (mainly the terrible graphic interface).  Other parts (e.g. htadd) of
> HyperDoc will do just fine.  So my patch to Axiom.build-improvemnt
> builds those parts that really do not need X11.  And we set up the path
> to macro table correctly.
> ...

\start
Date: Mon, 25 Jun 2007 10:42:24 -0500
From: Matt Kaufmann
To: Robert Dodier
Subject: Re: [Maxima] 2.7.0 nqthm compile times
Cc: Camm Maguire, Robert Boyer

Regarding:

>> My advice: ignore user-supplied ftype declaims.

I don't have any problem with that as the default behavior.  But I'd
like to be able to override that "ignore" -- that's what I was trying
to say in this part of my reply yesterday (where here I've tried to
eliminate some ambiguity in it).

  As you know, in ACL2 we do our own auto-proclaiming of function types.
  Just to be safe, I think it would be good if there were a way to turn
  off the auto-proclamation capability, as a way to work around any
      ^^^
     GCL's
  problems we might encounter, using our own proclaiming instead.
                               ^^^^^^^^^^^^^
                              by using ACL2's

Thanks --
-- Matt
   DKIM-Signature: a=rsa-sha1; c=relaxed/relaxed;
	   d=gmail.com; s=beta;
	   h=domainkey-signature:received:received:message-id:date:from:to:subject:cc:in-reply-to:mime-version:content-type:content-transfer-encoding:content-disposition:references;
	   b=VZiMC3HyT3UTewJZPY62wUlvOIzW8bNMIqcj7N7aoKMfRvx+L4OTSj0xu9lgHRjiOx8V4XriJpjyz5XbyEPEWWzOSbBIt1+DzVEotW9L/N7m8hFUewXaZIyHxb2JEl2bdM/Lms7XjA4u0qWKL4WOcfG0euxAmYNEmStO2MklU3Y   DomainKey-Signature: a=rsa-sha1; c=nofws;
	   d=gmail.com; s=beta;
	   h=received:message-id:date:from:to:subject:cc:in-reply-to:mime-version:content-type:content-transfer-encoding:content-disposition:references;
	   b=Uc7KjbTveZ5Y+baAcGZZ+FkahsWXBfq25sEF599pvFHDLdFq/ZCNUJWflqsNaRltPGEdYCNVtW6EW8zr4bUbf5IGM5N8J9BbzKGWSj6Va3qC3KFjA31NtFJe7ShtugO6Ys0hWjTy+SiDbmLNAl30ImZOZk7id3U/8HeSjR+9t8M=
   Date: Mon, 25 Jun 2007 09:03:49 -0600
   From: Robert Dodier
   Cc: "Robert Boyer" Robert Boyer, maxima@math.utexas.edu,
	   list, gcl-devel@gnu.org,
	   "Matt Kaufmann" Matt Kaufmann
   Content-Disposition: inline
   X-SpamAssassin-Status: No, hits=-1.8 required=5.0
   X-UTCS-Spam-Status: No, hits=-163 required0

   Camm,

   Thanks a lot for your work on GCL.

   My only comment about recompiling policy is that I hope that
   the system remains in a safe state by default.

   About this,

   > A final question remains of
   > whether or not to actually use ftype declaims if provided.

   My advice: ignore user-supplied ftype declaims.

   All the best, & keep up the good work.

\start
Date: Mon, 25 Jun 2007 12:02:44 -0400
From: Bill Page
To: Gabriel Dos Reis
Subject: Re: Version numbers
Cc: Waldek Hebisch

On 6/25/07, Gabriel Dos Reis wrote:
> ...
> I do not believe your posting was a waste -- although a patch to
> Axiom with equialvent size would have been nice :-) :-)
> ...

Thank you for comments and I agree with your sentiment above.

> Bill Page wrote:
> | Since I have been promoting the autoconf style of build process for
> | Axiom to Tim for several years, Tim asked me why I did not do this
> | work myself. I replied that I was very glad when someone came along
> | (Gaby) who was motivated and obviously knew enough about how to do it
> | - much more than me! The situation is that really I do not want to be
> | doing this kind of development. Since I am not very good at it, it
> | wastes my time and there is never enough time. I would very much
> | prefer to be an Axiom user/developer who discusses mathematics and
> | writes new algebra code for example in category theory and in
> | applications to physics. But here I have been stuck for nearly 5 years
> | now - just getting to the point where this is becoming possible.
>
>
> I very much disagree with that view. I too would very much perfer to be
> an Axiom user/developer who discusses mathematics and write algebra code for
> example in category theory and applications to various fields of
> computational science.  However, I also realize that I cannot just wish
> someone else come and does the dirty job for me so that I can theorize without
> getting my hands dirt.  I'm not a developer.  I'm a mathematician.
> I earned my degree in Differential Geometry.  I'm highly interested
> in computational mathematics.  Since *I need tools* and they are lacking, I
> have to build them.  That is why I have my hands dirt with C++, GCC, Axiom,
> etc.
>

Your point well taken. I realize that what you say is completely true
and applies to many other people on this list. I agree that the
attitude that I displayed in my comment above is *not* a productive
one. Instead I should point out that I have learned a lot about how to
use autoconf from your work on build-improvements. It is not my
intention to simply "just wish that someone else come and does the
dirty job for me" - certainly not at the expense of their own time
which they really wish to devote to something else. Perhaps I can make
some significant contribution in the future. In the mean time I am at
least attempting to test these changes as widely and as often as
possible.

> ...
> | > > > Bill Page wrote:
> | > > > (See for example recent revisions submitted by Gaby which he asked
> | > > > to revert pending something similar to be done by Tim.)
> | >
> Bill Page wrote:
> | I think Tim's reply to this is very important.
> |
> | He said that he had planned to work with the change that Gaby had
> | submitted and the fact that Gaby later withdrew it was *not* based
> | on his request.
>
> That is true: Tim never asked me to back off the change I made.
> The complain came from more vocal people who did not take any step in
> solving the problem I was attempting to solve.  I guess solving the problem
> they thought I erroneously solved would have been against the law.
>
> | (Check the mailing list). He said that I should get your facts
> | straight when you are making disparaging remarks about him in public.
>
> Is "you" referring to me (Gaby)?

No sorry, that is my grammatical error. I should have written:

  He (Tim) said that *I* (Bill) should get my facts straight when I am
  making disparaging remarks about him in public.

> Bill Page wrote:
> | I am very sorry about this. I do hereby state publicly that I was
> | wrong about that. I also get the impression that there were more
> | people than me who may have gotten the wrong impression about that
> | interchange so I am glad that Tim has set the record straight.
> ...

\start
Date: Mon, 25 Jun 2007 18:23:51 +0200
From: Gregory Vanuxem
To: Waldek Hebisch
Subject: Re: *read-default-float-format* in SBCL/wh-sandbox

Le samedi 23 juin 2007 =E0 21:08 +0200, Waldek Hebisch a =E9crit :
> > Hello Waldek,
> >
> > *read-default-float-format* is set to single-float in SBCL/wh-sandbox.
> > The problem, I think, is that SBCL does not save the value of this
> > variable when creating a new Lisp image. As far as I know this happens
> > for other variables (not exhaustive of course) *print-escape*
> > *load-verbose* *compile-verbose* *load-print* *compile-print*
> > *print-array*.
> >
>
> AFAICS in open source Axiom *read-default-float-format* always was
> set to single-float.  CCL based Axiom set *read-default-float-format*
> to double-float.  GCL uses the same precision for single and
> double floats (and also for long float), so for GCL it does not
> matter very much.

Yes, GCL is buggy from my point of view. I wonder how this is handled in
2.7.

> Do you think we should set *read-default-float-format*
> to T?  I must admit that in Lisp/boot sources I would prefer to
> explicitly specify double precision (when needed), while for
> Spad/input we are (or should be) using our own routines anyway.

I agree but I see two issues here, the first one is that when
$useBFasDefault is set to false Axiom creates single-floats and
therefore computations are done over single-floats. You can try in the
interpreter :

)bo $useBFasDefault := false

1.0/3*float(3,0,10)@DoubleFloat

=> 1.0000000298023224d0


This can be fixed by modifying the function MAKE-FLOAT in macros.lisp
(replacing the 'e' by a 'd' in the format) . This feature - using
DoubleFloat by default instead of Float - is very handy when you write a
Spad file where computations are done on DoubleFloat : you don't have to
coerce each Float and the generated Lisp file is cleaner.

The other issue is how a DoubleFloat is displayed. Since we let Lisp
display it and *read-default-float-format* is set to single-float the
'd' character is added to its printed representation.

I think that in the mean time (as far as the Lisp "formatter" is used to
displays double-floats) *read-default-float-format* should be set to
double-float.

[...]

>
> BTW: If you want to have quiet compilation/loading it is not
> enough to set *load-verbose* and *compile-verbose* to nil.
> One also have to handle various conditions (see for example
> |load_quietly| in axiom-lisp.lisp.pamphlet).

Ok, thanks, I just upgraded.

\start
Date: Mon, 25 Jun 2007 18:30:39 +0200
From: Gregory Vanuxem
To: Gabriel Dos Reis
Subject: Re: Lille

Le dimanche 24 juin 2007 =E0 17:51 -0500, Gabriel Dos Reis a =E9crit :
> Hi,
>
>   I'm currently in Lille; I visited the computer algebra group (headed by
> Michel Petitot) at LIFL last thursday.  Michel Petitot was an Axiom user and
> contributor in the late '80 and beginning '90 -- pieces of his contributions
> to the Axiom algebra are still there. 
>
>   I'll be giving a talk on Axiom next wednesday to the group.  Most of it
> will be update on the state of the project, current architcture, and possible
> future (technical) directions.

Hmm... I never speak about my private life but I'll make a small
exception.

Welcome (I live at 10 km of Lille, 8 km of Lille 1 (USTL)).

I wish you all the best in Lille.

\start
Date: 25 Jun 2007 19:16:32 +0200
From: Martin Rubey
To: Tim Daly
Subject: Re: Axiom version numbering

Tim Daly writes:

> > Only, the CHANGELOG is not installed.
> 
> Eh? <http://axiom.svn.sourceforge.net/viewvc/axiom/trunk/axiom>
> shows CHANGELOG in revision 631 of the trunk. Why is CHANGELOG
> not installed? Can you SVN get the file?

At least wh-sandbox does not install Changelog.wh. I.e., make install does not
copy Changelog.wh into the install destination.  I am not proposing that it
should, rather, I propose that the banner reflects the branch and the revision.

For me, the date when axiom was built is completely useless, but I don't mind
having it in the banner.

\start
Date: Mon, 25 Jun 2007 12:31:30 -0500 (CDT)
From: Gabriel Dos Reis
To: Gregory Vanuxem
Subject: Re: Lille

On Mon, 25 Jun 2007, Gregory Vanuxem wrote:

| Hmm... I never speak about my private life but I'll make a small
| exception.
| 
| Welcome (I live at 10 km of Lille, 8 km of Lille 1 (USTL)).
| 
| I wish you all the best in Lille.

Many thanks!

\start
Date: Mon, 25 Jun 2007 19:39:30 +0200
From: Ralf Hemmecke
To: Cliff Yapp
Subject: Re: Version numbers and merging improvements

> Well, the cvs and arch trees currently represent the Gold archive.

And I hope they will be gone once trunk turns into Gold. Then everything 
is on sourceforge. Who would bother with checking out via CVS. Any 
reasobable programmer has by now heard of SVN and will certainly be able 
to install it on his machine and get the Axiom sources via SVN.

Why should we bother an invest time in keeping Arch and CVS as mirrors?

> agree that normal procedure would be to "tag" the release and generate
> tarballs from that, but my understanding was that we were going to
> maintain the arch archive as "the" gold archive and the cvs mirror in
> sync with the arch archive.  Has that changed?

If there is a maintainer (you?) who has too much time, I don't care if 
someone maintains as many mirrors as possible. I won't and I will ignore 
them.

>> We should just make a note in the archive that this particular
>> revision is the release revision. That's it.

> Well, I suppose the function that prints the Axiom header could be made
> to check if the branch and build used to make the binary correspond to
> a known release, and if so print the release number.

You seem to have too much time. Lucky you.

\start
Date: Mon, 25 Jun 2007 20:08:38 +0200 (CEST)
From: Waldek Hebisch
To: Martin Rubey
Subject: re: Axiom version numbering

> Tim Daly writes:
> 
> > > Only, the CHANGELOG is not installed.
> > 
> > Eh? <http://axiom.svn.sourceforge.net/viewvc/axiom/trunk/axiom>
> > shows CHANGELOG in revision 631 of the trunk. Why is CHANGELOG
> > not installed? Can you SVN get the file?
> 
> At least wh-sandbox does not install Changelog.wh. I.e., make install does not
> copy Changelog.wh into the install destination.  I am not proposing that it
> should, rather, I propose that the banner reflects the branch and the revision.
>

Recent wh-sandbox prints: 

                        AXIOM Computer Algebra System
                 Version: Axiom wh-sandbox branch 2007-05-31
                Timestamp: Monday June 25, 2007 at 16:48:28
-----------------------------------------------------------------------------
   Issue )copyright to view copyright notices.
   Issue )summary for a summary of useful system commands.
   Issue )quit to leave AXIOM and return to shell.
-----------------------------------------------------------------------------

(1) ->


Note that this from sbcl based Axiom, so there is no Lisp banner,
only the Axiom banner.  The date represent the last date when
the banner was updated.  This is not the best situation, but I
see no easy (or even not so easy) way to automatically include
revision number.  Note that using svn it is easy to include in a
file the revision number corresponding to the last time the
file was modified.  So, for example with reasonable effort I
could include revision number correspnding to the last modification
of the file containing the banner string.  But having such
revision number solves nothing: if other files are modified
later the banner will be out of date anyway.

Of course, one could try to update banner on each commit by hand.
But I think that the gain is not worth the effort: it is quite
likely that somebody will forget to modify the banner so the
information will be unreliable.  OTOH the person fetching Axiom
via svn will be informed which revision was fetched, and sources
contain ChangeLog.wh, so the counfusion should be limited.

I think that with limited effort we could embed into Axiom the
last ChangeLog entry (or even the whole ChangeLog if that is
preferable), but I am not sure if we want this.

\start
Date: Mon, 25 Jun 2007 13:15:40 -0500
From: Tim Daly
To: Ralf Hemmecke
Subject: Version numbers and merging improvements

> And I hope they will be gone once trunk turns into Gold. Then everything
> is on sourceforge. Who would bother with checking out via CVS. Any
> reasobable programmer has by now heard of SVN and will certainly be able
> to install it on his machine and get the Axiom sources via SVN.

(a) Not all programmers are reasonable (me and linus, for instance)
(b) CVS ships with all known linux distros
(c) Savannah does not use SVN
(d) SVN didn't install cleanly on axiom-developer
(e) The project is widely available in stable "Gold" format

For most of the world Axiom should "just work". No need to install anything.

Sourceforge SVN is ok for developers but most of the world does not
consist of developers.  There is no need to know about SVN at
all. Sourceforge SVN is just a local cul-de-sac. Aside from the fact
that we can see local commits to private source trees it has no other
special function. Indeed it could be argued that exposing private source
trees enables the "cherry-picking" behavior. If these trees were not 
visible then changes would only be available as diff-Naur changesets.
That appears to be a more desireable behavior.


> Why should we bother an invest time in keeping Arch and CVS as mirrors?

You don't need to bother with this. Maintaining Arch, CVS@Sourceforge and
CVS@Savannah are my concerns.

Cliff's efforts to make tarballs of Gold for various platforms is a 
much needed effort. I don't believe that version numbering is of any
interest outside our little furball of developers but who knows....

\start
Date: Mon, 25 Jun 2007 11:18:36 -0700 (PDT)
From: Cliff Yapp
To: Ralf Hemmecke
Subject: Re: Version numbers and merging improvements

> > Well, the cvs and arch trees currently represent the Gold archive.
> 
> And I hope they will be gone once trunk turns into Gold. Then
> everything is on sourceforge. Who would bother with checking out
> via CVS. Any reasobable programmer has by now heard of SVN and will
> certainly be able to install it on his machine and get the Axiom
> sources via SVN.

The last time this came up (I believe) was when the AxiomSources page
was reorganized.  Tim at that time identified where Gold lived in one
of his responses:
http://lists.nongnu.org/archive/html/axiom-developer/2007-05/msg00609.html
 
> Why should we bother an invest time in keeping Arch and CVS as
> mirrors?

I certainly would not be adverse to centering on GIT with the SVN
connection, but that one isn't my call.

> If there is a maintainer (you?) who has too much time, I don't care
> if someone maintains as many mirrors as possible. I won't and I will
> ignore them.

The Gold archives were set up by Tim and he retains control of those. 
Whether he would agree with using GIT's tag system (how does the
SVN<->GIT setup handle Tags?) to identify Gold trees I don't know -
Tim?  It would reduce the upkeep and Git does appear to represent the
best technical solution (with SVN acting as a friendly face for those
who don't care for GIT).

To me the best of all possible solutions would be to center on the
GIT/SVN setup, release tarballs of Gold as it is currently defined, and
once Silver is tagged for the next Gold release retire all branches
except the GIT/SVN system.  (Bill's mercurial and darcs mirrors I don't
think would be bothered by this, unless I'm misunderstanding how they
work.)

Incidently, while I'm thinking of it, does anyone have any experience
with the qgit interface?  http://digilander.libero.it/mcostalba/

> > Well, I suppose the function that prints the Axiom header could be
> > made to check if the branch and build used to make the binary 
> > correspond to a known release, and if so print the release number.
> 
> You seem to have too much time. Lucky you.

No.  What I want is a solution that will be good enough to remove the
need or motivation to solve the problem again later.  Even if we end up
re-coding it someday for the literate process, I would like the design
of the solution to any given problem to be solid or scale easily.

I'm with Bill et. al. - I want to be figuring out how to implement
units and errors in Axiom to make the best scientific CAS ever.  But
Gaby is right - we need the tools, and since they don't exist we need
to create them.  Since we do need to, I figure we might as well learn
the lessons of Maxima and Axiom, and try and make solutions that are as
future proof as possible.

Interestingly enough, I notice that at least in wh-sandbox (and
presumably in build improvements as well) the version info is set in
configure.ac.pamphlet and this feeds on through.  Gaby, Waldek - does
autoconf read the repository information and update the appropriate
fields or do you manually update configure.ac.pamphlet with each
check-in?

\start
Date: 25 Jun 2007 20:29:11 +0200
From: Martin Rubey
To: Cliff Yapp
Subject: Re: Version numbers and merging improvements

Cliff Yapp writes:

> I'm not quite sure if I should risk muddying the waters further, but I
> have (sort of) an idea and perhaps it would make sense to other people.
> 
> If we step back and take a look at the requirements driving various
> aspects of this debate, I think the main points are:
> 
> 1.  Most open source software uses a numerical X.Y.Z style numbering
> system for released versions of software.  This is common enough that
> package management systems (Gentoo for example) are best suited to work
> with such arrangements.
> 
> 2.  When debugging Axiom, the most useful information is the branch and
> revision used to build the binary - we want to preserve this
> information in a form that can be easily accessed at need.  The current
> banner report reflects this.

No it does not.  Since wh-sandbox is currently one of the best working flavours
of axiom, you must not ignore it.

Switching to yet another version scheme is, in my opinion, stupid and
misleading.

PLEASE don't.

Personally, I like the version scheme yymm proposed and consistently used by
Tim.  It does lack some information, unfortunately, so I proposed to extend it
to

yy.mm.branch.revision-number.

Merits:

* Gaby agreed, I don't know about Waldek.

* it doesn't add yet another versioning scheme.

* it is crystal clear.

Drawbacks: might be a bit harder to implement, since the version number needs
           to get information from svn.  But I'd hope that it would be doable.
           In fact, why shouldn't that be done manually?

\start
Date: Mon, 25 Jun 2007 13:32:18 -0500
From: Tim Daly
To: Waldek Hebisch, Cliff Yapp
Subject: Version numbers and merging improvements

If you know the SVN command that will show the revision number it
would be possible to pipe the revision number into the file
mnt/sys/timestamp. The date and time stamp of this file is used to
generate the *yearweek* variable. The value of this variable is
set at build time in src/interp/Makefile. To quote from that file:



Axiom versions are given as a string of the form:
"Sunday September 21, 2003 at 20:38:05 "
which describes the day, date, and time of the build.
This is used for reporting bugs. It is only partially useful
in identifying which source code was used. Ideally we could create
a tar file of all of the date/time stamps of all of the source files
and use the MD5 hash of that file as the version stamp. Ultimately
though, this would be chasing the elusive "perfect information" idea.

A new variable [[boot::*build-version*]] is set and used by the 
{\tt yearweek} function to display the version number of the Axiom build.
This information is set by hand in the top level Makefile.

TIMESTAMP=${MNT}/${SYS}/timestamp
(progn 
 (setq timestampe "${TIMESTAMP}")
 (setq boot::*build-version* "${VERSION}")
 (yearweek))




The actual banner text is created in yearweek (src/interp/util.lisp).
If the mnt/sys/timestamp file contained the revision number at the
time of the build it would be trivial read the file and add it to 
the banner.

\start
Date: Mon, 25 Jun 2007 15:01:46 -0400
From: Bill Page
To: Tim Daly
Subject: Re: Version numbers and merging improvements

On 6/25/07Tim Daly wrote:
> ...
> (d) SVN didn't install cleanly on axiom-developer
> ...

SVN client works fine on axiom-developer. I had some problems
installing SVN server on axiom-developer because it depends on a newer
version of Apache then we are currently using. This problem is quite
easily solved. If this is really an issue, please let me know and  I
will give it some priority.

\start
Date: Mon, 25 Jun 2007 12:18:17 -0700 (PDT)
From: Cliff Yapp
To: Martin Rubey
Subject: Re: Version numbers and merging improvements

--- Martin Rubey wrote:
> > 2.  When debugging Axiom, the most useful information is the branch
> > and revision used to build the binary - we want to preserve this
> > information in a form that can be easily accessed at need.  The
> > current banner report reflects this.
> 
> No it does not.

OK, sorry - I'll look closer at it when I get home.

> Since wh-sandbox is currently one of the best
> working flavours of axiom, you must not ignore it.

Um - I don't propose to.  I have not given up on merging the wh-sandbox
build improvements back into Silver, and eventually to Gold.

> Switching to yet another version scheme is, in my opinion, stupid and
> misleading.
> 
> PLEASE don't.

Martin, I'm not going to arbitrarily implement any scheme - that's why
I'm discussing it on the list.  Nor am I proposing a switch, in the
true sense - I am proposing a numbering system for Stable releases
intended for end user consumption.  To date, we haven't had many of
those.

> Personally, I like the version scheme yymm proposed and consistently
> used by Tim.  It does lack some information, unfortunately, so I
> proposed to extend it to
> 
> yy.mm.branch.revision-number.

This is acceptable for development tarballs, but I personally think it
is going to look strange to most users if we use it for stable
releases.

> Merits:
> 
> * Gaby agreed, I don't know about Waldek.
> 
> * it doesn't add yet another versioning scheme.
> 
> * it is crystal clear.

My own opinion (and this is JUST my opinion) is that any numbering
scheme for STABLE RELEASES which doesn't follow the Major.Minor system
for release is going to look very odd to users.  Remember the version
number for a computer algebra system is part of its basic marketing
material - Maple 5, Mathematica 6, Maxima 5.9.3, etc.  When people talk
about Mathematica 5 vs. Mathematica 6, it is instantly clear.  If we
say Axiom 0703.gold.679 (for example), the first response of a
non-developer is going to be "what?"  The second will probably be "if I
can't understand the Version number, what will the rest of the system
be like?"  "Axiom 3.0" or "Axiom 4.1" would be a lot easier to say and
refer to.

So let me be clear - I am proposing we use an X.Y numbering system ONLY
for new Gold releases.  Not silver, not branches, JUST gold.  And that
version number can be translated into information like dates and
revision numbers, if we need to.  Since Gold releases will be what the
distributions (and end users) should focus on, in my opinion numbering
it in a way they expect will make things simpler.  Silver et. al.
shouldn't ever need tarballs or binaries, once the main Silver branch
and a Gold release can build on the target platforms with the key
features.

\start
Date: Mon, 25 Jun 2007 12:19:56 -0700 (PDT)
From: Cliff Yapp
To: Tim Daly, Ralf Hemmecke
Subject: Re: Version numbers and merging improvements

--- Tim Daly wrote:

> (c) Savannah does not use SVN

Currently true, but here's an interesting page:
https://savannah.gnu.org/maintenance/WhenSvN

(I can't tell - is Git already supported?
https://savannah.gnu.org/maintenance/Git)

\start
Date: Mon, 25 Jun 2007 21:32:51 +0200 (CEST)
From: Waldek Hebisch
To: Tim Daly
Subject: Re: other diff-Naur changesets

> So you're proposing:
> 
> 4.0 ANSI lisp
> 4.1 Autoconf
> 4.2 Hyperdoc
> 
> Frankly, I'm happy to merge changesets that add any SINGLE facility.
> Or changesets that fix any SINGLE bug. We can increment any number 
> in any field you like. Perhaps we need a "schedule" of changesets?
> 
> 
> I invite anyone who has a changeset to post a diff-Naur of the changeset.
> 

Many changes made to wh-sandbox depend on new build machinery.  For
example to make Hyperdoc functional I had to:
1) fix a buch of bugs, some is lib, some in interp and some in
   hyper subdirectory
2) correct paths embedded into various files
3) intall files in correct places

Part 3 was done mostly in Makefiles, part 2 depended on Makefile
changes.  One can try to separate 1 (ordinary bug fixes), but
without 2 and 3 the fixes are useless and hard to test.

Similary for ANSI compatibility we have various fixes:
1) Plain bugs which in default GCL mode (safety 0) gave undetected
   memory corruption
2) Few things that ANSI GCL 2.6.8 do not accept
3) Things things that clisp/sbcl do not accept
4) Things accepted by clisp/sbcl which work differently than GCL
5) Few thing that "work" but are ANSI violation and produced
   warnings
6) Changes to build process to support clisp, sbcl and openmcl

I one just want to work with ANSI GCL one could try to just pick
part 2.  But IMHO this would be misguided -- we should fix bugs
as soon as possible and 1-5 are just bug in a single logical
category.  Without 6 it is hard to test that fixes really worked.

On more basic level: currently I can not build out of the box 
gold or silver.  Silver recently made big progress: it used to
fail early in the build process, now it fails during graphic
build (it can not find libXpm.a).  To make things clear: I can
edit by hand silver Makefiles so that it build on my
machine.  I know how libXpm problem is solved in
build-improvements and wh-sandbox and I could probably prepare
some fix which applies to silver.

But the point is that to reliably solve problems with X libraries
one needs something like configure/autoconf.  Also,
build-improvements contains many fixes (possibly hundreds of fixes)
to many little problems which surfaced on various machines.

So I would say that build machinery is the first part which
should be merged.  I am affraid that the only realistic way
to do such merge is as a single rather large block.  I will
write separately about dependencies between various parts
and possiblities to do merge in stages.  However, my
conclusion is that doing merge in stages requires much
extra work and there is good chance that intermediate
stages will be more or less broken.

\start
Date: Mon, 25 Jun 2007 21:43:02 +0200
From: Ralf Hemmecke
To: Tim Daly
Subject: Re: Version numbers and merging improvements

> If you know the SVN command that will show the revision number

Issue "svn info" in the root path of the checkout.

\start
Date: Mon, 25 Jun 2007 14:52:13 -0500
From: Tim Daly
To: Waldek Hebisch
Subject: Version numbers and merging improvements

Waldek,

Try using AXIOM=`pwd`/mnt/fedora5 instead of `pwd`/mnt/linux

\start
Date: 25 Jun 2007 21:59:22 +0200
From: Martin Rubey
To: Cliff Yapp
Subject: Re: Version numbers and merging improvements

Cliff Yapp writes:

> My own opinion (and this is JUST my opinion) is that any numbering
> scheme for STABLE RELEASES which doesn't follow the Major.Minor system
> for release is going to look very odd to users.  Remember the version
> number for a computer algebra system is part of its basic marketing
> material - Maple 5, Mathematica 6, Maxima 5.9.3, etc.  When people talk
> about Mathematica 5 vs. Mathematica 6, it is instantly clear.  If we
> say Axiom 0703.gold.679 (for example), the first response of a
> non-developer is going to be "what?"  

Make it print

     Axiom 7.3 (gold, 679)

and they'll say "wow".  (Curiously, it is easier to produce a version number
that carries information like the one above, than a version number like 4.1
that doesn't carry any information at all.)

> Not silver, not branches, JUST gold.

At least here in Austria, most people use wh-sandbox.  (Surprisingly, at least
to me, Austrian researchers seem to embrace Axiom: MathAction lists Austria
with 2% before Canada, Russia and China, each with 1%.  Not bad, eh ? --
altogether there are only roughly 8 million Austrians...)

\start
Date: Mon, 25 Jun 2007 13:28:12 -0700 (PDT)
From: Cliff Yapp
To: Martin Rubey
Subject: Re: Version numbers and merging improvements

--- Martin Rubey wrote:

> 
> Make it print
> 
>      Axiom 7.3 (gold, 679)
> 
> and they'll say "wow".

Heh - true.  I suppose that could work, but I'm not sure it would
convey what really should be expressed by such numbers (see below.)

> (Curiously, it is easier to produce a version
> number that carries information like the one above, than a version
> number like 4.1 that doesn't carry any information at all.)

4.1 may not convey any technical information, but it DOES convey
information.  If the previous version was 3.0, the user expects 3.0.1
to be a minor fix (they probably won't directly see any change unless
they're triggering a specific bug that was fixed) 3.1 to have some new
features or significant fixes, and 4.0 to be a major improvement over
the 3.x series.

These types of versions are a marketing tool, telling customers in very
brief terms what their expectations should be.  For example,
Mathematica's new version 6 is a major version increase.  So
significant changes can be expected compared to the 5.x series - the
jump of the major version number indicates this.  Most software uses
this approach, in one form or another.  Maxima certainly does.

So you are corret that X.Y conveys less information than
yymm.branch.revision, but the X.Y version does more to tell the user
what to expect.  Major changes?  Minor fixes?  What does this new
version do?  X.Y is supposed to convey this (not that all projects get
it right, but in my experiences many of them do.)

> > Not silver, not branches, JUST gold.
> 
> At least here in Austria, most people use wh-sandbox. 

Now, that's true.  Eventually, we should reach the point where users
should be using Gold by default.  There are too many things that need
fixing for this to happen at this time.  That will change as Axiom
matures as an open source project, and we get a foundation strong
enough to let us focus on new mathematical work.  Until that point, we
aren't ready (in my opinion) for general consumption anyway.

So I agree Martin - right now people are using wh-sandbox.  What I'm
saying is in the long term we should have Gold in a state where people
will use it by default without feeling the lack-of-features pinch, and
when we get there I would like the numbering scheme used for Gold
releases to respect the common convention used by virtually all
software to communicate the magnitude of changes in releases.  It
doesn't replace any of the development schemes, so developers won't
have to care unless dealing with a bug report - and then they can
quickly decode the release # into what they need.  Does that seem
reasonable?

> (Surprisingly,
> at least to me, Austrian researchers seem to embrace Axiom: 
> MathAction lists Austria with 2% before Canada, Russia and China, 
> each with 1%.  Not bad, eh ?

Cool :-).

> altogether there are only roughly 8 million Austrians...)

Well, if y'all are using Axiom you won't need as many ;-)

\start
Date: Mon, 25 Jun 2007 15:34:48 -0500
From: Tim Daly
To: Martin Rubey
Subject: austria

So all of Austria has less people than just New York City? Wow.

\start
Date: 25 Jun 2007 22:39:23 +0200
From: Martin Rubey
To: Cliff Yapp
Subject: Re: Version numbers and merging improvements

Cliff Yapp writes:

> 4.1 may not convey any technical information, but it DOES convey
> information.  If the previous version was 3.0, the user expects 3.0.1
> to be a minor fix (they probably won't directly see any change unless
> they're triggering a specific bug that was fixed) 3.1 to have some new
> features or significant fixes, and 4.0 to be a major improvement over
> the 3.x series.

I find it extremely hard to classify many of the recent (i.e., last few months)
changes in wh-sandbox as minor.  May well be that only a single line in the
algebra sources was modified, but still, if the result was wrong before and
correct after, this may well affect long computations.

Fortunate as we are that Axiom is gratis, I suggest that serious users should
svn up as often as they can.

But I admit that there are landmarks.  HyperDoc in wh-sandbox was one for me.
Hm, in fact, I do not know of any other landmark.  I don't care whether axiom
uses autoconf or not, to be honest.  If Waldek and Gaby say autotools make
maintainance easier, OK.  If Tim says, it doesn't, OK.

> > At least here in Austria, most people use wh-sandbox. 
> 
> Now, that's true.  Eventually, we should reach the point where users
> should be using Gold by default.  

Cliff, please stop thinking about the future.  Well, one month is OK, but three
months is certainly not *now*.  If you want to implement a versioning scheme,
please implement one that works with the current situation.

If you implement one that works for Gold only, forget it.

\start
Date: Mon, 25 Jun 2007 13:42:28 -0700 (PDT)
From: Cliff Yapp
To: Tim Daly
Subject: mnt binary storage

Tim, as long as I'm stepping on land mines here's one more to round out
the day:

As I mentioned before, I'm in the process of figuring out how to make
asdf handle pamphlet files.  Of course, this basically means taking
over as much of the build logic as possible, and one of the questions
that arises is where to stick .o or .fasl files (the binary results of
a lisp compile-file).

I know Axiom has a directory setup for intermediate files, and I'm
going to try to make sense of that and teach asdf to respect it, but I
wanted to ask you specifically abou the whole mnt/linux/... storage of
the final results.

There is an asdf extension called asdf-binary-locations 
http://common-lisp.net/project/cl-containers/asdf-binary-locations/
I'm thinking this might come in handy for the Axiom build, since we
wind up stuffing our binaries in different directories from the source
files.  It is configurable according to the documentation, but also has
defaults.  According to this post:
http://groups.google.com/group/comp.lang.lisp/browse_frm/thread/72296ec04e5cb356/8d98a545b85c03f6

this scheme is used to keep things straight:
root/compiler-name-version-os-arch/path/to/file/foo.fasl 

This seems to be a variation on what we have with the mnt setup.  My
question - is the mnt structure currently in place required/hard
coded/have overwhelming logic behind it?  I sort of like the
compiler-name-version-os-arch directory namimg scheme, as it should
make it trivially simple to compile Axiom for multiple lisps on one
machine (even multiple versions of the same lisp!) and let ASDF keep
everything straight.  Is that binary structure something I shouldn't be
monkeying with?  

\start
Date: 25 Jun 2007 16:51:58 -0400
From: Stephen Wilson
To: list
Subject: Axisp news

Greetings all, FYI:

Today I updated the axisp repo with some new code.  The principle
change is a SPAD parser.  It is written in Lisp.

I am not promoting this code for release into Silver at this time.
For one, there are a few (minor) incompatibilities. Second, I view it
primarily as a development tool which will enable me to begin
substantial changes to the compiler proper.  However, in time, my hope
is that these efforts will eventually find their way into Silver.


For anyone interested in testing the new parser, be warned, this is
the first commit.  It is considered alpha quality.  I have been using
dhmatrix.spad and clifford.spad as a `representative' input.  There is
a lot of spad code the parser has never seen.

To explore these changes, note that they live in the remote branch
origin/axisp.  Anyone who would like some instruction as to how you
can view these changes with Git, I'd be pleased to provide the
details.  I will be updating the wiki page to contain more info in
this regard.


For those who compile a working checkout:  To enable the new
code you need to say `)set axisp on' at the Axiom command line.
Then, trying the new parser can be done with a standard `)co
foo.spad'.


Finally, any comments or feedback are greatly appreciated.

\start
Date: Mon, 25 Jun 2007 14:00:50 -0700 (PDT)
From: Cliff Yapp
To: Stephen Wilson
Subject: Re: Axisp news

--- Stephen Wilson wrote:

> 
> Greetings all, FYI:
> 
> Today I updated the axisp repo with some new code.  The principle
> change is a SPAD parser.  It is written in Lisp.

WOW.  Is it ANSI Common Lisp?

> For anyone interested in testing the new parser, be warned, this is
> the first commit.  It is considered alpha quality.  I have been using
> dhmatrix.spad and clifford.spad as a `representative' input.  There
> is a lot of spad code the parser has never seen.

Hmm.  How does it do with Martin's Guess package?

> To explore these changes, note that they live in the remote branch
> origin/axisp.  Anyone who would like some instruction as to how you
> can view these changes with Git, I'd be pleased to provide the
> details.  I will be updating the wiki page to contain more info in
> this regard.

I'll take a look, but it might be a little bit - summer is going to eat
some time :-/.

Thanks Steve for working on this!

\start
Date: 25 Jun 2007 17:05:17 -0400
From: Stephen Wilson
To: Cliff Yapp
Subject: Re: mnt binary storage

Hi Cliff,

I use asdf-binary-locations for private stuff, and I would imagine
that it would be usable in Axiom, but it would certainly be somewhat
involved to incorporate with the existing architecture so that you
actually get most of the benefits of using the tool.

For now, I would ask you to consider defining your own methods over
asdf:output-files, which enables you to say where particular types of
output should go.  This is a relatively straightforward process and
can be used to integrate with the existing scheme.  I would be happy to
supply the details, if needed.

\start
Date: Mon, 25 Jun 2007 16:09:06 -0500
From: Tim Daly
To: Cliff Yapp
Subject: binary naming scheme

There are 4 primary directories: src, int, obj, and mnt.
They can be located anywhere (including out of source builds)

The int directory contains system-independent, machine-generated code.
The obj directory contains system-dependent, machine-generated code.
The mnt directory contains the final ship tree. All else can be removed.

The obj and mnt directories contain a subdirectory that specifies the
system target. This target name is taken from the basename of the AXIOM
variable. Thus
   AXIOM=`pwd`/mnt/linux
creates
    obj/linux
    mnt/linux

but
   AXIOM=`pwd`/mnt/fedora5
creates
   obj/fedora5
   mnt/fedora5

Thus you can build for multiple target machines using the same src and int
subdirectories. The usual path was to use NFS to cross-mount the sources
and then use make to build on the target machine. Using this method it is
possible to build on multiple machines with different architecture in parallel.
This was heavily used when builds took 3 weeks.

The basename (linux, fedora5, whatever) selects a chunk out of the top
level Makefile.pamphlet. That chunk is used to create Makefile.whatever
which directs the build per architecture. Thus
   AXIOM=`pwd`/mnt/linux
selects and creates
   Makefile -> 
     Makefile.pamphlet (select linux chunk) -> 
       Makefile.linux

and
  AXIOM=`pwd`/mnt/fedora5
selects and creates
   Makefile -> 
     Makefile.pamphlet (select fedora5 chunk) -> 
       Makefile.fedora5

You can follow this scheme to create compiler-name-version-os-arch
   AXIOM=`pwd`/mnt/compiler-name-version-os-arch
which selects the chunk and creates the makefile:
   Makefile -> 
     Makefile.pamphlet (select compiler-name-version-os-arch chunk) -> 
       Makefile.compiler-name-version-os-arch
which creates the directories:
   int
   obj/compiler-name-version-os-arch
   mnt/compiler-name-version-os-arch
where 
   obj/compiler-name-version-os-arch contains machine-generated binaries
   mnt/compiler-name-version-os-arch contains a ship image for that arch

\start
Date: Mon, 25 Jun 2007 16:16:45 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: Axiom active branches

  Maybe your branch is really private and you were "forced"
to make it public.  However, build-improvements and wh-sandbox
are not private.  Please stop referring to them as private.
You're spearding confusion for no gain.

\start
Date: 25 Jun 2007 17:23:12 -0400
From: Stephen Wilson
To: Cliff Yapp
Subject: Re: Axisp news

Cliff Yapp writes:

> --- Stephen Wilson wrote:
> 
> > 
> > Greetings all, FYI:
> > 
> > Today I updated the axisp repo with some new code.  The principle
> > change is a SPAD parser.  It is written in Lisp.
> 
> WOW.  Is it ANSI Common Lisp?

Yes.  My main Lisp for axiom purposes is GCL2.6.8pre latest from cvs.
This is the only Lisp that I `support', but I have periodically
checked that sbcl and clisp accept the source.

> > For anyone interested in testing the new parser, be warned, this is
> > the first commit.  It is considered alpha quality.  I have been using
> > dhmatrix.spad and clifford.spad as a `representative' input.  There
> > is a lot of spad code the parser has never seen.
> 
> Hmm.  How does it do with Martin's Guess package?

I have not tested it.  I would be surprised if it worked.  The parser
handles a good chuck of the spad grammar but it is known to be
deficient in a few areas, and even intentionally incompatible in
others.  Perhaps I will use the guess package as `representative'
input during the next iteration of improvements.

> > To explore these changes, note that they live in the remote branch
> > origin/axisp.  Anyone who would like some instruction as to how you
> > can view these changes with Git, I'd be pleased to provide the
> > details.  I will be updating the wiki page to contain more info in
> > this regard.
> 
> I'll take a look, but it might be a little bit - summer is going to eat
> some time :-/.
> 
> Thanks Steve for working on this!

\start
Date: 25 Jun 2007 23:30:22 +0200
From: Martin Rubey
To: Stephen Wilson
Subject: Re: Axisp news

Stephen Wilson writes:

> > Hmm.  How does it do with Martin's Guess package?
> 
> I have not tested it.  I would be surprised if it worked.  The parser handles
> a good chuck of the spad grammar but it is known to be deficient in a few
> areas, and even intentionally incompatible in others.  Perhaps I will use the
> guess package as `representative' input during the next iteration of
> improvements.

I would urge you, not to.  I believe I use some hacks I'd rather have
non-working.  (I use them only because the proper way is not supported by SPAD)
Rather, PLEASE try to follow the Aldor User Guide.  Since Christian Aistleitner
wrote a parser for Aldor some time ago (in Aldor, sources being available from
himself, I believe), maybe you would like to get into contact with him.

Trying to model a parser after the current algebra is, in my opinion, a wast of
time. 

All the best and thanks for working on this,

\start
Date: Mon, 25 Jun 2007 14:32:06 -0700 (PDT)
From: Cliff Yapp
To: Martin Rubey
Subject: Re: Version numbers and merging improvements


> I find it extremely hard to classify many of the recent (i.e., last
> few months) changes in wh-sandbox as minor.  May well be that only 
> a single line in the algebra sources was modified, but still, if the
> result was wrong before and correct after, this may well affect long
> computations.

That's true, of course.  That's one of the reasons I hope we can
incorporate some formal proof software and be really sure our
implementation will produce correct results.
 
> Fortunate as we are that Axiom is gratis, I suggest that serious
> users should svn up as often as they can.

Yes, but they will also want to avoid the breakages that come with any
development cycle.  It's a tradeoff.

> But I admit that there are landmarks.  HyperDoc in wh-sandbox was one
> for me. Hm, in fact, I do not know of any other landmark.

HyperDoc has been the most recent user visible landmark.  Working
graphics was one as well.

> I don't care whether axiom uses autoconf or not, to be honest.  If
> Waldek and Gaby say autotools make maintainance easier, OK.  If Tim
> says, it doesn't, OK.

It's an indirect issue, true.  The consequence will be better
portability down the road.

> > > At least here in Austria, most people use wh-sandbox. 
> > 
> > Now, that's true.  Eventually, we should reach the point where
> > users should be using Gold by default.  
> 
> Cliff, please stop thinking about the future. 

On the project with the 30 year horizon, you want me to stop thinking
about the future?

> Well, one month is OK, but three months is certainly not *now*.  If
> you want to implement a versioning scheme, please implement one that
> works with the current situation.

But we do have one that works with the current situation -
yymm.branch.revision.  That's a development versioning scheme, and I
think it's a good one.  We should go with it for anything that's not
Gold.  Right now, that's everything useful - granted.  So we can
recommend new users try 0725.wh-sandbox.600 (or whatever the latest
revision is.)

It sounds like if we can make the right kind of change set, we can make
fairly rapid process on phasing things in to Silver.  If I ever get a
decent machine up and running again I'll try and help with that.  It
sounds like it should go:

1)  Tim's fix for the Win/Mac filename issues - then we can checkout on
multiple platforms
2)  Gaby's autoconf introdution.
3)  Working out the migration path from Silver as it currently exists
to Waldek's ANSI code.  Involved, but probably doable - I'll try to
help if I can.
4)  HyperDoc support.  This may come after #2 depending on details.
 
> If you implement one that works for Gold only, forget it.

No, no - not "works for Gold only" - it's FOR Gold.  That means right
now, it won't be very visible.  (I.e. it shouldn't annoy anybody.) 
Development versions should eventually be "behind the curtain" for
those who want to look, with releases being the public face of the
project.  Distributions are only going to want to build binaries for
distributions once in a while - they need a "let's include Axiom
version 5.1" target.  

Officially, the cvs Gold tree is the stable Axiom as put out by the
Axiom project.  That is a problem, but it is one I think we should
address rather than just throw up our hands fork with wh-sandbox.  We
have improvements to merge in, but Tim has a quality assurance process
to put them through and I can see why that should be done.  I have
little doubt they will pass - Waldek does good work - and there is
nothing to stop people from using any tree they wish in the meantime.

yymm.branch.revision will work fine for the current situation - when we
are ready to start going after market share, we want something more
conventional.  That future, where the project itself has a customer
ready version, is what I am thinking about.

So Martin, I'm off your radar - I'm in the future and can be ignored
:-).

I really want to be able to bring these efforts back into a unified
project, and I'd like to do what I can to help make that happen.  It
sounds like diff -Naur patches that isolate subjects are the key, so
I'll try to push in that direction.  It sounds like Tim has the first
one, Gaby is obviously the best qualified for the second, and the third
will be a lot of work to identify the purposes of various changes.

Tim - one question.  If Waldek is right and it proves very difficult to
produce working intermediate steps for these change sets (ANSI in
particular), would you settle for patches which implement changes that
relate to a concept but depend on another patch to actually reach a
working build state?  Otherwise we may wind up with a patching version
of a bootstrap problem, and that will be pure unmitigated nastiness for
minimal gain.

\start
Date: 25 Jun 2007 17:40:52 -0400
From: Stephen Wilson
To: Martin Rubey
Subject: Re: Axisp news

Martin Rubey writes:

> Stephen Wilson writes:
> 
> > > Hmm.  How does it do with Martin's Guess package?

> > I have not tested it.  I would be surprised if it worked.  The
> > parser handles a good chuck of the spad grammar but it is known to
> > be deficient in a few areas, and even intentionally incompatible
> > in others.  Perhaps I will use the guess package as
> > `representative' input during the next iteration of improvements.
 
> I would urge you, not to.  I believe I use some hacks I'd rather have
> non-working.  (I use them only because the proper way is not
> supported by SPAD)

Ok.  Thanks for the heads up.

> Rather, PLEASE try to follow the Aldor User Guide.  Since Christian
> Aistleitner wrote a parser for Aldor some time ago (in Aldor,
> sources being available from himself, I believe), maybe you would
> like to get into contact with him.

Grammatically, Spad is fairly similar to Aldor, as you know.  I am
actively thinking about Aldor features that I would like to integrate
with the compiler down the road.  However, I am not commiting to
cloning Aldor, as I feel there are shortcomings/difficulties.  The
same is true, or course, with Spad.  I would be happy to dicuss some
of my plans for enriching the compiler with features familiar to
Aldor if interested.

> Trying to model a parser after the current algebra is, in my
> opinion, a wast of time.

I agree. I am not attempting a replacement.  I dont care about being
able to parse the whole algebra.  

I would certainly like to encourage anyone to contribute their
thoughts on what an `ideal' language should be.

> All the best and thanks for working on this,

\start
Date: 25 Jun 2007 17:42:46 -0400
From: Camm Maguire
To: Waldek Hebisch
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

Greetings, and thanks again as always!

Waldek Hebisch writes:

> I wrote:
> > > But later I hit another one: I am getting messages like:
> > > 
> > > ;; Compiling stage0/ptyout.clisp.
> > > Segmentation violation: c stack ok:signalling errorError in error:
> > > ERROR TYPE-ERROR (DATUM #<FREE OBJECT 0000000001b5c888> EXPECTED-TYPE
> > >                         (OR METHOD-CALL FUNCTION)) NIL
> > > 
> 

Should be fixed now.  I'll put in a better fix soon.

> I have noticed that this error goes away if I change parameters to
> compiler link:  normally axiom has '(si::sgc-on t)' as part of init
> form, if I this to '(si::sgc-on nil)' I can proceed further.
> 

sgc should be ok now.

> Later I hit problem with setting memory parameters, gcl complained:
> 
> Condition in APPLY [or a callee]: INTERNAL-SIMPLE-ERROR: Can't set the limit for relocatable blocks to 1000.
> 
> This error went away when I commented Axiom code which tried to
> set memory parameteres.
> 

Hopefully these are no longer necessary for performance reasons, but
only testing will tell.  Hopefully this does not indicate memory is
short.  Can you do a (room) and :bt here?  Cannot reproduce.

> Later I met another error. Relevant (part of) log is below:
> 
> ;; Compiling def.lisp.
> ; (DEFUN B-MDEF ...) is being compiled.
> ;; Warning: The variable X is not used.
> ; (DEFUN DEF-INNER ...) is being compiled.
> ;; Warning: The variable SIGNATURE is not used.
> ;; End of Pass 1.
> ;; End of Pass 2.
> ;; OPTIMIZE levels: Safety=1 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
> ;; Finished compiling def.o.
> ;; Loading def.o
> Pass1 signature discovery on 86 functions ...
> ; (DEFUN B-MDEF ...) is being compiled.
> ;; Warning: The variable X is not used.
> ; (DEFUN DEF-INNER ...) is being compiled.
> ;; Warning: The variable SIGNATURE is not used.
> Pass1 signature discovery on 1 functions ...
> Mutual recursion detected: (|new2OldDefForm| |new2OldTran| |newDef2Def|
>                                LET_ERROR), recompiling |new2OldDefForm159046|
> Mutual recursion detected: (DEF-PROCESS B-MDEF DEF), recompiling DEF-PROCESS159056
> Mutual recursion detected: (DEFTRAN MKPROGN DEF-INNER ERRHUH DEF-LET
>                                     MK_LEFORM MK_LEFORM-CONS DEF-WHERE), recompiling DEF-WHERE159049
> Mutual recursion detected: (DEF-IS-REV DEF-IS-EQLIST), recompiling DEF-IS-EQLIST159053
> Pass1 signature discovery on 4 functions ...
> ; (DEFUN DEF-PROCESS159056 ...) is being compiled.
> ;; Warning: The variable X is not used.
> ; (DEFUN DEF-WHERE159049 ...) is being compiled.
> ;;; The declaration (DECLARE (OPTIMIZE (SAFETY 1))) was found in a bad place.
> ;;; The declaration (DECLARE (OPTIMIZE (SAFETY 1))) was found in a bad place.;;
> Warning: The variable SIGNATURE is not used.
> Pass1 signature discovery on 17 functions ...
> Compiling and loading new source in #<output stream "/tmp/gazonk_20011_4qT07D.lsp">
> ;; Compiling /tmp/gazonk_20011_4qT07D.lsp.
> ;; End of Pass 1.
> ;; End of Pass 2.
> ;; OPTIMIZE levels: Safety=1 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
> ;; Finished compiling /tmp/gazonk_20011_4qT07D0.o.
> ;; Compiling /tmp/gazonk_20011_4qT07D.lsp.
> ; (DEFUN DEF-PROCESS159056 ...) is being compiled.
> ;; Warning: The variable X is not used.
> ; (DEFUN DEF-WHERE159049 ...) is being compiled.
> ;;; The declaration (DECLARE (OPTIMIZE (SAFETY 1))) was found in a bad place.
> ;;; The declaration (DECLARE (OPTIMIZE (SAFETY 1))) was found in a bad place.;;
> Warning: The variable SIGNATURE is not used.
> No FASL generated.
> ;; Compiling /tmp/gazonk0.lsp.
> ;; End of Pass 1.
> ;; End of Pass 2.
> ;; OPTIMIZE levels: Safety=1 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
> ;; Finished compiling /tmp/gazonk_20011_4qT07D.o.
> ;; Loading /tmp/gazonk_20011_4qT07D.o
> ;; Loading /tmp/gazonk_20011_4qT07D0.o
>  ;; start address -T 0x10fd600 ;; Finished loading /tmp/gazonk_20011_4qT07D0.o
> ;; Loading /tmp/gazonk_20011_4qT07D1.o
> 
> Error:
> Fast links are on: do (si::use-fast-links nil) for debugging
> Signalled by LOAD.
> Condition in APPLY [or a callee]: INTERNAL-SIMPLE-ERROR: Unknown bfd format
> 

Should be fixed now -- thanks!

But please (setq si::*disable-recompile* t) for now in .../bin/lisp to
hasten compilation.  If axiom desires, it can make use of
(with-compilation-unit ...) to defer recompilation until the end of
large blocks.  There is still a little bug without this setting, as
the signature discovery gets trapped in an infinite loop.

Take care,


> Broken at APPLY.  Type :H for Help.
> 
> 
> /tmp/gazonk_20011_4qT07D1.o is empty, so no wonder that gcl can not
> load it.  I see no other files with name of form '/tmp/gazonk_20011_4qT07D1.*'
> (no .lsp file, no .c file).
> 
> BTW: it looks that at that stage I have 167 gazonk* files in the
> /tmp directory -- it looks that gcl is leaving trash files there. 

\start
Date: Mon, 25 Jun 2007 16:43:45 -0500 (CDT)
From: Gabriel Dos Reis
To: list
Subject: Automatic update of version number

   When I switched to Autoconf, one of the first thing I did was
to have the version number be part of configure and propagate
from there down -- Autoconf can do that very easily.

   One thing I put on my todo list but never felt an urgent need
to implement was an automatic record of the SVN revision number
in the banner as well has a nightly cron job to update the date.

   That is something I believe routine -- at least in GCC, that is
what we have.  To do that painlessly, you might want to create 
a simple file that contains only the branch information, the date,
and the revision number.  Then convince Autoconf to get revision
information from there (e.g. cat).  Set up a cron job on SF to daily
update the date.  Setup a commit script that automatically increment
the revision number in the file on every commit.

\start
Date: 25 Jun 2007 17:44:18 -0400
From: Camm Maguire
To: Stephen Wilson
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

Greetings!  Just interested, why do you execute si::top-level by hand?

Take care,

Stephen Wilson writes:

> Waldek Hebisch writes:
> 
> > Later I hit problem with setting memory parameters, gcl complained:
> > 
> > Condition in APPLY [or a callee]: INTERNAL-SIMPLE-ERROR: Can't set the limit for relocatable blocks to 1000.
> > 
> > This error went away when I commented Axiom code which tried to
> > set memory parameteres.
> 
> Unsure if its related, but I have hit similar problems after doing
> extensive wrok at the REPL then issuing (sys:top-level) which, IIFC,
> winds up in the calls to sys:allocate. 
> 
> Explicit call to gc in all cases so far has enabled me to continue.

\start
Date: Mon, 25 Jun 2007 23:45:35 +0200
From: Gregory Vanuxem
To: Waldek Hebisch
Subject: Re: Axiom under Windows

Le dimanche 24 juin 2007 =E0 14:03 +0200, Waldek Hebisch a =E9crit :

> Concerning writablep: I looked at your code.  But AFAICS we would
> need a separate version for each Lisp system.  And the code is
> actually more complicated than C version.  So I think it is better
> to call C version.  I still have to work out some details, but
> for writablep it seem to work.  To say the truth I would like
> to limit use writablep/readable just to (rare) sitations when
> one really needs them and eliminate them from other places.

Even in the algebra code (FileNameCategory) ? If I remember correctly
you suppressed several check of this type in the algebra. Does that mean
that you'll remove the readable? and consort functions ?

> Attached you will find a little Lisp file "ffi-tst.lisp" and a
> patch.  After applying the patch compiling Axiom will build
> a shared library "libspad.so" in the src subdirectory.  ATM one
> has to copy it by hand to "target/x86_64-unknown-linux/lib/" directory.
> Before installing "libspad.so" one has to compile "ffi-tst.lisp"
> (for Axiom, as it uses "BOOT" package) and copy resulting fasl
> to "target/x86_64-unknown-linux/lib/".  Once both are installed
> writablep should work OK.  Also some socket functions will work
> (but I have to work out "sock_get_string_buf" and fix various
> portablity problems including console handling before socket
> code will have any visible effect).

There is, apparently, no attachment to your mail. I would be glad to
look at your code.

\start
Date: Mon, 25 Jun 2007 16:51:20 -0500 (CDT)
From: Gabriel Dos Reis
To: Camm Maguire
Subject: Re: 2.7.0 reports

On Mon, 25 Jun 2007, Camm Maguire wrote:

| > This error went away when I commented Axiom code which tried to
| > set memory parameteres.
| > 
| 
| Hopefully these are no longer necessary for performance reasons, but
| only testing will tell. 

Thanks, Camm.  I have always meant to remove those memory parameters.
So, as soon as I get to build-improvemenets, I'll remove them and 
hopefully we will get some feedback.

| But please (setq si::*disable-recompile* t) for now in .../bin/lisp to
| hasten compilation. 

OK.

\start
Date: Tue, 26 Jun 2007 00:22:48 +0200 (CEST)
From: Waldek Hebisch
To: Gregory Vanuxem
Subject: Re: Axiom under Windows

Gregory Vanuxem wrote:
> Le dimanche 24 juin 2007 ? 14:03 +0200, Waldek Hebisch a =E9crit :
>
> > Concerning writablep: I looked at your code.  But AFAICS we would
> > need a separate version for each Lisp system.  And the code is
> > actually more complicated than C version.  So I think it is better
> > to call C version.  I still have to work out some details, but
> > for writablep it seem to work.  To say the truth I would like
> > to limit use writablep/readable just to (rare) sitations when
> > one really needs them and eliminate them from other places.
>
> Even in the algebra code (FileNameCategory) ? If I remember correctly
> you suppressed several check of this type in the algebra. Does that mean
> that you'll remove the readable? and consort functions ?
>

Yes, at some time we will have to rework FileNameCategory.  But
for both technical reasons (problem with bootstrap) and
nontechnical reasons (I do not want introduce now an incompatible
dialect od Spad) I wait with such change. 

> > Attached you will find a little Lisp file "ffi-tst.lisp" and a
> > patch.  After applying the patch compiling Axiom will build
> > a shared library "libspad.so" in the src subdirectory.  ATM one
> > has to copy it by hand to "target/x86_64-unknown-linux/lib/" directory.
> > Before installing "libspad.so" one has to compile "ffi-tst.lisp"
> > (for Axiom, as it uses "BOOT" package) and copy resulting fasl
> > to "target/x86_64-unknown-linux/lib/".  Once both are installed
> > writablep should work OK.  Also some socket functions will work
> > (but I have to work out "sock_get_string_buf" and fix various
> > portablity problems including console handling before socket
> > code will have any visible effect).
>
> There is, apparently, no attachment to your mail. I would be glad to
> look at your code.
>

Sorry I forgot to attach them -- I am sending them with this message.

--
                              Waldek Hebisch
Waldek Hebisch

--ELM1182810167-10392-0_

(in-package "BOOT")
;;; (use-package "SB-ALIEN")
#+sbcl 
(progn
     (SB-ALIEN::define-alien-routine
           ("writeablep" |writeablep|) SB-ALIEN::int
           (filename SB-ALIEN::c-string))

     (SB-ALIEN::define-alien-routine
           ("open_server" open_server) SB-ALIEN::int
           (server_name SB-ALIEN::c-string))
     (SB-ALIEN::define-alien-routine
          ("sock_get_int" sock_get_int) SB-ALIEN::int
          (purpose SB-ALIEN::int :in))
     (SB-ALIEN::define-alien-routine
          ("sock_send_int" sock_send_int) SB-ALIEN::int
          (purpose SB-ALIEN::int :in)
          (val SB-ALIEN::int :in))
     (SB-ALIEN::define-alien-routine
          ("sock_get_float" sock_get_float) SB-ALIEN::double
          (purpose SB-ALIEN::int :in))
     (SB-ALIEN::define-alien-routine
          ("sock_send_float" sock_send_float) SB-ALIEN::int
          (purpose SB-ALIEN::int :in)
          (num SB-ALIEN::double :in))
#|
     (define-alien-routine
          ("sock_get_string_buf" sock_get_string_buf_wrapper) int
          (purpose int :in)
          (...))
|#          
          
     (SB-ALIEN::define-alien-routine
          ("sock_send_string" sock_send_string) SB-ALIEN::int
          (purpose SB-ALIEN::int :in)
          (str SB-ALIEN::c-string))
     (SB-ALIEN::define-alien-routine
          ("sock_send_string_len" sock_send_string_len) SB-ALIEN::int
          (purpose SB-ALIEN::int :in)
          (str SB-ALIEN::c-string)
          (len SB-ALIEN::int :in))
     (SB-ALIEN::define-alien-routine ("server_switch" server_switch)
          SB-ALIEN::int)
#|
     (define-alien-routine ("sock_send_signal" sock_send_signal) int
          (purpose int :in)
          (sig int :in))
|#

)

--ELM1182810167-10392-0_

diff -ru --exclude=Makefile.in por/wh-20070527/src/interp/bookvol5.pamphlet wh-20070527.bb/src/interp/bookvol5.pamphlet
--- por/wh-20070527/src/interp/bookvol5.pamphlet	2007-05-27 17:01:40.000000000 +0200
+++ wh-20070527.bb/src/interp/bookvol5.pamphlet	2007-06-14 00:05:07.000000000 +0200
@@ -658,6 +658,18 @@
      (progn 
       (setq $openServerIfTrue nil) 
       (setq |$SpadServer| t)))))
+#+:sbcl
+ (let* ((ax-dir (|getEnv| "AXIOM"))
+        (spad-lib (concatenate 'string ax-dir "/lib/libspad.so"))
+        (sock-fasl (concatenate 'string ax-dir "/lib/ffi-tst.fasl")))
+     (when (axiom-probe-file spad-lib)
+         (sb-alien::load-shared-object spad-lib)
+         (load sock-fasl)
+         (let ((os (|openServer| $SpadServerName)))
+              (if (zerop os)
+                  (progn
+                       (setq $openServerIfTrue nil)
+                       (setq |$SpadServer| t))))))
 ;; We do the following test at runtime to allow us to use the same images
 ;; with Saturn and Sman.  MCD 30-11-95
 #+:CCL
diff -ru --exclude=Makefile.in por/wh-20070527/src/lib/Makefile.pamphlet wh-20070527.bb/src/lib/Makefile.pamphlet
--- por/wh-20070527/src/lib/Makefile.pamphlet	2007-05-27 17:01:54.000000000 +0200
+++ wh-20070527.bb/src/lib/Makefile.pamphlet	2007-06-14 00:05:08.000000000 +0200
@@ -41,6 +41,7 @@
 
 <<environment>>=
 core_sources = bsdsignal.c cfuns-c.c sockio-c.c
+core_objects = $(core_sources:.c=.$(OBJEXT))
 @
 
 
@@ -116,7 +117,7 @@
 .PRECIOUS: %.$(OBJEXT)
 
 %.$(OBJEXT): %.c $(axiom_c_macros_h)
-	$(CC) $(CCF) -c $(axiom_includes) $(AXIOM_X11_CFLAGS) $< -o $@
+	$(CC) -fPIC $(CCF) -c $(axiom_includes) $(AXIOM_X11_CFLAGS) $< -o $@
 @
 
 
@@ -168,7 +169,7 @@
 all: all-ax
 
 all-ax all-lib: stamp
-stamp: libspad.a $(other_objects)
+stamp: libspad.a libspad.so $(other_objects)
 	rm -f stamp
 	$(STAMP) stamp
 
@@ -176,6 +177,9 @@
 	$(AR) ru libspad.a $(libspad_a_objects)
 	$(RANLIB) libspad.a
 
+libspad.so: $(core_objects)
+	$(CC) -shared $(core_objects) -o $@
+
 <<C from pamphlet>>
 
 <<object from C>>

\start
Date: 25 Jun 2007 18:26:47 -0400
From: Stephen Wilson
To: Camm Maguire
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

Camm Maguire writes:

> Greetings!  Just interested, why do you execute si::top-level by hand?

Its just a hackish way of establishing bindings with dynamic extent
and quickly testing the effect on the system.  Executing the )fin
command at axiom toplevel returns to enclosing lisp repl.  Using
si:top-level lets me `nest' sessions.  I rarely do this, however.

> 
> Take care,
> 
> Stephen Wilson writes:
> 
> > Waldek Hebisch writes:
> > 
> > > Later I hit problem with setting memory parameters, gcl complained:
> > > 
> > > Condition in APPLY [or a callee]: INTERNAL-SIMPLE-ERROR: Can't set the limit for relocatable blocks to 1000.
> > > 
> > > This error went away when I commented Axiom code which tried to
> > > set memory parameteres.
> > 
> > Unsure if its related, but I have hit similar problems after doing
> > extensive wrok at the REPL then issuing (sys:top-level) which, IIFC,
> > winds up in the calls to sys:allocate. 
> > 
> > Explicit call to gc in all cases so far has enabled me to continue.

\start
Date: Mon, 25 Jun 2007 16:34:07 -0700 (PDT)
From: Cliff Yapp
To: Stephen Wilson
Subject: Re: mnt binary storage

--- Stephen Wilson wrote:

> Hi Cliff,
> 
> I use asdf-binary-locations for private stuff, and I would imagine
> that it would be usable in Axiom, but it would certainly be somewhat
> involved to incorporate with the existing architecture so that you
> actually get most of the benefits of using the tool.

OK, we'll leave consideration of that for stage two :-).

> For now, I would ask you to consider defining your own methods over
> asdf:output-files, which enables you to say where particular types of
> output should go.  This is a relatively straightforward process and
> can be used to integrate with the existing scheme.  I would be happy
> to supply the details, if needed.

Sounds good.  I'm busy thinking about the best way to generate
intermediate file names - I'm not sure if using random filenames is a
good idea because for rebuilds I would have to store the original
random mappings.  Doable, but a bit of a pain.  Once I've got that, it
should be just a case of implementing all the perform methods.

It would be nice to bootstrap Boot without having to dump a core - I'll
have to play around a little and see what the hurdles are.  Without
that, asdf can't build the entire Axiom from scratch in one shot as far
as I can tell - dumping core files ends a session.  Hmm.

\start
Date: Tue, 26 Jun 2007 02:03:14 +0200 (CEST)
From: Waldek Hebisch
To: Camm Maguire
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

Still tryinh gcl from 2007-06-23 with workarounds (sgc disabled),
and using (setq si::*disable-recompile* t).  The build went
further but I see another problem, the next image have problems
compiling files:

$ /var/tmp/hebisch/axp7/ax-build2/build/x86_64-unknown-linux/bin/depsys

GCL (GNU Common Lisp)  2.7.0 ANSI    Jun 23 2007 01:35:47
Source License: LGPL(gcl,gmp,pargcl), GPL(unexec,bfd,xgcl)
Binary License:  GPL due to GPL'ed components: (READLINE BFD UNEXEC)
Modifications of this banner must retain notice of a compatible license
Dedicated to the memory of W. Schelter

Use (help) to get some basic information on how to use GCL.

Temporary directory for compiler files set to /tmp/

>(si::use-fast-links nil)

NIL

>(compile-file "sfsfun.clisp" :output-file "sfsfun.o")

;; Compiling sfsfun.clisp.

Error:
Signalled by COMPILER::RESULT-TYPE-FROM-ARGS.
Condition in APPLY [or a callee]: INTERNAL-SIMPLE-PROGRAM-ERROR: COMPILER::RESULT-TYPE-FROM-ARGS [or a callee] requires more than two arguments.

Broken at APPLY.  Type :H for Help.
 1 (Continue) Retry compiling file "sfsfun.clisp".
 2 Retry compiling file "sfsfun.clisp".
 3 Return to top level.
BOOT>>:bt

#0   APPLY {loc0=#<compiled-function system:universal-error-handler>,loc1=program-error,loc...} [ihs=46]
#1   APPLY {loc0=#<compiled-function system:universal-error-handler>,loc1=program-error,loc...} [ihs=45]
#2   RESULT-TYPE-FROM-ARGS {loc0=complex,loc1=((long-float 0.0 0.0)),loc2=compiler::complex-propagator,loc3...} [ihs=41]
#3   C1SYMBOL-FUN {loc0=complex,loc1=(0.0),loc2=nil,loc3=0,loc4=1.0,loc5=0} [ihs=40]
#4   C1EXPR {form=(complex 0.0),loc1=((complex 0.0)),loc2=0} [ihs=39]
#5   C1EXPR* {loc0=(complex 0.0),loc1=#S(compiler::info type * ...)} [ihs=38]
#6   C1ARGS {info=(1.0 (complex 0.0)),loc1=#S(compiler::info type * ...),loc2=(#S(compiler::...} [ihs=37]
#7   C1SYMBOL-FUN {loc0=/,loc1=(1.0 (complex 0.0)),loc2=nil,loc3=nil,loc4=#<compiled-function func...} [ihs=36]
#8   C1EXPR {form=(/ 1.0 (complex 0.0)),loc1=((/ 1.0 (complex 0.0))),loc2=(return-from nil (...} [ihs=35]
#9   C1RETURN-FROM {loc0=(nil (/ 1.0 (complex 0.0))),loc1=((compiler::add-macro-callee block #<@000...} [ihs=34]
#10   C1SYMBOL-FUN {loc0=return-from,loc1=(nil (/ 1.0 (complex 0.0))),loc2=nil,loc3=nil,loc4=nil,lo...} [ihs=33]
#11   C1EXPR {form=(return-from nil (/ 1.0 (complex 0.0))),loc1=((return-from nil (/ 1.0 #)))...} [ihs=32]
#12   C1SYMBOL-FUN {loc0=return,loc1=((/ 1.0 (complex 0.0))),loc2=#<compiled-function return>,loc3=...} [ihs=31]
#13   C1EXPR {form=(return (/ 1.0 (complex 0.0))),loc1=((return (/ 1.0 #))),loc2=0} [ihs=30]
#14   C1EXPR* {loc0=(return (/ 1.0 (complex 0.0))),loc1=#S(compiler::info type t ...)} [ihs=29]
#15   C1TAGBODY {*tags*=((return (/ 1.0 #))),info=nil,loc2=#S(compiler::info type t ...),loc3=ni...} [ihs=28]
#16   C1SYMBOL-FUN {loc0=tagbody,loc1=((return (/ 1.0 #))),loc2=nil,loc3=#<compiled-function macroe...} [ihs=27]
#17   C1EXPR {form=(tagbody (return (/ 1.0 #))),loc1=((tagbody (return #))),loc2=nil} [ihs=26]
#18   C1PROGN {loc0=((tagbody (return #))),loc1=nil,loc2=nil,loc3=#<"COMPILER" package>} [ihs=25]
#19   C1DECL-BODY {loc0=nil,loc1=((tagbody (return #))),loc2=nil,loc3=nil,loc4=nil,loc5=nil,loc6=n...} [ihs=24]
#20   C1LET {*vars*=(nil (tagbody (return #))),loc1=nil,loc2=nil} [ihs=23]
#21   C1SYMBOL-FUN {loc0=let,loc1=(nil (tagbody (return #))),loc2=nil,loc3=nil,loc4=nil,loc5=nil} [ihs=22]
#22   C1EXPR {form=(let nil (tagbody (return #))),loc1=((let nil (tagbody #))),loc2=:ref-clb} [ihs=21]
#23   C1PROGN {loc0=((let nil (tagbody #))),loc1=nil,loc2=:ref,loc3=nil} [ihs]
#24   C1BLOCK {loc0=(nil (let nil (tagbody #))),loc1=t} [ihs=19]
#25   C1SYMBOL-FUN {loc0=block,loc1=(nil (let nil (tagbody #))),loc2=t,loc3=(t),loc4=#<"COMPILER" p...} [ihs=18]
#26   C1EXPR {form=(block nil (let nil (tagbody #))),loc1=((block nil (let nil #))),loc2=((bl...} [ihs=17]
#27   CO1SPECIAL-FIX-DECL {loc0=prog,loc1=(nil (return (/ 1.0 #))),loc2=((return (/ 1.0 #)))} [ihs=16]
#28   C1SYMBOL-FUN {loc0=prog,loc1=(nil (return (/ 1.0 #))),loc2=|nangenericcomplex|,loc3=nil,loc4=...} [ihs=15]
#29   C1EXPR {form=(prog nil (return (/ 1.0 #))),loc1=((prog nil (return #))),loc2=:ref-clb} [ihs=14]
#30   C1PROGN {loc0=((prog nil (return #))),loc1=|nangenericcomplex|,loc2=:ref,loc3=nil} [ihs=13]
#31   C1BLOCK {loc0=(|nangenericcomplex| (prog nil (return #))),loc1=nil} [ihs=12]
#32   C1SYMBOL-FUN {loc0=block,loc1=(|nangenericcomplex| (prog nil (return #))),loc2=nil,loc3=#<com...} [ihs=11]
#33   C1EXPR {form=(block |nangenericcomplex| (prog nil (return #))),loc1=((block |nangeneric...} [ihs=10]
#34   C1PROGN {loc0=((block |nangenericcomplex| (prog nil #))),loc1=t,loc2=nil,loc3=#<"COMPILE...} [ihs=9]
#35   C1DECL-BODY {loc0=nil,loc1=((block |nangenericcomplex| (prog nil #))),loc2=nil,loc3=nil,loc4...} [ihs=8]
#36   C1LAMBDA-EXPR {lambda-expr=(nil (prog nil (return #))),block-name=|nangenericcomplex|,block-it...} [ihs=7]
#37   T1DEFUN {loc0=(|nangenericcomplex| nil (prog nil (return #))),fname=(prog
nil (return (/...} [ihs=6]
#38   T1EXPR {loc0=(defun |nangenericcomplex| nil ...),loc1=(defun |nangenericcomplex| nil .....} [ihs=5]
#39   COMPILE-FILE1 {loc0="sfsfun.clisp",input-pathname=:output-file,output-file="sfsfun.o",o-file="...} [ihs=4]
#40   COMPILE-FILE {loc0="sfsfun.clisp",file=:output-file,args="sfsfun.o",loc3=(nil "sfsfun.clisp")...} [ihs=3]
#41   EVAL {loc0=nil,loc1=nil,loc2=nil,loc3=#<compiled-function compile-file>} [ihs=2]
BOOT>>

\start
Date: 25 Jun 2007 20:10:18 -0400
From: Stephen Wilson
To: Cliff Yapp
Subject: Re: mnt binary storage

Cliff Yapp writes:
[...]
> It would be nice to bootstrap Boot without having to dump a core - I'll
> have to play around a little and see what the hurdles are.  Without
> that, asdf can't build the entire Axiom from scratch in one shot as far
> as I can tell - dumping core files ends a session.  Hmm.

I was not aware that your goal was to actually build all of axiom
using asdf alone.  I thought the target was to get asdf handling
pamphlets?  Forgive me if I misunderstood.  

Dumping the images as is currently done yields the benefit that we
dont carry unneeded code into the final image.  This is, I feel,
important.

Driving the process using make is, IMHO, still preferred.  Make could
call out to an ASDF aware lisp at various stages to compile, load, and
save the system when appropriate.

\start
Date: Mon, 25 Jun 2007 17:33:01 -0700 (PDT)
From: Cliff Yapp
To: Stephen Wilson
Subject: Re: mnt binary storage

--- Stephen Wilson wrote:

> I was not aware that your goal was to actually build all of axiom
> using asdf alone.  I thought the target was to get asdf handling
> pamphlets?  Forgive me if I misunderstood.  

That's the first goal.  I hope to leverage that ability to be able to
build all of Axiom based on Lisp.  I don't insist on it, but it would
be nice.

> Dumping the images as is currently done yields the benefit that we
> dont carry unneeded code into the final image.  This is, I feel,
> important.

Agreed.  Whatever I come up with (if anything) will have to preserve
that advantage.

> Driving the process using make is, IMHO, still preferred.  Make could
> call out to an ASDF aware lisp at various stages to compile, load,
> and save the system when appropriate.

Yes.  That will probably be how it will be done at first.

\start
Date: 25 Jun 2007 21:41:45 -0400
From: Camm Maguire
To: Waldek Hebisch
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

Greetings, and thanks Waldek!  Should be fixed now.  (The format of
this report was very helpful.)

BTW, though sgc should be fine now, and it might be nice to confirm,
in general one should only put on sgc at the end of the axiom build
before saving the final image.  SGC is a read-only memory bifurcation
of the heap, and is useful when a large amount of permanent data has
been finalized and can be lifted from the GC algorithm.  In a rapidly
growing heap, sgc is slower.


Take care,

Waldek Hebisch writes:

> Still tryinh gcl from 2007-06-23 with workarounds (sgc disabled),
> and using (setq si::*disable-recompile* t).  The build went
> further but I see another problem, the next image have problems
> compiling files:
> 
> $ /var/tmp/hebisch/axp7/ax-build2/build/x86_64-unknown-linux/bin/depsys
> 
> GCL (GNU Common Lisp)  2.7.0 ANSI    Jun 23 2007 01:35:47
> Source License: LGPL(gcl,gmp,pargcl), GPL(unexec,bfd,xgcl)
> Binary License:  GPL due to GPL'ed components: (READLINE BFD UNEXEC)
> Modifications of this banner must retain notice of a compatible license
> Dedicated to the memory of W. Schelter
> 
> Use (help) to get some basic information on how to use GCL.
> 
> Temporary directory for compiler files set to /tmp/
> 
> >(si::use-fast-links nil)
> 
> NIL
> 
> >(compile-file "sfsfun.clisp" :output-file "sfsfun.o")
> 
> ;; Compiling sfsfun.clisp.
> 
> Error:
> Signalled by COMPILER::RESULT-TYPE-FROM-ARGS.
> Condition in APPLY [or a callee]: INTERNAL-SIMPLE-PROGRAM-ERROR: COMPILER::RESULT-TYPE-FROM-ARGS [or a callee] requires more than two arguments.
> 
> Broken at APPLY.  Type :H for Help.
>  1 (Continue) Retry compiling file "sfsfun.clisp".
>  2 Retry compiling file "sfsfun.clisp".
>  3 Return to top level.
> BOOT>>:bt
> 
> #0   APPLY {loc0=#<compiled-function system:universal-error-handler>,loc1=program-error,loc...} [ihs=46]
> #1   APPLY {loc0=#<compiled-function system:universal-error-handler>,loc1=program-error,loc...} [ihs=45]
> #2   RESULT-TYPE-FROM-ARGS {loc0=complex,loc1=((long-float 0.0 0.0)),loc2=compiler::complex-propagator,loc3...} [ihs=41]
> #3   C1SYMBOL-FUN {loc0=complex,loc1=(0.0),loc2=nil,loc3=0,loc4=1.0,loc5=0} [ihs=40]
> #4   C1EXPR {form=(complex 0.0),loc1=((complex 0.0)),loc2=0} [ihs=39]
> #5   C1EXPR* {loc0=(complex 0.0),loc1=#S(compiler::info type * ...)} [ihs=38]
> #6   C1ARGS {info=(1.0 (complex 0.0)),loc1=#S(compiler::info type * ...),loc2=(#S(compiler::...} [ihs=37]
> #7   C1SYMBOL-FUN {loc0=/,loc1=(1.0 (complex 0.0)),loc2=nil,loc3=nil,loc4=#<compiled-function func...} [ihs=36]
> #8   C1EXPR {form=(/ 1.0 (complex 0.0)),loc1=((/ 1.0 (complex 0.0))),loc2=(return-from nil (...} [ihs=35]
> #9   C1RETURN-FROM {loc0=(nil (/ 1.0 (complex 0.0))),loc1=((compiler::add-macro-callee block #<@000...} [ihs=34]
> #10   C1SYMBOL-FUN {loc0=return-from,loc1=(nil (/ 1.0 (complex 0.0))),loc2=nil,loc3=nil,loc4=nil,lo...} [ihs=33]
> #11   C1EXPR {form=(return-from nil (/ 1.0 (complex 0.0))),loc1=((return-from nil (/ 1.0 #)))...} [ihs=32]
> #12   C1SYMBOL-FUN {loc0=return,loc1=((/ 1.0 (complex 0.0))),loc2=#<compiled-function return>,loc3=...} [ihs=31]
> #13   C1EXPR {form=(return (/ 1.0 (complex 0.0))),loc1=((return (/ 1.0 #))),loc2=0} [ihs=30]
> #14   C1EXPR* {loc0=(return (/ 1.0 (complex 0.0))),loc1=#S(compiler::info type t ...)} [ihs=29]
> #15   C1TAGBODY {*tags*=((return (/ 1.0 #))),info=nil,loc2=#S(compiler::info type t ...),loc3=ni...} [ihs=28]
> #16   C1SYMBOL-FUN {loc0=tagbody,loc1=((return (/ 1.0 #))),loc2=nil,loc3=#<compiled-function macroe...} [ihs=27]
> #17   C1EXPR {form=(tagbody (return (/ 1.0 #))),loc1=((tagbody (return #))),loc2=nil} [ihs=26]
> #18   C1PROGN {loc0=((tagbody (return #))),loc1=nil,loc2=nil,loc3=#<"COMPILER" package>} [ihs=25]
> #19   C1DECL-BODY {loc0=nil,loc1=((tagbody (return #))),loc2=nil,loc3=nil,loc4=nil,loc5=nil,loc6=n...} [ihs=24]
> #20   C1LET {*vars*=(nil (tagbody (return #))),loc1=nil,loc2=nil} [ihs=23]
> #21   C1SYMBOL-FUN {loc0=let,loc1=(nil (tagbody (return #))),loc2=nil,loc3=nil,loc4=nil,loc5=nil} [ihs=22]
> #22   C1EXPR {form=(let nil (tagbody (return #))),loc1=((let nil (tagbody #))),loc2=:ref-clb} [ihs=21]
> #23   C1PROGN {loc0=((let nil (tagbody #))),loc1=nil,loc2=:ref,loc3=nil} [ihs]
> #24   C1BLOCK {loc0=(nil (let nil (tagbody #))),loc1=t} [ihs=19]
> #25   C1SYMBOL-FUN {loc0=block,loc1=(nil (let nil (tagbody #))),loc2=t,loc3=(t),loc4=#<"COMPILER" p...} [ihs=18]
> #26   C1EXPR {form=(block nil (let nil (tagbody #))),loc1=((block nil (let nil #))),loc2=((bl...} [ihs=17]
> #27   CO1SPECIAL-FIX-DECL {loc0=prog,loc1=(nil (return (/ 1.0 #))),loc2=((return (/ 1.0 #)))} [ihs=16]
> #28   C1SYMBOL-FUN {loc0=prog,loc1=(nil (return (/ 1.0 #))),loc2=|nangenericcomplex|,loc3=nil,loc4=...} [ihs=15]
> #29   C1EXPR {form=(prog nil (return (/ 1.0 #))),loc1=((prog nil (return #))),loc2=:ref-clb} [ihs=14]
> #30   C1PROGN {loc0=((prog nil (return #))),loc1=|nangenericcomplex|,loc2=:ref,loc3=nil} [ihs=13]
> #31   C1BLOCK {loc0=(|nangenericcomplex| (prog nil (return #))),loc1=nil} [ihs=12]
> #32   C1SYMBOL-FUN {loc0=block,loc1=(|nangenericcomplex| (prog nil (return #))),loc2=nil,loc3=#<com...} [ihs=11]
> #33   C1EXPR {form=(block |nangenericcomplex| (prog nil (return #))),loc1=((block |nangeneric...} [ihs=10]
> #34   C1PROGN {loc0=((block |nangenericcomplex| (prog nil #))),loc1=t,loc2=nil,loc3=#<"COMPILE...} [ihs=9]
> #35   C1DECL-BODY {loc0=nil,loc1=((block |nangenericcomplex| (prog nil #))),loc2=nil,loc3=nil,loc4...} [ihs=8]
> #36   C1LAMBDA-EXPR {lambda-expr=(nil (prog nil (return #))),block-name=|nangenericcomplex|,block-it...} [ihs=7]
> #37   T1DEFUN {loc0=(|nangenericcomplex| nil (prog nil (return #))),fname=(prog
> nil (return (/...} [ihs=6]
> #38   T1EXPR {loc0=(defun |nangenericcomplex| nil ...),loc1=(defun |nangenericcomplex| nil .....} [ihs=5]
> #39   COMPILE-FILE1 {loc0="sfsfun.clisp",input-pathname=:output-file,output-file="sfsfun.o",o-file="...} [ihs=4]
> #40   COMPILE-FILE {loc0="sfsfun.clisp",file=:output-file,args="sfsfun.o",loc3=(nil "sfsfun.clisp")...} [ihs=3]
> #41   EVAL {loc0=nil,loc1=nil,loc2=nil,loc3=#<compiled-function compile-file>} [ihs=2]
> BOOT>>

\start
Date: Tue, 26 Jun 2007 04:59:39 +0200 (CEST)
From: Waldek Hebisch
To: Camm Maguire
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

> Greetings, and thanks Waldek!  Should be fixed now.  (The format of
> this report was very helpful.)
>

Thanks for your message.  I tried new version from cvs and I again
have build problem:

;; Compiling ../lsp/gcl_callhash.lsp.
; (DEFUN DO-RECOMPILE ...) is being compiled.
;;; The declaration (DECLARE (IGNORE TPN)) was found in a bad place.
Error: ERROR "The tag (NIL) is undefined."
Signalled by COMPILER::CMPERR.
ERROR "The tag (NIL) is undefined."

Broken at COMPILER::CMPERR.  Type :H for Help.
SYSTEM>>make: *** [unixport/saved_pre_gcl] B=B3=B1d 255
 

The configure log is at:

http://www.math.uni.wroc.pl/~hebisch/prog/clogg

The build log is at:

http://www.math.uni.wroc.pl/~hebisch/prog/mlogg

The machine is 64-bit dual core Pentium D 805 running Debian etch.

\start
Date: Tue, 26 Jun 2007 07:45:31 +0200
From: Gernot Hueber
To: Camm Maguire
Subject: Re: New dynamic library access in GCL
Cc: Robert Boyer, Warren Hunt

Dear Camm,

this is great! Thanks for your effort related to this issue.

First I want to ask, is this version running on FreeBSD as well and how
can I access the source for this version?

Secondly, what types are supported by defdlfun and does it make sense to
finish cffi-gcl from your point. cffi seems to be the most actively
developed and used ffi for lisp and opens the door to use swig as
well :-). There is already some work done to support GCL, but still more
effort needed.

Best regards,

Gernot

On Fri, 2007-06-15 at 20:15 -0400, Camm Maguire wrote:
> Greetings!  GCL now has the ability to access arbitrary external
> shared library routines in a persitent fashion -- i.e. the binding is
> kept across image saves:
> 
> =============================================================================
> camm@intech19:/fix/t1/camm/debian/gcl/tmp/tmp/foo1$ unixport/saved_gcl
> GCL (GNU Common Lisp)  2.7.0 CLtL1    Jun 15 2007 19:45:46
> Source License: LGPL(gcl,gmp,pargcl), GPL(unexec,bfd,xgcl)
> Binary License:  GPL due to GPL'ed components: (XGCL READLINE BFD UNEXEC)
> Modifications of this banner must retain notice of a compatible license
> Dedicated to the memory of W. Schelter
> 
> Use (help) to get some basic information on how to use GCL.
> 
> Temporary directory for compiler files set to /tmp/
> 
> >(|libm|:|erf| 1.0)
> 
> Error: ERROR "Cannot find the external symbol erf in #<\"libm\" package>."
> Fast links are on: do (si::use-fast-links nil) for debugging
> Signalled by READ.
> ERROR "Cannot find the external symbol erf in #<\"libm\" package>."
> 
> Broken at READ.  Type :H for Help.
> >:q
> 
> >(si::show-lib-syms)
> 
> (LIB:|libm| 1074447640 #<"libm" package>) 
> (|libm|:|atan| 1094141472 #<compiled-function |libm|:|atan|>) 
> (|libm|:|ctan| 1094156208 #<compiled-function |libm|:|ctan|>) 
> (|libm|:|csqrt| 1094159152 #<compiled-function |libm|:|csqrt|>) 
> (|libm|:|clogf| 1094183232 #<compiled-function |libm|:|clogf|>) 
> (|libm|:|acosh| 1094146080 #<compiled-function |libm|:|acosh|>) 
> (|libm|:|ccosh| 1094153584 #<compiled-function |libm|:|ccosh|>) 
> (|libm|:|expf| 1094176432 #<compiled-function |libm|:|expf|>) 
> (|libm|:|atanhf| 1094176064 #<compiled-function |libm|:|atanhf|>) 
> (|libm|:|casin| 1094154864 #<compiled-function |libm|:|casin|>) 
> (|libm|:|cexpf| 1094181648 #<compiled-function |libm|:|cexpf|>) 
> (|libm|:|acosf| 1094175504 #<compiled-function |libm|:|acosf|>) 
> (|libm|:|sqrtf| 1094180496 #<compiled-function |libm|:|sqrtf|>) 
> (|libm|:|exp| 1094146864 #<compiled-function |libm|:|exp|>) 
> (|libm|:|atanh| 1094146512 #<compiled-function |libm|:|atanh|>) 
> (|libm|:|ccosf| 1094184128 #<compiled-function |libm|:|ccosf|>) 
> (|libm|:|ctanh| 1094156960 #<compiled-function |libm|:|ctanh|>) 
> (|libm|:|cosh| 1094146672 #<compiled-function |libm|:|cosh|>) 
> (|libm|:|ccoshf| 1094182688 #<compiled-function |libm|:|ccoshf|>) 
> (|libm|:|cosf| 1094172320 #<compiled-function |libm|:|cosf|>) 
> (|libm|:|atanf| 1094172032 #<compiled-function |libm|:|atanf|>) 
> (|libm|:|cos| 1094141792 #<compiled-function |libm|:|cos|>) 
> (|libm|:|cacos| 1094157584 #<compiled-function |libm|:|cacos|>) 
> (|libm|:|tanh| 1094145584 #<compiled-function |libm|:|tanh|>) 
> (|libm|:|ctanf| 1094185024 #<compiled-function |libm|:|ctanf|>) 
> (|libm|:|csinhf| 1094182144 #<compiled-function |libm|:|csinhf|>) 
> (|libm|:|tanf| 1094175168 #<compiled-function |libm|:|tanf|>) 
> (|libm|:|tan| 1094145536 #<compiled-function |libm|:|tan|>) 
> (|libm|:|asin| 1094146208 #<compiled-function |libm|:|asin|>) 
> (|libm|:|sinh| 1094150832 #<compiled-function |libm|:|sinh|>) 
> (|libm|:|csin| 1094155520 #<compiled-function |libm|:|csin|>) 
> (|libm|:|sinf| 1094175120 #<compiled-function |libm|:|sinf|>) 
> (|libm|:|cabs| 1094152304 #<compiled-function |libm|:|cabs|>) 
> (|libm|:|sin| 1094145488 #<compiled-function |libm|:|sin|>) 
> (|libm|:|catanhf| 1094187072 #<compiled-function |libm|:|catanhf|>) 
> (|libm|:|coshf| 1094176224 #<compiled-function |libm|:|coshf|>) 
> (|libm|:|catanh| 1094158672 #<compiled-function |libm|:|catanh|>) 
> (|libm|:|fabs| 1094144096 #<compiled-function |libm|:|fabs|>) 
> (|libm|:|catanf| 1094183504 #<compiled-function |libm|:|catanf|>) 
> (|libm|:|tanhf| 1094175216 #<compiled-function |libm|:|tanhf|>) 
> (|libm|:|acoshf| 1094175632 #<compiled-function |libm|:|acoshf|>) 
> (|libm|:|asinh| 1094141232 #<compiled-function |libm|:|asinh|>) 
> (|libm|:|csinh| 1094152928 #<compiled-function |libm|:|csinh|>) 
> (|libm|:|asinhf| 1094171792 #<compiled-function |libm|:|asinhf|>) 
> (|libm|:|atan2f| 1094175888 #<compiled-function |libm|:|atan2f|>) 
> (|libm|:|asinf| 1094175760 #<compiled-function |libm|:|asinf|>) 
> (|libm|:|sinhf| 1094180368 #<compiled-function |libm|:|sinhf|>) 
> (|libm|:|atan2| 1094146336 #<compiled-function |libm|:|atan2|>) 
> (|libm|:|csinf| 1094184448 #<compiled-function |libm|:|csinf|>) 
> (|libm|:|cabsf| 1094181552 #<compiled-function |libm|:|cabsf|>) 
> (|libm|:|fabsf| 1094174288 #<compiled-function |libm|:|fabsf|>) 
> (|libm|:|casinhf| 1094186160 #<compiled-function |libm|:|casinhf|>) 
> (|libm|:|logf| 1094179104 #<compiled-function |libm|:|logf|>) 
> (|libm|:|casinh| 1094157680 #<compiled-function |libm|:|casinh|>) 
> (|libm|:|clog| 1094154112 #<compiled-function |libm|:|clog|>) 
> (|libm|:|casinf| 1094183888 #<compiled-function |libm|:|casinf|>) 
> (|libm|:|ctanhf| 1094185616 #<compiled-function |libm|:|ctanhf|>) 
> (|libm|:|csqrtf| 1094187472 #<compiled-function |libm|:|csqrtf|>) 
> (|libm|:|log| 1094149536 #<compiled-function |libm|:|log|>) 
> (|libm|:|cacoshf| 1094186624 #<compiled-function |libm|:|cacoshf|>) 
> (|libm|:|cacosh| 1094158144 #<compiled-function |libm|:|cacosh|>) 
> (|libm|:|catan| 1094154432 #<compiled-function |libm|:|catan|>) 
> (|libm|:|cacosf| 1094186080 #<compiled-function |libm|:|cacosf|>) 
> (|libm|:|cexp| 1094152400 #<compiled-function |libm|:|cexp|>) 
> (|libm|:|acos| 1094145952 #<compiled-function |libm|:|acos|>) 
> (|libm|:|sqrt| 1094150976 #<compiled-function |libm|:|sqrt|>) 
> (|libm|:|ccos| 1094155168 #<compiled-function |libm|:|ccos|>) 
> (|libm|:|abs| 1090798240 #<compiled-function |libm|:|abs|>) 
> (LIB:|libc| 1074448272 #<"libc" package>) 
> (|libc|:|setjmp| 1090786864 NIL) 
> (|libc|:|feof| 1090993296 NIL) 
> (|libc|:|memset| 1091054096 NIL) 
> (|libc|:|getc| 1090994720 NIL) 
> (|libc|:|bzero| 1091054432 NIL) 
> (|libc|:|putc| 1090995664 NIL) 
> 
> >(in-package 'compiler)
> 
> #<"COMPILER" package>
> 
> COMPILER>(defdlfun (:double "erf" "libm.so") :double)
> 
> |libm|:|erf|
> 
> COMPILER>(compile *)
> 
> ;; Compiling /tmp/gazonk_18613_0.lsp.
> ;; End of Pass 1.  
> ;; End of Pass 2.  
> ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
> ;; Finished compiling /tmp/gazonk_18613_0.o.
> ;; Loading /tmp/gazonk_18613_0.o
>  ;; start address -T 0xa02000 ;; Finished loading /tmp/gazonk_18613_0.o
> #<compiled-function |libm|:|erf|>
> NIL
> NIL
> 
> COMPILER>(|libm|:|erf| 1.0)
> 
> 0.84270079294971489
> 
> COMPILER>(|libm|:|erf| 1.0s0)
> 
> Correctable error: TYPE-ERROR :DATUM 1.0S0 :EXPECTED-TYPE LONG-FLOAT NIL
> Fast links are on: do (si::use-fast-links nil) for debugging
> Signalled by EVAL.
> If continued: choose a new value
> TYPE-ERROR :DATUM 1.0S0 :EXPECTED-TYPE LONG-FLOAT NIL
> 
> Broken at EVAL.  Type :H for Help.
> COMPILER>>:q
> 
> Top level.
> COMPILER>(disassemble '(lambda (x) (|libm|:|erf| x)) nil)
> 
> ;; Compiling /tmp/gazonk_18613_0.lsp.
> ;; End of Pass 1.  
> ;; End of Pass 2.  
> ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
> ;; Finished compiling /tmp/gazonk_18613_0.o.
> 
> #include "gazonk_18613_0.h"
> void init_code(){do_init((void *)VV);}
> /*	local entry for function CMP-ANON	*/
> 
> static object LI1(V2)
> 
> object V2;
> {	 VMB1 VMS1 VMV1
> 	goto TTL;
> TTL:;
> 	{object V3 = (/* erf */(*LnkLI0)((V2)));VMR1
> 	(V3);}
> 	return Cnil;
> }
> static object  LnkTLI0(object first,...){object V1;va_list ap;va_start(ap,first);V1=(object )call_proc_new(((object)VV[0]),0,0,(void **)(void *)&LnkLI0,1,first,ap);va_end(ap);return V1;} /* erf */
> #(#(erf
>     (%INIT
>      . #((LET ((*DISABLE-RECOMPILE* T))
>            (MFSFUN 'CMP-ANON 0 1 0)
>            (ADD-HASH 'CMP-ANON '((T) T) '((erf (FLOAT) T))COMPILER
> libmerf-
>                '/tmp/gazonk_18613_0.lsp))
>          (DO-RECOMPILE)))))
> static object LI1();
> #define VMB1
> #define VMS1
> #define VMV1
> #define VMR1(VMT1) return(VMT1);
> #define VM1 0
> static void * VVi[2]={
> #define Cdata VV[1]
> (void *)(LI1)
> };
> #define VV (VVi)
> static object  LnkTLI0(object,...);
> static object  (*LnkLI0)() = (object (*)()) LnkTLI0;
> NIL
> 
> COMPILER>(disassemble '(lambda (x) (declare (long-float x)) (|libm|:|erf| x)) nil)
> 
> ;; Compiling /tmp/gazonk_18613_0.lsp.
> ;; End of Pass 1.  
> ;; End of Pass 2.  
> ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
> ;; Finished compiling /tmp/gazonk_18613_0.o.
> 
> #include "gazonk_18613_0.h"
> void init_code(){do_init((void *)VV);}
> /*	local entry for function CMP-ANON	*/
> 
> static double LI1(V2)
> 
> double V2;
> {	 VMB1 VMS1 VMV1
> 	goto TTL;
> TTL:;
> 	{double V3 = ((double(*)(double))dlerf)(V2);VMR1
> 	(V3);}
> }
> /*	global entry for the function CMP-ANON	*/
> 
> static void L1()
> {	register object *base=vs_base;
> 	base[0]=make_longfloat(LI1(lf(base[0])));
> 	vs_top=(vs_base=base)+1;
> }
> #(#(NIL
>     (%INIT
>      . #((MDL 'erf 'libm 1)
>          (LET ((*DISABLE-RECOMPILE* T))
>            (MF 'CMP-ANON 0)
>            (ADD-HASH 'CMP-ANON '((LONG-FLOAT) LONG-FLOAT)
>                '((erf (FLOAT) T))
> LISPLAMBDA!!,DECLAR,OPTIMIZ,SAFETY
> libmerf-
>                '/tmp/gazonk_18613_0.lsp))
>          (DO-RECOMPILE)))))
> static void L1();
> static double LI1();
> static void *dlerf;
> #define VMB1
> #define VMS1
> #define VMV1
> #define VMR1(VMT1) return(VMT1);
> #define VM1 0
> static void * VVi[2]={
> #define Cdata VV[1]
> (void *)(L1),
> (void *)(&dlerf)
> };
> #define VV (VVi)
> NIL
> 
> COMPILER>(funcall (compile nil  '(lambda (x) (|libm|:|erf| x))) 1.0)
> 
> ;; Compiling /tmp/gazonk_18613_0.lsp.
> ;; End of Pass 1.  
> ;; End of Pass 2.  
> ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
> ;; Finished compiling /tmp/gazonk_18613_0.o.
> ;; Loading /tmp/gazonk_18613_0.o
>  ;; start address -T 0x9e8b08 ;; Finished loading /tmp/gazonk_18613_0.o
> 0.84270079294971489
> 
> COMPILER>(funcall (compile nil  '(lambda (x) (declare (long-float x)) (|libm|:|erf| x))) 1.0)
> 
> ;; Compiling /tmp/gazonk_18613_0.lsp.
> ;; End of Pass 1.  
> ;; End of Pass 2.  
> ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
> ;; Finished compiling /tmp/gazonk_18613_0.o.
> ;; Loading /tmp/gazonk_18613_0.o
>  ;; start address -T 0xa08948 ;; Finished loading /tmp/gazonk_18613_0.o
> 0.84270079294971489
> 
> COMPILER>(si::save-system "/tmp/h")
> camm@intech19:/fix/t1/camm/debian/gcl/tmp/tmp/foo1$ /tmp/h
> GCL (GNU Common Lisp)  2.7.0 CLtL1    Jun 15 2007 19:45:46
> Source License: LGPL(gcl,gmp,pargcl), GPL(unexec,bfd,xgcl)
> Binary License:  GPL due to GPL'ed components: (XGCL READLINE BFD UNEXEC)
> Modifications of this banner must retain notice of a compatible license
> Dedicated to the memory of W. Schelter
> 
> Use (help) to get some basic information on how to use GCL.
> 
> Temporary directory for compiler files set to /tmp/
> 
> >(|libm|:|erf| 1.0)
> 
> 0.84270079294971489
> 
> >
> =============================================================================
> 
> Notes: 
> 
> 0) based on dlopen
> 1) Not yet tested on static linking
> 2) Cannot run such functions interpreted for the moment
> 3) compiling gives both a function with error checking, and an inline
>    providing single instuction access through a C pointer where
>    possible.
> 4) Plan on shipping a little blas, maybe mpi and lapack file to be
>    optionally loaded in the GCL distribution
> 5) package LIB contains libary name symbols bound to the dlopen
>    address of the library
> 6) each library has its own package with symbols bound to the external
>    function address.
> 7) symbols are created and linked on .o load if necessary
> 8) loaded .o code keeps a list of its external pointers in use, which
>    are then reset on image re-execution.
> 
> Enjoy!
> 

\start
Date: 26 Jun 2007 08:29:48 +0200
From: Martin Rubey
To: Stephen Wilson
Subject: Re: Axisp news

Stephen Wilson writes:

> > Rather, PLEASE try to follow the Aldor User Guide.  Since
> > Christian Aistleitner wrote a parser for Aldor some time ago (in
> > Aldor, sources being available from himself, I believe), maybe you
> > would like to get into contact with him.
 
> Grammatically, Spad is fairly similar to Aldor, as you know.  I am
> actively thinking about Aldor features that I would like to
> integrate with the compiler down the road.  However, I am not
> commiting to cloning Aldor, as I feel there are
> shortcomings/difficulties.

I would really like to know what shortcomings you mean here.  I know of only
very few, and these are - in my opinion - really difficult questions:

* the problem of needing both AbelianMonoid as well as Monoid.

* certain difficulties transforming Tuples

> I would be happy to dicuss some of my plans for enriching the compiler with
> features familiar to Aldor if interested.

For a start (which will keep you busy the next few months I guess), there are
the following features SPAD needs badly.  Top priorities first:

* types and functions should become truly first class objects.  Currently, SPAD
  distinguishes between functions within a domain or package (eg., + or
  integrate) and domain constructors (like Fraction or Complex).  This
  distinction has to go away.  For example, I need to have the following
  signature allowed:

  Plus(
    F: (L: LabelType) -> CombinatorialSpecies L,
    G: (L: LabelType) -> CombinatorialSpecies L
  )(L: LabelType): CombinatorialSpecies(L) == add {...}

  I.e., F and G are functions that produce domains, and Plus(F, G) returns
  another such function.

  It goes without saying that I need full support for dependent types.

* Currently exports may be conditional, but only in a very narrow sense: only
  "has" and "is" statements are allowed in the condition.  This is too
  restrictive, as the example of the "Complex" constructor shows, where we want
  to export "Field" only if -1 is not a square root in the ground ring.

* It should be possible to define types recursively, as detailed in the Aldor
  User Guide

* Generators

> I would certainly like to encourage anyone to contribute their thoughts on
> what an `ideal' language should be.

I'm afraid that attempting to have an ideal language results in yet another
useless language in the end.  Too many people tried to do that, and only very
very few, very very gifted people succeeded.  Aldor is a pretty good language
for doing mathematics.

\start
Date: 26 Jun 2007 08:35:12 +0200
From: Martin Rubey
To: Cliff Yapp
Subject: Re: Version numbers and merging improvements

Cliff Yapp writes:

> > Cliff, please stop thinking about the future. 
> 
> On the project with the 30 year horizon, you want me to stop thinking about
> the future?

No, I just would prefer if you keep the present in mind.

> > Well, one month is OK, but three months is certainly not *now*.  If you
> > want to implement a versioning scheme, please implement one that works with
> > the current situation.
> 
> But we do have one that works with the current situation -
> yymm.branch.revision.

But it's not implemented.  In a parallel email, Gaby pointed out how this could
be done.  Maybe you could take an afternoon to implement it for
build-improvements, wh-sandbox and trunk.  That would make me very happy.

> It sounds like it should go:
> 
> 1) 
> 2) 
> 3) 
> 4) 

:-)

\start
Date: 26 Jun 2007 04:59:27 -0400
From: Stephen Wilson
To: Martin Rubey
Subject: Re: Axisp news

Martin Rubey writes:

> Stephen Wilson writes:
> 
> > > Rather, PLEASE try to follow the Aldor User Guide.  Since Christian Aistleitner
> > > wrote a parser for Aldor some time ago (in Aldor, sources being available from
> > > himself, I believe), maybe you would like to get into contact with him.
> > 
> > Grammatically, Spad is fairly similar to Aldor, as you know.  I am actively
> > thinking about Aldor features that I would like to integrate with the
> > compiler down the road.  However, I am not commiting to cloning Aldor, as I
> > feel there are shortcomings/difficulties.
> 
> I would really like to know what shortcomings you mean here.  

Most of them are detailed in `The Aldor Type System' by E. Poll and
S. Thompson.

Another shortcoming relates to `first class types'.  One can generate
a new type at run time, but there is no elegant mechanism in place to
recover the exact type.  Consider:

          mkMod(n : Integer) : IntegerMod( ? ) ==
                                   IntegerMod(compute(n))

If domains and categories are truly first class, we need a way to
compute with them as such.  There needs to be a simple logic
associated with the type language which could help recover such
bindings lost to an inner scope.  Im considering ways of introducing a
form of pattern matching over type expressions which could accommodate
this situation.  See below.

In addition, IIRC (its been a while since I played with aldor), there
are real problems with how constants are treated.  In short, they are
not really constants.  I remeber seeing code such as:

        add!(r: %, s: %, t: %) : % == 
                 if one? % or zero? % then s + t else ...

To work around the fact that the destructive add would modify the
constants `0' or `1', leading to predictable surprises.  The
imperative aspect of the language needs to be more carefully
considered, IMHO, especially w.r.t the semantics of a types
parametrized over (possibly mutable) values.

One could say that a constant can only be used in a type expression,
but thats rather draconian.  Moreover, it does not play nice with type
constructing functions like `mkMod' above.

> I know of only
> very few, and these are - in my opinion - really difficult questions:
> 
> * the problem of needing both AbelianMonoid as well as Monoid.

Its been mentioned before that OBJ has a facility for defining these
kinds of relationships.  A solution is likely to derive from there.

> * certain difficulties transforming Tuples

I assume your talking about the issues raised in the article I
mentioned above?

> > I would be happy to dicuss some of my plans for enriching the compiler with
> > features familiar to Aldor if interested.
> 
> For a start (which will keep you busy the next few months I guess), there are
> the following features SPAD needs badly.  Top priorities first:
> 
> * types and functions should become truly first class objects.  Currently, SPAD
>   distinguishes between functions within a domain or package (eg., + or
>   integrate) and domain constructors (like Fraction or Complex).  This
>   distinction has to go away.  For example, I need to have the following
>   signature allowed:
> 
>   Plus(
>     F: (L: LabelType) -> CombinatorialSpecies L,
>     G: (L: LabelType) -> CombinatorialSpecies L
>   )(L: LabelType): CombinatorialSpecies(L) == add {...}
> 
>   I.e., F and G are functions that produce domains, and Plus(F, G) returns
>   another such function.
> 
>   It goes without saying that I need full support for dependent types.

Yes.  I agree that these things are desirable.  I will be working on
adding such facilities.  Id like to improve the syntax a bit, though.
For example, its common to write things like:

           D(R : Ring, P : Polynomial R) : ... == ...

Id like to introduce the ability to do a form of `pattern matching' on
the types, so that the above would read:

           D(P : Polynomial (R : Ring)) : ... == ...

For such things to work, one would need to enforce case sensitivity on
values, domains and categories to separate value expressions from type
expressions.  The system I have in mind would be roughly based on the
`:' operator.  Quick examples:

         x : D        -- Bind x to a value of domain D.  We know x is a
                         value of a domain as it is lowercase.

         D : C        -- Bind D to a domain of category C.  We know D
                         is a domain as it is uppercased.

         x : D : C    -- Bind x to a value of domain D, D to a domain of
                         category C.

You could have wildcards to ignore certain values, so `x : _ : C'
would bind x to the value of _some_ domain which has category C.

Such basics would allow one to give a type to the mkMod function
above:
       
          mkMod(n : Integer) : IntegerMod(_) ==
                                   IntegerMod(compute(n))

Here the return type contains an explicit wildcard variable.  If
IntegerMod were an overloaded function, one might write `IntegerMod(_
: Integer)' to remove ambiguity.

Such things could allow one to use a form of pattern matching over
types in order to recover a binding for the dynamic component. 

> * Currently exports may be conditional, but only in a very narrow sense: only
>   "has" and "is" statements are allowed in the condition.  This is too
>   restrictive, as the example of the "Complex" constructor shows, where we want
>   to export "Field" only if -1 is not a square root in the ground ring.

I have not spent a terrible amount of time on this issue.  However
arbitrary expressions lead immediately to undecidability.  Again, we
need to find ways to lift runtime properties back into the static type
system in a graceful manner.  

> * It should be possible to define types recursively, as detailed in the Aldor
>   User Guide

Agreed.  My work on the compiler will be taking this into account.

> * Generators

This will not be much of an issue, as the semantics are quite clear
and not difficult to implement.  I really would like to see
generators.

In addition, we also need exceptions, as they provide an important
runtime mechanism to enforce invarients that the compiler could not
statically check.

> > I would certainly like to encourage anyone to contribute their thoughts on
> > what an `ideal' language should be.
> 
> I'm afraid that attempting to have an ideal language results in yet another
> useless language in the end.  Too many people tried to do that, and only very
> very few, very very gifted people succeeded.  Aldor is a pretty good language
> for doing mathematics.

Yep, its pretty good.  I may not be the sharpest knife in the drawer,
but I'll take a stab at improving it.  I know that `ideal' is a
pipe-dream.

\start
Date: 26 Jun 2007 12:20:13 +0200
From: Martin Rubey
To: Stephen Wilson
Subject: Re: Axisp news
Cc: Christian Aistleitner, Ralf Hemmecke

Dear Stephen,

many thanks for your detailed answer.  I must admit however, that I dislike
your idea writing

   D(P : Polynomial (R : Ring)) : ... == ...

for

   D(R : Ring, P : Polynomial R) : ... == ...

Isn't this just syntactic sugar?  My feeling (!) is that this will pose more
questions than answers.  Enforcing case sensitivity on values, domains and
categories also does not look very appealing to me, sorry.

In any case, I'd like to point you again to Christian Aistleitner, who seems to
have thought a lot about issues about Aldor semantics.

To look at OBJ is probably a good idea, though.

> Another shortcoming relates to `first class types'.  One can generate a new
> type at run time, but there is no elegant mechanism in place to recover the
> exact type.  Consider:
> 
>           mkMod(n : Integer) : IntegerMod( ? ) ==
>                                    IntegerMod(compute(n))

I'm not absolutely sure what you mean here, since IntegerMod(compute(n)) is
certainly not of type IntegerMod( ? ), no matter what the ? will be.

Note that a type is allowed to export its "parameters",
RectangularMatrixCategory does that.

> In addition, IIRC (its been a while since I played with aldor), there
> are real problems with how constants are treated.  In short, they are
> not really constants.  I remeber seeing code such as:
> 
>         add!(r: %, s: %, t: %) : % == 
>                  if one? % or zero? % then s + t else ...

I could not find code like that -- apart from the typo, you probably meant

         add!(r: %, s: %, t: %) : % == 
                  if one? r or zero? r then s + t else ...

> To work around the fact that the destructive add would modify the constants
> `0' or `1', leading to predictable surprises.  The imperative aspect of the
> language needs to be more carefully considered, IMHO, especially w.r.t the
> semantics of a types parametrized over (possibly mutable) values.

Yes, constants may contain mutable data.  But that's just as in other
languages.  It is true that you can say

l: List Integer == [1,2,3];
l.1 := 4;

but in my opinion, you are not really modifying l, but rather l.1, and that's a
different story.

> > * certain difficulties transforming Tuples
> 
> I assume your talking about the issues raised in the article I mentioned
> above?

possibly, but Ralf knows better.  Maybe you want to join our discussion on how
to implement multisort species in Aldor?  There, we are pushing the limits of
Aldor, I guess.  Also, the parser and domain generator I wrote shows some
features one may want to have.

\start
Date: 26 Jun 2007 12:55:59 +0200
From: Martin Rubey
To: Stephen Wilson,  Christian Aistleitner, Ralf Hemmecke
Subject: Re: Axisp news

Martin Rubey writes:

> > > * certain difficulties transforming Tuples
> > 
> > I assume your talking about the issues raised in the article I mentioned
> > above?

I just checked.  Although I'm still not completely sure, but I think the
problem we have is that Tuples are *not quite* first class citizens, quite
contrary to the recommendation of PollThompson.

In any case, I think the best way to see this problem is to join our
discussion.

\start
Date: Tue, 26 Jun 2007 14:19:17 +0200
From: Ralf Hemmecke
To: Martin Rubey
Subject: Problem kTuple wish 2.
Cc: Christian Aistleitner

>>>> * certain difficulties transforming Tuples
>>> I assume your talking about the issues raised in the article I mentioned
>>> above?

> I just checked.  Although I'm still not completely sure, but I think the
> problem we have is that Tuples are *not quite* first class citizens, quite
> contrary to the recommendation of PollThompson.

Suppose you want a constructor like

M(T: Tuple Cat): MCat(T) == add {...}

for some given category Cat (For simplicity, lets say

   define Cat: Category == with {=:(%,%)->Boolean}

. The question now is how do I define MCat and the corresponding add 
{...} in such a way that I am able to generate an element of M in a 
simple form.

Basically, I want to say...

import from Integer, String, Boolean;
import from M(Integer, String);
import from M(String, String, Boolean);
a := m(4,"a");
b := m("x", "y", true);

Do you have an idea how to define the function m generically?

Also I would probably like to have

s: String := b.2;
i: Integer := a.1;
q: Boolean := b.3;

Try to define this apply function.

Important, I want to have as much type safety as possible, i.e. If I 
would have written

c := m(1, "x", false);

the compiler should already shout that the type of the first argument 
doesn't fit.

\start
Date: Tue, 26 Jun 2007 13:36:33 +0200
From: Ralf Hemmecke
To: Stephen Wilson
Subject: Re: Axisp news

>> * the problem of needing both AbelianMonoid as well as Monoid.
> 
> Its been mentioned before that OBJ has a facility for defining these
> kinds of relationships.  A solution is likely to derive from there.

Could you give a short account on how this code looks in OBJ?

\start
Date: Tue, 26 Jun 2007 13:46:57 +0200
From: Ralf Hemmecke
To: Martin Rubey
Subject: Re: Axisp news
Cc: Christian Aistleitner

> Yes, constants may contain mutable data.  But that's just as in other
> languages.  It is true that you can say
> 
> l: List Integer == [1,2,3];
> l.1 := 4;
> 
> but in my opinion, you are not really modifying l, but rather l.1, and that's a
> different story.

And I would even need mutable constants. I want to define a powerseries

y = 1 + x * y*y

as a constant. The only thing I want a user then to do is to ask for 
coefficients. But in order to provide such an infinite constant I need a 
way to compute it without having the compiler run infinitely long.

\start
Date: Tue, 26 Jun 2007 15:05:03 +0200 (CEST)
From: Waldek Hebisch
To: Tim Daly
Subject: Re: Version numbers and merging improvements

I wrote:
> On more basic level: currently I can not build out of the box
> gold or silver.  Silver recently made big progress: it used to
> fail early in the build process, now it fails during graphic
> build (it can not find libXpm.a).

Tim Daly wrote:
> Waldek,
> 
> Try using AXIOM=`pwd`/mnt/fedora5 instead of `pwd`/mnt/linux
> 

I would like to correct what I wrote above.  I made a mistake
and tried to build silver on machine where libXpm.a was not
intalled.  The build works when machine has libXpm.a installed
(at least it worked on 64-bit gentoo).

\start
Date: Tue, 26 Jun 2007 06:07:07 -0700 (PDT)
From: Cliff Yapp
To: Martin Rubey
Subject: Re: Version numbers and merging improvements

> > But we do have one that works with the current situation -
> > yymm.branch.revision.
> 
> But it's not implemented.  In a parallel email, Gaby pointed out how
> this could be done.  Maybe you could take an afternoon to implement
> it for build-improvements, wh-sandbox and trunk.  That would make me
> very happy.

That sounds doable.  I'm going to make another attempt at getting a
seriously working computer today - once I am up and running again
(fingers crossed), I'll attempt this.

Now, one question - as far as I can tell, trunk and the other branches
will be using different mechanisms to deal with this (obviously, as
some have autoconf and some don't).  Also, it will be necessary to run
svn (and maybe git, cvs or arch) commands to get the information
needed, and the commands to do so will probably vary somewhat depending
on platform.

I'll take a look at following Gaby's hints and make a file that
contains the key information for autoconf (or whatever) to target. 
That file could be script updated or hand updated as needed (say on a
platform where the script doesn't work).  I'll start on a pamphlet
file.  I guess for windows something like this would be done with a
.bat script?  Or can I assume sh since we will need the Windows compile
environment anyway?

Of course, for tarballs and binaries generated from development trees
the convention can be adopted straight off.  So a tarball made from
wh-sandbox revision 607 on July 1st 2007 would be:

axiom-20070701.wh-sandbox.607.tar.gz

and a binary compiled from that tree would be:

axiom-windows-20070701.wh-sandbox.607.exe

I like it.

\start
Date: 26 Jun 2007 16:04:21 +0200
From: Martin Rubey
To: Cliff Yapp
Subject: Re: Version numbers and merging improvements

Cliff Yapp writes:

> I'll take a look at following Gaby's hints and make a file that
> contains the key information for autoconf (or whatever) to target. 
> That file could be script updated or hand updated as needed (say on a
> platform where the script doesn't work).  I'll start on a pamphlet
> file.  

For svn

LC_ALL=C svn info | grep "Last Changed Rev:"

might be appropriate (as already pointed out by Ralf), although I do not know
how stable "Last Changed Rev:" is.

It seems that git uses a different sort of revision numbers, and I do not know
the appropriate command there.

In any case, I guess that it will be enough to provide scripts for git and svn
for the moment, don't you think?

\start
Date: Tue, 26 Jun 2007 16:22:28 +0200 (CEST)
From: Waldek Hebisch
To: Tim Daly
Subject: Dependencies

I promised to write about dependecies in build machinery.  First
I would like classify changes to build process:
1) adding autoconf part (configure.ac.pamphlet + config subdirectory)
2) changes to Makefiles
3) new directory layout
4) improvements to tools (notably document script and bootsys)
5) fixes and adjustments to sources so they work with new buuild
   process

Now dependencies:

Autoconf part modifies Makefiles, but reasonable effort we can
disable modification of Makefiles, so it can go into trunk
doing little good but no harm.

Makefiles assume new directory layout.  Makefiles depend on
enhanced document and bootsys (more precisely, interp Makefile
need fixes to bootsys).  New interp Makefile uses bootsys to
translate several files which previously was translated using
depsys.  This requires many changes to interp files and also
some bootsys fixes.

bootsys sources were reorganized, filenames had changed, so
current bootsys requires new Makefiles.

new directory layout forced updates to pathnames embedded in
sources, this affect interpreter, hypertex program and
hyperdoc pages.

I may have missed some, but the above are main dependencies
in build-improvements.

In wh-sandbox there are extra dependencies:

algebra bootstrap requires some interpreter changes. There is
one simple change that I could list just now, but I am affraid
that I had also to correct some problems with uninitialized
variables.

For ANSI compatibility (and easier support for multiple implementations)
in first stage wh-sandbox build "standarized" Lisp image.  This Lisp
image presents uniform interface to a number of system dependent
routines.  So, in current wh-sandbox interp build depends on this
changed Lisp image.

Finally, in wh-sandbox .pht pages are generated.  This depends on
fixes to hypertex program, interpeter and libspad.

\start
Date: Tue, 26 Jun 2007 16:25:01 +0200
From: Ralf Hemmecke
To: list
Subject: Axiom at version 3.4?

Ooops. There is already version 3.4 of Axiom. Very interesting. ;-)

http://rpmfind.net/linux/RPM/mandriva/2007.1/i586/media/contrib/release/axiom-3.4-0.20050901.1mdk.i586.html

\start
Date: Tue, 26 Jun 2007 07:30:06 -0700 (PDT)
From: Cliff Yapp
To: Martin Rubey
Subject: Re: Version numbers and merging improvements

--- Martin Rubey wrote:

> For svn
> 
> LC_ALL=C svn info | grep "Last Changed Rev:"
> 
> might be appropriate (as already pointed out by Ralf), although I do
> not know how stable "Last Changed Rev:" is.
> 
> It seems that git uses a different sort of revision numbers, and I do
> not know the appropriate command there.
> 
> In any case, I guess that it will be enough to provide scripts for
> git and svn for the moment, don't you think?

I should think so.  Thanks!

\start
Date: Tue, 26 Jun 2007 16:30:01 +0200 (CEST)
From: Waldek Hebisch
To: Martin Rubey
Subject: Re: Version numbers and merging improvements

Martin Rubey wrote:
> Cliff Yapp writes:
> 
> > I'll take a look at following Gaby's hints and make a file that
> > contains the key information for autoconf (or whatever) to target. 
> > That file could be script updated or hand updated as needed (say on a
> > platform where the script doesn't work).  I'll start on a pamphlet
> > file.  
> 
> For svn
> 
> LC_ALL=C svn info | grep "Last Changed Rev:"
> 
> might be appropriate (as already pointed out by Ralf), although I do not know
> how stable "Last Changed Rev:" is.
> 

Note that checked out source should work without svn (think about source
tree copied to a machine without network access).  Gaby proposed
script running on the svn server and that should be fine.  Somebody
just has to work out how to install such script on SourceForge.
Also, while script should be simple testing on SourceForge may be tricky,
so somebody having an svn server should probably first test such
script on their own server and only later install it on SourceForge.

\start
Date: Tue, 26 Jun 2007 11:07:10 -0400
From: Bill Page
To: Ralf Hemmecke
Subject: Re: Axiom at version 3.4?

On 6/26/07 Ralf Hemmecke wrote:
> Ooops. There is already version 3.4 of Axiom. Very interesting. ;-)
> http://rpmfind.net/linux/RPM/mandriva/2007.1/i586/media/contrib/release/axiom-3.4-0.20050901.1mdk.i586.html
>

I think Tim has defined at least axiom version 3.6 ((June 2005). See:

http://cvs.savannah.gnu.org/viewvc/axiom/axiom

\start
Date: 26 Jun 2007 17:18:10 +0200
From: Martin Rubey
To: Waldek Hebisch
Subject: Re: Version numbers and merging improvements

Waldek Hebisch writes:

> Note that checked out source should work without svn (think about source tree
> copied to a machine without network access).

> Gaby proposed script running on the svn server and that should be fine.
> Somebody just has to work out how to install such script on SourceForge.
> Also, while script should be simple testing on SourceForge may be tricky, so
> somebody having an svn server should probably first test such script on their
> own server and only later install it on SourceForge.

Hm, there are really two possibilities:

* run on the svn server

  pro: will work always, once properly set up

  cons: probably not so easy to set up.  How often should cron run to make
        wrong revision number assignment unlikely?

* run during build on the builders machine

  pro: probably easy to set up, although several versions depending on the
       version control software are necessary (i.e., git, svn)

  cons: does not work if built from source only tree.

Don't know what to recommend.

\start
Date: Tue, 26 Jun 2007 10:27:46 -0500 (CDT)
From: Gabriel Dos Reis
To: list
Subject: Automated version update

  You don't need to have separate programs for sepaerate branches.
Please find attached the script

     $GCC/maintainer-scripts/update_version_svn

that we use for GCC.  It is reltively simple.  It was originally written
for our CVS repository and quickly adapted to SVN -- without modifying
the comments, unfortunately.

As you can see, any branch that wishes to have its version updated
daily just needs to be added to ADD_BRANCHES.  Those who don't
want are in IGNORE_BRANCHES.

HTH

-- Gaby
--8323584-1681983912-1182871666=:22161
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--8323584-1681983912-1182871666=:22161--

\start
Date: Tue, 26 Jun 2007 18:08:48 +0200
From: Ralf Hemmecke
To: Bill Page
Subject: Re: Axiom at version 3.4?

On 06/26/2007 05:07 PM, Bill Page wrote:
> On 6/26/07 Ralf Hemmecke wrote:
>> Ooops. There is already version 3.4 of Axiom. Very interesting. ;-)
>> http://rpmfind.net/linux/RPM/mandriva/2007.1/i586/media/contrib/release/axiom-3.4-0.20050901.1mdk.i586.html 

> I think Tim has defined at least axiom version 3.6 ((June 2005). See:
> 
> http://cvs.savannah.gnu.org/viewvc/axiom/axiom

Even more interesting. Since I see September 2006 on my banner (which is 
--patch-50), that should probably be something > 3.6.

Oh I hope no one from the outside is watching our miscommunications. I 
must really have missed that version discussion one year ago. Maybe 
don't count as a developer anymore if I don't even know what version 
number Axiom currently has. Sorry that I am out.

\start
Date: Tue, 26 Jun 2007 18:21:44 +0200
From: Ralf Hemmecke
To: Gabriel Dos Reis
Subject: Re: Automated version update

Hi Gaby, Cliff, Martin,

isn't that a bit of overkill if the script updates every file?

SVN is different from CVS, there are global revision numbers. So it is 
simply enough if there is one file that contains some specific version 
information. (I guess the same is true for any newer SCM like git etc.)

So for SVN I would prefer if for every checkin there runs a script that 
together with the changes also modifies a file VERSION (or whatever the 
name would be) that makes sure that the new revision number is include 
in the VERSION file of the branch so that any checkout whether with SVN 
or SVK gets via update or checkout the correct information in that file.
How git is set up to update such a VERSION file is up to the people 
working with git. I think the only thing we should agree on is what 
information should be in that file and how should it be structured so 
that it is (in format) independent of the underlying SCM and thus the 
information would be *generically* available for the build process.
That information could be used to produce the banner and should work for
"axiom --version".

Ralf

On 06/26/2007 05:27 PM, Gabriel Dos Reis wrote:
> Cliff --
> 
>   You don't need to have separate programs for sepaerate branches.
> Please find attached the script
> 
>      $GCC/maintainer-scripts/update_version_svn
> 
> that we use for GCC.  It is reltively simple.  It was originally written
> for our CVS repository and quickly adapted to SVN -- without modifying
> the comments, unfortunately.
> 
> As you can see, any branch that wishes to have its version updated
> daily just needs to be added to ADD_BRANCHES.  Those who don't
> want are in IGNORE_BRANCHES.
> 
> HTH

\start
Date: Tue, 26 Jun 2007 11:34:28 -0500 (CDT)
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Re: Automated version update

On Tue, 26 Jun 2007, Ralf Hemmecke wrote:

| Hi Gaby, Cliff, Martin,
| 
| isn't that a bit of overkill if the script updates every file?

The script I sent does not update every file.
It modifies only a handful of GCC files: exclusively those that
contain version information.  
In case of Axiom, it would be only *one*.  

| SVN is different from CVS, there are global revision numbers.

Yes, but that has nothing to do with the script I sent.

\start
Date: Tue, 26 Jun 2007 11:43:51 -0500 (CDT)
From: Gabriel Dos Reis
To: list
Subject: Automated version update

Martin --

  It is obvious to me that automated version updated can run as follows:

    * daily bump: anywhere, preferably a machine that is almost always
        up -- we can use the cron job facility at SF.

    * release with version number:  this should be done when the
        release is made -- it cannot be wrong.  Therefore it runs 
        on the machine that makes the release.  From GCC exprience,
        we have a script, $GCC/maintainer-scripts/gcc_release
        that we use to roll release.  I've extensive experience
        with that sort of things, and on two occasions I was thankful
        that the process is automated.

    * inclusion of global revision number:  in principle, this runs 
        on the SVN server, which means SF.  I'm not sure, but I was under 
        the impression that SF has disabled that service.  One would
        have to check.


So, it looks to me that the problem has a maximum solution :-)

\start
Date: Tue, 26 Jun 2007 20:44:10 +0300
From: Vadim V. Zhytnikov
To: Ralf Hemmecke
Subject: Re: Axiom at version 3.4?

Ralf Hemmecke writes:
> On 06/26/2007 05:07 PM, Bill Page wrote:
>> On 6/26/07 Ralf Hemmecke wrote:
>>> Ooops. There is already version 3.4 of Axiom. Very interesting. ;-)
>>> http://rpmfind.net/linux/RPM/mandriva/2007.1/i586/media/contrib/release/axiom-3.4-0.20050901.1mdk.i586.html 
> 
> 
>> I think Tim has defined at least axiom version 3.6 ((June 2005). See:
>>
>> http://cvs.savannah.gnu.org/viewvc/axiom/axiom
> 
> Even more interesting. Since I see September 2006 on my banner (which is 
> --patch-50), that should probably be something > 3.6.
> 

No, quarterly gold releases in 2005 was numbered 3.4 (April 2005),
3.6 (June 2005), 3.9 (October 2005). In 2006 this numbering
scheme was abolished.

I watch this Axiom Version discussion with moderate interest.
Moderate since I already (twice AFAIR) suggested on this list
to choose some release numbering scheme convenient for
packaging (deb, rpm whatever) but found no understanding.
Surely, packaging is a nuisance external to Axiom but
it is not wise to ignore this aspect of real life.
Once again I venture to suggest two things

1. Please, make regular _tarball_ releases.
    No CVS, SVN etc - these are for development not for releases.

2. Choose some X.Y.Z... numbering scheme
    for these releases.

Absence of 1 and 2 hurts Axiom publicity.

With best regards,

\start
Date: 26 Jun 2007 13:25:31 -0400
From: Camm Maguire
To: Matt Kaufmann
Subject: Re: 2.7.0 nqthm compile times
Cc: Robert Boyer

Greetings!

Matt Kaufmann writes:

> Hi, Camm --
> 
> Here is some feedback with respect to the use of ACL2 on top of GCL,
> as I see it.
> 
> >>    A final question remains of
> >>    whether or not to actually use ftype declaims if provided.
> 
> As you know, in ACL2 we do our own auto-proclaiming of function types.
> Just to be safe, I think it would be good if there were a way to turn
> off the auto-proclamation capability, as a way to work around any
> problems we might encounter, using our own proclaiming instead.  That

Absolutely.  Currently, the switch is
compiler::*compiler-auto-proclaim*.  This said, I have not been
testing with it off for some time, so there is some risk of drift
here.


What I was really thinking of is what to do when it is on, as is the
default, and the user proclaims something anyway.  Three options --
compiler override, user override, or use a type-and of the two.

> said, I can imagine you do a signficantly better job than we do, and
> I'm looking forward to using this new GCL feature!
> 
> I imagine that we might avoid 'si::do-recompile entirely with ACL2.
> Here are some (potentially confused) thoughts:
> 

For large systems, it pays to defer any recompilation until the end.
It appears the only useful hook for this purpose in the cl spec is
with-compilation-unit.  So I imagine the three following situations:

1) casual interactive developement use, autoproclamation and
   recompilation at every step, all is safe and optimal.
2) large system compilation, the developers of which don't want to
   fiddle with proclamation -- wrap the compilation in
   with-compilation-unit. 
3) True old-school blackbelts who want to proclaim on their own --
   (setq si::*disable-recompile* t compiler::*compiler-auto-proclaim* nil)

   or 

   (setq si::*disable-recompile* t) and have the compiler either take
   user overrides or a type-and of the user and the compiler proclaims

> Regarding leaving things in a safe state: For many years we have told
> ACL2 users that they redefine functions at their own peril (and, they
> have to set a flag even to be able to do any redefinition).  So in a
> sense, that justifies leaving things in an unsafe state when there is
> redefinition.  But I think that for ACL2, it would be a nice default
> to leave things in a safe state, even if this means expensive
> recompilation (presumably by leaving si::*disable-recompile* at nil,
> if I understand correctly).  As for with-compilation-unit, I think
> that the important thing is that it leaves things in a safe state
> provided there is no redefinition.

OK, so just to clarify, you vote

1) (si::*disable-recompile* nil) by default, so that default
   interactive use has safe and hopefully optimal recompilation. 
2) with-compilation-unit recompiles any source files containing
   functions with detected signature conflicts at the end, but does
   not compile these functions yet another time for the purpose of
   loading into the running image.  (as stated ealier, it is not safe
   to reload the recompiled original source files due to other
   top-level forms therein.)

Thanks so much for the feedback.  I'd also like to know --

Do you think this is an improvement, or a dangerous complexity?

Take care,

> 
> Thanks --
> -- Matt
>    Sender: camm@intech19.enhanced.com
>    cc: list, maxima@math.utexas.edu,
> 	   Matt Kaufmann, gcl-devel@gnu.org
>    From: Camm Maguire
>    Date: 22 Jun 2007 17:41:25 -0400
>    X-SpamAssassin-Status: No, hits=-2.3 required=5.0
>    X-UTCS-Spam-Status: No, hits=-315 required0
> 
>    Greetings!
> 
>    [ cc'ed to the maxima and axiom lists, as I would greatly appreciate
>    any user feedback on what they would like (that is practical) in the
>    forthcoming gcl release.  If this is unwelcome traffic, please let me
>    know.]
> 
>    Robert Boyer writes:
> 
>    > Fantastic.  Thanks so much!
>    > 
> 
>    The above is most appreciated, but I was hoping for a bit more of an
>    opinion as to where GCL should be heading in this direction, to wit:
> 
>    Code calling compiled functions of known signature can be rendered
>    incorrect if the callee is subsequently compiled to produce a
>    different signature:
> 
>    =============================================================================
>    COMPILER>(defun foo (x y z) (list x y z))
> 
>    FOO
> 
>    COMPILER>(compile 'foo)
> 
>    ;; Compiling /tmp/gazonk_13883_1.lsp.
>    ;; End of Pass 1.  
>    ;; End of Pass 2.  
>    ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
>    ;; Finished compiling /tmp/gazonk_13883_1.o.
>    ;; Loading /tmp/gazonk_13883_1.o
>     ;; start address -T 0xaa2f80 ;; Finished loading /tmp/gazonk_13883_1.o
>    #<compiled-function FOO>
>    NIL
>    NIL
> 
>    COMPILER>(defun bar (x y z zz) (remove zz (foo x y z)))
> 
>    BAR
> 
>    COMPILER>(compile 'bar)
> 
>    ;; Compiling /tmp/gazonk_13883_1.lsp.
>    ;; End of Pass 1.  
>    ;; End of Pass 2.  
>    ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
>    ;; Finished compiling /tmp/gazonk_13883_1.o.
>    ;; Loading /tmp/gazonk_13883_1.o
>    ;; start address -T 0x87b2b0 ;; Finished loading /tmp/gazonk_13883_1.o
>    #<compiled-function BAR>
>    NIL
>    NIL
> 
>    COMPILER>(bar 1 2 3 1)
> 
>    (2 3)
> 
>    COMPILER>(setq si::*disable-recompile* t)
> 
>    T
> 
>    COMPILER>(defun foo (x y z) (coerce (list x y z) 'vector))
> 
>    FOO
> 
>    COMPILER>(compile 'foo)
> 
>    ;; Compiling /tmp/gazonk_13883_1.lsp.
>    ; (DEFUN FOO ...) is being compiled.
>    ;; Warning: ret type mismatch in auto-proclamation (CONS T
> 						       (CONS T
> 							(CONS T NULL)))(NIL) -> *
> 
>    ;; End of Pass 1.  
>    ;; End of Pass 2.  
>    ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
>    ;; Finished compiling /tmp/gazonk_13883_1.o.
>    ;; Loading /tmp/gazonk_13883_1.o
>     ;; start address -T 0x87b540 ;; Finished loading /tmp/gazonk_13883_1.o
>    #<compiled-function FOO>
>    NIL
>    NIL
> 
>    COMPILER>(bar 1 2 3 1)
>    Segmentation violation: c stack ok:signalling error
>    Error: ERROR "Caught fatal error [memory may be damaged]: Segmentation violation."
>    Fast links are on: do (si::use-fast-links nil) for debugging
>    Signalled by BAR.
>    ERROR "Caught fatal error [memory may be damaged]: Segmentation violation."
> 
>    Broken at BAR.  Type :H for Help.
>    COMPILER>>:q
> 
>    Top level.
>    COMPILER>(setq si::*disable-recompile* nil)
> 
>    NIL
> 
>    COMPILER>(si::do-recompile)
>    Pass1 signature discovery on 1 functions ...
>    Compiling and loading new source in #<output stream "/tmp/gazonk_13883_jvaAQ9.lsp">
>    ;; Compiling /tmp/gazonk_13883_jvaAQ9.lsp.
>    ;; End of Pass 1.  
>    ;; End of Pass 2.  
>    ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
>    ;; Finished compiling /tmp/gazonk_13883_jvaAQ9.o.
>    ;; Loading /tmp/gazonk_13883_jvaAQ9.o
>     ;; start address -T 0x87ff40 ;; Finished loading /tmp/gazonk_13883_jvaAQ9.o
>    done
>    NIL
> 
>    COMPILER>(bar 1 2 3 1)
> 
>    #(2 3)
> 
>    COMPILER>(defun foo (x y z) (list x y z))
> 
>    FOO
> 
>    COMPILER>(compile 'foo)
> 
>    ;; Compiling /tmp/gazonk_13883_1.lsp.
>    ;; End of Pass 1.  
>    ;; End of Pass 2.  
>    ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
>    ;; Finished compiling /tmp/gazonk_13883_1.o.
>    ;; Loading /tmp/gazonk_13883_1.o
>    Pass1 signature discovery on 1 functions ...
>    Compiling and loading new source in #<output stream "/tmp/gazonk_13883_XL6AKh.lsp">
>    ;; Compiling /tmp/gazonk_13883_XL6AKh.lsp.
>    ;; End of Pass 1.  
>    ;; End of Pass 2.  
>    ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
>    ;; Finished compiling /tmp/gazonk_13883_XL6AKh.o.
>    ;; Loading /tmp/gazonk_13883_XL6AKh.o
>     ;; start address -T 0x880a20 ;; Finished loading /tmp/gazonk_13883_XL6AKh.o
>     ;; start address -T 0x887320 ;; Finished loading /tmp/gazonk_13883_1.o
>    #<compiled-function FOO>
>    NIL
>    NIL
> 
>    COMPILER>(bar 1 2 3 1)
> 
>    (2 3)
> 
>    COMPILER>
>    =============================================================================
> 
>    The existing philosophy is therefore not to let the load of the new
>    foo complete without executing the recompile.  This has the
>    disadvantage of compiling functions possibly multiple times, and
>    fragmenting the contiguous memory space.
> 
>    'si::do-recompile has the following behavior at the moment:
> 
> 	   a) if called without an argument, as is done in every loaded
> 	   .o file, will 1) do a fast pass1-only signature discovery run
> 	   on the out of date functions, 2) will write the necessary
> 	   functions to a temporary file, compile and then load it.  Each
> 	   function passes through gcc once, but possibly multiple times
> 	   only through pass1.  System is left in a safe state, but code
> 	   can be recompiled multiple times on subsequent multiple loads.
> 
> 	   b) if called with a non-nil argument, will do the above, but
> 	   write the new source to the filespec provided in the argument,
> 	   which is compiled but not loaded.  The system is left in an
> 	   unsafe state, and implicitly leaves to the user the job of
> 	   integrating the freshly compiled source.
> 
> 	   c) if called with a nil argument, will do the pass1 signature
> 	   discovery, and collect a list of original source files
> 	   containing the recompiled functions.  These files are then
> 	   probed for and recompiled if found.  The system is left in an
> 	   unsafe state, and implicitly leaves to the user the job of
> 	   integrating the freshly recompiled code.  (These files cannot
> 	   be automatically reloaded, as they may contain other top-level
> 	   forms which are only intended to be executed once.  Given
> 	   this, the load was also skipped for the non-nil argument case
> 	   in b) by way of symmetry.  A third recompile for automatic
> 	   loading purposes (as in a)) is ommitted to save compile time.)
> 
>    'with-compilation-unit is as follows:
> 
>    (defmacro with-compilation-unit (opt &rest body)   
>      (declare (optimize (safety 1)))
>      (declare (ignore opt)) 
>      `(progn
> 	(let ((*disable-recompile* t))
> 	  ,@body)
> 	(do-recompile nil)))
> 
>    So at present it leaves the system in an unsafe state to avoid a
>    second pass through gcc and load for every recompiled function.  If
>    there are only compile-files and no loads in the unit, no signature
>    conflict is detected and no recompilation is done.  Only loaded
>    functions within the unit trigger recompilation at unit end.  This is
>    somewhat counter to what one might expect from the ansi-doc
>    definition, given its emphasis on compile-file item deferral.
> 
>    Here are some alternatives:
> 
>    1) do another pass through gcc followed by a load when passing the nil
>       argument (or a just a load when passing the non-nil argument) to
>       leave the system in a safe state at the expense of more compile
>       time.
> 
>    2) Never automatically recompile at load, leaving the safety < 3 user
>       to the whims of random segfaults, but provide a safety 3 which
>       eliminates all branch elimination depending on known return
>       signatures.
> 
>    3) Defer auto recompiles to a re-entry of top-level, minimizing the
>       window of unsafe code execution.
> 
>    ...
> 
>    Thoughts most appreciated.  Please help me make this serve the needs
>    of the community.  For those new to this thread, this mechanism
>    obviates the need for ftype declaims.  A final question remains of
>    whether or not to actually use ftype declaims if provided.

\start
Date: 26 Jun 2007 13:35:39 -0400
From: Camm Maguire
To: Gernot Hueber
Subject: Re: [Maxima] New dynamic library access in GCL
Cc: Robert Boyer, Warren Hunt

Greetings!

Gernot Hueber writes:

> Dear Camm,
> 
> this is great! Thanks for your effort related to this issue.
> 
> First I want to ask, is this version running on FreeBSD as well and how
> can I access the source for this version?
> 

Probably, but untested.

export CVSROOT=:pserver:anonymous@cvs.sv.gnu.org:/sources/gcl
cvs -z9 -q co -d gclcvs-2.7.0 -r HEAD gcl


> Secondly, what types are supported by defdlfun and does it make sense to
> finish cffi-gcl from your point. cffi seems to be the most actively

Right now just:

(dolist (l '((:float      "make_shortfloat"      short-float     cnum)
	     (:double     "make_longfloat"       long-float      cnum)
	     (:char       "code_char"            char            cnum)
	     (:short      "make_fixnum"          short           cnum)
	     (:int        "make_fixnum"          int             cnum)
	     (:fixnum     "make_fixnum"          fixnum          cnum)
	     (:fcomplex   "make_fcomplex"        fcomplex        cnum)
	     (:dcomplex   "make_dcomplex"        dcomplex        cnum)
	     (:string     "make_simple_string"   string)
	     (:float*     nil                    nil             (array short-float) "->sfa.sfa_self")
	     (:double*    nil                    nil             (array long-float)  "->lfa.lfa_self")
	     (:long*      nil                    nil             (array fixnum)      "->fixa.fixa_self")
	     (:void*      nil                    nil             (array)             "->v.v_self")))

I need to change string to :char*, I think.  Also would like to add
support for :fcomplex* and :dcomplex*.  Any others you can think of?
You comments most appreciated.  Obviously generic C structures and
pointers thereto will need some thought.  If we are very lucky, their
binary representation will be the same as the lisp struct.

BTW, you might enjoy experimenting with

(defdlfun (:double "cblas_ddot" "libblas.so") :int :double* :int :double* :int)

and the like.  I hope to get a complete interface file in at some
point.

Note -- there is currently no automatic protection enforcing :static
arrays, so external calls which malloc might cause problems if the
user does not explicitly use :static.  Non-static arrays are faster,
and so should be allowed for those routines which do not malloc.


> developed and used ffi for lisp and opens the door to use swig as
> well :-). There is already some work done to support GCL, but still more
> effort needed.

I haven't looked at it due to time pressure.  It would seem that if
the above proves stable, then the hooks into a generic ffi might be
simple.

Take care,

> 
> Best regards,
> 
> Gernot
> 
> On Fri, 2007-06-15 at 20:15 -0400, Camm Maguire wrote:
> > Greetings!  GCL now has the ability to access arbitrary external
> > shared library routines in a persitent fashion -- i.e. the binding is
> > kept across image saves:
> > 
> > =============================================================================
> > camm@intech19:/fix/t1/camm/debian/gcl/tmp/tmp/foo1$ unixport/saved_gcl
> > GCL (GNU Common Lisp)  2.7.0 CLtL1    Jun 15 2007 19:45:46
> > Source License: LGPL(gcl,gmp,pargcl), GPL(unexec,bfd,xgcl)
> > Binary License:  GPL due to GPL'ed components: (XGCL READLINE BFD UNEXEC)
> > Modifications of this banner must retain notice of a compatible license
> > Dedicated to the memory of W. Schelter
> > 
> > Use (help) to get some basic information on how to use GCL.
> > 
> > Temporary directory for compiler files set to /tmp/
> > 
> > >(|libm|:|erf| 1.0)
> > 
> > Error: ERROR "Cannot find the external symbol erf in #<\"libm\" package>."
> > Fast links are on: do (si::use-fast-links nil) for debugging
> > Signalled by READ.
> > ERROR "Cannot find the external symbol erf in #<\"libm\" package>."
> > 
> > Broken at READ.  Type :H for Help.
> > >:q
> > 
> > >(si::show-lib-syms)
> > 
> > (LIB:|libm| 1074447640 #<"libm" package>) 
> > (|libm|:|atan| 1094141472 #<compiled-function |libm|:|atan|>) 
> > (|libm|:|ctan| 1094156208 #<compiled-function |libm|:|ctan|>) 
> > (|libm|:|csqrt| 1094159152 #<compiled-function |libm|:|csqrt|>) 
> > (|libm|:|clogf| 1094183232 #<compiled-function |libm|:|clogf|>) 
> > (|libm|:|acosh| 1094146080 #<compiled-function |libm|:|acosh|>) 
> > (|libm|:|ccosh| 1094153584 #<compiled-function |libm|:|ccosh|>) 
> > (|libm|:|expf| 1094176432 #<compiled-function |libm|:|expf|>) 
> > (|libm|:|atanhf| 1094176064 #<compiled-function |libm|:|atanhf|>) 
> > (|libm|:|casin| 1094154864 #<compiled-function |libm|:|casin|>) 
> > (|libm|:|cexpf| 1094181648 #<compiled-function |libm|:|cexpf|>) 
> > (|libm|:|acosf| 1094175504 #<compiled-function |libm|:|acosf|>) 
> > (|libm|:|sqrtf| 1094180496 #<compiled-function |libm|:|sqrtf|>) 
> > (|libm|:|exp| 1094146864 #<compiled-function |libm|:|exp|>) 
> > (|libm|:|atanh| 1094146512 #<compiled-function |libm|:|atanh|>) 
> > (|libm|:|ccosf| 1094184128 #<compiled-function |libm|:|ccosf|>) 
> > (|libm|:|ctanh| 1094156960 #<compiled-function |libm|:|ctanh|>) 
> > (|libm|:|cosh| 1094146672 #<compiled-function |libm|:|cosh|>) 
> > (|libm|:|ccoshf| 1094182688 #<compiled-function |libm|:|ccoshf|>) 
> > (|libm|:|cosf| 1094172320 #<compiled-function |libm|:|cosf|>) 
> > (|libm|:|atanf| 1094172032 #<compiled-function |libm|:|atanf|>) 
> > (|libm|:|cos| 1094141792 #<compiled-function |libm|:|cos|>) 
> > (|libm|:|cacos| 1094157584 #<compiled-function |libm|:|cacos|>) 
> > (|libm|:|tanh| 1094145584 #<compiled-function |libm|:|tanh|>) 
> > (|libm|:|ctanf| 1094185024 #<compiled-function |libm|:|ctanf|>) 
> > (|libm|:|csinhf| 1094182144 #<compiled-function |libm|:|csinhf|>) 
> > (|libm|:|tanf| 1094175168 #<compiled-function |libm|:|tanf|>) 
> > (|libm|:|tan| 1094145536 #<compiled-function |libm|:|tan|>) 
> > (|libm|:|asin| 1094146208 #<compiled-function |libm|:|asin|>) 
> > (|libm|:|sinh| 1094150832 #<compiled-function |libm|:|sinh|>) 
> > (|libm|:|csin| 1094155520 #<compiled-function |libm|:|csin|>) 
> > (|libm|:|sinf| 1094175120 #<compiled-function |libm|:|sinf|>) 
> > (|libm|:|cabs| 1094152304 #<compiled-function |libm|:|cabs|>) 
> > (|libm|:|sin| 1094145488 #<compiled-function |libm|:|sin|>) 
> > (|libm|:|catanhf| 1094187072 #<compiled-function |libm|:|catanhf|>) 
> > (|libm|:|coshf| 1094176224 #<compiled-function |libm|:|coshf|>) 
> > (|libm|:|catanh| 1094158672 #<compiled-function |libm|:|catanh|>) 
> > (|libm|:|fabs| 1094144096 #<compiled-function |libm|:|fabs|>) 
> > (|libm|:|catanf| 1094183504 #<compiled-function |libm|:|catanf|>) 
> > (|libm|:|tanhf| 1094175216 #<compiled-function |libm|:|tanhf|>) 
> > (|libm|:|acoshf| 1094175632 #<compiled-function |libm|:|acoshf|>) 
> > (|libm|:|asinh| 1094141232 #<compiled-function |libm|:|asinh|>) 
> > (|libm|:|csinh| 1094152928 #<compiled-function |libm|:|csinh|>) 
> > (|libm|:|asinhf| 1094171792 #<compiled-function |libm|:|asinhf|>) 
> > (|libm|:|atan2f| 1094175888 #<compiled-function |libm|:|atan2f|>) 
> > (|libm|:|asinf| 1094175760 #<compiled-function |libm|:|asinf|>) 
> > (|libm|:|sinhf| 1094180368 #<compiled-function |libm|:|sinhf|>) 
> > (|libm|:|atan2| 1094146336 #<compiled-function |libm|:|atan2|>) 
> > (|libm|:|csinf| 1094184448 #<compiled-function |libm|:|csinf|>) 
> > (|libm|:|cabsf| 1094181552 #<compiled-function |libm|:|cabsf|>) 
> > (|libm|:|fabsf| 1094174288 #<compiled-function |libm|:|fabsf|>) 
> > (|libm|:|casinhf| 1094186160 #<compiled-function |libm|:|casinhf|>) 
> > (|libm|:|logf| 1094179104 #<compiled-function |libm|:|logf|>) 
> > (|libm|:|casinh| 1094157680 #<compiled-function |libm|:|casinh|>) 
> > (|libm|:|clog| 1094154112 #<compiled-function |libm|:|clog|>) 
> > (|libm|:|casinf| 1094183888 #<compiled-function |libm|:|casinf|>) 
> > (|libm|:|ctanhf| 1094185616 #<compiled-function |libm|:|ctanhf|>) 
> > (|libm|:|csqrtf| 1094187472 #<compiled-function |libm|:|csqrtf|>) 
> > (|libm|:|log| 1094149536 #<compiled-function |libm|:|log|>) 
> > (|libm|:|cacoshf| 1094186624 #<compiled-function |libm|:|cacoshf|>) 
> > (|libm|:|cacosh| 1094158144 #<compiled-function |libm|:|cacosh|>) 
> > (|libm|:|catan| 1094154432 #<compiled-function |libm|:|catan|>) 
> > (|libm|:|cacosf| 1094186080 #<compiled-function |libm|:|cacosf|>) 
> > (|libm|:|cexp| 1094152400 #<compiled-function |libm|:|cexp|>) 
> > (|libm|:|acos| 1094145952 #<compiled-function |libm|:|acos|>) 
> > (|libm|:|sqrt| 1094150976 #<compiled-function |libm|:|sqrt|>) 
> > (|libm|:|ccos| 1094155168 #<compiled-function |libm|:|ccos|>) 
> > (|libm|:|abs| 1090798240 #<compiled-function |libm|:|abs|>) 
> > (LIB:|libc| 1074448272 #<"libc" package>) 
> > (|libc|:|setjmp| 1090786864 NIL) 
> > (|libc|:|feof| 1090993296 NIL) 
> > (|libc|:|memset| 1091054096 NIL) 
> > (|libc|:|getc| 1090994720 NIL) 
> > (|libc|:|bzero| 1091054432 NIL) 
> > (|libc|:|putc| 1090995664 NIL) 
> > 
> > >(in-package 'compiler)
> > 
> > #<"COMPILER" package>
> > 
> > COMPILER>(defdlfun (:double "erf" "libm.so") :double)
> > 
> > |libm|:|erf|
> > 
> > COMPILER>(compile *)
> > 
> > ;; Compiling /tmp/gazonk_18613_0.lsp.
> > ;; End of Pass 1.  
> > ;; End of Pass 2.  
> > ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
> > ;; Finished compiling /tmp/gazonk_18613_0.o.
> > ;; Loading /tmp/gazonk_18613_0.o
> >  ;; start address -T 0xa02000 ;; Finished loading /tmp/gazonk_18613_0.o
> > #<compiled-function |libm|:|erf|>
> > NIL
> > NIL
> > 
> > COMPILER>(|libm|:|erf| 1.0)
> > 
> > 0.84270079294971489
> > 
> > COMPILER>(|libm|:|erf| 1.0s0)
> > 
> > Correctable error: TYPE-ERROR :DATUM 1.0S0 :EXPECTED-TYPE LONG-FLOAT NIL
> > Fast links are on: do (si::use-fast-links nil) for debugging
> > Signalled by EVAL.
> > If continued: choose a new value
> > TYPE-ERROR :DATUM 1.0S0 :EXPECTED-TYPE LONG-FLOAT NIL
> > 
> > Broken at EVAL.  Type :H for Help.
> > COMPILER>>:q
> > 
> > Top level.
> > COMPILER>(disassemble '(lambda (x) (|libm|:|erf| x)) nil)
> > 
> > ;; Compiling /tmp/gazonk_18613_0.lsp.
> > ;; End of Pass 1.  
> > ;; End of Pass 2.  
> > ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
> > ;; Finished compiling /tmp/gazonk_18613_0.o.
> > 
> > #include "gazonk_18613_0.h"
> > void init_code(){do_init((void *)VV);}
> > /*	local entry for function CMP-ANON	*/
> > 
> > static object LI1(V2)
> > 
> > object V2;
> > {	 VMB1 VMS1 VMV1
> > 	goto TTL;
> > TTL:;
> > 	{object V3 = (/* erf */(*LnkLI0)((V2)));VMR1
> > 	(V3);}
> > 	return Cnil;
> > }
> > static object  LnkTLI0(object first,...){object V1;va_list ap;va_start(ap,first);V1=(object )call_proc_new(((object)VV[0]),0,0,(void **)(void *)&LnkLI0,1,first,ap);va_end(ap);return V1;} /* erf */
> > #(#(erf
> >     (%INIT
> >      . #((LET ((*DISABLE-RECOMPILE* T))
> >            (MFSFUN 'CMP-ANON 0 1 0)
> >            (ADD-HASH 'CMP-ANON '((T) T) '((erf (FLOAT) T))COMPILER
> > libmerf-
> >                '/tmp/gazonk_18613_0.lsp))
> >          (DO-RECOMPILE)))))
> > static object LI1();
> > #define VMB1
> > #define VMS1
> > #define VMV1
> > #define VMR1(VMT1) return(VMT1);
> > #define VM1 0
> > static void * VVi[2]={
> > #define Cdata VV[1]
> > (void *)(LI1)
> > };
> > #define VV (VVi)
> > static object  LnkTLI0(object,...);
> > static object  (*LnkLI0)() = (object (*)()) LnkTLI0;
> > NIL
> > 
> > COMPILER>(disassemble '(lambda (x) (declare (long-float x)) (|libm|:|erf| x)) nil)
> > 
> > ;; Compiling /tmp/gazonk_18613_0.lsp.
> > ;; End of Pass 1.  
> > ;; End of Pass 2.  
> > ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
> > ;; Finished compiling /tmp/gazonk_18613_0.o.
> > 
> > #include "gazonk_18613_0.h"
> > void init_code(){do_init((void *)VV);}
> > /*	local entry for function CMP-ANON	*/
> > 
> > static double LI1(V2)
> > 
> > double V2;
> > {	 VMB1 VMS1 VMV1
> > 	goto TTL;
> > TTL:;
> > 	{double V3 = ((double(*)(double))dlerf)(V2);VMR1
> > 	(V3);}
> > }
> > /*	global entry for the function CMP-ANON	*/
> > 
> > static void L1()
> > {	register object *base=vs_base;
> > 	base[0]=make_longfloat(LI1(lf(base[0])));
> > 	vs_top=(vs_base=base)+1;
> > }
> > #(#(NIL
> >     (%INIT
> >      . #((MDL 'erf 'libm 1)
> >          (LET ((*DISABLE-RECOMPILE* T))
> >            (MF 'CMP-ANON 0)
> >            (ADD-HASH 'CMP-ANON '((LONG-FLOAT) LONG-FLOAT)
> >                '((erf (FLOAT) T))
> > LISPLAMBDA!!,DECLAR,OPTIMIZ,SAFETY
> > libmerf-
> >                '/tmp/gazonk_18613_0.lsp))
> >          (DO-RECOMPILE)))))
> > static void L1();
> > static double LI1();
> > static void *dlerf;
> > #define VMB1
> > #define VMS1
> > #define VMV1
> > #define VMR1(VMT1) return(VMT1);
> > #define VM1 0
> > static void * VVi[2]={
> > #define Cdata VV[1]
> > (void *)(L1),
> > (void *)(&dlerf)
> > };
> > #define VV (VVi)
> > NIL
> > 
> > COMPILER>(funcall (compile nil  '(lambda (x) (|libm|:|erf| x))) 1.0)
> > 
> > ;; Compiling /tmp/gazonk_18613_0.lsp.
> > ;; End of Pass 1.  
> > ;; End of Pass 2.  
> > ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
> > ;; Finished compiling /tmp/gazonk_18613_0.o.
> > ;; Loading /tmp/gazonk_18613_0.o
> >  ;; start address -T 0x9e8b08 ;; Finished loading /tmp/gazonk_18613_0.o
> > 0.84270079294971489
> > 
> > COMPILER>(funcall (compile nil  '(lambda (x) (declare (long-float x)) (|libm|:|erf| x))) 1.0)
> > 
> > ;; Compiling /tmp/gazonk_18613_0.lsp.
> > ;; End of Pass 1.  
> > ;; End of Pass 2.  
> > ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
> > ;; Finished compiling /tmp/gazonk_18613_0.o.
> > ;; Loading /tmp/gazonk_18613_0.o
> >  ;; start address -T 0xa08948 ;; Finished loading /tmp/gazonk_18613_0.o
> > 0.84270079294971489
> > 
> > COMPILER>(si::save-system "/tmp/h")
> > camm@intech19:/fix/t1/camm/debian/gcl/tmp/tmp/foo1$ /tmp/h
> > GCL (GNU Common Lisp)  2.7.0 CLtL1    Jun 15 2007 19:45:46
> > Source License: LGPL(gcl,gmp,pargcl), GPL(unexec,bfd,xgcl)
> > Binary License:  GPL due to GPL'ed components: (XGCL READLINE BFD UNEXEC)
> > Modifications of this banner must retain notice of a compatible license
> > Dedicated to the memory of W. Schelter
> > 
> > Use (help) to get some basic information on how to use GCL.
> > 
> > Temporary directory for compiler files set to /tmp/
> > 
> > >(|libm|:|erf| 1.0)
> > 
> > 0.84270079294971489
> > 
> > >
> > =============================================================================
> > 
> > Notes: 
> > 
> > 0) based on dlopen
> > 1) Not yet tested on static linking
> > 2) Cannot run such functions interpreted for the moment
> > 3) compiling gives both a function with error checking, and an inline
> >    providing single instuction access through a C pointer where
> >    possible.
> > 4) Plan on shipping a little blas, maybe mpi and lapack file to be
> >    optionally loaded in the GCL distribution
> > 5) package LIB contains libary name symbols bound to the dlopen
> >    address of the library
> > 6) each library has its own package with symbols bound to the external
> >    function address.
> > 7) symbols are created and linked on .o load if necessary
> > 8) loaded .o code keeps a list of its external pointers in use, which
> >    are then reset on image re-execution.

\start
Date: 26 Jun 2007 19:37:00 +0200
From: Martin Rubey
To: Gabriel Dos Reis
Subject: Re: Automated version update

Dear Gaby,

Gabriel Dos Reis writes:

>   It is obvious to me that automated version updated can run as follows:
> 
>     * daily bump: anywhere, preferably a machine that is almost always
>         up -- we can use the cron job facility at SF.

Yes, of course.  But suppose that Mrs. Xyz commits at 12:34 GMT, the cron job
runs at 23:59 GMT and Mrs. Uvw checks out inbetween.

By the way, I just realised that I do not understand completely: you propose to
have one file "version" for each branch, that is modified by a cron job on SF,
if and only if the revision has changed.  (More precisely, whenever 

  LC_ALL=C svn info | grep "Last Changed Rev:"

has changed.)

But, if this file is under version control, wouldn't that update trigger
another revision number?  Or are you bypassing svn?

Martin

Important PS: just after the last AxiomWorkshop I realized that there are zero
female developers for Axiom.  Any ideas how to change this?

\start
Date: Tue, 26 Jun 2007 13:02:12 -0500
From: Matt Kaufmann
To: Camm Maguire
Subject: Re: 2.7.0 nqthm compile times
Cc: Robert Boyer

Hi, Camm --

My reply is interspersed below.

   Sender: camm@intech19.enhanced.com
   Cc: Robert Boyer, list, maxima@math.utexas.edu,
	   gcl-devel@gnu.org
   From: Camm Maguire
   Date: 26 Jun 2007 13:25:31 -0400
   X-SpamAssassin-Status: No, hits=-2.3 required=5.0
   X-UTCS-Spam-Status: No, hits=-315 required0

   Greetings!

   Matt Kaufmann writes:

   > Hi, Camm --
   > 
   > Here is some feedback with respect to the use of ACL2 on top of GCL,
   > as I see it.
   > 
   > >>    A final question remains of
   > >>    whether or not to actually use ftype declaims if provided.
   > 
   > As you know, in ACL2 we do our own auto-proclaiming of function types.
   > Just to be safe, I think it would be good if there were a way to turn
   > off the auto-proclamation capability, as a way to work around any
   > problems we might encounter, using our own proclaiming instead.  That

   Absolutely.  Currently, the switch is
   compiler::*compiler-auto-proclaim*.  This said, I have not been
   testing with it off for some time, so there is some risk of drift
   here.

Then it would be great if you'd be willing to test the latest ACL2
(currently Version 3.2.1) using compiler::*compiler-auto-proclaim*
off.  Moreover, it would be interesting to know how (also in GCL
2.7.0) the resulting regression time compares with the use of GCL's
auto-proclaim (and I can tell you how to turn off ACL2's auto-proclaim
for that test), and how these both compare with ACL2 regression time
using GCL 2.6.7.

   What I was really thinking of is what to do when it is on, as is the
   default, and the user proclaims something anyway.  Three options --
   compiler override, user override, or use a type-and of the two.

Good question.  For ACL2 I think we'd be content with whichever is
easiest for you.  If you implement compiler override, you could
perhaps print a message saying that the user proclaim has been
ignored, with a suggestion to set compiler::*compiler-auto-proclaim*
to nil if one wants to use the user's type.

   > said, I can imagine you do a signficantly better job than we do, and
   > I'm looking forward to using this new GCL feature!
   > 
   > I imagine that we might avoid 'si::do-recompile entirely with ACL2.
   > Here are some (potentially confused) thoughts:
   > 

   For large systems, it pays to defer any recompilation until the end.
   It appears the only useful hook for this purpose in the cl spec is
   with-compilation-unit.  So I imagine the three following situations:

   1) casual interactive developement use, autoproclamation and
      recompilation at every step, all is safe and optimal.

I think this would be great for ACL2 users.  They already have the
option of avoiding compilation if they are worried about speed.  By
the way, when users invoke ACL2's so-called book certification,
recompilation is unnecessary (redefinition is disallowed); so ACL2
might set si::*disable-recompile* to nil under the hood at such times.

   2) large system compilation, the developers of which don't want to
      fiddle with proclamation -- wrap the compilation in
      with-compilation-unit. 

That's probably what we will do for ACL2 builds using GCL 2.7.0, if
all is well.

   3) True old-school blackbelts who want to proclaim on their own --
      (setq si::*disable-recompile* t compiler::*compiler-auto-proclaim* nil)

We might want to do this with ACL2 if we run into issues, in which
case we'd still like with-compilation-unit to behave reasonably.  I
don't imagine we'd feel any need to try the other alternative just
below.

      or 

      (setq si::*disable-recompile* t) and have the compiler either take
      user overrides or a type-and of the user and the compiler proclaims

   > Regarding leaving things in a safe state: For many years we have told
   > ACL2 users that they redefine functions at their own peril (and, they
   > have to set a flag even to be able to do any redefinition).  So in a
   > sense, that justifies leaving things in an unsafe state when there is
   > redefinition.  But I think that for ACL2, it would be a nice default
   > to leave things in a safe state, even if this means expensive
   > recompilation (presumably by leaving si::*disable-recompile* at nil,
   > if I understand correctly).  As for with-compilation-unit, I think
   > that the important thing is that it leaves things in a safe state
   > provided there is no redefinition.

   OK, so just to clarify, you vote

   1) (si::*disable-recompile* nil) by default, so that default
      interactive use has safe and hopefully optimal recompilation. 

Great.

   2) with-compilation-unit recompiles any source files containing
      functions with detected signature conflicts at the end, but does
      not compile these functions yet another time for the purpose of
      loading into the running image.  (as stated ealier, it is not safe
      to reload the recompiled original source files due to other
      top-level forms therein.)

In short: I think I'd be content to see an error if functions are
redefined within a with-compilation-unit, and maybe that means I'm
fine with your #2 just above.

Longer reply to your #2 just above: Sorry, but I think I'm not
following here.  I believe that with-compilation-unit is invoked when
building ACL2, but not when users define functions in ACL2.  For the
ACL2 build, I just want things fast and as safe as they are today.  If
you're suggesting that the ACL2 build process might be unsafe because
a final recompile is avoided, that would certainly be unfortunate.
But perhaps the missing recompile you mention isn't relevant to ACL2
builds since we do not redefine functions (I think!) during the ACL2
build process.  Hmmm, well we do redefine a few, for example
user-homedir-pathname for GCL 2.7.0 (I think Bob Boyer had a problem
with that), but probably not inside with-compilation-unit.

   Thanks so much for the feedback.

Thank *you* for all this work and for all you've done for GCL!

   I'd also like to know --

   Do you think this is an improvement, or a dangerous complexity?

I assume that by "this" you mean all the GCL auto-proclaim stuff.  In
the case of ACL2, I don't know if this will have much benefit, since
we already do our own limited auto-proclaiming.  It would be
interesting to do some timings of the ACL2 regression suite as
mentioned above.  But the case of ACL2 may well not be representative,
since not only do we already do some auto-proclaiming, but also we are
in perhaps in an unusual position to do so because ACL2 puts syntactic
restrictions on its definitions beyond what are required by Common
Lisp.

   Take care,

Thanks again --
-- Matt
   > 
   > Thanks --
   > -- Matt
   >    Sender: camm@intech19.enhanced.com
   >    cc: list, maxima@math.utexas.edu,
   > 	   Matt Kaufmann, gcl-devel@gnu.org
   >    From: Camm Maguire
   >    Date: 22 Jun 2007 17:41:25 -0400
   >    X-SpamAssassin-Status: No, hits=-2.3 required=5.0
   >    X-UTCS-Spam-Status: No, hits=-315 required0
   > 
   >    Greetings!
   > 
   >    [ cc'ed to the maxima and axiom lists, as I would greatly appreciate
   >    any user feedback on what they would like (that is practical) in the
   >    forthcoming gcl release.  If this is unwelcome traffic, please let me
   >    know.]
   > 
   >    Robert Boyer writes:
   > 
   >    > Fantastic.  Thanks so much!
   >    > 
   > 
   >    The above is most appreciated, but I was hoping for a bit more of an
   >    opinion as to where GCL should be heading in this direction, to wit:
   > 
   >    Code calling compiled functions of known signature can be rendered
   >    incorrect if the callee is subsequently compiled to produce a
   >    different signature:
   > 
   >    =============================================================================
   >    COMPILER>(defun foo (x y z) (list x y z))
   > 
   >    FOO
   > 
   >    COMPILER>(compile 'foo)
   > 
   >    ;; Compiling /tmp/gazonk_13883_1.lsp.
   >    ;; End of Pass 1.  
   >    ;; End of Pass 2.  
   >    ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
   >    ;; Finished compiling /tmp/gazonk_13883_1.o.
   >    ;; Loading /tmp/gazonk_13883_1.o
   >     ;; start address -T 0xaa2f80 ;; Finished loading /tmp/gazonk_13883_1.o
   >    #<compiled-function FOO>
   >    NIL
   >    NIL
   > 
   >    COMPILER>(defun bar (x y z zz) (remove zz (foo x y z)))
   > 
   >    BAR
   > 
   >    COMPILER>(compile 'bar)
   > 
   >    ;; Compiling /tmp/gazonk_13883_1.lsp.
   >    ;; End of Pass 1.  
   >    ;; End of Pass 2.  
   >    ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
   >    ;; Finished compiling /tmp/gazonk_13883_1.o.
   >    ;; Loading /tmp/gazonk_13883_1.o
   >    ;; start address -T 0x87b2b0 ;; Finished loading /tmp/gazonk_13883_1.o
   >    #<compiled-function BAR>
   >    NIL
   >    NIL
   > 
   >    COMPILER>(bar 1 2 3 1)
   > 
   >    (2 3)
   > 
   >    COMPILER>(setq si::*disable-recompile* t)
   > 
   >    T
   > 
   >    COMPILER>(defun foo (x y z) (coerce (list x y z) 'vector))
   > 
   >    FOO
   > 
   >    COMPILER>(compile 'foo)
   > 
   >    ;; Compiling /tmp/gazonk_13883_1.lsp.
   >    ; (DEFUN FOO ...) is being compiled.
   >    ;; Warning: ret type mismatch in auto-proclamation (CONS T
   > 						       (CONS T
   > 							(CONS T NULL)))(NIL) -> *
   > 
   >    ;; End of Pass 1.  
   >    ;; End of Pass 2.  
   >    ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
   >    ;; Finished compiling /tmp/gazonk_13883_1.o.
   >    ;; Loading /tmp/gazonk_13883_1.o
   >     ;; start address -T 0x87b540 ;; Finished loading /tmp/gazonk_13883_1.o
   >    #<compiled-function FOO>
   >    NIL
   >    NIL
   > 
   >    COMPILER>(bar 1 2 3 1)
   >    Segmentation violation: c stack ok:signalling error
   >    Error: ERROR "Caught fatal error [memory may be damaged]: Segmentation violation."
   >    Fast links are on: do (si::use-fast-links nil) for debugging
   >    Signalled by BAR.
   >    ERROR "Caught fatal error [memory may be damaged]: Segmentation violation."
   > 
   >    Broken at BAR.  Type :H for Help.
   >    COMPILER>>:q
   > 
   >    Top level.
   >    COMPILER>(setq si::*disable-recompile* nil)
   > 
   >    NIL
   > 
   >    COMPILER>(si::do-recompile)
   >    Pass1 signature discovery on 1 functions ...
   >    Compiling and loading new source in #<output stream "/tmp/gazonk_13883_jvaAQ9.lsp">
   >    ;; Compiling /tmp/gazonk_13883_jvaAQ9.lsp.
   >    ;; End of Pass 1.  
   >    ;; End of Pass 2.  
   >    ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
   >    ;; Finished compiling /tmp/gazonk_13883_jvaAQ9.o.
   >    ;; Loading /tmp/gazonk_13883_jvaAQ9.o
   >     ;; start address -T 0x87ff40 ;; Finished loading /tmp/gazonk_13883_jvaAQ9.o
   >    done
   >    NIL
   > 
   >    COMPILER>(bar 1 2 3 1)
   > 
   >    #(2 3)
   > 
   >    COMPILER>(defun foo (x y z) (list x y z))
   > 
   >    FOO
   > 
   >    COMPILER>(compile 'foo)
   > 
   >    ;; Compiling /tmp/gazonk_13883_1.lsp.
   >    ;; End of Pass 1.  
   >    ;; End of Pass 2.  
   >    ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
   >    ;; Finished compiling /tmp/gazonk_13883_1.o.
   >    ;; Loading /tmp/gazonk_13883_1.o
   >    Pass1 signature discovery on 1 functions ...
   >    Compiling and loading new source in #<output stream "/tmp/gazonk_13883_XL6AKh.lsp">
   >    ;; Compiling /tmp/gazonk_13883_XL6AKh.lsp.
   >    ;; End of Pass 1.  
   >    ;; End of Pass 2.  
   >    ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
   >    ;; Finished compiling /tmp/gazonk_13883_XL6AKh.o.
   >    ;; Loading /tmp/gazonk_13883_XL6AKh.o
   >     ;; start address -T 0x880a20 ;; Finished loading /tmp/gazonk_13883_XL6AKh.o
   >     ;; start address -T 0x887320 ;; Finished loading /tmp/gazonk_13883_1.o
   >    #<compiled-function FOO>
   >    NIL
   >    NIL
   > 
   >    COMPILER>(bar 1 2 3 1)
   > 
   >    (2 3)
   > 
   >    COMPILER>
   >    =============================================================================
   > 
   >    The existing philosophy is therefore not to let the load of the new
   >    foo complete without executing the recompile.  This has the
   >    disadvantage of compiling functions possibly multiple times, and
   >    fragmenting the contiguous memory space.
   > 
   >    'si::do-recompile has the following behavior at the moment:
   > 
   > 	   a) if called without an argument, as is done in every loaded
   > 	   .o file, will 1) do a fast pass1-only signature discovery run
   > 	   on the out of date functions, 2) will write the necessary
   > 	   functions to a temporary file, compile and then load it.  Each
   > 	   function passes through gcc once, but possibly multiple times
   > 	   only through pass1.  System is left in a safe state, but code
   > 	   can be recompiled multiple times on subsequent multiple loads.
   > 
   > 	   b) if called with a non-nil argument, will do the above, but
   > 	   write the new source to the filespec provided in the argument,
   > 	   which is compiled but not loaded.  The system is left in an
   > 	   unsafe state, and implicitly leaves to the user the job of
   > 	   integrating the freshly compiled source.
   > 
   > 	   c) if called with a nil argument, will do the pass1 signature
   > 	   discovery, and collect a list of original source files
   > 	   containing the recompiled functions.  These files are then
   > 	   probed for and recompiled if found.  The system is left in an
   > 	   unsafe state, and implicitly leaves to the user the job of
   > 	   integrating the freshly recompiled code.  (These files cannot
   > 	   be automatically reloaded, as they may contain other top-level
   > 	   forms which are only intended to be executed once.  Given
   > 	   this, the load was also skipped for the non-nil argument case
   > 	   in b) by way of symmetry.  A third recompile for automatic
   > 	   loading purposes (as in a)) is ommitted to save compile time.)
   > 
   >    'with-compilation-unit is as follows:
   > 
   >    (defmacro with-compilation-unit (opt &rest body)   
   >      (declare (optimize (safety 1)))
   >      (declare (ignore opt)) 
   >      `(progn
   > 	(let ((*disable-recompile* t))
   > 	  ,@body)
   > 	(do-recompile nil)))
   > 
   >    So at present it leaves the system in an unsafe state to avoid a
   >    second pass through gcc and load for every recompiled function.  If
   >    there are only compile-files and no loads in the unit, no signature
   >    conflict is detected and no recompilation is done.  Only loaded
   >    functions within the unit trigger recompilation at unit end.  This is
   >    somewhat counter to what one might expect from the ansi-doc
   >    definition, given its emphasis on compile-file item deferral.
   > 
   >    Here are some alternatives:
   > 
   >    1) do another pass through gcc followed by a load when passing the nil
   >       argument (or a just a load when passing the non-nil argument) to
   >       leave the system in a safe state at the expense of more compile
   >       time.
   > 
   >    2) Never automatically recompile at load, leaving the safety < 3 user
   >       to the whims of random segfaults, but provide a safety 3 which
   >       eliminates all branch elimination depending on known return
   >       signatures.
   > 
   >    3) Defer auto recompiles to a re-entry of top-level, minimizing the
   >       window of unsafe code execution.
   > 
   >    ...
   > 
   >    Thoughts most appreciated.  Please help me make this serve the needs
   >    of the community.  For those new to this thread, this mechanism
   >    obviates the need for ftype declaims.  A final question remains of
   >    whether or not to actually use ftype declaims if provided.

\start
Date: 26 Jun 2007 14:07:45 -0400
From: Stephen Wilson
To: Martin Rubey
Subject: Re: Axisp news
Cc: Christian Aistleitner, Ralf Hemmecke

Martin Rubey writes:
> Dear Stephen,
> 
> many thanks for your detailed answer.  I must admit however, that I dislike
> your idea writing
> 
>    D(P : Polynomial (R : Ring)) : ... == ...
> 
> for
> 
>    D(R : Ring, P : Polynomial R) : ... == ...
> 
> Isn't this just syntactic sugar?  My feeling (!) is that this will pose more
> questions than answers.  Enforcing case sensitivity on values, domains and
> categories also does not look very appealing to me, sorry.

It may be syntactic sugar for the sake of a function definition, but it
implies a handling of types which diverges from how things are
currently done.

Case sensitivity is not a requirement for this to work.  For example,
you could just as well have a binding operator which matches values to
domains, and another which matches domains to categories

Big difference is that with a parametrized type, the parametrization
forms a part of the `public interface' to the type.  No
domain/category should be allowed to `hide' their parametrization,
nor should they ever need to explicitly `export' them, as you
mentioned RectangularMatrixCategory does.

> In any case, I'd like to point you again to Christian Aistleitner, who seems to
> have thought a lot about issues about Aldor semantics.
> 
> To look at OBJ is probably a good idea, though.
> 
> > Another shortcoming relates to `first class types'.  One can generate a new
> > type at run time, but there is no elegant mechanism in place to recover the
> > exact type.  Consider:
> > 
> >           mkMod(n : Integer) : IntegerMod( ? ) ==
> >                                    IntegerMod(compute(n))
> 
> I'm not absolutely sure what you mean here, since IntegerMod(compute(n)) is
> certainly not of type IntegerMod( ? ), no matter what the ? will be.
> 

Ah, sorry. Should have been something like:

       mkMod(n : Integer) : IntegerMod( ? ) ==
                                foo(n)::IntegerMod(compute(n))


The point is that types can be instantiated dynamically,  but there is
no way to state what the type is outside the dynamic context.  This is
compounded by the fact that, in Aldor, when you write IntegerMod(n +
1), to compare that type with any other the test for equality basicly
boils down to comparison of (typed) AST's.  Clearly, that is not
sufficient, as there is no way to `lift' those AST's from the context
of a callee to a caller. 

The notion of pattern matching over a parametrized domain/category
would allow type variables to be made abstract, and then reified
according to some (hopefully) sound rules.

> > In addition, IIRC (its been a while since I played with aldor), there
> > are real problems with how constants are treated.  In short, they are
> > not really constants.  I remeber seeing code such as:
> > 
> >         add!(r: %, s: %, t: %) : % == 
> >                  if one? % or zero? % then s + t else ...
> 
> I could not find code like that -- apart from the typo, you probably meant
> 
>          add!(r: %, s: %, t: %) : % == 
>                   if one? r or zero? r then s + t else ...

Again, sorry for the typo.  Your rendition is exactly what I meant.

Im not sure why you could not find code like that. I took a quick
look, and found a few examples in about a minute.  I also probably
found a bug too.  Check alg_sup0 in libalgebra and sal_intgmp in
libaldor.  Note that sal_fltgmp does not consistently check.  You may
want to test that calling add!(0, 1) on a gmp float actually changes
the value of `0' to `1'.  (Note that I could be wrong, I dont have
Aldor so I cant check myself). 

> > To work around the fact that the destructive add would modify the constants
> > `0' or `1', leading to predictable surprises.  The imperative aspect of the
> > language needs to be more carefully considered, IMHO, especially w.r.t the
> > semantics of a types parametrized over (possibly mutable) values.
> 
> Yes, constants may contain mutable data.  But that's just as in other
> languages.  It is true that you can say
> 
> l: List Integer == [1,2,3];
> l.1 := 4;
> 
> but in my opinion, you are not really modifying l, but rather l.1, and that's a
> different story.

Yes.  I understand the distinction.  The issue is how this plays with
a type parametrized over a mutable value.  There are three
alternatives that I see off hand:
    
      1) Dont worry about it, but make sure its written down that the
         consequences are undefined if an object which is used in type
         context is subsequently modified.

      2) At the level of implementation, ensure the property of
         `constantness' is checked at runtime before destructive
         update.

      3) Inject the notion of `constantness' into the type system.

I do not consider either of the above ideal, but option 1) is probably
the most pragmatic.  Option 2) gives safety but at some (small)
runtime cost. Option 3) is just there for its own sake.

> > > * certain difficulties transforming Tuples
> > 
> > I assume your talking about the issues raised in the article I mentioned
> > above?
> 
> possibly, but Ralf knows better.  Maybe you want to join our discussion on how
> to implement multisort species in Aldor?  There, we are pushing the limits of
> Aldor, I guess.  Also, the parser and domain generator I wrote shows some
> features one may want to have.

I am afraid I would not be able to contribute much to that
discussion.  I also have few free cycles to spare, unfortunately.

\start
Date: Tue, 26 Jun 2007 11:23:02 -0700 (PDT)
From: Cliff Yapp
To: Vadim V. Zhytnikov
Subject: Re: Axiom at version 3.4?

--- Vadim V. Zhytnikov wrote:

> No, quarterly gold releases in 2005 was numbered 3.4 (April 2005),
> 3.6 (June 2005), 3.9 (October 2005). In 2006 this numbering
> scheme was abolished.

Hmm.  Tim, does 3.9 correspond to the last update of the arch archive,
or was there some subsequent work?  My first tarball upload should be
the last Gold release, whatever that was.

> I watch this Axiom Version discussion with moderate interest.
> Moderate since I already (twice AFAIR) suggested on this list
> to choose some release numbering scheme convenient for
> packaging (deb, rpm whatever) but found no understanding.

I (think) I understand.  Once we have taken care of the banner
information and naming scheme for development versions I hope some form
of my Gold numbering proposal will be put in place.

> Surely, packaging is a nuisance external to Axiom but
> it is not wise to ignore this aspect of real life.

Agreed.

> Once again I venture to suggest two things
> 
> 1. Please, make regular _tarball_ releases.
>     No CVS, SVN etc - these are for development not for releases.

Right.  But most of the current work IS development work at the moment
- the feeding from development back to stable is kind of busted at the
moment.  Tim was kind enough to give me access to the sourceforge
project site, so I will be able to volunteer some effort to make the
tarball part happen.  That of course relies on getting the feeding of
improvements back into stable working, but I think we are about to seem
some real progress there.  (Tim's patch to fix file name issues on
various platforms, followed by Gaby's autoconf will go a LONG way to
making things more tolerable - after that come ANSI and working
HyperDoc.) 

> 2. Choose some X.Y.Z... numbering scheme
>     for these releases.

Martin, once we get the development version stuff worked out, did you
have any objections to the Gold numbering proposal?  

Tim, since you are after all the keeper of Gold (and the flame,
religion, etc ;-) does my proposal for distribution-friendly numbering
for the Gold releases make sense?

> Absence of 1 and 2 hurts Axiom publicity.

I tend to agree - publicity needs sound bites.

\start
Date: 26 Jun 2007 14:43:51 -0400
From: Stephen Wilson
To: Ralf Hemmecke
Subject: Re: Problem kTuple wish 2.
Cc: Christian Aistleitner

Hello Ralf,

Ralf Hemmecke writes:
[...]
> Try to define this apply function.
> 
> Important, I want to have as much type safety as possible, i.e. If I
> would have written
> 
> c := m(1, "x", false);
> 
> the compiler should already shout that the type of the first argument
> doesn't fit.

Initial thinking suggests that this would be difficult, if not
impossible, to implement genericly using static types.  I know of no
way to specify a non-homogeneous `cross' of arbitrary dimension, for
use as a meaningfull signature for `m' which the compiler could check.

Its been said before that static typing, when pushed to the limit,
becomes equivalent to dynamic typing -- that is to say, they are not
polar opposites.

Certainly this kind of generality is not on the radar for me any time
soon.

\start
Date: 26 Jun 2007 20:46:25 +0200
From: Martin Rubey
To: Stephen Wilson
Subject: Re: Axisp news
Cc: Christian Aistleitner, Ralf Hemmecke

Stephen Wilson writes:

> Martin Rubey writes: Big difference is that with
> a parametrized type, the parametrization forms a part of the `public
> interface' to the type.  No domain/category should be allowed to `hide' their
> parametrization, nor should they ever need to explicitly `export' them, as
> you mentioned RectangularMatrixCategory does.

OK.  The way I see aldor (and SPAD) is, that they simply allow functions that
produce types.  I'm not sure whether that is the same as a parametrized type.

I do not see why a domain should not be allowed to hide it's parametrization.
In fact, if you need access to a parameter, it is easy (in Aldor) to gain
access using "extend".

> Ah, sorry. Should have been something like:
> 
>        mkMod(n : Integer) : IntegerMod( ? ) ==
>                                 foo(n)::IntegerMod(compute(n))

But how are you going to compute with a result whose type you do not really
know.  I (meanwhile) really prefer something like

mkMod(n : Integer) : (m: Integer, IntegerMod m) == {
        (m := compute n, foo(n)::IntegerMod(m))
}

> Note that sal_fltgmp does not consistently check.  You may want to test that
> calling add!(0, 1) on a gmp float actually changes the value of `0' to `1'.

I checked, you are right.

> > Maybe you want to join our discussion on how to implement multisort species
> > in Aldor?  There, we are pushing the limits of Aldor, I guess.  Also, the
> > parser and domain generator I wrote shows some features one may want to
> > have.
> 
> I am afraid I would not be able to contribute much to that discussion.  

I'm quite sure that this is not true.  But even if true, it might make clearer
which features the language lacks.

\start
Date: 26 Jun 2007 20:49:36 +0200
From: Martin Rubey
To: Cliff Yapp
Subject: Re: Axiom at version 3.4?

Cliff Yapp writes:

> Martin, once we get the development version stuff worked out, did you have
> any objections to the Gold numbering proposal?

I suggest that we discuss that part once you (or somebody) has implemented the
(possibly semi-)automatic version information in the banner.

\start
Date: Tue, 26 Jun 2007 20:59:20 +0200
From: Ralf Hemmecke
To: Stephen Wilson
Subject: Re: Axisp news
Cc: Christian Aistleitner

On 06/26/2007 08:07 PM, Stephen Wilson wrote:
> Martin Rubey writes:
>> Dear Stephen,
>>
>> many thanks for your detailed answer.  I must admit however, that I dislike
>> your idea writing
>>
>>    D(P : Polynomial (R : Ring)) : ... == ...
>>
>> for
>>
>>    D(R : Ring, P : Polynomial R) : ... == ...
>>
>> Isn't this just syntactic sugar?  My feeling (!) is that this will pose more
>> questions than answers.  Enforcing case sensitivity on values, domains and
>> categories also does not look very appealing to me, sorry.
> 
> It may be syntactic sugar for the sake of a function definition, but it
> implies a handling of types which diverges from how things are
> currently done.

I must say, no matter whether it is syntactic sugar or not, a definition 
of the form

(*)     D(P : Polynomial (R : Ring)) : ... == ...

would confuse me. How am I supposed to used that? Should I write

D(P) for some polynomial? (Note that Polynomial is a domain so P is an 
element.)

You probably don't mean that. So let's assume that Polynom(R) is a category.

Now suppose I define

define MyPolyCat:Category == Polynom(Integer) with ...
MyPoly: MyPolyCat == add ...

Now can I write

   D MyPoly

??? (Note that it doesn't exactly match your pattern (*).)
Or should I rather write

   D(Integer, MyPoly)

even with just the definition (*)?

I cannot see that I would like such sugar.

\start
Date: Tue, 26 Jun 2007 15:08:15 -0400
From: Bill Page
To: Vadim V. Zhytnikov
Subject: Re: Axiom at version 3.4?

On 6/26/07, Vadim V. Zhytnikov wrote:
> Ralf Hemmecke writes:
> > ...
> > Even more interesting. Since I see September 2006 on my banner
> > (which is> --patch-50), that should probably be something > 3.6.
> >
>
> No, quarterly gold releases in 2005 was numbered 3.4 (April 2005),
> 3.6 (June 2005), 3.9 (October 2005). In 2006 this numbering
> scheme was abolished.
>

Vadim, can you find any record of the decision to abolish this
numbering system? I tried to find some reference in the
axiom-developer archives but failed.

> I watch this Axiom Version discussion with moderate interest.
> Moderate since I already (twice AFAIR) suggested on this list
> to choose some release numbering scheme convenient for
> packaging (deb, rpm whatever) but found no understanding.
> Surely, packaging is a nuisance external to Axiom but  it is not
> wise to ignore this aspect of real life.

Indeed. I find it very embarrassing. :-(

> Once again I venture to suggest two things
>
> 1. Please, make regular _tarball_ releases.
>     No CVS, SVN etc - these are for development not for releases.
>
> 2. Choose some X.Y.Z... numbering scheme
>     for these releases.
>

I agree and plead for some sanity in this discussion. There is no need
to be very creative here. We just need to follow *standard* practice -
and stick to it.

> Absence of 1 and 2 hurts Axiom publicity.
>

Yes, but I suppose it is only one of several such issues. I hope that
eventually if we can get more people who are willing to taking
responsibility for these administrative tasks, then we will be able to
reach a reasonable consensus acceptable to all and at the same time
improve our public image. I think that making this the responsibility
of one person is not enough.

As I said to Cliff when he decided to become an Axiom project
administrator at SourceForge: I think the purpose of requiring that
people register and that they must ask to be assigned administrator
rights is not to limit or prevent "unqualified" people from joining
(if you are here and you are interested, then you are qualified) - but
rather to help ensure that the project administrators are really
committed to taking responsibility for the job. So if anyone has an
opinion and some energy to devote to this task I would encourage you
to join.

\start
Date: 26 Jun 2007 15:12:12 -0400
From: Stephen Wilson
To: Martin Rubey
Subject: Re: Axisp news
Cc: Christian Aistleitner, Ralf Hemmecke

Martin,

Martin Rubey writes:
> Stephen Wilson writes:
> 
> > Martin Rubey writes: Big difference is that with
> > a parametrized type, the parametrization forms a part of the `public
> > interface' to the type.  No domain/category should be allowed to `hide' their
> > parametrization, nor should they ever need to explicitly `export' them, as
> > you mentioned RectangularMatrixCategory does.
> 
> OK.  The way I see aldor (and SPAD) is, that they simply allow functions that
> produce types.  I'm not sure whether that is the same as a parametrized type.
> 
> I do not see why a domain should not be allowed to hide it's parametrization.
> In fact, if you need access to a parameter, it is easy (in Aldor) to gain
> access using "extend".
> 
> > Ah, sorry. Should have been something like:
> > 
> >        mkMod(n : Integer) : IntegerMod( ? ) ==
> >                                 foo(n)::IntegerMod(compute(n))
> 
> But how are you going to compute with a result whose type you do not really
> know.  I (meanwhile) really prefer something like
> 
> mkMod(n : Integer) : (m: Integer, IntegerMod m) == {
>         (m := compute n, foo(n)::IntegerMod(m))
> }

Ah!  So terribly simple.  My thinking was reaching for exactly this
kind of construction.  Basicly my proposal extends the destructuring
of a tuple type to an arbirary type constructor, but it would
certainly not be necessary.  Your rendition would be sufficient.  Many
thanks for the insight!

> > Note that sal_fltgmp does not consistently check.  You may want to test that
> > calling add!(0, 1) on a gmp float actually changes the value of `0' to `1'.
> 
> I checked, you are right.
> 
> > > Maybe you want to join our discussion on how to implement multisort species
> > > in Aldor?  There, we are pushing the limits of Aldor, I guess.  Also, the
> > > parser and domain generator I wrote shows some features one may want to
> > > have.
> > 
> > I am afraid I would not be able to contribute much to that discussion.  
> 
> I'm quite sure that this is not true.  But even if true, it might make clearer
> which features the language lacks.

There is a mailing list?  I could lurk there and contribute as appropriate.

\start
Date: 26 Jun 2007 21:34:10 +0200
From: Martin Rubey
To: Stephen Wilson
Subject: Re: combinat mailing list
Cc: Christian Aistleitner, Ralf Hemmecke

Stephen Wilson writes:

> > > > Maybe you want to join our discussion on how to implement multisort
> > > > species in Aldor?  There, we are pushing the limits of Aldor, I guess.
> > > > Also, the parser and domain generator I wrote shows some features one
> > > > may want to have.
> > > 
> > > I am afraid I would not be able to contribute much to that discussion.
> > 
> > I'm quite sure that this is not true.  But even if true, it might make
> > clearer which features the language lacks.
> 
> There is a mailing list?  I could lurk there and contribute as appropriate.

https://lists.sourceforge.net/lists/listinfo/aldor-combinat-devel

What concerns the trouble with tuples, Ralf has already forwarded the
appropriate mail.

What concerns my parser and domain generator, there have been long discussions
a while back, concluding that my code is not legal Aldor code, but since it
works and Aldor (the language) doesn't seem to provide an alternative, we kept
it.

The main function is

interpret(p: List ExpressionTree): List LabelSpecies == {
        import from MachineInteger, LabelSpecies, List LabelSpecies;
        A: LabelSpecies == coerce EmptySetSpecies;
        res: List LabelSpecies := [A for x in p];
        E(i: MachineInteger)(L: LabelType): CombinatorialSpecies(L) == 
          (coerce evaluate(p.i, res))(L) add;
        for i in 1..#p repeat res.i := coerce E(i);        
        res;
}


which you find in trunk/combinat/src/interp.as.nw of the aldor-combinat tree.
There, you will also find quite precise documentation.

\start
Date: Tue, 26 Jun 2007 23:41:06 +0300
From: Vadim V. Zhytnikov
To: Bill Page
Subject: Re: Axiom at version 3.4?

Bill Page writes:
> On 6/26/07, Vadim V. Zhytnikov wrote:
>> Ralf Hemmecke writes:
>> > ...
>> > Even more interesting. Since I see September 2006 on my banner
>> > (which is> --patch-50), that should probably be something > 3.6.
>> >
>>
>> No, quarterly gold releases in 2005 was numbered 3.4 (April 2005),
>> 3.6 (June 2005), 3.9 (October 2005). In 2006 this numbering
>> scheme was abolished.
>>
> 
> Vadim, can you find any record of the decision to abolish this
> numbering system? I tried to find some reference in the
> axiom-developer archives but failed.
> 

I can't remember such discussion on the list either.
It just happened with next gold update.
I know this since I package axiom for one of Linux
distros and have to cope somehow with package
numbering.

\start
Date: 26 Jun 2007 15:43:39 -0400
From: Stephen Wilson
To: Ralf Hemmecke
Subject: Re: Axisp news
Cc: Christian Aistleitner

Ralf Hemmecke writes:

> On 06/26/2007 08:07 PM, Stephen Wilson wrote:
> > Martin Rubey writes:
> >> Dear Stephen,
> >>
> >> many thanks for your detailed answer.  I must admit however, that I dislike
> >> your idea writing
> >>
> >>    D(P : Polynomial (R : Ring)) : ... == ...
> >>
> >> for
> >>
> >>    D(R : Ring, P : Polynomial R) : ... == ...
> >>
> >> Isn't this just syntactic sugar?  My feeling (!) is that this will pose more
> >> questions than answers.  Enforcing case sensitivity on values, domains and
> >> categories also does not look very appealing to me, sorry.
> > It may be syntactic sugar for the sake of a function definition, but
> > it
> > implies a handling of types which diverges from how things are
> > currently done.
> 
> I must say, no matter whether it is syntactic sugar or not, a
> definition of the form
> 
> (*)     D(P : Polynomial (R : Ring)) : ... == ...
> 
> would confuse me. How am I supposed to used that? Should I write

Boy, my first email this morn had a few more typos than I would have
liked.  Ill try to ensure I have at least one cup of coffee before
sitting down to write an email :)

In the scheme I was (trying, badly) to suggest would have looked as
follows:

        D(p : Polynomial (R : Ring)) : ... == ..

Notice the p is lowercased, hense denoting a domain value.

Note that Martins email gave me some understanding into how the
advantages of such `patterns' can be expressed in target types using
only the notion of tuple.  So this really is just syntatic sugar.  Im
not married to it at all :)
 
> D(P) for some polynomial? (Note that Polynomial is a domain so P is an
> element.)
> You probably don't mean that. So let's assume that Polynom(R) is a category.
> 
> Now suppose I define
> 
> define MyPolyCat:Category == Polynom(Integer) with ...
> MyPoly: MyPolyCat == add ...
> 
> Now can I write
> 
>    D MyPoly
> 
> ??? (Note that it doesn't exactly match your pattern (*).)
> Or should I rather write
> 
>    D(Integer, MyPoly)
> 
> even with just the definition (*)?
> 
> I cannot see that I would like such sugar.

Ok, sorry for the confusion.  Using your example, I would have
written:  D(P : Polynom(R : Ring)) ...

Then yes, you would write `D MyPoly'.


As an involved example, consider the following from libalgebra.  We have:

  macro {
          DRX == DenseUnivariatePolynomial R;
          UPC == UnivariatePolynomialAlgebra;
          UTSC == UnivariateTaylorSeriesType;
  }

  UnivariateTaylorSeriesNewtonSolver(R:Join(ArithmeticType, ExpressionType),
                                     RXX:UTSC R, RXXY:UPC RXX): with {
                                     ...

One way you could write such a thing using the scheme I proposed is:

   macro { 
          DUP(R) == DenseUnivariatePolynomial R;
          UPC == UnivariatePolynomialAlgebra;
          UTSC == UnivariateTaylorSeriesType;
          UTSNS == UnivatiateTaylorSeriesNewtonSolver;
   }

   UTSNS(RXXY : UPC(RXX: UTSC(R : Join(ArithmeticType, ExpressionType))))

Thus, a user of the solver would only need to supply a single pice of
information, a domain implementing UnivariatePolynomialAlgebra.  The
arity is reduced from three to one.

But it is just syntatic sugar.

\start
Date: 26 Jun 2007 15:57:54 -0400
From: Stephen Wilson
To: Martin Rubey
Subject: Re: combinat mailing list
Cc: Christian Aistleitner, Ralf Hemmecke

I subscribed to the combinat list.  I am also in the process of
setting up an older machine which I hope will allow me to get an aldor
binary running.

I will look at you code, and at the archives, and attempt to
understand the issues involved.

I have high hopes that we can enrich Axiom's abilities to describe
mathematics.

Take care,
Steve

Martin Rubey writes:

> Stephen Wilson writes:
> 
> > > > > Maybe you want to join our discussion on how to implement multisort
> > > > > species in Aldor?  There, we are pushing the limits of Aldor, I guess.
> > > > > Also, the parser and domain generator I wrote shows some features one
> > > > > may want to have.
> > > > 
> > > > I am afraid I would not be able to contribute much to that discussion.
> > > 
> > > I'm quite sure that this is not true.  But even if true, it might make
> > > clearer which features the language lacks.
> > 
> > There is a mailing list?  I could lurk there and contribute as appropriate.
> 
> https://lists.sourceforge.net/lists/listinfo/aldor-combinat-devel
> 
> What concerns the trouble with tuples, Ralf has already forwarded the
> appropriate mail.
> 
> What concerns my parser and domain generator, there have been long discussions
> a while back, concluding that my code is not legal Aldor code, but since it
> works and Aldor (the language) doesn't seem to provide an alternative, we kept
> it.
> 
> The main function is
> 
> interpret(p: List ExpressionTree): List LabelSpecies == {
>         import from MachineInteger, LabelSpecies, List LabelSpecies;
>         A: LabelSpecies == coerce EmptySetSpecies;
>         res: List LabelSpecies := [A for x in p];
>         E(i: MachineInteger)(L: LabelType): CombinatorialSpecies(L) == 
>           (coerce evaluate(p.i, res))(L) add;
>         for i in 1..#p repeat res.i := coerce E(i);        
>         res;
> }
> 
> 
> which you find in trunk/combinat/src/interp.as.nw of the aldor-combinat tree.
> There, you will also find quite precise documentation.

\start
Date: Tue, 26 Jun 2007 15:48:07 -0500 (CDT)
From: Gabriel Dos Reis
To: list
Subject: Axiom versioning

Vadim --

  I completely agree with your assessment.

Please just pick 4.0 and be done with it.  

\start
Date: 26 Jun 2007 22:49:11 +0200
From: Martin Rubey
To: Waldek Hebisch
Subject: fixes / day

I would like to propose a new unit of measurement for fixes per day and call it
Waldek.

Many thanks, Waldek!

\start
Date: 26 Jun 2007 17:20:44 -0400
From: Camm Maguire
To: Waldek Hebisch
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

Greetings!  My cvs is down at the moment.  Until I get the fix in, you
can replace

(declare (ignore tpn))

 with

tpn

in lsp/gcl_callhash.lsp, function do-recompile.

Please let me know if problems persist.

Take care,


Waldek Hebisch writes:

> > Greetings, and thanks Waldek!  Should be fixed now.  (The format of
> > this report was very helpful.)
> >
>
> Thanks for your message.  I tried new version from cvs and I again
> have build problem:
>
> ;; Compiling ../lsp/gcl_callhash.lsp.
> ; (DEFUN DO-RECOMPILE ...) is being compiled.
> ;;; The declaration (DECLARE (IGNORE TPN)) was found in a bad place.
> Error: ERROR "The tag (NIL) is undefined."
> Signalled by COMPILER::CMPERR.
> ERROR "The tag (NIL) is undefined."
>
> Broken at COMPILER::CMPERR.  Type :H for Help.
> SYSTEM>>make: *** [unixport/saved_pre_gcl] B=B3=B1d 255
>
>
> The configure log is at:
>
> http://www.math.uni.wroc.pl/~hebisch/prog/clogg
>
> The build log is at:
>
> http://www.math.uni.wroc.pl/~hebisch/prog/mlogg
>
> The machine is 64-bit dual core Pentium D 805 running Debian etch.

\start
Date: Tue, 26 Jun 2007 16:45:28 -0500 (CDT)
From: Gabriel Dos Reis
To: Martin Rubey
Subject: Re: Automated version update

On Tue, 26 Jun 2007, Martin Rubey wrote:

| Dear Gaby,
| 
| Gabriel Dos Reis writes:
| 
| >   It is obvious to me that automated version updated can run as follows:
| > 
| >     * daily bump: anywhere, preferably a machine that is almost always
| >         up -- we can use the cron job facility at SF.
| 
| Yes, of course.  But suppose that Mrs. Xyz commits at 12:34 GMT, the cron job
| runs at 23:59 GMT and Mrs. Uvw checks out inbetween.

I don't understand what the concrete practical problem is.  We have been using
this scheme for a decade now.  Most certainly, GCC has far more developers,
check out, check in activity than Axiom had or will ever have.

| By the way, I just realised that I do not understand completely: you propose to
| have one file "version" for each branch, that is modified by a cron job on SF,
| if and only if the revision has changed.

By daily version update, I mean the "2006-06-26" date stamp.  That
happens at most once a day, and is a string manipulation in a source file --
see the script I sent.

|  (More precisely, whenever 
| 
|   LC_ALL=C svn info | grep "Last Changed Rev:"
| 
| has changed.)
| 
| But, if this file is under version control, wouldn't that update trigger
| another revision number?

Yes, and that is why nobody want to do that. :-)

For the SVN revision number in a release, I suggested that it is put in place
when the release is done, so the release script can use svnversion (which
retrieves the revision number of the checked out path).

| Important PS: just after the last AxiomWorkshop I realized that
| there are zero female developers for Axiom.  Any ideas how to change
| this?

\start
Date: 26 Jun 2007 18:22:47 -0400
From: Stephen Wilson
To: Camm Maguire
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

Camm,

Camm Maguire writes:

> Greetings!  My cvs is down at the moment.  Until I get the fix in, you
> can replace
>
> (declare (ignore tpn))
>
>  with
>
> tpn
>
> in lsp/gcl_callhash.lsp, function do-recompile.
>
> Please let me know if problems persist.

FYI, this change allowed the build to complete for me with ./configure
--enable-ansi on i386 slackware 11.0.0

> Waldek Hebisch writes:
>
> > > Greetings, and thanks Waldek!  Should be fixed now.  (The format of
> > > this report was very helpful.)
> > >
> >
> > Thanks for your message.  I tried new version from cvs and I again
> > have build problem:
> >
> > ;; Compiling ../lsp/gcl_callhash.lsp.
> > ; (DEFUN DO-RECOMPILE ...) is being compiled.
> > ;;; The declaration (DECLARE (IGNORE TPN)) was found in a bad place.
> > Error: ERROR "The tag (NIL) is undefined."
> > Signalled by COMPILER::CMPERR.
> > ERROR "The tag (NIL) is undefined."
> >
> > Broken at COMPILER::CMPERR.  Type :H for Help.
> > SYSTEM>>make: *** [unixport/saved_pre_gcl] B=B3=B1d 255
> >
> >
> > The configure log is at:
> >
> > http://www.math.uni.wroc.pl/~hebisch/prog/clogg
> >
> > The build log is at:
> >
> > http://www.math.uni.wroc.pl/~hebisch/prog/mlogg
> >
> > The machine is 64-bit dual core Pentium D 805 running Debian etch.

\start
Date: Tue, 26 Jun 2007 17:39:28 -0500
From: Tim Daly
To: William Sit
Subject: a suggestion

William,

Post your suggestion publicly. Ask for a vote. We will go with
the majority opinion. You get to keep the final count.

\start
Date: Wed, 27 Jun 2007 00:39:26 +0200
From: Ralf Hemmecke
To: Stephen Wilson
Subject: Re: Axisp news
Cc: Christian Aistleitner

>> I must say, no matter whether it is syntactic sugar or not, a
>> definition of the form
>>
>> (*)     D(P : Polynomial (R : Ring)) : ... == ...
>>
>> would confuse me. How am I supposed to used that? Should I write
> 
> Boy, my first email this morn had a few more typos than I would have
> liked.  Ill try to ensure I have at least one cup of coffee before
> sitting down to write an email :)
> 
> In the scheme I was (trying, badly) to suggest would have looked as
> follows:
> 
>         D(p : Polynomial (R : Ring)) : ... == ..
> 
> Notice the p is lowercased, hense denoting a domain value.

Oh, you would like to turn a convention into a language construct. I 
have programmed enough in Aldor to be able to say, that is a bad thing.
Note that + or 1 can be used to denote identifiers in Aldor. Are they 
lower or upper case?

>> Now suppose I define
>>
>> define MyPolyCat:Category == Polynom(Integer) with ...
>> MyPoly: MyPolyCat == add ...
>>
>> Now can I write
>>
>>    D MyPoly
>>
>> ??? (Note that it doesn't exactly match your pattern (*).)
>> Or should I rather write
>>
>>    D(Integer, MyPoly)
>>
>> even with just the definition (*)?
>>
>> I cannot see that I would like such sugar.
> 
> Ok, sorry for the confusion.  Using your example, I would have
> written:  D(P : Polynom(R : Ring)) ...
> 
> Then yes, you would write `D MyPoly'.

So then let's go on. How would MyPoly now tell you that it is defined 
over Integer? Its type is MyPolyCat (there is still no Integer). So in 
order to find out that the Argument I give you fits your pattern, you 
have to look inside the category hierarchy. OK, should be doable, but is 
more than just pattern matching. Still, I don't like it.

Suppose you would have something like

DAldor(R: Ring, D1: CatA(R), D2: CatB(R)): ...

Then your way would probably lead to

DSteve(D1: CatA(R: Ring), D2: CatB(R: Ring)): ...

That is needless doubly typing "Ring" and even worse, it is ambiguous.
Who does tell me that this definition would be equal or different from

DSteve(D1: CatA(R: Ring), D2: CatB(S: Ring)): ...

I must say, if you modify the language in that direction, I am the first 
who doesn't follow your direction.

\start
Date: Wed, 27 Jun 2007 00:42:23 +0200 (CEST)
From: Waldek Hebisch
To: Camm Maguire
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

> Greetings!  My cvs is down at the moment.  Until I get the fix in, you
> can replace
> 
> (declare (ignore tpn))
> 
>  with
> 
> tpn
> 
> in lsp/gcl_callhash.lsp, function do-recompile.
> 
> Please let me know if problems persist.
> 

Thank you for the hint.  After editing lsp/gcl_callhash.lsp and
restarting build it went much further, however I see another
error:

./raw_ansi_gcl /var/tmp/hebisch/lisp/gcl-20070626.2/unixport/  -libdir /var/tmp/hebisch/lisp/gcl-20070626.2/ < foo
GCL (GNU Common Lisp)  April 1994  524288 pages
Building symbol table for /var/tmp/hebisch/lisp/gcl-20070626.2/unixport/raw_ansi_gcl ..

<many lines snipped>

Signalled by LET.
SIMPLE-ERROR: can't compile CMP-ANON

Broken at LET.  Type :H for Help.
 1 (Continue) Retry compiling (COMPILER::CMP-ANON NIL).
 2 Retry compiling (COMPILER::CMP-ANON NIL).
 3 Return to top level.


Note that before I saw your e-mail I have fetched newer gcl version
from cvs, it failed exactly in the same place as previously.  Following
your advice I edited the problematic file and restarted the build.

Log of build after restart is at:

http://www.math.uni.wroc.pl/~hebisch/prog/mlogg2

\start
Date: 26 Jun 2007 18:54:28 -0400
From: Stephen Wilson
To: Ralf Hemmecke
Subject: Re: Axisp news
Cc: Christian Aistleitner

Ralf Hemmecke writes:

> >> I must say, no matter whether it is syntactic sugar or not, a
> >> definition of the form
> >>
> >> (*)     D(P : Polynomial (R : Ring)) : ... == ...
> >>
> >> would confuse me. How am I supposed to used that? Should I write
> > Boy, my first email this morn had a few more typos than I would have
> > liked.  Ill try to ensure I have at least one cup of coffee before
> > sitting down to write an email :)
> > In the scheme I was (trying, badly) to suggest would have looked as
> > follows:
> >         D(p : Polynomial (R : Ring)) : ... == ..
> > Notice the p is lowercased, hense denoting a domain value.
> 
> Oh, you would like to turn a convention into a language construct. I
> have programmed enough in Aldor to be able to say, that is a bad thing.
> Note that + or 1 can be used to denote identifiers in Aldor. Are they
> lower or upper case?

Im not going to try and defend the idea, as I feel I can work with
simpler notions.  But 1 and + would be considered value identifiers.

> 
> >> Now suppose I define
> >>
> >> define MyPolyCat:Category == Polynom(Integer) with ...
> >> MyPoly: MyPolyCat == add ...
> >>
> >> Now can I write
> >>
> >>    D MyPoly
> >>
> >> ??? (Note that it doesn't exactly match your pattern (*).)
> >> Or should I rather write
> >>
> >>    D(Integer, MyPoly)
> >>
> >> even with just the definition (*)?
> >>
> >> I cannot see that I would like such sugar.
> > Ok, sorry for the confusion.  Using your example, I would have
> > written:  D(P : Polynom(R : Ring)) ...
> > Then yes, you would write `D MyPoly'.
> 
> So then let's go on. How would MyPoly now tell you that it is defined
> over Integer? Its type is MyPolyCat (there is still no Integer). So in
> order to find out that the Argument I give you fits your pattern, you
> have to look inside the category hierarchy. OK, should be doable, but
> is more than just pattern matching. Still, I don't like it.
> 
> Suppose you would have something like
> 
> DAldor(R: Ring, D1: CatA(R), D2: CatB(R)): ...
> 
> Then your way would probably lead to
> 
> DSteve(D1: CatA(R: Ring), D2: CatB(R: Ring)): ...
> 
> That is needless doubly typing "Ring" and even worse, it is ambiguous.
> Who does tell me that this definition would be equal or different from
> 
> DSteve(D1: CatA(R: Ring), D2: CatB(S: Ring)): ...
> 
> I must say, if you modify the language in that direction, I am the
> first who doesn't follow your direction.

No, my way would be:

   DSteve(D1: CatA(R: Ring), D2: CatB(R)): ...

However, I need to explore the use tuples exclusively to lift types
otherwise hidden by sope into an enclosing context.  I suspected that
type patterns would be generally useful but I like the simplicity of
Martins approach and will try to work with that.

\start
Date: Tue, 26 Jun 2007 19:09:43 -0400
From: William Sit
To: Tim Daly
Subject: A suggestion for Gold

The following email (with minor changes) was originally sent
to Tim and he replied: "Post your suggestion publicly. Ask
for a vote. We will go with the majority opinion. You get to
keep the final count."

So please feel free to comment, and may be Bill Page can set
up a sandbox page to keep votes? (sorry, I don't have the
expertise).

William
---

Dear Tim:

What I am proposing may be very drastic and objectionable
from yours perspectives. Still, I think it may be worth your
consideration. All I would like is simply to suggest, in my
uneducated opinion, a possibly more efficient path of lesser
resistance to bring the release version of Axiom up-to-date
asap so we can attract more users and developers.

Given that the consensus (at least 90% by unscientific
observation counts) is that wh-sandbox is the preferrable
version, I wonder how difficult it would be for you to port
(co-opt) your modifications (such as regression tests and
case modificiations) to the wh-sandbox branch and then make
it Gold? Let's forget about documentation for the moment
because documentation slows development efforts. People in
the know can read the code and I agree that in the final
analysis, no matter how much documentation is included, it
is the code that really matters. Documentation will help,
but lack of documentation does not hold back the determined
and knowledgeable. In fact, there is a balance where if
tipped towards too much documentation, then it would be more
time consuming to wade through the verbal explanation than
to read the code itself. So to ask Waldek or Gaby (just two
such examples) to spend their valuable time to fit into your
vision at this time of Axiom development cycle is simply
unwise, even if the horizon is more than 20 years.

The improvement with Axiom is too fast for anyone but the
real
gurus like Waldek or Gaby to catch up with. If Axiom release
mechanism continues on its present course, I am afraid that
many of the improvements and bug fixes will not be
incorporated in a timely manner and this divergence will
only get magnified with time and we may lose developers or
have the project forked.

I know you are worried about correctness, but we can develop
a plan to verify correctness by co-opting resources from the
mailing list and parcelling out specific tests to
individuals. Your regression tests can still be run after
each major rebuild.

So if it is not too difficult, merging your changes into
wh-sandbox would be the fastest way to a new release that
"just works" (this does not mean there will be no bugs, or
old working code will not be broken, but these will be
tested
and then fixed, just like any other bugs). The lack of
documentation is not a big problem because it would be a
waste to document code that is not final (much of
intermediate documentation must be either removed or revised
and if left as part of the historical documentation, will
clutter up the source). Once the "pre-algebra" layers are
seet up and have the right tools for building Axiom, we can
then concentrate on documenting the new source and algebra.

If you can do this, you would be giving the project a big
uplift.

And, thanks to all your efforts (and others), Axiom will
survive, and be better.

\start
Date: Wed, 27 Jun 2007 01:11:02 +0200
From: Ralf Hemmecke
To: Stephen Wilson
Subject: Re: Axisp news

> Im not going to try and defend the idea, as I feel I can work with
> simpler notions.  But 1 and + would be considered value identifiers.

You might be right, but what I will certainly do in a near future is an 
implementation of a domain whose elements are combinatorial species. 
That domain will be a semiring, so I will use + and 1 to denote the 
"elements" Plus
(http://www.risc.uni-linz.ac.at/people/hemmecke/AldorCombinat/combinatsu23.html#x37-550008.10)
and EmptySetSpecies 
(http://www.risc.uni-linz.ac.at/people/hemmecke/AldorCombinat/combinatsu17.html#x31-380008.4.1).
As you see these identifiers actually denote not only domains but 
functions that return domains. Would you like me not to use 1 just 
because my elements would be domains?

Having the types as first class objects has the consequence that type 
can appear in places where you expect an "element".

> However, I need to explore the use tuples exclusively to lift types
> otherwise hidden by sope into an enclosing context.  I suspected that
> type patterns would be generally useful but I like the simplicity of
> Martins approach and will try to work with that.

Martin was just demonstrating ordinary use of a dependent type.

\start
Date: 26 Jun 2007 19:35:31 -0400
From: Stephen Wilson
To: Ralf Hemmecke
Subject: Re: Axisp news

Ralf Hemmecke writes:

> > Im not going to try and defend the idea, as I feel I can work with
> > simpler notions.  But 1 and + would be considered value identifiers.
> 
> You might be right, but what I will certainly do in a near future is
> an implementation of a domain whose elements are combinatorial
> species. That domain will be a semiring, so I will use + and 1 to
> denote the "elements" Plus
> (http://www.risc.uni-linz.ac.at/people/hemmecke/AldorCombinat/combinatsu23.html#x37-550008.10)
> and EmptySetSpecies
> (http://www.risc.uni-linz.ac.at/people/hemmecke/AldorCombinat/combinatsu17.html#x31-380008.4.1).
> As you see these identifiers actually denote not only domains but
> functions that return domains. Would you like me not to use 1 just
> because my elements would be domains?
> 
> Having the types as first class objects has the consequence that type
> can appear in places where you expect an "element".

Ok.  There are certainly issues and am dropping the idea for now.

> 
> > However, I need to explore the use tuples exclusively to lift types
> > otherwise hidden by sope into an enclosing context.  I suspected that
> > type patterns would be generally useful but I like the simplicity of
> > Martins approach and will try to work with that.
> 
> Martin was just demonstrating ordinary use of a dependent type.

Yes.  Unfortuanately it is not so ordinary for Spad.  I will see what
I can do.

\start
Date: Tue, 26 Jun 2007 19:46:05 -0400
From: Bill Page
To: William Sit
Subject: Re: A suggestion for Gold

On 6/26/07, William Sit wrote:
> The following email (with minor changes) was originally sent
> to Tim and he replied: "Post your suggestion publicly. Ask
> for a vote. We will go with the majority opinion. You get to
> keep the final count."
>
> So please feel free to comment, and may be Bill Page can set
> up a sandbox page to keep votes? (sorry, I don't have the
> expertise).
>
> ...

As William requested I have created the following page on the Axiom wiki:

http://wiki.axiom-developer.org/VoteASuggestionForGold

Please click on the above link and vote for or against his proposal.

\start
Date: Tue, 26 Jun 2007 20:13:10 -0400
From: Bill Page
To: William Sit
Subject: Re: A suggestion for Gold

William

On Tue Jun 26 18:55:59 -0500 2007 you commented:

> I think everyone can "vote" using the page rating just above the
> "Add Comments" area. However, the rating choices right now are
> biased positively. I think the range should be from -2 to +2 and not
> -1 to +3. Comments, in particular, dicussions on technicalities, of
> course are welcome.

> Bill, is there a way to enforce voting only "once"?
>
> Thanks for putting up this page.

You are welcome. But sorry, no there is no way to use the page rating
in the manner that you suggest. I have reverted this comment from the
web page since it might otherwise cause some confusion.

I think it is best if people simply identify themselves when they
leave a comment.

\start
Date: Wed, 27 Jun 2007 02:46:10 +0200 (CEST)
From: Waldek Hebisch
To: Gregory Vanuxem
Subject: Re: *read-default-float-format* in SBCL/wh-sandbox


> Le samedi 23 juin 2007 ? 21:08 +0200, Waldek Hebisch a =E9crit :
> > Do you think we should set *read-default-float-format*
> > to T?  I must admit that in Lisp/boot sources I would prefer to
> > explicitly specify double precision (when needed), while for
> > Spad/input we are (or should be) using our own routines anyway.
>
> I agree but I see two issues here, the first one is that when
> $useBFasDefault is set to false Axiom creates single-floats and
> therefore computations are done over single-floats. You can try in the
> interpreter :
>
> )bo $useBFasDefault := false
>
> 1.0/3*float(3,0,10)@DoubleFloat
>
> => 1.0000000298023224d0
>
>
> This can be fixed by modifying the function MAKE-FLOAT in macros.lisp
> (replacing the 'e' by a 'd' in the format) . This feature - using
> DoubleFloat by default instead of Float - is very handy when you write a
> Spad file where computations are done on DoubleFloat : you don't have to
> coerce each Float and the generated Lisp file is cleaner.
>
> The other issue is how a DoubleFloat is displayed. Since we let Lisp
> display it and *read-default-float-format* is set to single-float the
> 'd' character is added to its printed representation.
>
> I think that in the mean time (as far as the Lisp "formatter" is used to
> displays double-floats) *read-default-float-format* should be set to
> double-float.
>

OK.  As of revision 645 *read-default-float-format* should be set to
double-float.  This was somewhat tricky with sbcl -- if one just
sets value it seem to get lost after restarting the image (IIUC
you wrote about this problem).  So I introduced an init function
which is called before toplevel.  In the process I think that
I also fixed the )fin issue (typing )fin now gives the sbcl
prompt).

\start
Date: Tue, 26 Jun 2007 21:56:23 -0400
From: Bill Page
To: William Sit
Subject: Re: A suggestion for Gold
Cc: Gabriel Dos Reis

On 6/26/07, William Sit wrote:
> The following email (with minor changes) was originally sent
> to Tim and he replied: "Post your suggestion publicly. Ask
> for a vote. We will go with the majority opinion. You get to
> keep the final count."
>
> So please feel free to comment, and may be Bill Page can set
> up a sandbox page to keep votes? (sorry, I don't have the
> expertise).
>

http://wiki.axiom-developer.org/VoteASuggestionForGold

When someone asks for a vote and it is seconded by another, William
Sitt and Tim Daly in this case, I suppose the usual "rules-of-order"
would say that we should just vote with a minimum of further
discussion. But since we seem to be making the rules as we go, I can't
resist the opportunity to make a few comments before deciding how I
should vote.

First, I want to thank William for suggesting such a bold but perhaps
obvious move. This is certainly one way to resolve a lot of problems
and move ahead very quickly without further risk of a fork in the
Axiom project.  It also has the merit of apparently being quite simple
and easy to accomplish. After building and using wh-sandbox on several
different machines I also have a lot of confidence that wh-sandbox is
a very significant improvement over the current Axiom Gold release.
But is it too big of a quantum leap?

Thanks to Waldek's admirable energy and skill wh-sandbox is still
evolving quite rapidly. Should we really just pick a current revision
of wh-sandbox and merge it with Tim's current Silver (= SVN trunk) as
William proposes? We can define the result as the new Silver, but then
what happens to build-improvments which thanks to Gaby's continuing
effort has also been evolving on a somewhat different but related
path? wh-sandbox was branched from build-improvements but that is now
several hundred revisions ago. Would this make it easier or more
difficult to merge build-improvements also back into SVN trunk?

And what about the actual process? We would presumably rather quickly
promote this new Silver to new Gold so that the largest number of
Axiom users would be able to take advantage of these changes. But are
we risking the possibility of a serious reversion of functionality if
the testing is not sufficient and if the documentation remains at it's
present minimum level?

I agree in principle that open source development should proceed at a
very aggressive pace. That is the best (only?) way by which we can
hope to keep the interest and attention of the largest number of Axiom
developers and users. And I think it is reasonable to take a fairly
high level of risk - moderated by use of modern source code management
tools that in principle make it possible to manage multiple versions
of source code very easily. Also we should acknowledge that Axiom in
it's current state is still very much a "research work in progress"
and *not* a direct competitor for the existing commercial alternatives
when it comes to "production oriented" applications. So we are
therefore free to engage "warp drive" when we feel we need to without
risking it all down some wormhole. (If you will tolerate my extended
metaphor. :-)

Of course all of this depends on the willingness of the primary
maintainers of wh-sandbox, build-improvments and Silver to co-operate
in the suggested manner. Without that, "voting" on the issue seems
rather moot.

I think I will ponder these questions of another 24 hours before I
decide my final reply to this proposal.

\start
Date: Tue, 26 Jun 2007 22:35:56 -0400
From: Bill Page
To: Gabriel Dos Reis
Subject: re: Autoconf change

On 6/25/07, Gabriel Dos Reis wrote:
> ...
> On Mon, 25 Jun 2007, Tim Daly wrote:
> | ...
> | I have a pending downcase change which is complete and ready to
> | undergo testing. Since it is guaranteed to make your changeset
> | incompatible I'll withhold it until your changeset is ready to
> | apply. Then I'll refit the downcase change.
>
> Please don't hold your downcasing changes on the Autoconf machinery.
> As I explained two weeks ago (or so), I'm on travel and my main machine at
> this moment is a windows based system.  I'm not fully back to home
> untill August 2-3.  we will most certainly meet at ISSAC,
> July 29-August 1, and try to resolve other issues in a face-to-face
> meeting.
>

Although I understand the complications that case-reserving
case-insensitive file names can create on Windows and MAC OS/X and a
few other systems but I think that complete downcasing of of all file
names in the Axiom source code is unnecessary and significantly
degrades the readability of the code. Right now both the
build-improvements and wh-sandbox branches have solved this problem of
the collision of file names with only the minimum changes necessary to
support Windows and OS/X. In my view this is the proper approach. As
long as Axiom developers remain aware of the possibility of such
collision of names, then I think that the possibility of confusion is
remote and the maximum utilization of the capabilities of "sane" like
those of Unix and Linux remains.

So, please don't downcase all file names.

\start
Date: 27 Jun 2007 08:58:03 +0200
From: Martin Rubey
To: Stephen Wilson
Subject: Re: Axisp news

Dear Stephen,

Just to make sure: I hope Ralf and myself have not discouraged you from your
work on SPAD.  However, I think it would be more promising to try to make SPAD
converge towards the Aldor language:

* Aldor (the language) is relatively well understood - thanks for recalling the
  article by Poll and Thompson, by the way

* Aldor (the language!) proved useful (even if not fully implemented) and
  sufficiently stable

Maybe it is not as "sexy" to try to implement a language specification, but I
assure you, it would help a lot if you made some progress here.  Personally I
made the experience that I do not have the talent to design a new language, but
using Aldor, I sometimes see how one could go on.  (To make this more precise:
I really want to work with Tuples as first class citizens, for example.  Also,
I would like to be able to check -- some sort of -- equality of domains at
times, even if impossible in general.)

Maybe I can propose some projects:

* Obviously, the most important thing for now would be to make types truly
  first class objects.  I guess that this is quite hard, though.  

* Possibly it is easier to make Axiom understand signatures as they are
  possible in Aldor.  For example, it would be wonderful if we could use the
  signatures used in our species project directly in Aldor.  Possibly SPAD
  doesn't understand curried signatures at the domain/package level:  in
  src/species.as.nw we have

<<dom: CharacteristicSpecies>>=
CharacteristicSpecies(n:Integer)(L:LabelType): CombinatorialSpecies L == add {
        Rep == SetSpecies L;
        import from Rep;
        nn: I == machine n;
        <<implementation: CharacteristicSpecies>>
}
@

but in SPAD / Axiom we cannot use it: 


(1) -> )sh CharacteristicSpecies
 CharacteristicSpecies n: ACInteger  is a domain constructor
 Abbreviation for CharacteristicSpecies is CHARACT 
 This constructor is exposed in this frame.
 Issue )edit csspecies.as to see algebra source code for CHARACT 

------------------------------- Operations --------------------------------
 CharacteristicSpecies n is a domain constructor.
 Abbreviation for CharacteristicSpecies is CHARACT 
 This constructor is exposed in this frame.
 Issue )edit csspecies.as to see algebra source code for CHARACT 

------------------------------- Operations --------------------------------

(1) -> generatingSeries()$(CharacteristicSpecies(2)(ACINT))
 
   Category, domain or package constructor CharacteristicSpecies2 is 
      not available.
(1) -> generatingSeries()$(CharacteristicSpecies(2, ACINT))
 
   The constructor CharacteristicSpecies takes 1 argument and you have 
      given  2  .


* Finally, maybe you could make SPAD accept arbitrary conditions for
  conditional exports.  I.e., the following should keep working when commenting
  out the second condition.  (Currently SPAD accepts only conditions like "A
  has B" and "A is B", connected with "and", "or", "not".

)abb package TEST Test
Test(R: Field): with
    if R has Finite -- and (one?(size()$R)) 
    then foo: Integer -> Integer
    else bar: Integer -> Integer

  == add

    if R has Finite -- and (one?(size()$R)) 
    then foo n == n
    else bar n == n

Maybe one of these projects is for you,

\start
Date: Wed, 27 Jun 2007 12:17:24 +0200
From: Gernot Hueber
To: Waldek Hebisch
Subject: SBCL/wh-sandbox

Dear Waldek,

I am trying to compile wh-sandbox (co from yesterday) with sbcl on a
FreeBSD 6.2 system. Compile ran fine for a long time (it finished with
gcl). Yet a problem occured. Pls see below for the locking?! Can you
give me some advice. Is this due to the sockets and writablep issue?

I configured using "--with-lisp=/usr/local/bin/sbcl" only!

[...]
gmake[2]: Entering directory
`/usr/home/ghue/src/wh-sandbox-sbcl/src/paste'
(cd /home/ghue/src/wh-sandbox-sbcl/target/i386-unknown-freebsd6.2/share/hypertex/pages; \
          rm -f ht.db ; \
          /home/ghue/src/wh-sandbox-sbcl/target/i386-unknown-freebsd6.2/bin/htadd *.ht)
Added   3 pages and/or macros from ALIST.ht
Added  19 pages and/or macros from ANNA-ES.ht
Added   3 pages and/or macros from ARRAY1.ht
Added   3 pages and/or macros from ARRAY2.ht
Added   3 pages and/or macros from BBTREE.ht
Added   3 pages and/or macros from BINARY.ht
Added   3 pages and/or macros from BOP.ht
Added   3 pages and/or macros from BSTREE.ht
Added   3 pages and/or macros from CARD.ht
Added   3 pages and/or macros from CARTEN.ht
Added   3 pages and/or macros from CCLASS.ht
Added   3 pages and/or macros from CHAR.ht
Added  15 pages and/or macros from CLIF.ht
Added   3 pages and/or macros from COMPLEX.ht
Added   3 pages and/or macros from CONTFRAC.ht
Added   1 pages and/or macros from CPHelp.ht
Added   3 pages and/or macros from CYCLES.ht
Added   3 pages and/or macros from DECIMAL.ht
Added   3 pages and/or macros from DERHAM.ht
Added   3 pages and/or macros from DFLOAT.ht
Added   3 pages and/or macros from DMP.ht
Added   3 pages and/or macros from EQ.ht
Added   3 pages and/or macros from EQTBL.ht
Added   3 pages and/or macros from EXIT.ht
Added   3 pages and/or macros from EXPR.ht
Added   3 pages and/or macros from FARRAY.ht
Added   3 pages and/or macros from FILE.ht
Added  15 pages and/or macros from FLOAT.ht
Added   3 pages and/or macros from FNAME.ht
Added   3 pages and/or macros from FPARFRAC.ht
Added  18 pages and/or macros from FR.ht
Added   3 pages and/or macros from FR2.ht
Added   3 pages and/or macros from FRAC.ht
Added   3 pages and/or macros from GBF.ht
Added   3 pages and/or macros from GSTBL.ht
Added   3 pages and/or macros from HEAP.ht
Added   3 pages and/or macros from HEXADEC.ht
Added   5 pages and/or macros from HTXAdvPage1.ht
Added   1 pages and/or macros from HTXAdvPage2.ht
Added   1 pages and/or macros from HTXAdvPage3.ht
Added   4 pages and/or macros from HTXAdvPage4.ht
Added   1 pages and/or macros from HTXAdvPage5.ht
Added   7 pages and/or macros from HTXAdvPage6.ht
Added   1 pages and/or macros from HTXAdvTopPage.ht
Added   5 pages and/or macros from HTXFormatPage1.ht
Added   9 pages and/or macros from HTXFormatPage2.ht
Added   9 pages and/or macros from HTXFormatPage3.ht
Added  11 pages and/or macros from HTXFormatPage4.ht
Added   7 pages and/or macros from HTXFormatPage5.ht
Added   5 pages and/or macros from HTXFormatPage6.ht
Added   7 pages and/or macros from HTXFormatPage7.ht
Added   5 pages and/or macros from HTXFormatPage8.ht
Added   1 pages and/or macros from HTXFormatTopPage.ht
Added   1 pages and/or macros from HTXIntroPage1.ht
Added   1 pages and/or macros from HTXIntroPage2.ht
Added   1 pages and/or macros from HTXIntroPage3.ht
Added   1 pages and/or macros from HTXIntroTopPage.ht
Added   4 pages and/or macros from HTXLinkPage1.ht
Added   3 pages and/or macros from HTXLinkPage2.ht
Added   7 pages and/or macros from HTXLinkPage3.ht
Added  11 pages and/or macros from HTXLinkPage4.ht
Added   5 pages and/or macros from HTXLinkPage5.ht
Added   5 pages and/or macros from HTXLinkPage6.ht
Added   1 pages and/or macros from HTXLinkTopPage.ht
Added   1 pages and/or macros from HTXTopPage.ht
Added   1 pages and/or macros from HTXTryPage.ht
Added   1 pages and/or macros from HTXplay.ht
Added  12 pages and/or macros from INT.ht
Added   3 pages and/or macros from INTHEORY.ht
Added   3 pages and/or macros from KAFILE.ht
Added   3 pages and/or macros from KERNEL.ht
Added   3 pages and/or macros from LAZM3PK.ht
Added   3 pages and/or macros from LEXP.ht
Added   3 pages and/or macros from LEXTRIPK.ht
Added   3 pages and/or macros from LIB.ht
Added  18 pages and/or macros from LIST.ht
Added   6 pages and/or macros from LODO.ht
Added   6 pages and/or macros from LODO1.ht
Added   9 pages and/or macros from LODO2.ht
Added   3 pages and/or macros from LPOLY.ht
Added   3 pages and/or macros from LWORD.ht
Added  16 pages and/or macros from Link.ht
Added   3 pages and/or macros from MAGMA.ht
Added   3 pages and/or macros from MAPPKG1.ht
Added   9 pages and/or macros from MATRIX.ht
Added   3 pages and/or macros from MKFUNC.ht
Added   3 pages and/or macros from MPOLY.ht
Added   3 pages and/or macros from MSET.ht
Added   3 pages and/or macros from NONE.ht
Added   3 pages and/or macros from OCT.ht
Added   3 pages and/or macros from ODPOL.ht
Added   3 pages and/or macros from OP.ht
Added   3 pages and/or macros from OVAR.ht
Added   3 pages and/or macros from PERMAN.ht
Added   3 pages and/or macros from PFR.ht
Added   3 pages and/or macros from POLY.ht
Added   3 pages and/or macros from QUAT.ht
Added   3 pages and/or macros from RADIX.ht
Added   3 pages and/or macros from RECLOS.ht
Added   3 pages and/or macros from REGSET.ht
Added   3 pages and/or macros from ROMAN.ht
Added   3 pages and/or macros from SEG.ht
Added   3 pages and/or macros from SEGBIND.ht
Added   3 pages and/or macros from SET.ht
Added   3 pages and/or macros from SINT.ht
Added   3 pages and/or macros from SQMATRIX.ht
Added   3 pages and/or macros from SREGSET.ht
Added   3 pages and/or macros from STBL.ht
Added   3 pages and/or macros from STREAM.ht
Added   3 pages and/or macros from STRING.ht
Added   3 pages and/or macros from STRTBL.ht
Added   3 pages and/or macros from SYMBOL.ht
Added   3 pages and/or macros from TABLE.ht
Added   3 pages and/or macros from TEXTFILE.ht
Added   3 pages and/or macros from UNISEG.ht
Added   3 pages and/or macros from UP.ht
Added   3 pages and/or macros from VECTOR.ht
Added   3 pages and/or macros from VOID.ht
Added   3 pages and/or macros from WUTSET.ht
Added   3 pages and/or macros from XPBWPOLY.ht
Added   3 pages and/or macros from XPOLY.ht
Added   3 pages and/or macros from XPR.ht
Added   3 pages and/or macros from ZDSOLVE.ht
Added   3 pages and/or macros from ZLINDEP.ht
Added   2 pages and/or macros from algebra.ht
Added  29 pages and/or macros from aspex.ht
Added   2 pages and/or macros from basic.ht
Added   1 pages and/or macros from bmcat.ht
Added  10 pages and/or macros from coverex.ht
Added   2 pages and/or macros from evalex.ht
Added   6 pages and/or macros from exdiff.ht
Added  10 pages and/or macros from exint.ht
Added   6 pages and/or macros from exlap.ht
Added   7 pages and/or macros from exlimit.ht
Added   6 pages and/or macros from exmatrix.ht
Added   4 pages and/or macros from explot2d.ht
Added   3 pages and/or macros from explot3d.ht
Added   4 pages and/or macros from expose.ht
Added   4 pages and/or macros from exseries.ht
Added   8 pages and/or macros from exsum.ht
Added   5 pages and/or macros from function.ht
Added   1 pages and/or macros from gloss.ht
Added  22 pages and/or macros from graphics.ht
Added   4 pages and/or macros from grpthry.ht
Added   0 pages and/or macros from help.ht
Added   1 pages and/or macros from hyperdoc.ht
Added   3 pages and/or macros from man0.ht
Added   2 pages and/or macros from mapping.ht
Added   5 pages and/or macros from nagaux.ht
Added  21 pages and/or macros from nagc.ht
Added  26 pages and/or macros from nagd.ht
Added  43 pages and/or macros from nage.ht
Added  46 pages and/or macros from nagf.ht
Added   7 pages and/or macros from nagm.ht
Added  39 pages and/or macros from nags.ht
Added  12 pages and/or macros from nagx.ht
Added   2 pages and/or macros from newuser.ht
Added  10 pages and/or macros from numbers.ht
Added   8 pages and/or macros from patch.ht
Added   6 pages and/or macros from polys.ht
Added   2 pages and/or macros from record.ht
Added   3 pages and/or macros from releaseNotes.ht
Added   6 pages and/or macros from rootpage.ht
Added   0 pages and/or macros from srchkey.ht
Added   4 pages and/or macros from topics.ht
Added   1 pages and/or macros from type.ht
Added   1 pages and/or macros from ug.ht
Added  18 pages and/or macros from ug00.ht
Added  81 pages and/or macros from ug01.ht
Added  63 pages and/or macros from ug02.ht
Added  30 pages and/or macros from ug03.ht
Added  24 pages and/or macros from ug04.ht
Added  63 pages and/or macros from ug05.ht
Added  83 pages and/or macros from ug06.ht
Added  76 pages and/or macros from ug07.ht
Added 126 pages and/or macros from ug08.ht
Added  30 pages and/or macros from ug10.ht
Added  33 pages and/or macros from ug11.ht
Added  39 pages and/or macros from ug12.ht
Added  66 pages and/or macros from ug13.ht
Added  33 pages and/or macros from ug14.ht
Added  39 pages and/or macros from ug15.ht
Added  90 pages and/or macros from ug16.ht
Added  45 pages and/or macros from ug21.ht
Added   4 pages and/or macros from union.ht
Added 283 pages and/or macros from util.ht
Added   3 pages and/or macros from xmpexp.ht
gmake nphts
gmake[3]: Entering directory
`/usr/home/ghue/src/wh-sandbox-sbcl/src/paste'
(export
AXIOM=/home/ghue/src/wh-sandbox-sbcl/target/i386-unknown-freebsd6.2;
unset
DAASE; /home/ghue/src/wh-sandbox-sbcl/target/i386-unknown-freebsd6.2/bin/sman -noihere -paste /home/ghue/src/wh-sandbox-sbcl/target/i386-unknown-freebsd6.2/share/hypertex/pages/ALIST.ht)
This is SBCL 1.0.3, an implementation of ANSI Common Lisp.
More information about SBCL is available at <http://www.sbcl.org/>.

SBCL is free software, provided as is, with absolutely no warranty.
It is mostly in the public domain; some portions are provided under
BSD-style licenses.  See the CREDITS and COPYING files in the
distribution for more information.
                        AXIOM Computer Algebra System
                 Version: Axiom wh-sandbox branch 2007-05-31
                Timestamp: Tuesday June 26, 2007 at 21:16:56
-----------------------------------------------------------------------------
   Issue )copyright to view copyright notices.
   Issue )summary for a summary of useful system commands.
   Issue )quit to leave AXIOM and return to shell.
-----------------------------------------------------------------------------

(1) -> (HyperDoc) Error opening AXIOM server. Retrying ...
(HyperDoc) Error opening AXIOM server. Retrying ...
(HyperDoc) Couldn't connect to AXIOM server!
(HyperDoc) Couldn't connect to AXIOM server!

At this point, the system is locked forever. I am wondering why two sman
processes are running?
ps aux produces:

83240  p0  I+     0:00.00 gmake
83241  p0  I+     0:00.00 /usr/local/bin/bash -c cd ./src && gmake
all-src
83242  p0  I+     0:00.01 gmake all-src
83322  p0  I+     0:00.00 /usr/local/bin/bash -c cd paste && gmake
83323  p0  I+     0:00.01 gmake
83328  p0  I+     0:00.01 gmake nphts
83329  p0  I+     0:00.00 [bash]
83330  p0  I+     0:00.00 [bash]
83331  p0  I+
0:00.00 /home/ghue/src/wh-sandbox-sbcl/target/i386-unknown-freebsd6.2/bin/sman -noihere -paste /home/ghue/
83335  p0  S+
0:00.56 /home/ghue/src/wh-sandbox-sbcl/target/i386-unknown-freebsd6.2/lib/session
83337  p0  S+
0:00.51 /home/ghue/src/wh-sandbox-sbcl/target/i386-unknown-freebsd6.2/lib/viewman
83338  p0  I+
0:00.00 /home/ghue/src/wh-sandbox-sbcl/target/i386-unknown-freebsd6.2/bin/sman -noihere -paste /home/ghue/

\start
Date: Wed, 27 Jun 2007 13:00:38 +0200 (CEST)
From: Waldek Hebisch
To: Gernot Hueber
Subject: Re: SBCL/wh-sandbox

> Dear Waldek,
> 
> I am trying to compile wh-sandbox (co from yesterday) with sbcl on a
> FreeBSD 6.2 system. Compile ran fine for a long time (it finished with
> gcl). Yet a problem occured. Pls see below for the locking?! Can you
> give me some advice. Is this due to the sockets and writablep issue?
> 
> I configured using "--with-lisp=/usr/local/bin/sbcl" only!
>

>From README.wh:

If you use Lisp different than
gcl you should also specify --with-x=no option (otherwise
build will hang trying to generate HyperDoc pages)


I could automatically disable X part when sbcl is in use if giving
extra option is a problem.

<snip> 
> DAASE; /home/ghue/src/wh-sandbox-sbcl/target/i386-unknown-freebsd6.2/bin/sman -noihere -paste /home/ghue/src/wh-sandbox-sbcl/target/i386-unknown-freebsd6.2/share/hypertex/pages/ALIST.ht)
> This is SBCL 1.0.3, an implementation of ANSI Common Lisp.
> More information about SBCL is available at <http://www.sbcl.org/>.
> 
> SBCL is free software, provided as is, with absolutely no warranty.
> It is mostly in the public domain; some portions are provided under
> BSD-style licenses.  See the CREDITS and COPYING files in the
> distribution for more information.
>                         AXIOM Computer Algebra System
>                  Version: Axiom wh-sandbox branch 2007-05-31
>                 Timestamp: Tuesday June 26, 2007 at 21:16:56
> -----------------------------------------------------------------------------
>    Issue )copyright to view copyright notices.
>    Issue )summary for a summary of useful system commands.
>    Issue )quit to leave AXIOM and return to shell.
> -----------------------------------------------------------------------------
> 
> (1) -> (HyperDoc) Error opening AXIOM server. Retrying ...
> (HyperDoc) Error opening AXIOM server. Retrying ...
> (HyperDoc) Couldn't connect to AXIOM server!
> (HyperDoc) Couldn't connect to AXIOM server!
> 
> At this point, the system is locked forever. I am wondering why two sman
> processes are running?
> ps aux produces:
> 
> 83240  p0  I+     0:00.00 gmake
> 83241  p0  I+     0:00.00 /usr/local/bin/bash -c cd ./src && gmake
> all-src
> 83242  p0  I+     0:00.01 gmake all-src
> 83322  p0  I+     0:00.00 /usr/local/bin/bash -c cd paste && gmake
> 83323  p0  I+     0:00.01 gmake
> 83328  p0  I+     0:00.01 gmake nphts
> 83329  p0  I+     0:00.00 [bash]
> 83330  p0  I+     0:00.00 [bash]
> 83331  p0  I+
> 0:00.00 /home/ghue/src/wh-sandbox-sbcl/target/i386-unknown-freebsd6.2/bin/sman -noihere -paste /home/ghue/
> 83335  p0  S+
> 0:00.56 /home/ghue/src/wh-sandbox-sbcl/target/i386-unknown-freebsd6.2/lib/session
> 83337  p0  S+
> 0:00.51 /home/ghue/src/wh-sandbox-sbcl/target/i386-unknown-freebsd6.2/lib/viewman
> 83338  p0  I+
> 0:00.00 /home/ghue/src/wh-sandbox-sbcl/target/i386-unknown-freebsd6.2/bin/sman -noihere -paste /home/ghue/
> 
> Best regards,
> 

The processes are created as expected, but due to not working sockets
enter infinite wait.  If you get to this point just kill the processes
-- all parts that should be build are build already.

\start
Date: Wed, 27 Jun 2007 16:52:10 +0200 (CEST)
From: Waldek Hebisch
To: Bill Page
Subject: Re: A suggestion for Gold
Cc: Gabriel Dos Reis

Bill Page wrote:
> On 6/26/07, William Sit wrote:
> > The following email (with minor changes) was originally sent
> > to Tim and he replied: "Post your suggestion publicly. Ask
> > for a vote. We will go with the majority opinion. You get to
> > keep the final count."
> >
> > So please feel free to comment, and may be Bill Page can set
> > up a sandbox page to keep votes? (sorry, I don't have the
> > expertise).
> >
> 
> http://wiki.axiom-developer.org/VoteASuggestionForGold
> 
> When someone asks for a vote and it is seconded by another, William
> Sitt and Tim Daly in this case, I suppose the usual "rules-of-order"
> would say that we should just vote with a minimum of further
> discussion. But since we seem to be making the rules as we go, I can't
> resist the opportunity to make a few comments before deciding how I
> should vote.
> 

I was not sure if should say more in the recent version debate.  But
I feel that silence may be bad here and this is logical place to talk.

First, the vote may be interpreted as a vote about work that I
have done.  Custom in my country (and I suppose in most democracies)
tells that I should not vote in such case (and consequently I plan
not ot vote).  However to avoid confusion I must say that I fully
support William's proposal.  In fact, he very much articulated
pragmatic approach to Axiom developement that I tried to advocate.

\start
Date: Wed, 27 Jun 2007 11:26:39 -0500 (CDT)
From: Gabriel Dos Reis
To: Bill Page
Subject: re: Autoconf change

On Tue, 26 Jun 2007, Bill Page wrote:

| So, please don't downcase all file names.

You understand the value of incremental improvements.  I wish we were more in
sharing that view.

\start
Date: 27 Jun 2007 12:48:45 -0400
From: Stephen Wilson
To: Martin Rubey
Subject: Re: Axisp news

Martin Rubey writes:

> Dear Stephen,
> 
> Just to make sure: I hope Ralf and myself have not discouraged you from your
> work on SPAD. 

Oh no, not at all.  I _greatly_ appreciate the input from both of you.
In no way have I taken anything as being even remotely discouraging.

> However, I think it would be more promising to try to make SPAD
> converge towards the Aldor language:
> 
> * Aldor (the language) is relatively well understood - thanks for recalling the
>   article by Poll and Thompson, by the way
> 
> * Aldor (the language!) proved useful (even if not fully implemented) and
>   sufficiently stable

I wrote the parser to be mostly-compatible with Spad for two main
reasons.  First, the building of the parser itself gives me detailed
insight into how Axiom represents the source input as an AST.  This is
critical for understanding the rest of the compiler.  And finally, the
the grammatical variations between Spad and Aldor are quite small.
Pile mode and the use of `(' and ')' as opposed to `{' and `}' to
delimit code sequences are the primary differences.  Most Aldor
constructs, but not all, are `backwards compatible' with Spad.

So, the syntax is not so important.  The parser is a tool for hacking
the compiler at the moment.  I can modify it easily to accept `Aldor'.

> Maybe it is not as "sexy" to try to implement a language specification, but I
> assure you, it would help a lot if you made some progress here.  Personally I
> made the experience that I do not have the talent to design a new language, but
> using Aldor, I sometimes see how one could go on.  (To make this more precise:
> I really want to work with Tuples as first class citizens, for example.  Also,
> I would like to be able to check -- some sort of -- equality of domains at
> times, even if impossible in general.)

The basic list of items I will incorporating are:

   1) Dependent types.  This may not be 100% compatible with Aldor.
      But when I get the the point of needing to make some decisions I
      will most certainly be asking for everyones feedback.

   2) Anonymous functions, e.g. +-> in aldor.

   3) Exceptions.

   4) Generators.

> Maybe I can propose some projects:
  [...]
> Maybe one of these projects is for you,

The stated goal of the Axisp branch is to rewrite the compiler and
interpreter in Lisp.  So its not so much a question if _one_ of those
projects are for me.  They _all_ are.

Clearly this is ambitious, but it even extends beyond just language
features.  For example:

    * I want the design to be modular and extensible.  In particular,
      I want to ensure that interfaces exist so that one can use and
      change the behavior of various components.  The notion of the
      `crystal', a more ambitious undertaking then what I am working
      on, will primarily drive the requirements in this respect.

    * Related to the last point, I am looking at ways to define
      domains/categories in a natural way at the lisp level.  This
      would give a canonical representation which is immediately
      available to the programmer without having to go through
      Spad. In other words, I want to ensure the notion of domain and
      category is throughly decoupled from a source code
      representation, and ensure they can be handled gracefully as any
      other kind of Lisp code/data.

    * One of the next sub-projects is to implement a testing framework
      based on one of the many unit-testing tools available to Lisp. I
      want to ensure that all aspects of the system are checked.

    * Literate documentation.  Going through the existing code and
      documenting it fully in an artful way would be almost as great a
      challenge as the task I am taking on.  My hope is that we get
      literate code almost `for free' as a consequence of the
      rewrite.

So, I am really advocating a vision for Axiom as a whole.  But the
means by which I am going to advance these notions is by writing the
code, by making it happen.

As far as I can predict, when this work has reached a usable state, I
have no doubt that the compiler will accept a language very similar to
Aldor.

Martin, Ralf, many thanks for your input and thoughts.  They are
terrifically important to me and greatly appreciated!

\start
Date: Wed, 27 Jun 2007 14:17:09 -0400
From: Cliff Yapp
To: Stephen Wilson
Subject: Re: Axisp news

Stephen Wilson wrote:

>     * One of the next sub-projects is to implement a testing framework
>       based on one of the many unit-testing tools available to Lisp. I
>       want to ensure that all aspects of the system are checked.

That sounds like a good idea :-).  If you decide on a good one, perhaps
we can standardize on it for other aspects of Lisp in Axiom.

This is probably dated now, but perhaps it can be a starting point:
http://wiki.alu.org/Test_Frameworks

>     * Literate documentation.  Going through the existing code and
>       documenting it fully in an artful way would be almost as great a
>       challenge as the task I am taking on.  My hope is that we get
>       literate code almost `for free' as a consequence of the
>       rewrite.

That is my opinion (and hope) as well.

> So, I am really advocating a vision for Axiom as a whole.  But the
> means by which I am going to advance these notions is by writing the
> code, by making it happen.

\start
Date: 27 Jun 2007 14:40:33 -0400
From: Stephen Wilson
To: Cliff Yapp
Subject: Re: Axisp news

Cliff Yapp writes:

> Stephen Wilson wrote:
> 
> >     * One of the next sub-projects is to implement a testing framework
> >       based on one of the many unit-testing tools available to Lisp. I
> >       want to ensure that all aspects of the system are checked.
> 
> That sounds like a good idea :-).  If you decide on a good one, perhaps
> we can standardize on it for other aspects of Lisp in Axiom.
> 
> This is probably dated now, but perhaps it can be a starting point:
> http://wiki.alu.org/Test_Frameworks

I have explored several.  My current candidate is Lift:

           http://common-lisp.net/project/lift/

Main reasons. CLOS based, easy to extend. No real dependencies on
other libraries.  The code is easy to understand. It works under
gclcvs.  I have used it in smaller projects. Main issue is scalability
-- how well would it handle thousands of test cases?  I have read that
in comparison to other frameworks, Lift is a little bloated (see the
article linked below).

FiveAM is a good framework as well but requires several other
libraries.  I have yet to build it under gclcvs: 

 http://common-lisp.net/project/bese/FiveAM.html

Lisp-unit is dirt simple, not as powerful as the other two, but I am
still considering it:

 http://www.cs.northwestern.edu/academics/courses/325/readings/lisp-unit.html

I found the following quite useful, giving a good overview of the
`leading contenders' in the lisp unit-testing world:

 http://aperiodic.net/phil/archives/Geekery/notes-on-lisp-testing-frameworks.html

Any suggestions, preferences, comments, etc very much appreciated!

\start
Date: Wed, 27 Jun 2007 22:53:28 +0200 (CEST)
From: Waldek Hebisch
To: Camm Maguire
Subject: Axiom and GCL FFI
Cc: Robert Boyer, Warren Hunt

I have a modest proposal concerning FFI, which I belive will solve
many Axiom problems.  While the proposal is motivated by Axiom
needs I belive that it may be useful also to other projects.

What Axiom needs?  Main need is support for various "kernel" type
functions, which are able to quickly perform operation on 
relatively simple data.  Relatively simple means something which
is easy to manipulate in C, but in many cases more compicated
than homogeneous array.  Also, it is a must that called routines
are allowed to call malloc.  It is undesirable to give special
parameters like :static when allocating such object in Lisp.

Form my point of view constrant that data passed to foreign
function must be allocated differently than native Lisp data
means that foreign calls are not usable on general Lisp data.
Fortunatly, at higher level Axiom is a strongly typed system
which means that collection of foreign function and data
can be wrapped inside an Axiom domain.  However once I have
a piece of data which is _only_ mainipulated by foreign
functions it is natural to represent it just by a pointer,
the actual data beeing allocated by C malloc.  So the
proposal is: add to GCL a new type which can store a C
pointer.  The main operation on this type would be to pass
it to a C function or get it back as a function result.
AFAIUI for 32-bit code one can get equivalent results
just using integers.  But 64-bit code needs correct return
type, otherwise pointers would get truncated.

Given such foreign pointers one can add more operations
(like copying data between C and Lisp), for example using
macros which expand to 'clines' construct.  It would be
nice to have a standard set of operations included in GCL,
but pointer type is critical -- the other parts can be
coded using existing GCL constructs.

The other operations may include dereferencing foreign pointers
and block copy between foreign memory and Lisp.

\start
Date: Wed, 27 Jun 2007 14:01:27 -0700 (PDT)
From: Cliff Yapp
To: Stephen Wilson
Subject: Re: Axisp news

--- Stephen Wilson wrote:

> Any suggestions, preferences, comments, etc very much appreciated!

It looks like Lift has had a new release within the last few days - it
might be worthwhile to inquire if the performance issues have been
ironed out since the comparison article was written?  I agree it sounds
very interesting but I think we should probably first figure out if the
performance drop is something that can be avoided.

\start
Date: 27 Jun 2007 17:22:56 -0400
From: Stephen Wilson
To: Cliff Yapp
Subject: Re: Axisp news

Cliff Yapp writes:

> --- Stephen Wilson wrote:
> 
> > Any suggestions, preferences, comments, etc very much appreciated!
> 
> It looks like Lift has had a new release within the last few days - it
> might be worthwhile to inquire if the performance issues have been
> ironed out since the comparison article was written?  I agree it sounds
> very interesting but I think we should probably first figure out if the
> performance drop is something that can be avoided.

Initial comparisons are suggesting that the issue is specific to
SBCL, which appears to be the implementation on which the comparison
was based.

For reasons not clear to me, SBCL's CLOS requires a significant amount
of run-time initialization.  Once this process has completed, SBCL
runs very fast.

GCL does not appear to suffer from this.

Looking at the code for Lift further encourages to me to belive that
this is SBCL specific.

\start
Date: Thu, 28 Jun 2007 03:32:56 -0500
From: Tim Daly
To: list
Subject: A modest proposal

Now that we've had a full, frank, and open debate about William Sit's
proposal I have a counter-proposition. It can be summed up in a single
word:

Contribute.

A contribution to an open source project is one in which a developer
submits a diff-Naur patch that fixes a bug or adds a feature. The
diff-Naur patch is against either the shipping version or the upcoming
version. It's not a novel concept. It is used by hundreds of projects.
Posted today is a 40kb patch to SBCL for ANSI-compatible modern casing
(similar to the axiom downcase). Posted today are diff-Naur changes to
GNU binutils. These are changes in my email stream inbox. They
contain diff-Naur changesets by people who contribute to the projects.
People who did the hard work of tracking a bug and developing a fix or
the tedious work of changing a global feature in hundreds of files.

Waldek, of course you support William's proposal. It implies that you
have no work to do and that I have to refit all of my changes into
your code base. Pretty sweet deal. Do you really find it beyond your
powers to decode the changes you made to fix hyperdoc? Did you
document the way hyperdoc works so we can all understand? Is the
changeset way too subtle? Or just a lot of hard, tedious work that
might slow you down?  It took the bettter part of the last 6 months
teasing out clean, single-issue diff-Naur changesets of the "Waldek"
branch and contributing them to silver. I know it is time-consuming
and slow. But your "contributions" were made despite a glaring lack of
effort on your part to contribute.

Waldek, your work is very valuable and we pay close attention to
it. It is likely that you are well-intentioned and are not trying to
co-opt the rest of the project.  You can contribute if you would only
take the time. It would improve the trunk considerably.

Gaby, it is highly annoying that you continue to spout sarcasm
about "your view" of the project. To quote you today: 
 >>(BillPage) So, please don't downcase all file names 
 >(Gaby) You understand the value of incremental improvements.  
 > I wish we were more in sharing that view.
(Please don't say I don't understand what you wrote.)
Yet you made a valuable, massive, monolithic change to the
build system.  At no time did you try to incrementally improve the
trunk by submitting diff-Naur patches. Now you have the problem of
creating an autoconf changeset that will make the purely syntactic 
downcase changeset look puny. If you really believed in that philosophy 
we would have seen a stream of diff-Naur patches from you against the
trunk. But there has been no "incremental" stream of changsets. We know 
that making these changesets is time-consuming and slow. It took the 
better part of the last 6 months teasing out diff-Naur patches of the 
"BI" branch and contributiong them to silver. Thus your "contributions" 
were made despite a glaring lack of effort on your part to contribute.

Gaby, your work is very valuable and we pay close attention to
it. It is likely that you are well-intentioned and are not trying to
co-opt the rest of the project.  You can contribute if you would only
take the time. It would improve the trunk considerably.

Bill Page, your comments about downcasing files is very poorly founded. 
A mono-cased Axiom would eliminate the port issue to Windows (something
dear to your heart, according to you). It would also establish the
beginnings of a system-wide standard of using monocase everywhere. 
Thus code can reliably down-case a string and expect that they get 
the right filesystem names. Do you find that global downcasing will 
cause a disruptive impact on your code contributions? It hardly seems 
so. You claim to only want to spend your time on new algebra 
(wouldn't we all?). The downcase issue will have little impact
on your new algebra. But it will make future Windows ports easier.  
It is time consuming and slow to figure out how to build Axiom on
Windows. But you're the primary Windows person on the project. It
would be nice if you did more than just point at some repository that
contains a "windows port" and tried to figure out how to diff-Naur the
changes as a contribution. It would also be nice if you didn't criticize 
changesets that don't impact you.

William, "contributing" to a project also implies supporting stated
project goals. You write 
> Let's forget about documentation for the moment because documentation 
> slows development effort.
Yet one of the PRIMARY Axiom goals is documentation. Every file is
literate. Sure it is time-consuming and slow. I know because I have
been doing literate documentation. You write:
> I know you are worried about correctness, but we can develop a plan
> to verify correctness by co-opting resources from the mailing list
> and parceling out specific tests to individuals. Your regression
> tests can still be run after each major build.
Umm, no. It takes a lot of time to construct those regression tests.
Try it sometime. Where is the regression test suite for your code?
If you won't write it then who can you "co-opt" from the mailing list
to write it? Who best understands your algebra code? You write:
> So if it is not too difficult, merging your changes into wh-sandbox
> would be the fastest way to a new release that "just works"
Oh, really? So it "just works" as in:
<http://wiki.axiom-developer.org/366Gcl267CrashesBuildingWhSandbox/diff>
from today's mailbox. wh-sandbox crashes in build. We're not talking about 
"just works" here. You write:
> The lack of documentation is not a big problem because it would be a
> waste to document code that is not final.
You mean, like documenting the fast changing partial differential code
you wrote 20 years ago? Is documenting that code a waste of time? You
already have the technical papers written. Is it that hard to adapt
them to produce even minimal documentation?



All of these remarks are stinging and pointed. So were the remarks
directed at me. Raise your eyes. Look toward cooperating by contributing 
your time and energy to goals that go beyond the personal. Spend SOME of 
your time on documenting/merging/testing your work.  We need to start 
working like SBCL, like GNU binutils, like Linux, like every other 
project. There are no quick fixes. It is all hard work. We need to 
change the "best-branch-wins" attitude so we can work together to 
build a great system.


So we've entertained the "Sit Proposal". Now it is time to entertain
the "Daly Proposal". We don't need a web page to vote. Here's how to
submit your vote.... Figure out a needed feature (e.g. Hyperdoc fix),
make a diff-Naur changeset, document, test, and post it.

Contribute.

\start
Date: Thu, 28 Jun 2007 11:15:46 +0200
From: Ondrej Certik
To: Tim Daly
Subject: Re: A modest proposal

yes, I think Axiom should have just one official branch and it should
just work. And that official branch should be the one in Debian (it
will get to Ubuntu automatically) and other distributions that people
use. This way the possible new contributors will know, that their
patch, if accepted will get to the Axiom that people use and to all
distributions. And that is the motivation - that his new code will be
used by people (and will not be lost somewhere in some branch, that
maybe will not "win").

Ondrej

On 6/28/07, Tim Daly wrote:
> Now that we've had a full, frank, and open debate about William Sit's
> proposal I have a counter-proposition. It can be summed up in a single
> word:
>
> Contribute.
>
> A contribution to an open source project is one in which a developer
> submits a diff-Naur patch that fixes a bug or adds a feature. The
> diff-Naur patch is against either the shipping version or the upcoming
> version. It's not a novel concept. It is used by hundreds of projects.
> Posted today is a 40kb patch to SBCL for ANSI-compatible modern casing
> (similar to the axiom downcase). Posted today are diff-Naur changes to
> GNU binutils. These are changes in my email stream inbox. They
> contain diff-Naur changesets by people who contribute to the projects.
> People who did the hard work of tracking a bug and developing a fix or
> the tedious work of changing a global feature in hundreds of files.
>
> Waldek, of course you support William's proposal. It implies that you
> have no work to do and that I have to refit all of my changes into
> your code base. Pretty sweet deal. Do you really find it beyond your
> powers to decode the changes you made to fix hyperdoc? Did you
> document the way hyperdoc works so we can all understand? Is the
> changeset way too subtle? Or just a lot of hard, tedious work that
> might slow you down?  It took the bettter part of the last 6 months
> teasing out clean, single-issue diff-Naur changesets of the "Waldek"
> branch and contributing them to silver. I know it is time-consuming
> and slow. But your "contributions" were made despite a glaring lack of
> effort on your part to contribute.
>
> Waldek, your work is very valuable and we pay close attention to
> it. It is likely that you are well-intentioned and are not trying to
> co-opt the rest of the project.  You can contribute if you would only
> take the time. It would improve the trunk considerably.
>
> Gaby, it is highly annoying that you continue to spout sarcasm
> about "your view" of the project. To quote you today:
>  >>(BillPage) So, please don't downcase all file names
>  >(Gaby) You understand the value of incremental improvements.
>  > I wish we were more in sharing that view.
> (Please don't say I don't understand what you wrote.)
> Yet you made a valuable, massive, monolithic change to the
> build system.  At no time did you try to incrementally improve the
> trunk by submitting diff-Naur patches. Now you have the problem of
> creating an autoconf changeset that will make the purely syntactic
> downcase changeset look puny. If you really believed in that philosophy
> we would have seen a stream of diff-Naur patches from you against the
> trunk. But there has been no "incremental" stream of changsets. We know
> that making these changesets is time-consuming and slow. It took the
> better part of the last 6 months teasing out diff-Naur patches of the
> "BI" branch and contributiong them to silver. Thus your "contributions"
> were made despite a glaring lack of effort on your part to contribute.
>
> Gaby, your work is very valuable and we pay close attention to
> it. It is likely that you are well-intentioned and are not trying to
> co-opt the rest of the project.  You can contribute if you would only
> take the time. It would improve the trunk considerably.
>
> Bill Page, your comments about downcasing files is very poorly founded.
> A mono-cased Axiom would eliminate the port issue to Windows (something
> dear to your heart, according to you). It would also establish the
> beginnings of a system-wide standard of using monocase everywhere.
> Thus code can reliably down-case a string and expect that they get
> the right filesystem names. Do you find that global downcasing will
> cause a disruptive impact on your code contributions? It hardly seems
> so. You claim to only want to spend your time on new algebra
> (wouldn't we all?). The downcase issue will have little impact
> on your new algebra. But it will make future Windows ports easier.
> It is time consuming and slow to figure out how to build Axiom on
> Windows. But you're the primary Windows person on the project. It
> would be nice if you did more than just point at some repository that
> contains a "windows port" and tried to figure out how to diff-Naur the
> changes as a contribution. It would also be nice if you didn't criticize
> changesets that don't impact you.
>
> William, "contributing" to a project also implies supporting stated
> project goals. You write
> > Let's forget about documentation for the moment because documentation
> > slows development effort.
> Yet one of the PRIMARY Axiom goals is documentation. Every file is
> literate. Sure it is time-consuming and slow. I know because I have
> been doing literate documentation. You write:
> > I know you are worried about correctness, but we can develop a plan
> > to verify correctness by co-opting resources from the mailing list
> > and parceling out specific tests to individuals. Your regression
> > tests can still be run after each major build.
> Umm, no. It takes a lot of time to construct those regression tests.
> Try it sometime. Where is the regression test suite for your code?
> If you won't write it then who can you "co-opt" from the mailing list
> to write it? Who best understands your algebra code? You write:
> > So if it is not too difficult, merging your changes into wh-sandbox
> > would be the fastest way to a new release that "just works"
> Oh, really? So it "just works" as in:
> <http://wiki.axiom-developer.org/366Gcl267CrashesBuildingWhSandbox/diff>
> from today's mailbox. wh-sandbox crashes in build. We're not talking about
> "just works" here. You write:
> > The lack of documentation is not a big problem because it would be a
> > waste to document code that is not final.
> You mean, like documenting the fast changing partial differential code
> you wrote 20 years ago? Is documenting that code a waste of time? You
> already have the technical papers written. Is it that hard to adapt
> them to produce even minimal documentation?
>
>
>
> All of these remarks are stinging and pointed. So were the remarks
> directed at me. Raise your eyes. Look toward cooperating by contributing
> your time and energy to goals that go beyond the personal. Spend SOME of
> your time on documenting/merging/testing your work.  We need to start
> working like SBCL, like GNU binutils, like Linux, like every other
> project. There are no quick fixes. It is all hard work. We need to
> change the "best-branch-wins" attitude so we can work together to
> build a great system.
>
>
> So we've entertained the "Sit Proposal". Now it is time to entertain
> the "Daly Proposal". We don't need a web page to vote. Here's how to
> submit your vote.... Figure out a needed feature (e.g. Hyperdoc fix),
> make a diff-Naur changeset, document, test, and post it.
>
> Contribute.

\start
Date: Thu, 28 Jun 2007 11:48:54 +0200
From: Ralf Hemmecke
To: Tim Daly
Subject: Re: A modest proposal
Cc: list

> All of these remarks are stinging and pointed. So were the remarks
> directed at me. Raise your eyes. Look toward cooperating by contributing 
> your time and energy to goals that go beyond the personal. Spend SOME of 
> your time on documenting/merging/testing your work.  We need to start 
> working like SBCL, like GNU binutils, like Linux, like every other 
> project. There are no quick fixes. It is all hard work. We need to 
> change the "best-branch-wins" attitude so we can work together to 
> build a great system.

> So we've entertained the "Sit Proposal". Now it is time to entertain
> the "Daly Proposal". We don't need a web page to vote. Here's how to
> submit your vote.... Figure out a needed feature (e.g. Hyperdoc fix),
> make a diff-Naur changeset, document, test, and post it.

Tim, in order to help Gaby and Waldek to submit patches (which at least 
Gaby said, he will do), it is very important that they know the svn 
revision numbers of the changes that you took out.

*Please, post the ranges of SVN revisions* (something like 
234:256,332:341, etc.) that you took from Waldek's or Gaby's branch and 
post them to the list.

If that is done then we probably would not have to vote about taking 
over Waldek's branch and just move it to trunk. That this will cause 
problems for you is clear. But at the moment, there is no easy way to 
relate the patches that you have applied to trunk to revision numbers of 
Gaby's and Waldek's branch. That is one of the current problems. It is 
not the unwillingness to contribute to trunk.
It is the problem that we cannot agree on *one* SCM and that the 
relation between trunk and build-improvements and wh-sandbox is unclear.

\start
Date: Thu, 28 Jun 2007 12:48:39 +0200 (CEST)
From: Waldek Hebisch
To: Tim Daly
Subject: Re: A modest proposal

> Oh, really? So it "just works" as in:
> <http://wiki.axiom-developer.org/366Gcl267CrashesBuildingWhSandbox/diff>
> from today's mailbox. wh-sandbox crashes in build. We're not talking about 
> "just works" here.

Tim, have you tried Gentoo?  You will probably (I write probably
because two Gentoo systems may be quite different) notice that
Gentoo gcl crashes on simple Lisp code that normally gcl handles
without problem.  My conclusion is that Gentoo gcl is broken.

The problem vanishes if one uses self-build gcl-2.6.8-pre.  This
of course risks restarting discussion about using tools provided
with distribution versus our own tools.  At least my experience
was that gcl-2.6.6 simply does not work for Axiom, but it is
still common in older installations.  I have mixed experience
using gcl-2.6.7, on a few machines self-build gcl-2.6.7 works
just fine, but on some other I noticed problems.  If I were
making a release tarball now I would probably include gcl-2.6.8-pre
inside and made it a default.

\start
Date: Thu, 28 Jun 2007 07:33:13 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: Tim and Axiom

Tim --

  I'm highly annoyed to find Axiom in almost the same situation as
GCC in mid 1997 where emails were not about technical contributions
but political discussions on one individual's weight on GCC.  The
end result was a successful fork, known as EGCS, which gave us
the wonderful GCC project as we know today.  

  I hope you're not intending to push Axiom further into a fork state.
If your unstated desire is that contirbutors leave you alone with Axiom,
please say so frankly. Otherwise, please stop being obnixious -- we have
enough on the plate to make Axiom better.

  As of incremental changes to trunk, I guess you prefer ignore my recent 
changes to trunk, which was quickly vocally criticized and you proposed
that you had a mega patch -- yet to be see as of today -- that would
supercede the incremental solving of a fundamental annoying problem.
The solution I proposed was a merge from build-improvements to trunk,
for a solution that has been for months on both build-improvements
and wh-sandbox.

  The rest of your email about "contribute" is utter nonsene.  It is 
likely that you were well-intensioned; but the execution is void of
content.

\start
Date: Thu, 28 Jun 2007 07:40:08 -0500 (CDT)
From: Gabriel Dos Reis
To: list
Subject: GCL-2.6.8 and Axiom

Waldek --

   GCL-2.6.8 is still in build-improvements.  It did noy go away.
It is a simple change to test GCL version and decide that anything
prior to GCL-2.6.8pre is not worth it and build our own.  I can
implement that change if you agree.

   For packaging, I believe we can adopt Subversion 1.4.4 solution:
Make the core system available along a separate tarball of the
dependencies.  If you unpack both in the same directory, you have
all dependencies resolved.  I can implement that too -- but I need
to finish another work that is pending.

\start
Date: 28 Jun 2007 14:54:17 +0200
From: Martin Rubey
To: Gabriel Dos Reis, Waldek Hebisch
Subject: Re: GCL-2.6.8 and Axiom

Gabriel Dos Reis writes:

>    For packaging, I believe we can adopt Subversion 1.4.4 solution: Make the
> core system available along a separate tarball of the dependencies.  If you
> unpack both in the same directory, you have all dependencies resolved.  I can
> implement that too -- but I need to finish another work that is pending.

There is another issue I find highly annoying and too difficult to resolve for
an average linux user:

configure does not complain load enough if certain packages / header files are
missing.  It is not clear which packages one has to install.

(I sent a list once, but it would be much better if configure would say:

necessary libraries missing: xxx.h, yyy.h, ...

libraries missing for hyperdoc / graphics: zzz.h, ...

  (the latter is in fact issued by configure / wh-sandbox, but buried in many
  many other messages)

I still have colleagues who tried to install wh-sandbox but didn't succeed.  Of
course, there is the mailing list, but many just don't bother / are too shy /
don't know what to do / etc...

\start
Date: 28 Jun 2007 09:10:23 -0400
From: Stephen Wilson
To: Tim Daly
Subject: Re: A modest proposal

Tim Daly writes:

> Now that we've had a full, frank, and open debate about William Sit's
> proposal I have a counter-proposition. It can be summed up in a single
> word:
> 
> Contribute.

I have read virtually very email on this list since 2004.  The basic
expectations have never changed for a developer who wishes to help
move axiom forward.  Work on a change, document it, submit a patch.

I am free to use whatever SCM I choose.  I am free to pursue whatever
problem my heart desires.  There are no restrictions, there are no
bottlenecks.

If I have a problem to solve I can hack away in whatever manner suits
me.  I can document my work in the process.  I can test and verify my
changes locally using whatever technique gives me confidence.  Once
satisfied, using any tool of my choosing, I can post a diff against
Silver in a matter of seconds.  It is my responsibility, and mine
alone, to ensure that the change is a quality change.

Silver is a moving target.  If a conflict were to emerge between my
change and Silver, I deal with it.

The process is so blindingly simple I find it hard to believe it even
needs discussion.

\start
Date: Thu, 28 Jun 2007 08:12:46 -0500 (CDT)
From: Gabriel Dos Reis
To: Martin Rubey
Subject: Re: GCL-2.6.8 and Axiom
Cc: Waldek Hebisch

On Thu, 28 Jun 2007, Martin Rubey wrote:

| There is another issue I find highly annoying and too difficult to resolve for
| an average linux user:
| 
| configure does not complain load enough if certain packages / header files are
| missing.  It is not clear which packages one has to install.

I have hard errors in many places in configure -- for example, there
is no configuration if <unistd.h> is missing.  And the message indicates
that.  Configure stops with hard errors when noweb is not present.  Many there
is not enough.  Please, could you be more specific?  That would
help me in figuring out what to implement as solution.

\start
Date: Thu, 28 Jun 2007 08:30:29 -0500 (CDT)
From: Gabriel Dos Reis
To: Tim Daly
Subject: open source, etc.
Cc: list

Tim --

  I'm also a contributor to GDB.  Indeed, there is no similaritie
between GDB and Axiom -- yet GDB is far more complex than Axiom.
We don't have to deal with political drama all the time.

  If you're afraid that people would improve your work, don't publish
it.  If you're afraid that you would have to deal with people having
different ideas from yours, don't publish your work.  If you're paranoiac
about your work and you have tendency of seeing any modification as taking
away your work, don't publish your work.  If you cannot be flexible
about your ideas, don't publish your work.  
Don't go open source.  Don't moralize about open source.

Now, if you're still interested in in making Axiom better let's work on
technical points.

\start
Date: 28 Jun 2007 09:34:36 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Tim and Axiom

Gabriel Dos Reis writes:
>   As of incremental changes to trunk, I guess you prefer ignore my recent 
> changes to trunk, which was quickly vocally criticized and you proposed
> that you had a mega patch -- yet to be see as of today -- that would
> supercede the incremental solving of a fundamental annoying problem.
> The solution I proposed was a merge from build-improvements to trunk,
> for a solution that has been for months on both build-improvements
> and wh-sandbox.

I would love to see a documented patch which gives Axiom a more robust
build environment, or even the first patch of a series addressing a
meaningful component.  I would be more than happy to study such a
change and comment on technicalities.

Without that, I'm afraid, the execution is void of content.

\start
Date: Thu, 28 Jun 2007 08:36:02 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Tim and Axiom

On Thu, 28 Jun 2007, Stephen Wilson wrote:

| Gabriel Dos Reis writes:
| >   As of incremental changes to trunk, I guess you prefer ignore my recent 
| > changes to trunk, which was quickly vocally criticized and you proposed
| > that you had a mega patch -- yet to be see as of today -- that would
| > supercede the incremental solving of a fundamental annoying problem.
| > The solution I proposed was a merge from build-improvements to trunk,
| > for a solution that has been for months on both build-improvements
| > and wh-sandbox.
| 
| I would love to see a documented patch which gives Axiom a more robust
| build environment, or even the first patch of a series addressing a
| meaningful component.  I would be more than happy to study such a
| change and comment on technicalities.

You vocally expressed that you had no interest in build-improvements
or wh-sandbox.  If you had any sense, you would be more productive in 
staying our of this debate.

\start
Date: 28 Jun 2007 09:54:01 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Tim and Axiom

Gabriel Dos Reis writes:

> You vocally expressed that you had no interest in build-improvements
> or wh-sandbox. 

I never said I have no interest in build-improvements or wh-sandbox.

Axiom is a huge system.  I can wrap my head around the state of
Silver, I can manage my own local trees.  Im not about to follow in
detail the work in build-improvements or wh-sandbox, nor should I need
to.

> If you had any sense, you would be more productive in staying our of
> this debate.

I care about Axiom.  This debate affects the entire community. 

\start
Date: Thu, 28 Jun 2007 09:02:54 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Tim and Axiom

On Thu, 28 Jun 2007, Stephen Wilson wrote:

| > If you had any sense, you would be more productive in staying our of
| > this debate.
| 
| I care about Axiom.  This debate affects the entire community. 

Since it is not one of your priotities to merge build-improvements or
wh-sandbox with silver, you should be doing something more productive
than you're at the moment.

\start
Date: 28 Jun 2007 10:20:12 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Tim and Axiom

Gabriel Dos Reis writes:

> On Thu, 28 Jun 2007, Stephen Wilson wrote:
> 
> | > If you had any sense, you would be more productive in staying our of
> | > this debate.
> | 
> | I care about Axiom.  This debate affects the entire community. 
> 
> Since it is not one of your priotities to merge build-improvements or
> wh-sandbox with silver, you should be doing something more productive
> than you're at the moment.

I wrote in my first message to this thread that I would be happy to
invest my time in studying any propossed changes.  I would do that in
the hopes that an extra pair of eyes might yeild a contribution to the
effort.

But your right, its not one of my priorities to collect said changes
and propose a patch.

\start
Date: Thu, 28 Jun 2007 09:21:02 -0500 (CDT)
From: Gabriel Dos Reis
To: Stephen Wilson
Subject: Re: Tim and Axiom

On Thu, 28 Jun 2007, Stephen Wilson wrote:

| But your right, its not one of my priorities to collect said changes
| and propose a patch.

All I ask is that you stop distracting people whose priority it is.

\start
Date: Thu, 28 Jun 2007 13:46:57 -0400
From: William Sit
To: Tim Daly
Subject: Re: A modest proposal

<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
Tim:
<blockquote TYPE=CITE>
<pre>> The lack of documentation is not a big problem because it would be a
> waste to document code that is not final.
You mean, like documenting the fast changing partial differential code
you wrote 20 years ago? Is documenting that code a waste of time? You
already have the technical papers written. Is it that hard to adapt
them to produce even minimal documentation?</pre>
</blockquote>

<p><br>Okay, guilty as charged (although you ignored the phrase "that is
not final" in my argument, and so your example does not refute my argument;
I also have no pde software.).
<p>I am not a system developer and I am not really qualified to discuss
the technical work done by you, or the others. So far I have also been
holding back on my view on pamphlets. But since you press the issue, I
feel I should speak out.
<br>I believe documenting the build improvement and rearrangement of the
boot and compiling sequence faces the same issues below (perhaps simpler
if without the theory part).&nbsp;
<p>I am not convinced of the merits of the pamphlet way of documentation.
Everyone else seems to be convinced of the usefulness of pamphlets. I am
not. I am also not against documentation, but the way a pamphlet is composed
is simply not the way I would do documentation for algebra code. The flow
of pamphlet content also does not reflect the way how a mathematical algorithm
is developed and implemented. There are many aspects in this process: theory,
algorithm, data representation, and code; most of the time in that order,
but often, new insight from experimental implementation and computation
provide feedback and one cycles back to the beginning: to prove some more
theoretical results that lead to better algorithms, requiring improved
data structure, and added or simplified code. To me, it would be a waste
of time to document carefully at that stage (yes, there has to be some
documentation to remind oneself: certainly proofs have to be written down,
reasons for change of data structure noted, and why certain parts of the
code need changes -- but these need not be "carefully" documented -- it
only need to be for personal use; and during this development cycle, I
don't want to be distracted by the rigid format required by a pamphlet,
and besides, that format is still under experimentation). When the project
is completed to satisfaction, such as when one is ready to write up a paper
for publication, then it is time to carefully document the final data structure
and code.&nbsp; So, yes, my Axiom code should be better documented, but
not in a pamphlet. Moreover, I believe the style of programming (for example,
choosing meaningful variable identifiers and function interfaces) is far
more important for clarity of the code than any documentation.
<p>Your intention of a pamphlet is to be "self-contained": to include theory,
algorithm, data-structure and code, and examples (for regression tests).
Let's say I have already written up a paper on the theory and algorithm,
and I have the code with embedded documentations, and I have ran examples.
These are all in different files and they can be easily read and understood
by one "with ordinary skills in the art", perhaps with some cross-referencing.&nbsp;
Why should I now repackage all these files into one huge pamphlet, broken
into "chunks",&nbsp; intersperse explanation of data-structure, and code
among theory, distracting from the flow of the theoretical development,
or code development? In order to "glue" these coherently, the original
documents have to be rewritten, in a way that one cannot recover them even
after "noweave" or "notangle".&nbsp; The logical development of theory
need not correspond to the logical development of code, requiring constant
shuffling of these chunks. By dicing up the code into chunks, one has to
then test that after reassembly, no accidental errors are introduced even
when the original code had been tested thoroughly. For what? What is wrong
with just placing all the original files into one directory or zipped file?
<p>You also seem to think a pamphlet file should be a "tutorial" so that
anyone can follow, and not only that, the pamphlet should capture the thoughts
during the development process as well. That is simply not necessary. I
can understand developing a few sample tutorials for pedagogical purposes
(like your dhmatrix pamphlet), but this is not the most efficient method
to transfer knowledge. While ideally and in principle, any one should be
able to learn any subject matter from scratch given sufficient time and
a good teacher or book, this is not the case in the real world because
one must learn "fast" or else be crowned "too slow" (that's a polite version
of "stupid").&nbsp; Everyone is "too slow" for some subjects. It does not
mean *every* book should be written at the same level.
<p>To be useful, documentation should be aimed at people already with sufficient
background. It is a highly difficult skill to write at just the right level
for a targeted class of readers. Too much detail, and people skim it or
get bored. Not enough or carelessly written, it is hard to follow. Is it
worth it? Definitely, but not in the form of a pamphlet.
<br>&nbsp;
<p>So what I "propose" is simply a kind of "restart" for Axiom.
<br>IIRC, even Linus said they simply "restarted" when they move to git.&nbsp;
Obviously, if you feel that the burden is on you to merge your branch to
wh-sandbox, you are darn right.&nbsp; Your response is certainly not unexpected.
That is why my suggestion ("proposal" if you like) was conditioned on your
approval and qualified by "if it is not too difficult".&nbsp; You are the
one who asked me to make my suggestion public and you said you would follow
majority opinion. I certainly did not originate this idea of "best branch
win".&nbsp; Rather my starting point was stated in my email:
<p>"All I would like is simply to suggest, in my
<br>uneducated opinion, a possibly more efficient path of lesser
<br>resistance to bring the release version of Axiom up-to-date
<br>asap so we can attract more users and developers."
<p>Certainly, if&nbsp; you disagree, then it is not a "more efficient path
of lesser resistance".
<p>Thanks for considering it anyway.
<p>William
<br>&nbsp;
<br>&nbsp;</html>

\start
Date: 28 Jun 2007 17:18:21 -0400
From: Camm Maguire
To: Waldek Hebisch
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

Greetings!

OK, fresh cvs checkout, ansi mode, just passed the depsys stage of the
wh-sandbox.  With si::*disable-recompile* t -- there is a minor issue
otherwise yet unfixed.

Take care,

Waldek Hebisch writes:

> > Greetings!  My cvs is down at the moment.  Until I get the fix in, you
> > can replace
> > 
> > (declare (ignore tpn))
> > 
> >  with
> > 
> > tpn
> > 
> > in lsp/gcl_callhash.lsp, function do-recompile.
> > 
> > Please let me know if problems persist.
> > 
> 
> Thank you for the hint.  After editing lsp/gcl_callhash.lsp and
> restarting build it went much further, however I see another
> error:
> 
> ./raw_ansi_gcl /var/tmp/hebisch/lisp/gcl-20070626.2/unixport/  -libdir /var/tmp/hebisch/lisp/gcl-20070626.2/ < foo
> GCL (GNU Common Lisp)  April 1994  524288 pages
> Building symbol table for /var/tmp/hebisch/lisp/gcl-20070626.2/unixport/raw_ansi_gcl ..
> 
> <many lines snipped>
> 
> Signalled by LET.
> SIMPLE-ERROR: can't compile CMP-ANON
> 
> Broken at LET.  Type :H for Help.
>  1 (Continue) Retry compiling (COMPILER::CMP-ANON NIL).
>  2 Retry compiling (COMPILER::CMP-ANON NIL).
>  3 Return to top level.
> 
> 
> Note that before I saw your e-mail I have fetched newer gcl version
> from cvs, it failed exactly in the same place as previously.  Following
> your advice I edited the problematic file and restarted the build.
> 
> Log of build after restart is at:
> 
> http://www.math.uni.wroc.pl/~hebisch/prog/mlogg2

\start
Date: 28 Jun 2007 17:55:41 -0400
From: Stephen Wilson
To: Camm Maguire
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

Hello,

I too would like to report that gclcvs as of two days ago (missed
latest commits), ansi mode, is well into the algebra build.

This is Silver with some small modifications. si::*disable-recompile*
set to t.

Will replay with fresh gclcvs tonight.

Camm Maguire writes:

> Greetings!
> 
> OK, fresh cvs checkout, ansi mode, just passed the depsys stage of the
> wh-sandbox.  With si::*disable-recompile* t -- there is a minor issue
> otherwise yet unfixed.
> 
> Take care,
> 
> Waldek Hebisch writes:
> 
> > > Greetings!  My cvs is down at the moment.  Until I get the fix in, you
> > > can replace
> > > 
> > > (declare (ignore tpn))
> > > 
> > >  with
> > > 
> > > tpn
> > > 
> > > in lsp/gcl_callhash.lsp, function do-recompile.
> > > 
> > > Please let me know if problems persist.
> > > 
> > 
> > Thank you for the hint.  After editing lsp/gcl_callhash.lsp and
> > restarting build it went much further, however I see another
> > error:
> > 
> > ./raw_ansi_gcl /var/tmp/hebisch/lisp/gcl-20070626.2/unixport/  -libdir /var/tmp/hebisch/lisp/gcl-20070626.2/ < foo
> > GCL (GNU Common Lisp)  April 1994  524288 pages
> > Building symbol table for /var/tmp/hebisch/lisp/gcl-20070626.2/unixport/raw_ansi_gcl ..
> > 
> > <many lines snipped>
> > 
> > Signalled by LET.
> > SIMPLE-ERROR: can't compile CMP-ANON
> > 
> > Broken at LET.  Type :H for Help.
> >  1 (Continue) Retry compiling (COMPILER::CMP-ANON NIL).
> >  2 Retry compiling (COMPILER::CMP-ANON NIL).
> >  3 Return to top level.
> > 
> > 
> > Note that before I saw your e-mail I have fetched newer gcl version
> > from cvs, it failed exactly in the same place as previously.  Following
> > your advice I edited the problematic file and restarted the build.
> > 
> > Log of build after restart is at:
> > 
> > http://www.math.uni.wroc.pl/~hebisch/prog/mlogg2

\start
Date: Thu, 28 Jun 2007 17:54:09 -0500
From: Tim Daly
To: William Sit
Subject: A modest proposal

William,

Rather than starting by refuting your points in detail let me ask the
question....If you know that literate programming is a PRIMARY design
goal of Axiom and you don't support that goal, then wouldn't it make
sense to take the freely available original sources, which are not
literate, and start a new Sourceforge project (say, OpenAxiom,
RawAxiom, whatever)? That way you can define the goals to be anything
you like.

Axiom, as it exists in this project, is an experiment in developing
software designed to be maintained, modified, and expanded by people
at least 30 years in the future. The fundamental conjecture is that
without documentation complex code cannot survive.

To that end the Axiom project adopted Knuth's technology of literate
programming.  To quote Patrick McPhee:

   Without wanting to be elitist, the thing that will prevent 
   literate programming from becoming a mainstream method is that
   it requires thought and discipline. The mainstream is established
   by people who want fast results while using roughly the same
   methods that everyone else seems to be using, and literate
   programming is never going to have that kind of appeal. This 
   doesn't take away from the usefulness of the approach.




Indeed I hear, underlying email on this list, both kinds of complaint:

  a) "we want fast results" ...therefore throw out the trunk and let the
     latest, greatest, branch win. This is the essence of your argument.
     So what do we do when Mark Botch shows up with the latest, greatest
     branch? Or Stephen's branch suddenly has a new feature we want? Do
     we throw Waldek's out, rinse and repeat? Surely this is the "fastest
     way" to get the new features. Do we each "do our own thing" and
     fail to contribute?

Fast is NOT a project goal. Literate Programming with deep documentation 
is a project goal. Correctness is a project goal. Being a research 
platform for new ideas is a project goal. But FAST is not. There is no
need to "get it running by September". Development that requires thought
and discipline takes time. We have time. There are no deadlines. The
Axiom project has a "30 year horizon".


  b) "using roughly the same methods that everyone else seems to be using"...
     which is exactly how Scratchpad was developed. William Sit came to
     visit at IBM Research, wrote some code, documented nothing and left.
     I don't object to this kind of programming and I am not advocating
     that all projects should switch to literate programming everywhere.
     But the Axiom project on Sourceforge and Savannah has a PRIMARY
     goal of developing a literate CAS using Knuth's technology.




You state:
> To me, it would be a waste of time to document carefully at that 
> stage (...[snip]...). it only need to be for personal use;

That's fine. Do anything you want for personal use. But if you want to
write code in the Axiom project and you want it in the distribution
then your "personal code" in your "own branch" has graduated to the
stage that an unknown number of people will use it, maintain it,
modify it, and support it. So the "Axiom Distribution" strives for
literate documentation, written for people first, not machines.

If you spend the time to figure out how an algorithm works (e.g.
how the compiler resolves types, how hyperdoc builds pages, or
how the databases are structured (see src/interp/daase.lisp)
then we need you to leverage that effort so that we can understand,
maintain, and modify it later. Otherwise it gets lost. It gets 
"too hard to merge". 




You state:
> and during the development cycle I don't want to be distracted by 
> the rigid format required by a pamphlet. And besides, that format
> is still under experimentation

I don't recall that we've defined the shape of pamphlets. Ralf has
done pioneering work with ALLPROSE. I've made some initial attempts
with DH matrices and quaternions. Pamphlets are hardly a rigid format.
They certainly don't constrain your development or experimentation.
They are only latex files with some special tags. And in the near
future they will be pure latex files once we write latex macros
that replace the current chunk-name syntax for the special tags.
So they are not "home-grown" technology but general-purpose technology
over 20 years old with a known-good example (See TeX: The Program by
Knuth ISBN 0-201-13437-3)



You state:
> So, yes, my Axiom code should be better documented, but not in a pamphlet.

Which raises two questions. First, why are you trying to associate yourself
with a project which has the goal of putting everything in a pamphlet? 
Second, you're not doing documentation anyway so why is this an issue?



You state:
> I believe the style of programming (for example, choosing meaningful
> variable identifiers and function interfaces) is far more important
> for clarity of the code than any documentation.

That's a nice belief. And it is not wrong, just trivial. You surely
chose the variable names in your algebra code to be insightful. Or they
would be if we understood the theory behind the code, the mindset that
you had when you wrote it and unit tests to see what it actually does.
I assure you that my variable names chosen in Axiom, most times, have
followed this. I certainly do this every time I program. So tell me,
how does the interpreter resolve types? Reference the variable names,
explain the algorithm by incanting the variable names in some order,
and show your work. You have one hour.




You state:
> Why should I now repackage all these files into one huge pamphlet, 
> broken into "chunks", intersperse explanation of data-structure, and
> code among theory, distracting from the flow of the theoretical
> development.....

Why bother to use chapter 2 of a dissertation to prove a lemma?
Why introduce the theory of networks to explain the FFT algorithm?
Why not give students the final theorems in the course and simply
state "All the results follow from the theorems, which have carefully
chosen names"? 

These pamphlet files are intended to be read by humans, learned by
humans, and maintained by humans. Pamphlet should explain the "why",
the motivation, the theory, the ideas, the magic. None of that is
in the code no matter how clever you are in choosing variable names.




You write:
> although you ignored the phrase "that is not final" in my argument

No, I didn't ignore it. I'm simply asking when you might consider
work final? (Clearly Manual Bronstein's work is final. He's dead.
However he and his wife have given permission for Axiom to use his
work to document Axiom. That's a future task.) You are still around.
When is your work "final" and when do you think you'll document it?
Are we going to pass the documentation task onto the future? Why will
they be any more inclined to document your work than you are? Do you
really want some third-rate pseudo-mathematician like myself doing it?

If the new build system is stable (and this is entirely up to the
discretion of the developer) and it is going to be the basis for the
new build system then it needs to be documented. One of the primary
reasons is that, of all of the people, I use the build system on a
daily basis. For the past few years I've almost always had at least
one system doing a build (albeit with ancient, buggy, worthless Makes
that don't use standard methods). So of all of the people this 
change will impact I am surely center stage.


The Axiom project has no fundamental opinions about which SCM to
use. We argue over SVN, CVS, Git, Arch, etc. All of that can be
changed. Even the build system can be replaced eventually.  But
literate programming is fundamental. The Axiom project, as it is
defined, is literate.


It is NOT important for the goals of this project that we "get there
FAST" or that "we use the standard methods". If those are your needs
then, by all means, start a Sourceforge project that achieves those
goals. Make a Scratchpad or FASTAxiom or STANDARDAxiom or SITAxiom
project. Take a copy of Waldek's branch and release it under that
name.  Axiom, and by that I mean, THIS Sourceforge project, does not
have those goals. My ONLY request is that you choose a different name
for your new project and stop referring to it as "Axiom".



I freely admit that the goals of the project "Axiom" as it exists
today flow from my prior experience with IBM Axiom. When I got the
distribution from NAG and did all of the work to set up and build this
project I hoped that people would be inspired to achieve something new
and different.  Would they build a literate CAS? And a CAS that stresses
correctness, possibly provable correctness. A CAS that can form the
basis of a science of computational mathematics for the next hundred
years. A CAS to carry on the research tradition with fundamental
changes like provisos. Will people be motivated to take the time to
"do it right"? Can people be motivated to work toward a future they
will never see?

If you want to work on this project please respect the fundamental goals.
That's not an unreasonable request.

\start
Date: Thu, 28 Jun 2007 17:58:57 -0500
From: Tim Daly
To: Ondrej Certik
Subject: A modest proposal

Ondrej,

> yes, I think Axiom should have just one official branch and it should
> just work. And that official branch should be the one in Debian...

Camm Maguire did the debian version. As far as I'm aware Camm is the
only debian-committer on this mailing list. Debian has a whole series
of constraints and rules which make it a challenge to maintain. It is
true that Debian would give Axiom considerably more exposure.

Are you a debian-committer? Can you take up the task of making a
Debian release of Gold?

\start
Date: Fri, 29 Jun 2007 01:12:57 +0200
From: Ondrej Certik
To: Tim Daly
Subject: Re: A modest proposal

> Camm Maguire did the debian version. As far as I'm aware Camm is the
> only debian-committer on this mailing list. Debian has a whole series
> of constraints and rules which make it a challenge to maintain. It is
> true that Debian would give Axiom considerably more exposure.
>
> Are you a debian-committer? Can you take up the task of making a
> Debian release of Gold?

I am not a Debian developer, but I use Debian and I have some packages
in Debian:

http://qa.debian.org/developer.php?login=Ondrej Certik

but I always need to find a sponsor (a Debian developer) who uploads
the package for me. Yes, I can update the package, but I don't have
time to sort out bugs and stuff. But if you help me with compiling (I
had problems with compiling the wh-sandbox), I can do that. But then I
need to find a sponsor, which is really hard.

\start
Date: Thu, 28 Jun 2007 18:13:13 -0500
From: Tim Daly
To: Ralf Hemmecke
Subject: A modest proposal

Ralf,

> Tim, in order to help Gaby and Waldek submit patches (which at least
> Gaby said, he will do), it is very important that they know thesvn
> revision numbers of the changes that you took out.

> *Please, post the ranges of SVN revisions* (something like
> 234:256,332:341, etc.) that you took from Waldek's or Gaby's branch and
> post them to the list

If you look at the SVN revisions you'll see that the "changesets" 
that are posted have two problems. First, a fair portion of the
changesets reference the new Makefiles in addition to changes made
in particular files. Thus, the revision cannot be applied.
Second, "changeset" changes, that is, a clean, complete, single-idea 
change do not occur everywhere in the revision list. Thus there are
"mixed changesets" that are both applied and not applied or partial.

At Gaby's request I reviewed all of the SVN revisions and my changes
and posted a document at
<http://lists.gnu.org/archive/html/axiom-developer/2007-05/msg00320.html>

These changes are arranged by "topic" and would have been complete
changesets in the new git/svn-trunk version but were made prior to that.

The kind of diff-Naur patch I've asked from Gaby (autoconf) or
Waldek (hyperdoc) are not represented in any of the changes I made.
Thus there should be minimal collisions.

\start
Date: Thu, 28 Jun 2007 18:24:21 -0500
From: Tim Daly
To: Ondrej Certik
Subject: A modest proposal

Ondrej,

As noted, Camm both did the prior port and sponsored Axiom.
If we can do the port I believe he can be asked to sponsor it.

\start
Date: Thu, 28 Jun 2007 22:36:41 -0400
From: William Sit
To: Tim Daly
Subject: Re: A modest proposal

<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
Tim Daly wrote:
<br>&nbsp;
<blockquote TYPE=CITE>You state:
<br>> So, yes, my Axiom code should be better documented, but not in a
pamphlet.
<p>Which raises two questions. First, why are you trying to associate yourself
<br>with a project which has the goal of putting everything in a pamphlet?
<br>Second, you're not doing documentation anyway so why is this an issue?</blockquote>
For the first, see below. For the second, no, it is not an issue for me.
It is one for YOU.
<p>[sniped]
<blockquote TYPE=CITE>If you want to work on this project please respect
the fundamental goals.</blockquote>

<blockquote TYPE=CITE>That's not an unreasonable request.</blockquote>
No, that is not unreasonable. I have been respecting this fundamental goal
of literate programming even though I disagree (that is the reason I have
kept quiet on the issue until recently "provoked" by your sarcastic personal
criticisms -- by the way, have I ever personally criticized your work or
even ideas before now?). Respect does not mean agreement. I associate with
the Axiom project because there are other goals besides literate programming,
say to spread the original ideas of Axiom and enlarge user base.
<p>It is not true that:
<blockquote TYPE=CITE>
<pre>William Sit came to visit at IBM Research, wrote some code, documented nothing and left.</pre>
</blockquote>

<p><br>When Bob Sutor developed hyperdoc and wrote the Axiom book, I documented
according to his hyperdoc requirements the packages on differential polynomial
rings (I recall he explicitly said there was not enough room to have similar
documentation for other packages I wrote). There are tests you can run
(in Examples of the spad source) as regression tests that you can even
try if hyperdoc is running as designed. But hyperdoc has not been working.
Without hyperdoc working, Axiom (the algebra code) is very difficult to
use. I participated in MathAction mostly to help myself and others understand
Axiom's sometimes seemingly absurd outputs. Hyperdoc is not available in
its full form. Hyperdoc is a way of documentation, as designed by the original
Axiom team. It still is way ahead of current browser technologies in many
ways. (I have articulated on this, see the archives).
<p>If "contributing to literate programming in the style of Knuth" is a
prerequisite for participation, then you are correct that I should not
hang around any more. But you are wrong. Even though you started the revival
of Axiom and make literate programming a primary goal, there are many more
aspects that users want. Not every user of Axiom is a developer. Not every
user wants to understand the theory behind a particular algorithm. Not
every user cares how Axiom is built. Every user wants Axiom to "just work"
on their platform of choice. That should be another primary goal of your
project. "just work" is not simply "just build" or "just compute" (both
essential, but not comprehensive).
<p>My parametric linear equation package IS documented: in a published
paper in the Journal of Symbolic computation, and in the source code. It
is not in a pamphlet style or what you call "literate with Knuth technology".&nbsp;
You have spent time to convert my IBM Script source to LaTeX, in the hope
I will expand it to a pamphlet. (and I haven't). But have you tried to
read and understand the paper? If you did not (and I believe you did not)
then what good would a pamphlet do? If you did, and have difficulty following
the mathematics, would putting the same mathematics in a pamphlet help?
and did you ever ask? I'll be very glad to explain or give talks on the
subject. Where do you think the paper needs improvement? Do you think by
literate programming the paper and code, you can just lie down on your
bed and read and understand them without effort? Is literate programming
the panacea?
<p>I respect your philosophy of literate programming, and I only ask you
to&nbsp; respect that there are other ways to make code (and theory) understandable.
You don't have to agree.
<p>I do not intend to convince you or others of my way of working (or unconvince
others of literate programming). I don't try to win in philosophy fights,
only in logical and mathematical discussions. I have no need to create
a SitAxiom branch because I have no agenda. I am a user of Axiom. I'll
use it when it suits my purpose and works. I'll use other CAS if other
CAS suits my purpose and works. I know my limits and I won't be able to
contribute to build-development work. I'll contribute to algebra code when
I start writing Axiom code again. Meanwhile, I am still learning about
the subtleties of Axiom (algebra code).
<p>Once again, I am not out to convince anyone of anything philosophical.
Please continue and carry on with your good work.
<p>My apologies for bringing this to the forum. It was not my intention.
As Donnie Brasco said in the namesake movie, let's "forget about it".
<p>William
<br>&nbsp;
<br>&nbsp;</html>

\start
Date: 28 Jun 2007 22:42:37 -0400
From: Stephen Wilson
To: Cliff Yapp
Subject: Re: Axisp news

Cliff Yapp writes:

> --- Stephen Wilson wrote:
> 
> > Any suggestions, preferences, comments, etc very much appreciated!
> 
> It looks like Lift has had a new release within the last few days - it
> might be worthwhile to inquire if the performance issues have been
> ironed out since the comparison article was written?  I agree it sounds
> very interesting but I think we should probably first figure out if the
> performance drop is something that can be avoided.


As you know, I discovered that Lift, despite initial measurements,
does not currently scale very well.

I discovered the principle bottleneck, and implemented a fix.

ASSEMBLE-TESTS is a macro which generates n assorted, simple minded
tests.  Tests are run by default at the point of definition, and can
be re-executed at any time via RUN-TESTS.

*** Here are some timings from the original Lift:

  >(time (assemble-tests 50))

  real time       :      7.520 secs
  run-gbc time    :      2.480 secs
  child run time  :      0.980 secs
  gbc time        :      0.390 secs
  #<Test passed>

  >(time (run-tests))

  Start: LIFT-EXAMPLES-1
  real time       :      1.700 secs
  run-gbc time    :      0.450 secs
  child run time  :      0.000 secs
  gbc time        :      0.150 secs
  #<Results for LIFT-EXAMPLES-1 [50 Successful tests]>
  
  >(time (assemble-tests 100))

  real time       :     32.310 secs
  run-gbc time    :     14.580 secs
  child run time  :      0.000 secs
  gbc time        :      1.360 secs
  #<Test passed>

  >(time (run-tests))

  Start: LIFT-EXAMPLES-1
  real time       :      2.410 secs
  run-gbc time    :      1.000 secs
  child run time  :      0.000 secs
  gbc time        :      0.170 secs
  #<Results for NIL [100 Successful tests]>


*** And some timings with my optimization:

  >(time (assemble-tests 100))

  real time       :      0.840 secs
  run-gbc time    :      0.310 secs
  child run time  :      0.000 secs
  gbc time        :      0.120 secs
  #<Test passed>

  >(time (run-tests))

  Start: LIFT-EXAMPLES-1
  real time       :      0.700 secs
  run-gbc time    :      0.220 secs
  child run time  :      0.000 secs
  gbc time        :      0.130 secs
  #<Results for LIFT-EXAMPLES-1 [100 Successful tests]>
  
  >(time (assemble-tests 2500))
  
  real time       :     33.300 secs
  run-gbc time    :     14.740 secs
  child run time  :      0.000 secs
  gbc time        :      1.230 secs
  #<Test passed>
  
  >(time (run-tests))
  
  Start: LIFT-EXAMPLES-1
  real time       :     14.470 secs
  run-gbc time    :      5.660 secs
  child run time  :      0.000 secs
  gbc time        :      0.850 secs
  #<Results for LIFT-EXAMPLES-1 [2500 Successful tests]>


As you can see, we can now define 2500 tests in approximately the same
amount of time as 100 tests used to take.

There are other optimizations available, but I am not pressed to
implement them.  I am fairly confident that we can use Lift to support
thousands of tests for Axiom.

I will submit a patch to the author of Lift, including this
optimization and the port to GCL.  There are a few remaining wrinkles
to work out but should be able to have something soon-ish.

\start
Date: Thu, 28 Jun 2007 20:32:17 -0700 (PDT)
From: Cliff Yapp
To: Stephen Wilson
Subject: Re: Axisp news

--- Stephen Wilson wrote:

> As you know, I discovered that Lift, despite initial measurements,
> does not currently scale very well.
> 
> I discovered the principle bottleneck, and implemented a fix.

[snip]

Very impressive!  Thanks Steve for the hard work.

\start
Date: 29 Jun 2007 00:40:28 -0400
From: Stephen Wilson
To: list
Subject: Re: 2.7.0 reports
Cc: Camm Maguire, Gabriel Dos Reis

Hello,

Axiom build with gclcvs-2.7.0, --enable-ansi, latest cvs checkout (and prior
revision), on an i686-pc-linux-gnu, fails midway into the algebra build.

The bug appears to be the following. Call to (VECTOR 0 0 0) returns
#(0 0) instead of #(0 0 0).

==----- test.lisp ---

(defun mkvector () (vector 0 0 0))

==-------------------


steve:tmp> gcl                                                                                                  12:32am[307]
GCL (GNU Common Lisp)  2.7.0 ANSI    Jun 28 2007 20:34:59
Source License: LGPL(gcl,gmp,pargcl), GPL(unexec,bfd,xgcl)
Binary License:  GPL due to GPL'ed components: (XGCL READLINE BFD UNEXEC)
Modifications of this banner must retain notice of a compatible license
Dedicated to the memory of W. Schelter

Use (help) to get some basic information on how to use GCL.

Temporary directory for compiler files set to /tmp/

>(compile-file "test.lisp")

;; Compiling test.lisp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling test.o.
#P"/home/steve/tmp/test.o"
NIL
NIL

>(load "test.o")

;; Loading test.o
 ;; start address -T 0xa59c40 ;; Finished loading test.o
196

>(mkvector)

#(0 0)

>(disassemble 'mkvector)

;; Compiling /tmp/gazonk_14243_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_14243_0.o.

#include "gazonk_14243_0.h"
void init_code(){do_init((void *)VV);}
/*      local entry for function MKVECTOR       */

static object LI1()

{        VMB1 VMS1 VMV1
        goto TTL;
TTL:;
        /*(VECTOR 0 0 0)*/
        {object V1;
        V1= 
        !3? Cnil : (alloca_val=alloca((3)*sizeof(struct cons)+sizeof(object)),
        ({object _b=(void *)alloca_val;if (((unsigned long)_b)&sizeof(_b)) _b++;
        {register struct cons *_p=(void *)_b;
        _p->c_car=make_fixnum(0);_p->c_cdr=(object)(_p+1);_p++;
        _p->c_car=make_fixnum(0);_p->c_cdr=(object)(_p+1);_p++;
        _p->c_car=make_fixnum(0);_p->c_cdr=(object)(_p+1);_p++;
        _p[-1].c_cdr=Cnil;}_b;}));
        {object V2;
        /*(LENGTH OBJECTS)*/
        {register object V4;
        V4= (V1);
        /*(ENDP (SETQ X (CDR X)))*/
        {object V5;
        V4= CMPcdr((V4));
        V5= (V4);}
        /* END (ENDP (SETQ X (CDR X)))*/
        /*(ENDP (SETQ X (CDR X)))*/
        {object V6;
        V4= CMPcdr(Cnil);
        V6= (V4);}
        /* END (ENDP (SETQ X (CDR X)))*/
        V3= make_fixnum(2);}
        /* END (LENGTH OBJECTS)*/
        V2= 
        !1? Cnil : (alloca_val=alloca((1)*sizeof(struct cons)+sizeof(object)),
        ({object _b=(void *)alloca_val;if (((unsigned long)_b)&sizeof(_b)) _b++;
        {register struct cons *_p=(void *)_b;
        _p->c_car=V3;_p->c_cdr=(object)(_p+1);_p++;
        _p[-1].c_cdr=Cnil;}_b;}));
        {object V7 = (VFUN_NARGS=5,(/* MAKE-ARRAY */(*LnkLI2)((V2),((object)VV[0]),Ct,((object)VV[1]),(V1))));VMR1
        (V7);}}}
        /* END (VECTOR 0 0 0)*/
        return Cnil;
}
static object  LnkTLI2(object first,...){object V1;va_list ap;va_start(ap,first);V1=(object )call_vproc_new(((object)VV[2]),0,0,(void **)(void *)&LnkLI2,first,ap);va_end(ap);return V1;} /* MAKE-ARRAY */
#(#(ELEMENT-TYPE INITIAL-CONTENTS MAKE-ARRAY
    (%INIT
     . #((LET ((*DISABLE-RECOMPILE* T))
           (MFSFUN 'MKVECTOR 0 0 0)
           (ADD-HASH 'MKVECTOR '(NIL (ARRAY T *))
               '((VECTOR (*) (ARRAY T *)))
COMMON-LISP-USER
LISPLAMBD,DECLA,OPTIMIZ,SAFETY  ,BLOCK
                                     MKVECTOR
,VECTOR '/tmp/gazonk_14243_0.lsp))
         (DO-RECOMPILE)))))
static object LI1();
#define VMB1 object  V3;
#define VMS1
#define VMV1
#define VMR1(VMT1) return(VMT1);
#define VM1 0
static void * VVi[4]={
#define Cdata VV[3]
(void *)(LI1)
};
#define VV (VVi)
static object  LnkTLI2(object,...);
static object  (*LnkLI2)() = (object (*)()) LnkTLI2;

/tmp/gazonk_14243_0.o:     file format elf32-i386

Disassembly of section .text:

00000000 <init_code>:
   0:   68 00 00 00 00          push   $0x0
   5:   e8 fc ff ff ff          call   6 <init_code+0x6>
   a:   58                      pop    %eax
   b:   c3                      ret    

0000000c <LI1>:
   c:   55                      push   %ebp
   d:   89 e5                   mov    %esp,%ebp
   f:   83 ec 2c                sub    $0x2c,%esp
  12:   8d 54 24 0f             lea    0xf(%esp),%edx
  16:   83 e2 f0                and    $0xfffffff0,%edx
  19:   8d 42 08                lea    0x8(%edx),%eax
  1c:   89 02                   mov    %eax,(%edx)
  1e:   c7 42 04 00 00 00 d0    movl   $0xd0000000,0x4(%edx)
  25:   c7 40 04 00 00 00 d0    movl   $0xd0000000,0x4(%eax)
  2c:   8d 42 10                lea    0x10(%edx),%eax
  2f:   89 42 08                mov    %eax,0x8(%edx)
  32:   c7 40 04 00 00 00 d0    movl   $0xd0000000,0x4(%eax)
  39:   83 ec 1c                sub    $0x1c,%esp
  3c:   8d 42 18                lea    0x18(%edx),%eax
  3f:   89 42 10                mov    %eax,0x10(%edx)
  42:   c7 40 f8 00 00 00 00    movl   $0x0,0xfffffff8(%eax)
  49:   8d 44 24 0f             lea    0xf(%esp),%eax
  4d:   83 e0 f0                and    $0xfffffff0,%eax
  50:   8d 48 08                lea    0x8(%eax),%ecx
  53:   89 08                   mov    %ecx,(%eax)
  55:   c7 40 04 02 00 00 d0    movl   $0xd0000002,0x4(%eax)
  5c:   c7 41 f8 00 00 00 00    movl   $0x0,0xfffffff8(%ecx)
  63:   52                      push   %edx
  64:   ff 35 04 00 00 00       pushl  0x4
  6a:   68 00 00 00 00          push   $0x0
  6f:   ff 35 00 00 00 00       pushl  0x0
  75:   50                      push   %eax
  76:   a3 00 00 00 00          mov    %eax,0x0
  7b:   66 c7 05 04 00 00 00    movw   $0x5,0x4
  82:   05 00 
  84:   ff 15 10 00 00 00       call   *0x10
  8a:   c9                      leave  
  8b:   c3                      ret    

0000008c <LnkTLI2>:
  8c:   8d 44 24 08             lea    0x8(%esp),%eax
  90:   50                      push   %eax
  91:   ff 74 24 08             pushl  0x8(%esp)
  95:   68 10 00 00 00          push   $0x10
  9a:   6a 00                   push   $0x0
  9c:   6a 00                   push   $0x0
  9e:   ff 35 08 00 00 00       pushl  0x8
  a4:   e8 fc ff ff ff          call   a5 <LnkTLI2+0x19>
  a9:   83 c4 18                add    $0x18,%esp
  ac:   c3                      ret    
NIL


Thanks,
Steve

\start
Date: Fri, 29 Jun 2007 01:27:46 -0500
From: Tim Daly
To: William Sit
Subject: A modest proposal

William,

I apologize that I've been sarcastic to you in public. As you know
from personal experience I hold you and your opinions in high esteem.
Please accept my apology.

\start
Date: Fri, 29 Jun 2007 03:11:09 -0500
From: Tim Daly
To: William Sit
Subject: A modest proposal

William,

> My parametric linear equation package IS documented: in a published
> paper in the Journal of Symbolic computation, and in the source code.
> It is not in a pamphlet style or what you call "literate with Knuth
> technology.

> You have spent time to convert my IBM script to LaTeX, in the hope
> I will expand it to a pamphlet. (and I haven't).

Yes, I spent approximately 3 weeks of evenings recasting your paper
into latex hoping to lower your "personal cost" of contributing it
and its ideas as documentation. Despite that effort you still objected.
That's fine. It is your choice to contribute or not. I didn't demand
that you do, I simply tried to make it straightforward. I've done
other "behind the scenes" work, including rewriting Barry's thesis,
which has yet to bear fruit (due to lack of time as Barry has quite
generously agreed to let his work be used in pamphlets).



> But have you tried to read the paper?  If you did not (and I believe
> you did not) then what good would a pamphlet do?

A pamphlet form would document the ideas for the future users of Axiom
in a form we can use. There are thousands of mathematics textbooks but
not many that explain the theory and the computational mathematics, in
context with a particular implementation and its choices. A pamphlet
is not just a copy of the paper. It should explain the "why" of the
code in the context of the theory. We need to know not just the theory
but how specific Axiom code implements it, what are its design
constraints, what are its limitations, etc.

I did read your paper, in detail, along with converting it. But my
primary focus at the time was making it into latex. The effort was
not for me but for people who might need to understand your code.

If my goal was to document your code rather than recast your paper I
would have spend considerably more time trying to understand the
mathematics. For instance, I documented dhmatrix by understanding how
they work. I helped Scott use them as the basis for the pictures in
the Jenks book. I just started documenting the quaternions (see the
new quat.spad). You'll recall I sent you some private links related to
the theory of exterior and geometric algebras that I found during the
course of understanding quaternions.  I'm still studying those papers
for the mathematics and hope to expand the quaternion and octonions
domains in a more general setting. Indeed, if I could find the time
there are some wonderful ideas that need to be reduced to working
code. We've had discussions about your new algebra work, which I
believe I do understand. But not to the level of being able to reduce
the ideas to code. You do and you can.

The point I'm trying to make is that I believe I could have understood
the beginnings of your algebra on differential polynomials from a pamphlet
you wrote using your paper. But my time was spent "on making the 
machinery work", which is needed rather than using my time to understand
the algebra to the point where I could document it (which would have
been a pleasant luxury). You're clearly much more qualified to explain
your own work.

That said, you have recently agreed to allow me to use the paper I
converted as the basis for a pamphlet form of your work. Since you 
disagree so strongly about making pamphlets perhaps we can compromise.
I'll make an effort to understand your algebra and an effort to write
a pamphlet form. All I ask is that you have the patience to review it,
explain what I don't understand, and correct the nonsense. Perhaps when
you've seen it done you'll be more convinced of the power of literate
programming.




> I respect your philosophy of literate programming, and I only ask you
> to repect that there are other ways to make code (and theory)
> understandable.

Of course there are other ways to make code understandable. But other
code, e.g. Microsoft Word, won't give the same answers in 100 years.
So there is a qualitative difference between computational mathematics
and any other code being written. 

Almost all commercial code dies. All of the projects I've worked on
have died "in the belly of the corporation". I believe that this fate
awaits Mathematica and Maple, a topic which we've discussed. It
certainly happened to Macsyma and would have happened to Scratchpad,
but for the very generous efforts of Mike Dewar and other people at
NAG. I've been trying hard to get Derive put into a "dead code safe",
hoping that TI will agree to release the code if they lose interest in
it.

But getting the code is not enough. I've talked to the developers of
Mathematica and Maple. The kernel code of those systems are very, very
poorly documented by the programmers estimates. Yet I've attended ISSAC
talks about the super-speed numerics at the heart of the system. I do
not know but I'd bet that the only existing documentation will be the
few pages of text from that paper. Due to publication constraints an
ISSAC paper cannot address any real details about the code, the choice
of data structures, or the relation of that code to the theory. That
would take a pamphlet file.

The point is that if Mathematica or Maple dies and if the failing
company would release the code it is unlikely that the code will be
brought back to life without the involvement of the original
developer(s). (Of course code is now considered "intellectual
property" (a non-legal concept but...) and is considered a real asset
of the company.  So if a company should go bankrupt they cannot "give
away" the code.  They need to sell it to recover the asset's value. I
was quoted a price of $250k dollars for the source code for Macsyma.
I don't have that kind of money.) Yet even in the unlikely
circumstance that they do give it away you'll have a million lines of
C code with clearly chosen variable names and no documentation.

Thus we are faced with a choice. Do we let systems simply die and then
invest the thousands of manyears of work to build new ones so the cycle
repeats? Or do we invest in the code and try to make it "live" in a
way that new users can learn about the concepts and their specific
implementation? If we do that it requires the effort of the original
developers to communicate with the future generations in specific detail.




> Is literate programming the panacea?

Would pamphlets help? We do not know for sure. But I firmly believe
they will and this project is an experiment on that thesis, among 
other goals.

So while there are many ways to write clear code (e.g. variable name
choices) and various ways of documenting (ISSAC papers, textbooks,
specification documents, Rational relation diagrams, ...) I believe
that Knuth "got it right". He produced high quality, nearly bug free
code with deep documentation. He placed his focus on writing for
people rather than writing for the machine. And his program, Tex, has
outlasted many other similar tools, even those backed by big money
like IBM script.



> As Donnie Brasco said in the namesake movie, let's "forget about it".

Drop the debate but not the fundamental goal. There really is a
guiding philosophy behind the choices that informs decisions about the
quality of a proposed direction.




All that said, I again apologize for being sarcastic. When the
fundamentals of the project are being questioned I need to be quite
clear when a debate misses the point. "Reducto ad sarcasm" is not a
proper way to debate and I'm sorry that I fell to that level.  I hold
you in high personal esteem and I regret that mistake. Mea culpa.

\start
Date: Fri, 29 Jun 2007 10:28:58 +0200
From: Ondrej Certik
To: Tim Daly
Subject: Re: A modest proposal

> Ondrej,
>
> As noted, Camm both did the prior port and sponsored Axiom.
> If we can do the port I believe he can be asked to sponsor it.

OK. When you merge the repositories and make a release, let me know
which exact version you would like to have in Debian and if Camm
doesn't have time to update the package, I can do it.

\start
Date: Fri, 29 Jun 2007 11:36:50 +0200
From: Ralf Hemmecke
To: list
Subject: LogiWeb

Hello

I am just sitting in a talk of Klaus Grue. He is talking about LogiWeb.

http://logiweb.eu/

That seems to be a very interesting project.

\start
Date: Fri, 29 Jun 2007 12:07:15 +0200
From: Ralf Hemmecke
To: William Sit
Subject: re: A modest proposal

Hello,

sorry if I prolong this thread although much has already been said.

Literate programming can currently be seen as religion. Even though TeX 
survived until today, there must be some reason why a lot of people 
don't follow it.

I must say, I am happy that Tim set LP as a main goal for Axiom. I think 
it is an important one.

But not only from Tim's and William's mails I learned that it should not 
be the only goal. Following LP too strictly, does not work. At least not 
at the moment. Currently, more important than LP is the need to attract 
more developers. Currently, the rules that everything must per properly 
documented should be a bit relaxed. Axiom currently is not documented 
properly and it will not be for another 10 years. We have a lot of 
legacy code.

But without new and ambitious developers, Axiom will become even more 
uninteresting. Axiom must spread to the world and attract users and 
developers. If you set the entry barrrier too high. Axiom is going to 
become a Tim-only project.

Tim, that does *not* mean that I am against LP. Quite the contrary. LP 
should be preached again and again. And it should definitely be the 
essential goal of the Axiom project.

What I want to say is: Tim is right and William is right. (sic!)

But LP is not everything. Think about why there are two books "TeX the 
Program" and "The TeXbook". The first one describes the program and the 
second one is for users to teach them how to use the program.

I don't quite know whether Tim wants to have both kinds of documentation 
in the Axiom project. If I understood correctly, that is the "facets of 
the crystal" view. Yes, Axiom should be a big monster which not only 
contains code.

It should be a collection of
1 code,
2 API descriptions (this is what the +++ comments are)
3 explanation of
     motivations,
     tricks that were used in the implementation,
     things that are not used in the code (and the reason for it)
4 informal description of why the code is there
5 informal overall description of how some piece of code works
6 formal descriptions of the theory behind the code
7 proofs that the code fulfils its specification (its API)
8 test scripts that tests the code (we don't have automated
   program verification yet)
(This list is certainly not complete.)

William (I have not actually looked at your code so excuse me if I am 
wrong), what you contributed was/is in the code and API part and maybe 
in the test and formal description part (1,2,6,8). But what I think is 
very important is also the interconnection between all of this. Can you 
point me to some text in current Axiom that explains *why* (4) you have 
designed your contribution as it is now?

I agree that some people are not interested in the code and in the 
description of the code, but for developers who maintain code it is very 
important to know about design issues. That is a different issue from 
the actual mathematical theory and it is important for maintainers of 
the code.

Axiom should have everything and it should be able to show to some 
person exactly the amount of detail s/he wants to see. If someone is 
only interested in the theory, extract something that doesn't show the 
implementation details. But some people would not only like to see the 
theory, but they want to see a "running theory", they want an 
interactive paper where they see the theory and can compute with the 
algorithms implemented by the paper. Other people like to see the actual 
algorithm in a specific programming language. Some people are not 
interested to be distracted by a lot of text and want to concentrate on 
more focused details of the implementation. Axiom should be able to 
extract all these different forms in nicely human readable formats. All 
that should be provided by a (or several) pamphlet(s).

The important thing is that the information is there. I am not so sure 
that we already have a good format of how a pamphlet should look like.

I also agree that it is hard to actually write good LP documents. I made 
my experience with Aldor-Combinat. Look at it at 
http://www.risc.uni-linz.ac.at/people/hemmecke/AldorCombinat/ .
It has a lot of documentation. But I myself would not say that it is a 
proper literate program. Try it out, read it. I guess, you will not be 
able to understand the overall project goals. I have not written that 
but still the program is working. Now, if I would require proper LP 
documentation, I would never be able to release this code at all. I try 
hard to add a lot of design decisions, but all that is still not enough.

And that Aldor-Combinat experience lets me think that it is better to 
release code even if it is not properly documented. So in this sense I 
do not fully agree with Tim. I find it better if I throw something at 
the public and have referees that tell me, hey there is something wrong, 
this and that is not understandable. So I have a chance to extend 
code+documentation at places where people complain. I am committed to 
LP, but I also have only limited time so it's better if there is really 
a community develepment. I am all for feedback. That should be our 
"quality assurance" way of makeing Axiom incrementally better.

That is my little comment to the issue...
I'm sorry if I wasted your time.

\start
Date: Fri, 29 Jun 2007 14:59:23 -0400
From: Bill Page
To: Ralf Hemmecke
Subject: Re: LogiWeb

Ralf,

On 6/29/07, you wrote:
>
> I am just sitting in a talk of Klaus Grue. He is talking about LogiWeb.
>
> http://logiweb.eu/
>
> That seems to be a very interesting project.
>

Yes it does seem both interesting and relevant to Axiom but I hope
that the talk was easier to navigate and to understand than the above
website! It took me a long time to decide that this was indeed
something interesting.

When you have a chance, could you try to (briefly) summarize the talk?
Or do you have a link to a more readable introduction?

\start
Date: Fri, 29 Jun 2007 14:19:31 -0500
From: Tim Daly
To: Ralf Hemmecke
Subject: Combinat

Ralf,

The MuPad-Combinat link is broken.

34 sections of documentation. From browsing around I can infer
that a "species" is somehow related to sets. However, I can find
no definition of what a species is. Perhaps this is related to
the point-set topology structures? I cannot tell. Perhaps an
"overview of the theory" section might help. Something  like:
<http://mathworld.wolfram.com/Species.html>

\start
Date: Fri, 29 Jun 2007 15:23:36 -0400
From: Bill Page
To: Ralf Hemmecke
Subject: re: A modest proposal

On 6/29/07, Ralf Hemmecke wrote:
>
> Literate programming can currently be seen as religion. Even though TeX
> survived until today, there must be some reason why a lot of people
> don't follow it.
>
> I must say, I am happy that Tim set LP as a main goal for Axiom. I think
> it is an important one.
>
> But not only from Tim's and William's mails I learned that it should not
> be the only goal. Following LP too strictly, does not work. At least not
> at the moment. Currently, more important than LP is the need to attract
> more developers. Currently, the rules that everything must per properly
> documented should be a bit relaxed. Axiom currently is not documented
> properly and it will not be for another 10 years. We have a lot of
> legacy code.
>
> But without new and ambitious developers, Axiom will become even more
> uninteresting. Axiom must spread to the world and attract users and
> developers. If you set the entry barrrier too high. Axiom is going to
> become a Tim-only project.
> ...

I agree with both Ralf and William Sit on this issue. Like Ralf, I
think that I am a strong supporter of the *concept* of literate
programming, but that the experiment in literate programming as
defined by Tim Daly in the current Axiom open source project is (for
the most part) a failure. And I do not think that this is simply
because insufficient effort has been devoted to developing this part
of the project. Or rather I should say it the other way: insufficient
effort has be devoted to literate programming in the Axiom project
*because* the current approach to literate programming in the project
is a failure. I think the Knuth-style literate programming (pamphlet)
methodology is just not suitable to the task.

But I am not sure what to do about this. I think that already the
Axiom project has suffered a very significant and maybe even critical
lose of interest on the part of other possible contributors at least
in part because of the insistence on this approach. It complicates the
build environment and puts a extra layer between the developer and the
system. It is clear that developers do not want to be reading their
source code from a dvi viewer, two steps removed from the problem on
which they are focused. And at the same time the raw pamphlet format
source code is even more awkward and obscure than the original
"illiterate" source code by the interposed presence of coding and
documentation which is normally otherwise "out of the way".

These comments (by me, Ralf, William and others) should *not* be
construed as in anyway being against documentation or even against the
concept of literate programming. But as Ralf says, we have to face up
to these uncomfortable facts or risk the death of the Axiom project
due to placing a barrier which no developer other than the one who
originated the idea is willing to climb.

\start
Date: 29 Jun 2007 21:27:12 +0200
From: Martin Rubey
To: Tim Daly
Subject: Re: Combinat

Tim Daly writes:

> Ralf,
> 
> The MuPad-Combinat link is broken.

thanks, "www" has to be removed.
 
> However, I can find no definition of what a species is. 

Section 8.1, Definition 8.1. (in trunk)

> <http://mathworld.wolfram.com/Species.html>

The wikipedia site is much better.

\start
Date: Fri, 29 Jun 2007 21:34:05 +0200 (CEST)
From: Waldek Hebisch
To: list
Subject: Fork time

First, I would like to thank Wiliam Sit for starting this
debate.  He formulated pragmatic view of Axiom development
that I share.  I hoped that eventually Axiom project will
take such direction.  However, the debate made clear for me
what I shall do.

In response to Wiliam Sit Tim Daly wrote:
> Rather than starting by refuting your points in detail let me ask the
> question....If you know that literate programming is a PRIMARY design
> goal of Axiom and you don't support that goal, then wouldn't it make
> sense to take the freely available original sources, which are not
> literate, and start a new Sourceforge project (say, OpenAxiom,
> RawAxiom, whatever)? That way you can define the goals to be anything
> you like.
>

Later:

> It is NOT important for the goals of this project that we "get there
> FAST" or that "we use the standard methods". If those are your needs
> then, by all means, start a Sourceforge project that achieves those
> goals. Make a Scratchpad or FASTAxiom or STANDARDAxiom or SITAxiom
> project. Take a copy of Waldek's branch and release it under that
> name.  Axiom, and by that I mean, THIS Sourceforge project, does not
> have those goals. My ONLY request is that you choose a different name
> for your new project and stop referring to it as "Axiom".

I decided that it is best to follow this advice -- I plan to
created a new project called FriCAS -- many details are undecided
yet (even the name may change).

Let me shortly state my reasons:
- I feel that current "offical" statements about Axiom project
  are harmful for the project
- my attempts to change project direction are labeled as
  stealing the project -- new project should make sitation
  clear

I value Axiom comunity, but feel that leaving current project is
the best way to clarify situation.

\start
Date: Fri, 29 Jun 2007 15:44:08 -0400
From: William Sit
To: Tim Daly
Subject: Re: A modest proposal

Tim Daly wrote:
> 
> William,
> 
> I apologize that I've been sarcastic to you in public. As you know
> from personal experience I hold you and your opinions in high esteem.
> Please accept my apology.
> 
> Tim

A bit of sarcasm was exactly what's needed to bring the
issues out! But be careful when you next use it. Apology
(not needed) accepted. Thanks for your kind comment above.

\start
Date: Fri, 29 Jun 2007 16:11:30 -0400
From: William Sit
To: Tim Daly
Subject: Re: A modest proposal

Tim Daly wrote:
[sniped]
> That said, you have recently agreed to allow me to use the paper I
> converted as the basis for a pamphlet form of your work. Since you
> disagree so strongly about making pamphlets perhaps we can compromise.
> I'll make an effort to understand your algebra and an effort to write
> a pamphlet form. All I ask is that you have the patience to review it,
> explain what I don't understand, and correct the nonsense. Perhaps when
> you've seen it done you'll be more convinced of the power of literate
> programming.

The ability to review a pamphlet depends on familiarity with
that format, which I don't have. But I'll answer any
questions you may have on the paper or code. In fact, if you
(or anyone else) send me questions, I'll answer them and
maybe we can then piece together some form of documentation
satisfactory to all concerned. I think MathAction Wiki pages
may be one media to start this.

There is one problem: I do not know whether copyright (by
Journal of Symbolic Computation) may be violated if large
chunks of my paper is reproduced on the web. It is fair use
to send an individual who asks me a copy, but I believe any
mass distribution would require prior copyright clearance
(the same legal reason why a library cannot distribute
printed copies of articles in a pile, say for use in a
course, but may make an individual copy for anyone who
asks). 

\start
Date: 29 Jun 2007 16:45:08 -0400
From: Stephen Wilson
To: Bill Page
Subject: re: A modest proposal

Hi Bill,

I share some of the concerns about literate programming, but I'd like
to spell out some of my thoughts.

Bill Page writes:
> I agree with both Ralf and William Sit on this issue. Like Ralf, I
> think that I am a strong supporter of the *concept* of literate
> programming, but that the experiment in literate programming as
> defined by Tim Daly in the current Axiom open source project is (for
> the most part) a failure. And I do not think that this is simply
> because insufficient effort has been devoted to developing this part
> of the project. Or rather I should say it the other way: insufficient
> effort has be devoted to literate programming in the Axiom project
> *because* the current approach to literate programming in the project
> is a failure. I think the Knuth-style literate programming (pamphlet)
> methodology is just not suitable to the task.

> But I am not sure what to do about this. I think that already the
> Axiom project has suffered a very significant and maybe even critical
> lose of interest on the part of other possible contributors at least
> in part because of the insistence on this approach. It complicates the
> build environment and puts a extra layer between the developer and the
> system. 

The build environment is not an issue for me at all.  If there is
complication, it is due to the fact that there is no clean integration
between the tools required to both build the system and extract the
code/document bits.  This is one reason why I am excited about
asdf-literate, as it should significantly simplify the build as it
understands the model.  We need the proper tools for the job, and if
they do not yet exist, we can create them.

> It is clear that developers do not want to be reading their
> source code from a dvi viewer, two steps removed from the problem on
> which they are focused.

I dont do that myself.  I write my code as most other programmers do.
I write it and use traditional comments as a form of documentation.  I
do most of my coding in Lisp, which for the most part does not care
about things like the order of definitions.  So I can code and
document and build towards  a literate document.  Its not yet a
pamphlet, and the comments lack LaTeX markup,  but its a form of a
literate document.  It is no different than any other pice of code
written by any other programmer, except that the comments might seem a
tad verbose.

Once I have polished a file, once it is looking good and stable and Im
relatively sure it is up to snuff, It is pretty straight forward to
convert to a pamphlet.  I dont resent the need to convert the code.  I
view it as an opportunity to audit and re-check.  Something you can
never do enough of.

So the rpocess of writing a pamphlet file is something of a support
structure for writing nice code -- something you want anyways before
you even think about pushing a change out to the mainstream.

Of course, others might write literately from the beginning, but thats
not how I do it.  I would find that approach to be restrictive and
unproductive.  But thats just me.  Fortunately, nobody is telling me
how I should go about it.

Moreover, very few files in axiom are truely literate.  They are just
shells, just raw code waiting to be improved.

> And at the same time the raw pamphlet format source code is even
> more awkward and obscure than the original "illiterate" source code
> by the interposed presence of coding and documentation which is
> normally otherwise "out of the way".

This is one point to which I partially agree with.  The format is
somehow `odd' -- it is not native to the programming language in which
your writing.  However, it is fairly native to the task of writing a
document, but that is what your doing.  

Leo, from the small amount I know of it, trys to blend the two notions
of coding and documenting.  Some might prefer that way of working and
thinking.  Thats OK with me.  I feel that the main issue is having
high quality tools available.  I do pretty good with emacs, but it
certainly does not suit everyone.

> These comments (by me, Ralf, William and others) should *not* be
> construed as in anyway being against documentation or even against the
> concept of literate programming. But as Ralf says, we have to face up
> to these uncomfortable facts or risk the death of the Axiom project
> due to placing a barrier which no developer other than the one who
> originated the idea is willing to climb.

This is the main point of my post.  If you agree in principle with the
goals of the Axiom project then there is no real hill.  You can get to
the top either by doing somersaults of by taking the elevator.  The
challenge is discovering for yourself what the path of least
resistance is, what works for you.

The Axiom project, quite naturally, is based on a few fundamental
axioms.  These first principles are not the same as those found in
other projects.  But just like in science or math, when a new set of
fundamental ideas are suggested as a foundation for the discipline,
there is always resistance and criticism, years upon years of
resistance and criticism.

If you believe in the goals, if you believe in the axioms, the
philosophys, stand by them and press on.

\start
Date: Fri, 29 Jun 2007 23:28:00 +0200
From: Ralf Hemmecke
To: Tim Daly
Subject: Re: Combinat

> The MuPad-Combinat link is broken.

Thanks. But I think that is a problem of the MuPAD-Combinat people. I've
forwarded the broken link message.

Yes, it's a shame. The abstract of Aldor-Combinat is much too short. And
the introduction section does not explain anything useful. But that is
the reason why we have no official release yet. We are still at 0.0.3
but develop in the public. I hope at 0.1.0 we will have something that
can be better understood. But it seems that I am the only person who
will do this.

> 34 sections of documentation. From browsing around I can infer that a
> "species" is somehow related to sets. However, I can find no
> definition of what a species is.

Oh, yes, you could have found it.
http://www.risc.uni-linz.ac.at/people/hemmecke/AldorCombinat/combinatsu14.html#x27-320008.1
But you are right. The information is not properly organised.
However, if instead of the html documentation you would have read the
.dvi documentation, you would certainly have used your search button of
your viewer. On our html presentation one would go to the "Index"
section, look for "combinatorial species" and press on the red number
(which lead to the definition of "combinatorial species").

But again, your feedback helps. Since it tells me that it is not so
obvious to look through the index.

> Perhaps this is related to the point-set topology structures? I
> cannot tell.

I cannot tell, either.

 > Perhaps an "overview of the theory" section might help.

I'll do some restructuring this summer.

> Something  like: <http://mathworld.wolfram.com/Species.html>

I think http://en.wikipedia.org/wiki/Combinatorial_species is much better.

\start
Date: Fri, 29 Jun 2007 23:36:21 +0200 (CEST)
From: Franz Lehner
To: list
Subject: Tuples

Hello

here is an algebra question for a change.
Do I understand correctly that there is currently no way to implement
DirectProduct(L: List Group) or DirectProduct(L: Tuple Group)?
That is, one has to manually iterate DirectProduct(G1,G2)
if one wants a direct product of more than two groups?

\start
Date: Fri, 29 Jun 2007 14:39:48 -0700 (PDT)
From: Cliff Yapp
To: William Sit, Tim Daly
Subject: Paper usage policy (for authors)

--- William Sit wrote:

> There is one problem: I do not know whether copyright (by
> Journal of Symbolic Computation) may be violated if large
> chunks of my paper is reproduced on the web.

Hard to say - I think this is the place to start:
http://www.elsevier.com/wps/find/supportfaq.cws_home/copyright

One item on the "rights the author retains" list gives hope:

"the right to prepare other derivative works, to extend the article
into book-length form, or to otherwise re-use portions or excerpts in
other works, with full acknowledgement of its original publication in
the journal."

Whether pamphlets qualify is probably a question for a lawyer.

I'm assuming anyone other than the original author has no special
rights period.

This is why I think the logical approch to take for pamphlets on
subjects where we have no legal right to the original source material
is to write our own review paper in the process, outlining the key
points and weaving the original papers' ideas together into a whole
(which is also the point of the CAS code, after all - at least for the
well established mathematical work that will probably form the focus of
most of our literate efforts for the first few years.)  What to do
about original work without a larger body of literate is somewhat less
clear, although I think in most cases an article appropriate for
inclusion as a pamphlet will have to be slightly different from a
typical research article.  (More background, context, etc.)

Hopefully, we can eventually make Axiom a driver for free availability
of new publications in mathematical research via some sort of Axiom
journal.  If the goal is truly to spread knowledge and learn, expensive
commercial journals and their per-article or subscription fees present
a barrior to that goal.  (Certainly I feel it, not being at a major
university - there are ways but especially for older papers tracking
them down can be extremely difficult.  We want knowledge to be easily
accessible.  It's hard enough to get people to want to learn - why make
it any harder when they actually do try to learn?)  I view this as a
secondary goal of pamphlets - if Axiom is structured correctly, the
pamphlets should eventually constitute a very high quality, complete
description of the mathematical landscape that is freely available to
everyone (which just incidently happens to have running CAS code to let
you immediately apply those same ideas).

I think the Axiom project might be a bit like the Free Software
Foundation in that respect - to me at least it's about more than just a
working CAS.  It's about changing the landscape itself.  Not replacing
the academic institutions and their work as they exist today, but
making them more visible and more readily applicable to the rest of the
world.  That's a more ambitious project than just a working CAS, but
the potential rewards are even greater.

The analogy I have always liked is the advancement of transportation. 
Take traveling west in the US, for example - people started doing it in
covered wagons because that was quicker and easier for them than
building anything better.  But soon, people built railways that
dramatically improved just about everything where travel was concerned.
 It made all sorts of things possible that were impossible before. 
Same with the US highway system - two lane roads will get you there,
but superhighways will do it faster and much more quickly.  For an
individual car, it makes more sense to use what is already there.  When
many people rely on something, it's worth doing right even at the
expense of greater up front cost and work.  Hopefully Axiom will prove
to be an enabler for new types of mathematical research and and new
levels of rigor and speed.  That's worth doing right, even if we have
to spend the time to make the infrastructure to make it possible first.

\start
Date: Fri, 29 Jun 2007 15:08:44 -0700 (PDT)
From: Cliff Yapp
To: Stephen Wilson, Bill Page
Subject: re: A modest proposal

--- Stephen Wilson wrote:

> The build environment is not an issue for me at all.  If there is
> complication, it is due to the fact that there is no clean
> integration between the tools required to both build the system and
> extract the code/document bits.  This is one reason why I am excited
> about asdf-literate, as it should significantly simplify the build
> as it understands the model.  We need the proper tools for the job,
> and if they do not yet exist, we can create them.

Bingo.  None of what we're doing with pamphlets or compiling the system
is fundamentally hard (except maybe the def* parsing, but that can come
later) and it's just a question of teaching the tools to deal with it
correctly.

> I dont do that myself.  I write my code as most other programmers do.
> I write it and use traditional comments as a form of documentation. 
> I do most of my coding in Lisp, which for the most part does not care
> about things like the order of definitions.  So I can code and
> document and build towards  a literate document.  Its not yet a
> pamphlet, and the comments lack LaTeX markup,  but its a form of a
> literate document.  It is no different than any other pice of code
> written by any other programmer, except that the comments might seem
> a tad verbose.

I think CFFI's comments are like that, come to think of it...

> Once I have polished a file, once it is looking good and stable and
> Im relatively sure it is up to snuff, It is pretty straight forward 
> to convert to a pamphlet.  I dont resent the need to convert the
> code.  I view it as an opportunity to audit and re-check.  Something
> you can never do enough of.

Amen.

> So the rpocess of writing a pamphlet file is something of a support
> structure for writing nice code -- something you want anyways before
> you even think about pushing a change out to the mainstream.
> 
> Of course, others might write literately from the beginning, but
> thats not how I do it.  I would find that approach to be restrictive
> and unproductive.  But thats just me.  Fortunately, nobody is
> telling me how I should go about it.

Right.  The way I do it is close to that, but because I usually lack
the domain knowledge to just start writing code I will begin writing
the background parts of the paper as a way to educate myself.  (The
Units and Dimensions draft is an example, not yet finished).  Once I
understand it well enough to have an idea of what should be done, I
will fire up sbcl and start poking around trying things and figuring
out how pieces I am going to need should be done.  From there, its
usually an iterative process of adding working pieces to the pamphlet
and documenting them, and then figuring out the next piece.  Then a
cycle or two of figuring out if I did it the right way, and if not
re-doing whatever.  Once the program begins to reach a working stage, I
usually convert over to editing just in the pamphlet - by that point
there is enough functionality in the pamphlet that I load that when I
figure out the next piece.

There is a helpful quality about being forced to write out ideas - it's
a variation on the "to teach someone you must truly understand the
material" idea.  For already skilled developers it probably feels more
like a waste of time, but for me it really helps.

> Moreover, very few files in axiom are truely literate.  They are just
> shells, just raw code waiting to be improved.

Yep.

> > And at the same time the raw pamphlet format source code is even
> > more awkward and obscure than the original "illiterate" source code
> > by the interposed presence of coding and documentation which is
> > normally otherwise "out of the way".
> 
> This is one point to which I partially agree with.  The format is
> somehow `odd' -- it is not native to the programming language in
> which your writing.  However, it is fairly native to the task of 
> writing a document, but that is what your doing.  

We need better editor support to make that part seemless.  I have a few
ideas about that but it's down the road.

> This is the main point of my post.  If you agree in principle with
> the goals of the Axiom project then there is no real hill.  You can
> get to the top either by doing somersaults of by taking the
> elevator.  The challenge is discovering for yourself what the path
> of least resistance is, what works for you.

Right.  There is no getting around the fact that a literate
implementation of something is a lot of work, but the idea of that work
is to make something that is "finished" - it won't have to be rewritten
in 30 years because someone can't understand what it is doing.  (If
there's a better algorithm out there then of course that's different,
but the rewrite would have been needed in that case regardless.)

\start
Date: Sat, 30 Jun 2007 00:28:37 +0200
From: Ralf Hemmecke
To: Stephen Wilson
Subject: re: A modest proposal

>> It is clear that developers do not want to be reading their
>> source code from a dvi viewer, two steps removed from the problem on
>> which they are focused.

Huh? I am sure, you have not used ALLPROSE. Your code is only one click 
away.

> I dont do that myself.  I write my code as most other programmers do.

Because you are trained in programming. But what you do is writing the 
program for yourself. Not for other people.

Well, that is fine. I think I also do that to a great deal. But if I 
write mathematical code, it is quite useful that I can see the formulas 
in .dvi and have the code very close to it. I am not good at writing 
ascii art and always putting something like ++ in front of a line is 
painful.

Anyway, write your code as you like, nobody is forcing. The only thing 
is that one should not forget that LP is not about documenting a 
program. It is about documenting an idea where the documentation is 
equipped with real code. Human understandable, of course. If that is the 
  final product that you give to the public nobody cares how it was 
produced. I have not yet heard of someone who has good guidelines of how 
to produce a nice literate document.

Additionally, one should also distinguish at least 3 cases.
1) An idea was already published together with pseudo code.
2) The idea is developed and at the same time coded (i.e. it is
    relatively clear how to put it into a programming language.)
3) The idea might be clear but the design in the actual programming
    language is not. It might be that the programming language does
    not allow certain constructs that one has in mind. So there is some
    time to experiment with the programming language first until one can
    put a report on the different attempts into a nice pamphlet.

For 1) it should be better to start immediately with the text and just 
turn the pseudo code into actual code. There might be some restructuring 
necessary, but it is certainly the easiest task of the three.

I think 2) should be the future way of writing papers that describe 
algorithms. Instead of pseudo code there should be a high-level language 
that can be used instead of pseudo code. And LP helps here quite a lot.

Case 3) is something that appeared several times to me. We currently 
face that in Aldor-Combinat. The theory is clear, it is written in a 
book, but how this is translated into Aldor is totally unclear. There 
are some ideas, but it seems for the ideal version, the Aldor language 
is simply too weak. But to find that out I have to do some experiments 
with the language. Sure, I do them without the pamphlet burden, but in 
my case (ie with ALLPROSE) that only means that my code chunks are huge 
and unstructured (similar to current Axiom). In the end I might throw 
away a lot of code, but at least I should have an account of what has 
been tried out and what turned out to be bad and why. For future 
developers that might be important (even the bad and stupid code) so 
they safe time in not trying again the wrong route. Or they see that I 
falsely classified something as the wrong route. I'm not perfect.

\start
Date: Fri, 29 Jun 2007 18:33:44 -0400
From: Bill Page
To: Cliff Yapp
Subject: re: A modest proposal

On 6/29/07, C Y wrote:
> --- Stephen Wilson wrote:
>
> > The build environment is not an issue for me at all.  If there is
> > complication, it is due to the fact that there is no clean
> > integration between the tools required to both build the system and
> > extract the code/document bits.  This is one reason why I am excited
> > about asdf-literate, as it should significantly simplify the build
> > as it understands the model.  We need the proper tools for the job,
> > and if they do not yet exist, we can create them.
>
> Bingo.  None of what we're doing with pamphlets or compiling the system
> is fundamentally hard (except maybe the def* parsing, but that can come
> later) and it's just a question of teaching the tools to deal with it
> correctly.
> ...

I very strongly disagree. I do not think the AXIOM project should be
in the business of building literate programming tools. And I am
rather surprised that Stephen should think so since he is also against
the idea of building and maintaining intermediate tools like BOOT that
are much more intimately related to AXIOM than literate programming
tools.

I think one of the great advantages of open source is the ability to
build freely on the work of other open source projects. Tim had the
right idea (but the wrong tool) when he decided to use noweb for
literate programming in Axiom. Re-writing such things in Lisp is just
a diversion away from the real point of the Axiom project (at least
what the Axiom project should be). I cannot imagine that spending time
extending asdf to understand pamphlet format will be anything but a
similar diversion. The result of all this effort is just to build a
bigger ghetto in which Axiom will eventually die... :-(

\start
Date: 29 Jun 2007 18:48:09 -0400
From: Stephen Wilson
To: Ralf Hemmecke
Subject: re: A modest proposal

Ralf Hemmecke writes:

> > I dont do that myself.  I write my code as most other programmers do.
> 
> Because you are trained in programming. But what you do is writing the
> program for yourself. Not for other people.

Sorry, I dont understand why you would jump to that conclusion.
Although I have not released a literate document for inclusion in the
project,  I certainly have stuff pending.  Im taking my time.

I will be writing for others, including myself.  In ten years time the
code I write today may as well have been written by another.

[...]
> Anyway, write your code as you like, nobody is forcing. The only thing
> is that one should not forget that LP is not about documenting a
> program. It is about documenting an idea where the documentation is
> equipped with real code. Human understandable, of course.

Im pretty sure we are on the same page.  Im not at all certain what it
was about my post that implied otherwise.

> If that is the final product that you give to the public nobody
> cares how it was produced. I have not yet heard of someone who has
> good guidelines of how to produce a nice literate document.

Sure.  Guidelines are probably a waste of time.  As I said, the
challenge is for the individual to figure out what works for them.

> Additionally, one should also distinguish at least 3 cases.
[...]

Yes, absolutely.  There are at _least_ 3 cases.  Probably half a dozen
more which any one of us will encounter during or work.  One thing is
clear, at least to me:  Literate programming does not get in the way
given a little bit of imagination.

\start
Date: Fri, 29 Jun 2007 17:57:36 -0500 (CDT)
From: Gabriel Dos Reis
To: list
Subject: Fork time

Waldek --

  I read your message with high interest.  I fully understand the
frustration that you can feel and unjustified labels that have been
put on the amazing contributions you've made.  The motives that would
press someone to feel the need to qualify your contributions (and others')
as steeling from the project is beyond my understanding.

  Many times, I've been tempted to just fork.  Many times, I've resisted --
because it is not a light decision to make.  While it can give you free 
hands, you also run the risk of fracturing further the small 
community -- I care about the community, even more than the project,
because as a community we can build more than the project.

  I do believe there is a way out of this apparant dead end.  Remember,
someone on ths list once said "running code wins".  Get past the current
debate and move on *with* Axiom.

\start
Date: Sat, 30 Jun 2007 01:00:09 +0200
From: Ralf Hemmecke
To: Franz Lehner
Subject: Re: Tuples

On 06/29/2007 11:36 PM, Franz Lehner wrote:
> Hello
> 
> here is an algebra question for a change.
> Do I understand correctly that there is currently no way to implement
> DirectProduct(L: List Group) or DirectProduct(L: Tuple Group)?
> That is, one has to manually iterate DirectProduct(G1,G2)
> if one wants a direct product of more than two groups?
> 
> thanks for your consideration
> Franz

Ooops. You seem to be hitting the same problem as me.
If you have a constructor DP which takes a tuple as input, you will run 
into the problem that it is (nearly) impossible to create actual 
elements of that thing.

Let's try do define something... Again that will be Aldor, but I hope 
the problem becomes understandable.

DP(T: Tuple Group): with {
   construct: T -> %
} == add {
   Rep == Array Pointer;
   construct(t: T): % == ...
}

Well the problem is the T here. It is something like (G1, G2, G3) where 
all groups might be different. Now take (g1, g2, g3) where gi is of type 
Gi. That thing is of type (G1, G2, G3) but not a Tuple(A) for some 
domain A, because Tuple constructs homogeneous things. We can only have 
that the type of (g1, g2, g3) is Cross(G1, G2, G3).

Well, if you use Cross, you must give the types at compile time. But 
that you cannot do.

However, you have said "iterate DirectProduct(G1,G2)" and that lets me 
start thinking. I don't claim that I will come up with a good 
"workaround" but the iteration idea might be something that I could 
eventually turn into something I like. You have to wait a bit, though.
Better listen at the aldor-combinat mailing list. I might forget to post 
something to axiom-dev.

\start
Date: 29 Jun 2007 19:03:15 -0400
From: Stephen Wilson
To: Bill Page
Subject: re: A modest proposal

Bill Page writes:
> I very strongly disagree. I do not think the AXIOM project should be
> in the business of building literate programming tools. And I am
> rather surprised that Stephen should think so since he is also against
> the idea of building and maintaining intermediate tools like BOOT that
> are much more intimately related to AXIOM than literate programming
> tools.

Ok, no problem.  Besides, Axiom is not in the business of doing
anything.  It is the sum total of the efforts and skill of the
individual contributors.  If I have a problem which I need a tool to
solve, and if no one else is already pursuing a solution, Ill create
it myself. 

It just so happens that Boot doesn't solve anything for me.  But thats
another, completely unrelated, issue.

> I think one of the great advantages of open source is the ability to
> build freely on the work of other open source projects. Tim had the
> right idea (but the wrong tool) when he decided to use noweb for
> literate programming in Axiom. Re-writing such things in Lisp is just
> a diversion away from the real point of the Axiom project (at least
> what the Axiom project should be). 

No one, to my knowledge, is rewriting noweb or some equivalent in Lisp.

> I cannot imagine that spending time extending asdf to understand
> pamphlet format will be anything but a similar diversion. The result
> of all this effort is just to build a bigger ghetto in which Axiom
> will eventually die... :-(

Not sure what to say about that.  There are technical reasons why asdf
is a reasonable direction to pursue.  I have no idea what you mean by
`ghetto'.

\start
Date: Sat, 30 Jun 2007 01:08:44 +0200
From: Ralf Hemmecke
To: Gabriel Dos Reis
Subject: Re: Fork time

>   I do believe there is a way out of this apparant dead end.  Remember,
> someone on ths list once said "running code wins".  Get past the current
> debate and move on *with* Axiom.

Thanks Gaby. I very much hope that you find time to post a mega patch 
that makes trunk contain the autoconf stuff. I am sure that would 
improve the current situation.

I also very much hope that we stay together as a community and even 
fight for a bigger one.

\start
Date: Fri, 29 Jun 2007 16:14:18 -0700 (PDT)
From: Cliff Yapp
To: Bill Page
Subject: re: A modest proposal

--- Bill Page wrote:

> I very strongly disagree. I do not think the AXIOM project should be
> in the business of building literate programming tools. And I am
> rather surprised that Stephen should think so since he is also
> against the idea of building and maintaining intermediate tools
> like BOOT that are much more intimately related to AXIOM than
> literate programming tools.

Um.  I would argue that literate programming tools are intimiately
related to Axiom - Axiom may end up pushing literate programming in
directions no one has really gone before, depending on where the work
leads.  (I'll avoid the BOOT question - the archives are full of that
debate.)

> I think one of the great advantages of open source is the ability to
> build freely on the work of other open source projects. Tim had the
> right idea (but the wrong tool) when he decided to use noweb for
> literate programming in Axiom. Re-writing such things in Lisp is just
> a diversion away from the real point of the Axiom project (at least
> what the Axiom project should be).

I know my views about reducing the dependency tree are extreme, so I'll
just state that I find it an interesting direction to pursue - I like
working in Lisp and prefer to have Axiom rely only on Lisp from a long
term viability standpoint.  From my standpoint the foundations must be
firm (well understood and literately documented) before Algebra related
tasks can be tackled, and foundations means anything a working Axiom
must rely on.  Eventually I would like to extend this principle to the
Lisp implementation itself, although there are hurdles there (dpANS3's
copyright status).

What the project "should be" is in the eye of the beholder.  I have my
opinion of course, just as everyone else does.  Tim has taken this
project in one direction, which I find interesting.  If other people
feel another direction is better and want to go that, I have no problem
with that.  They may be right.  Waldek has already shown he can produce
very good results.  I happen to like the current Axiom direction, but
that's just one man's opinion.

> I cannot imagine that spending time extending asdf to understand
> pamphlet format will be anything but a similar diversion. The result
> of all this effort is just to build a bigger ghetto in which Axiom
> will eventually die... :-(

Well, it's not like asdf-literate is costing you any time or effort
;-).  It's an experiment, not a foregone conclusion.  Like any
experiment, it might fail.  Indeed, the Axiom project itself is an
experiment.  Perhaps Waldek's fork will prove the better way to go and
outlive Axiom proper - if it does I wish it success.  (I do anyway, of
course - I have no wish to see any open source project fail and work
done on another version of Axiom will probably be of use to this
version of the project as well - ideas are always a good thing. 
Algebra work will probably be fairly easy to move between the two, if
either ever get to the stage of working on Algebra.)

I believe the potential for long term viability and robustness is worth
pursuing even at the cost of up front time and effort.  I am not in a
hurry personally to create another working CAS - we have many of those.
 To me the effort is worth it if we create a CAS that will scale in the
long term and be maintainable in the long term.  Hopefully it will last
even beyond the 30 year horizon - there are only so many ways some
tasks can be solved, and if we solve them well enough here perhaps they
won't have to be solved again.  The design of TeX is a perfect example,
in my book - even if the code itself is re-implemented someday the
ideas expressed TeX are timeless and will still govern the design. 
They still have not been surpassed after decades.

Anyway.  I think the best solution is for the two camps to pursue their
directions, rather than arguing further about it - I don't see anybody
being convinced at this stage.  Let's write some pamphlets! (or code,
as the case may be.)

\start
Date: Fri, 29 Jun 2007 18:25:37 -0500 (CDT)
From: Gabriel Dos Reis
To: Ralf Hemmecke
Subject: Re: Fork time

On Sat, 30 Jun 2007, Ralf Hemmecke wrote:

| >   I do believe there is a way out of this apparant dead end.  Remember,
| > someone on ths list once said "running code wins".  Get past the current
| > debate and move on *with* Axiom.
| 
| Thanks Gaby. I very much hope that you find time to post a mega patch that
| makes trunk contain the autoconf stuff. I am sure that would improve the
| current situation.

I'm working on that.

As I reiterated last thursday during my talk here in Lille, build-improvements
branch is not envisioned to be my private thing.  It was and is a project
for the community (and by the community).

| I also very much hope that we stay together as a community and even fight for
| a bigger one.

Yes.  I'll soon make my slides public.  For me, Axiom is, among other things,
a tool.  It needs a *user* community.  Otherwise, it will die in futil
philosophical debates about the literate sex of angels.

\start
Date: Fri, 29 Jun 2007 16:25:43 -0700 (PDT)
From: Cliff Yapp
To: Stephen Wilson, Bill Page
Subject: re: A modest proposal

--- Stephen Wilson wrote:

> No one, to my knowledge, is rewriting noweb or some equivalent in
> Lisp.

He's referring to cl-web, I believe.  That can be viewed as a
functional replacement for noweb in Lisp, although it does not support
all of noweb's features.  It is a requirement for asdf-literate to be
able to handle pamphlet files.  In theory I could write a lisp routine
that calls noweb every time (I have a test script I used for
comparisons which did something of the sort) but it seemed to me that
the better solution for portability and simplicity within the Lisp
environment was to have the abilities native.  As a bonus, Waldek
provided a finite-state based solution that appears to be faster at the
tangle operation than noweb - but that's not the primary benefit for
me.
 
> > I cannot imagine that spending time extending asdf to understand
> > pamphlet format will be anything but a similar diversion. The
> result
> > of all this effort is just to build a bigger ghetto in which Axiom
> > will eventually die... :-(
> 
> Not sure what to say about that.  There are technical reasons why
> asdf is a reasonable direction to pursue.  I have no idea what you
> mean by `ghetto'.

If I understand correctly from previous posts, in this context "ghetto"
is being used to describe a large body of tools that are divorced from
mainstream directions being taken by the open source community. 
Centering on Lisp already triggers some of those complaints, and Bill's
concern (if I understand correctly) is that if we home-grow too much we
will end up not being able to grow with the open source world and be
left behind with a bunch of non-standard tools no one wants to take the
time to understand.

Obviously I disagree that this is what will happen - Lisp I don't
regard as a ghetto and ASDF is the standard solution within the Lisp
world.  It seems to be well designed and flexible.  And the goal is to
develop tools such that given a working Lisp environment users and
developers will be able to focus on the Algebra without worrying about
the underlying tools.  If they MUST work with them, I would like them
to be literate all the way down - no dark corners to get into trouble
with.  But that's again just me.

\start
Date: Sat, 30 Jun 2007 02:06:25 +0200
From: Ralf Hemmecke
To: Bill Page
Subject: Re: LogiWeb
Cc: Christian Aistleitner, Klaus Grue

>> http://logiweb.eu/

>> That seems to be a very interesting project.

> Yes it does seem both interesting and relevant to Axiom but I hope
> that the talk was easier to navigate and to understand than the above
> website! It took me a long time to decide that this was indeed
> something interesting.

I am sorry that I did not write more.

> When you have a chance, could you try to (briefly) summarize the talk?
> Or do you have a link to a more readable introduction?

In fact, I was at the talk more by accident than actually planned.

What I got from the talk is that LogiWeb is actually more of an 
infrastructure than anything else. But it does seem to have some 
connections to proof systems.

Think of the Axiom Journal idea. From the talk I thought that LogiWeb 
implements a lot of that idea. It is, in fact, a revision control system 
(I would say very much like GIT, but maybe Klaus Grue can say more about 
it). LogiWeb allows to write and publish papers that contain formal 
mathematics and a way to specify a proof system that actually checks the 
correctness of the paper (including the referenced papers). There is no 
connection to CAS yet, but maybe that can be changed.

An Axiom Journal for me is like LogiWeb only that the papers are our 
pamphlets and that we need a compiler that actually compiles the 
referenced pamphlets into a running Axiom with an appropriate library 
that is relevant for the paper you are currently interested in.

There are questions like how to make sure that a paper that is runnable 
  today would run also on some computer in 5 years. I still don't know 
how to achieve this properly, but Klaus Grue seemed to have ideas about it.

LogiWeb is GPL. The only drawback I see is that it is basically a 
one-man-project. And I am still not clear about what it really means to 
program in pure lambda calculus. It sounds a bit scary to me, but maybe 
it's a good thing.

Ralf

PS For Klaus Grue: A pamphlet is a file that apart from mathematics and 
design decisions etc. also contains code that can be compiled. I somehow 
have the suspicion that a pamphlet could be seen as a logiweb paper if 
our underlying programming language were pure lambda calculus. But we 
want to use some higher level language like Aldor/SPAD.

\start
Date: 29 Jun 2007 20:13:40 -0400
From: Stephen Wilson
To: Cliff Yapp
Subject: re: A modest proposal

Cliff Yapp writes:

> --- Stephen Wilson wrote:
> 
> > No one, to my knowledge, is rewriting noweb or some equivalent in
> > Lisp.
> 
> He's referring to cl-web, I believe. 

Duh, of course. Sorry Cliff! Temporary blackout, I belive. 

> If I understand correctly from previous posts, in this context "ghetto"
> is being used to describe a large body of tools that are divorced from
> mainstream directions being taken by the open source community. 
> Centering on Lisp already triggers some of those complaints, and Bill's
> concern (if I understand correctly) is that if we home-grow too much we
> will end up not being able to grow with the open source world and be
> left behind with a bunch of non-standard tools no one wants to take the
> time to understand.

Ok.  I recall similar notions.  New tools that solve new problems are
always non-standard by definition.  I just never connected `ghetto'
with that perspective.  

> Obviously I disagree that this is what will happen - Lisp I don't
> regard as a ghetto and ASDF is the standard solution within the Lisp
> world.  It seems to be well designed and flexible.  And the goal is to
> develop tools such that given a working Lisp environment users and
> developers will be able to focus on the Algebra without worrying about
> the underlying tools.  If they MUST work with them, I would like them
> to be literate all the way down - no dark corners to get into trouble
> with.  But that's again just me.

Your certainly not alone :)

\start
Date: Sat, 30 Jun 2007 03:37:09 +0200 (CEST)
From: Waldek Hebisch
To: Gabriel Dos Reis
Subject: Re: Fork time

Gabriel Dos Reis wrote:
>
>   Many times, I've been tempted to just fork.  Many times, I've resisted --
> because it is not a light decision to make.  While it can give you free 
> hands, you also run the risk of fracturing further the small 
> community -- I care about the community, even more than the project,
> because as a community we can build more than the project.
> 
>   I do believe there is a way out of this apparant dead end.  Remember,
> someone on ths list once said "running code wins".  Get past the current
> debate and move on *with* Axiom.
> 

It was not a light decision.  But I feel that comunity needs clear
situation.  Otherwise inside we risk quarrels that make cooperation
difficult and from outside project looks unfocused, which limits
comunity growth.

\start
Date: 29 Jun 2007 21:56:51 -0400
From: Stephen Wilson
To: Waldek Hebisch
Subject: Re: Fork time
Cc: Gabriel Dos Reis

Waldek Hebisch writes:
> It was not a light decision.  But I feel that comunity needs clear
> situation.  Otherwise inside we risk quarrels that make cooperation
> difficult and from outside project looks unfocused, which limits
> comunity growth.

Waldek,

I have respect for your conviction, and your willingness to follow
through.

I regret we have not had an opportunity to collaborate.  It is a real
hope of mine that, despite disagreements, there still remains a hope
that collaboration is possible.  We will always have the freedom to
share knowledge and understanding.

Good luck and thanks for all your past and future work!  I believe any
incarnation of Axiom will benefit greatly from your efforts.

\start
Date: 29 Jun 2007 23:47:38 -0400
From: Camm Maguire
To: Stephen Wilson
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

Greetings, and thanks so much!  Believe this is fixed now.

Take care,

Stephen Wilson writes:

> Hello,
> 
> Axiom build with gclcvs-2.7.0, --enable-ansi, latest cvs checkout (and prior
> revision), on an i686-pc-linux-gnu, fails midway into the algebra build.
> 
> The bug appears to be the following. Call to (VECTOR 0 0 0) returns
> #(0 0) instead of #(0 0 0).
> 
> ==----- test.lisp ---
> 
> (defun mkvector () (vector 0 0 0))
> 
> ==-------------------
> 
> 
> steve:tmp> gcl                                                                                                  12:32am[307]
> GCL (GNU Common Lisp)  2.7.0 ANSI    Jun 28 2007 20:34:59
> Source License: LGPL(gcl,gmp,pargcl), GPL(unexec,bfd,xgcl)
> Binary License:  GPL due to GPL'ed components: (XGCL READLINE BFD UNEXEC)
> Modifications of this banner must retain notice of a compatible license
> Dedicated to the memory of W. Schelter
> 
> Use (help) to get some basic information on how to use GCL.
> 
> Temporary directory for compiler files set to /tmp/
> 
> >(compile-file "test.lisp")
> 
> ;; Compiling test.lisp.
> ;; End of Pass 1.  
> ;; End of Pass 2.  
> ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
> ;; Finished compiling test.o.
> #P"/home/steve/tmp/test.o"
> NIL
> NIL
> 
> >(load "test.o")
> 
> ;; Loading test.o
>  ;; start address -T 0xa59c40 ;; Finished loading test.o
> 196
> 
> >(mkvector)
> 
> #(0 0)
> 
> >(disassemble 'mkvector)
> 
> ;; Compiling /tmp/gazonk_14243_0.lsp.
> ;; End of Pass 1.  
> ;; End of Pass 2.  
> ;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
> ;; Finished compiling /tmp/gazonk_14243_0.o.
> 
> #include "gazonk_14243_0.h"
> void init_code(){do_init((void *)VV);}
> /*      local entry for function MKVECTOR       */
> 
> static object LI1()
> 
> {        VMB1 VMS1 VMV1
>         goto TTL;
> TTL:;
>         /*(VECTOR 0 0 0)*/
>         {object V1;
>         V1= 
>         !3? Cnil : (alloca_val=alloca((3)*sizeof(struct cons)+sizeof(object)),
>         ({object _b=(void *)alloca_val;if (((unsigned long)_b)&sizeof(_b)) _b++;
>         {register struct cons *_p=(void *)_b;
>         _p->c_car=make_fixnum(0);_p->c_cdr=(object)(_p+1);_p++;
>         _p->c_car=make_fixnum(0);_p->c_cdr=(object)(_p+1);_p++;
>         _p->c_car=make_fixnum(0);_p->c_cdr=(object)(_p+1);_p++;
>         _p[-1].c_cdr=Cnil;}_b;}));
>         {object V2;
>         /*(LENGTH OBJECTS)*/
>         {register object V4;
>         V4= (V1);
>         /*(ENDP (SETQ X (CDR X)))*/
>         {object V5;
>         V4= CMPcdr((V4));
>         V5= (V4);}
>         /* END (ENDP (SETQ X (CDR X)))*/
>         /*(ENDP (SETQ X (CDR X)))*/
>         {object V6;
>         V4= CMPcdr(Cnil);
>         V6= (V4);}
>         /* END (ENDP (SETQ X (CDR X)))*/
>         V3= make_fixnum(2);}
>         /* END (LENGTH OBJECTS)*/
>         V2= 
>         !1? Cnil : (alloca_val=alloca((1)*sizeof(struct cons)+sizeof(object)),
>         ({object _b=(void *)alloca_val;if (((unsigned long)_b)&sizeof(_b)) _b++;
>         {register struct cons *_p=(void *)_b;
>         _p->c_car=V3;_p->c_cdr=(object)(_p+1);_p++;
>         _p[-1].c_cdr=Cnil;}_b;}));
>         {object V7 = (VFUN_NARGS=5,(/* MAKE-ARRAY */(*LnkLI2)((V2),((object)VV[0]),Ct,((object)VV[1]),(V1))));VMR1
>         (V7);}}}
>         /* END (VECTOR 0 0 0)*/
>         return Cnil;
> }
> static object  LnkTLI2(object first,...){object V1;va_list ap;va_start(ap,first);V1=(object )call_vproc_new(((object)VV[2]),0,0,(void **)(void *)&LnkLI2,first,ap);va_end(ap);return V1;} /* MAKE-ARRAY */
> #(#(ELEMENT-TYPE INITIAL-CONTENTS MAKE-ARRAY
>     (%INIT
>      . #((LET ((*DISABLE-RECOMPILE* T))
>            (MFSFUN 'MKVECTOR 0 0 0)
>            (ADD-HASH 'MKVECTOR '(NIL (ARRAY T *))
>                '((VECTOR (*) (ARRAY T *)))
> COMMON-LISP-USER
> LISPLAMBD,DECLA,OPTIMIZ,SAFETY  ,BLOCK
>                                      MKVECTOR
> ,VECTOR '/tmp/gazonk_14243_0.lsp))
>          (DO-RECOMPILE)))))
> static object LI1();
> #define VMB1 object  V3;
> #define VMS1
> #define VMV1
> #define VMR1(VMT1) return(VMT1);
> #define VM1 0
> static void * VVi[4]={
> #define Cdata VV[3]
> (void *)(LI1)
> };
> #define VV (VVi)
> static object  LnkTLI2(object,...);
> static object  (*LnkLI2)() = (object (*)()) LnkTLI2;
> 
> /tmp/gazonk_14243_0.o:     file format elf32-i386
> 
> Disassembly of section .text:
> 
> 00000000 <init_code>:
>    0:   68 00 00 00 00          push   $0x0
>    5:   e8 fc ff ff ff          call   6 <init_code+0x6>
>    a:   58                      pop    %eax
>    b:   c3                      ret    
> 
> 0000000c <LI1>:
>    c:   55                      push   %ebp
>    d:   89 e5                   mov    %esp,%ebp
>    f:   83 ec 2c                sub    $0x2c,%esp
>   12:   8d 54 24 0f             lea    0xf(%esp),%edx
>   16:   83 e2 f0                and    $0xfffffff0,%edx
>   19:   8d 42 08                lea    0x8(%edx),%eax
>   1c:   89 02                   mov    %eax,(%edx)
>   1e:   c7 42 04 00 00 00 d0    movl   $0xd0000000,0x4(%edx)
>   25:   c7 40 04 00 00 00 d0    movl   $0xd0000000,0x4(%eax)
>   2c:   8d 42 10                lea    0x10(%edx),%eax
>   2f:   89 42 08                mov    %eax,0x8(%edx)
>   32:   c7 40 04 00 00 00 d0    movl   $0xd0000000,0x4(%eax)
>   39:   83 ec 1c                sub    $0x1c,%esp
>   3c:   8d 42 18                lea    0x18(%edx),%eax
>   3f:   89 42 10                mov    %eax,0x10(%edx)
>   42:   c7 40 f8 00 00 00 00    movl   $0x0,0xfffffff8(%eax)
>   49:   8d 44 24 0f             lea    0xf(%esp),%eax
>   4d:   83 e0 f0                and    $0xfffffff0,%eax
>   50:   8d 48 08                lea    0x8(%eax),%ecx
>   53:   89 08                   mov    %ecx,(%eax)
>   55:   c7 40 04 02 00 00 d0    movl   $0xd0000002,0x4(%eax)
>   5c:   c7 41 f8 00 00 00 00    movl   $0x0,0xfffffff8(%ecx)
>   63:   52                      push   %edx
>   64:   ff 35 04 00 00 00       pushl  0x4
>   6a:   68 00 00 00 00          push   $0x0
>   6f:   ff 35 00 00 00 00       pushl  0x0
>   75:   50                      push   %eax
>   76:   a3 00 00 00 00          mov    %eax,0x0
>   7b:   66 c7 05 04 00 00 00    movw   $0x5,0x4
>   82:   05 00 
>   84:   ff 15 10 00 00 00       call   *0x10
>   8a:   c9                      leave  
>   8b:   c3                      ret    
> 
> 0000008c <LnkTLI2>:
>   8c:   8d 44 24 08             lea    0x8(%esp),%eax
>   90:   50                      push   %eax
>   91:   ff 74 24 08             pushl  0x8(%esp)
>   95:   68 10 00 00 00          push   $0x10
>   9a:   6a 00                   push   $0x0
>   9c:   6a 00                   push   $0x0
>   9e:   ff 35 08 00 00 00       pushl  0x8
>   a4:   e8 fc ff ff ff          call   a5 <LnkTLI2+0x19>
>   a9:   83 c4 18                add    $0x18,%esp
>   ac:   c3                      ret    
> NIL
> 
\start
Date: Fri, 29 Jun 2007 23:08:57 -0500
From: Tim Daly
To: Ralf Hemmecke
Subject: Combinat

Ralf,

I've been studying your combinatorial species project.

Would it be reasonable to say that one could redefine (some of) the
data structures in axiom using a series of transformations and
combinations on sets? Would it be a set of pointers? So a species
is a "builder function" that would build a given data structure,
like a linked list, from a set of pointers?

\start
Date: Sat, 30 Jun 2007 00:52:06 -0400
From: Bill Page
To: Stephen Wilson
Subject: re: A modest proposal

> ...
> C Y writes:
> > If I understand correctly from previous posts, in this context "ghetto"
> > is being used to describe a large body of tools that are divorced from
> > mainstream directions being taken by the open source community.
> > Centering on Lisp already triggers some of those complaints, and Bill's
> > concern (if I understand correctly) is that if we home-grow too much we
> > will end up not being able to grow with the open source world and be
> > left behind with a bunch of non-standard tools no one wants to take the
> > time to understand.
>

Thanks for carrying my side of the conversation for me, Cliff. :-)
I've had my mind on other things for the last few hours... Yes, you
state very clearly and exactly my concerns.

On 29 Jun 2007 20:13:40 -0400, Stephen Wilson wrote:

> Ok.  I recall similar notions.  New tools that solve new problems are
> always non-standard by definition.  I just never connected `ghetto'
> with that perspective.
>

What "new problems" are you referring to here? I do not see any new
problems in this part of the Axiom project. The methodologies that we
are talking about here have been around nearly as long as Axiom
itself.

> > Obviously I disagree that this is what will happen - Lisp I don't
> > regard as a ghetto and ASDF is the standard solution within the Lisp
> > world.  It seems to be well designed and flexible.

I have a very great respect for Lisp, but I wonder how you can look
around the web and at the type and number of programs that have been
written in the last 10 years and not think that Lisp is essentially
already a ghetto (as you have so clearly and accurately defined it).
We might wish that that was not true but all the evidence is clearly
there. Ask the people who teach computer science at university what
they think of Lisp. Ask them what there students think of Lisp. Gaby
for example has already said what the reaction of his colleagues was
to the fact that he has been spending so much time on an "old Lisp"
system like Axiom... When I mentioned Lisp to a room full of
enthusiastic Sage developers you should have seen the "tolerant
amusement" on the faces those under 25 in the crowd. Man, did that
make me feel old... :-(

What does ASDF do that 'make' and other parts of the existing build
system does not already do?

> >  And the goal is to develop tools such that given a working Lisp
> > environment users and developers will be able to focus on the Algebra
> > without worrying about the underlying tools.  If they MUST work with
> > them, I would like them to be literate all the way down - no dark corners
> > to get into trouble with.  But that's again just me.

That part I completely agree with but I fail to see why that requires
doing the things that you and Stephen are proposing.

>
> Your certainly not alone :)
>

That's what I like about the web! ;-)

\start
Date: Sat, 30 Jun 2007 01:35:46 -0400
From: Bill Page
To: Waldek Hebisch
Subject: Re: Fork time

Waldek,

On 6/29/07, you wrote:
>
> ... I plan to created a new project called FriCAS -- many details are
> undecided yet (even the name may change).

I was amused when I saw the name you chose for the new project.
Perhaps it is not obvious to a non-English speaker (or perhaps this
really was your intention since there is a similar word in French) but
this project name bears a very close similarity the to English word
'fracas' meaning: "a noisy quarrel or brawl"

http://www.m-w.com/cgi-bin/dictionary?sourceid=Mozilla-search&va=fracas

That certainly seems appropriate given the nature of recent exchanges
on this email list. :-)

This name also has other mostly humorous connotations to me, but I can
think of some like "Fri" as in Friday (today), so FriCAS would be
today's version of the former Axiom project... Or maybe Fri as a
suffix that sounds like "free"??

Anyway, I think it is a terrible choice of name.

>
> Let me shortly state my reasons:
> - I feel that current "official" statements about Axiom project
>   are harmful for the project
> - my attempts to change project direction are labeled as
>   stealing the project -- new project should make situation
>   clear
>
> I value Axiom comunity, but feel that leaving current project is
> the best way to clarify situation.
>

While I do agree with you and I also strongly disagree with most of
the current "official" statements about the Axiom project, I am not
sure that creating a fork of the Axiom project is such a good idea. I
am disappointed that so few people were willing to reply to William
Sit and Tim Daly's request for a vote on the subject of whether to
promote wh-sandbox as our best candidate for a new Axiom Gold, but my
sense is that in spite of the silence, this proposal has the support
of a majority of the people who are reading this list and who are
seriously interested in Axiom. I still consider this a much better
alternative than the creation of a new project.

http://wiki.axiom-developer.org/VoteASuggestionForGold

On the other hand, if you personally have enough energy and time to
devote to an entirely new development path for Axiom and you are
confident that you will be able to attract the interest of other
developers and users of computer algebra systems who for what ever
reason are not currently interested in the existing Axiom project,
then this might be a positive development for both the "old" Axiom
project and the new FirCAS project.

If you are serious, then this a a bold step and I thank you again for
your continuing contributions to this work - by what ever name you
wish to call it. :-)

\start
Date: 30 Jun 2007 02:26:04 -0400
From: Stephen Wilson
To: Bill Page
Subject: re: A modest proposal

Hello Bill,

Bill Page writes:
> > ...
> > C Y writes:
> > > If I understand correctly from previous posts, in this context "ghetto"
> > > is being used to describe a large body of tools that are divorced from
> > > mainstream directions being taken by the open source community.
> > > Centering on Lisp already triggers some of those complaints, and Bill's
> > > concern (if I understand correctly) is that if we home-grow too much we
> > > will end up not being able to grow with the open source world and be
> > > left behind with a bunch of non-standard tools no one wants to take the
> > > time to understand.
> >
> 
> Thanks for carrying my side of the conversation for me, Cliff. :-)
> I've had my mind on other things for the last few hours... Yes, you
> state very clearly and exactly my concerns.

Im glad Cliff reflected your thoughts accurately as well.

> On 29 Jun 2007 20:13:40 -0400, Stephen Wilson wrote:
> 
> > Ok.  I recall similar notions.  New tools that solve new problems are
> > always non-standard by definition.  I just never connected `ghetto'
> > with that perspective.
> >
> 
> What "new problems" are you referring to here? I do not see any new
> problems in this part of the Axiom project. The methodologies that we
> are talking about here have been around nearly as long as Axiom
> itself.

In some ways this is true.  But take your own concern about a
complicated build environment as an example.  There is no reason for
it.

I am skipping the next segment of your post because I do not feel
there is a need to promote or justify Lisp.  I really would like to
avoid a language war.

[...]
> What does ASDF do that 'make' and other parts of the existing build
> system does not already do?

There are several things.

Make has a specific attitude, if you can call it that, about what it
takes to build a system.  It is very much rooted in the requirements
of C and similarly compiled software.  In short, it invokes a compiler
repeatedly over a list of files, topologically sorted w.r.t a DAG of
dependencies, and finally links an executable.

Lisp is different. You still need to consider dependencies, but you do
not need the iterative process and the final `link' stage to get a
working system.  Everything can be done dynamically while the system
is running.  For example, I use ASDF in the Axisp repo for all new
lisp code.  I can edit a pice of code in one emacs buffer, and have a
running Axiom system in another.  When I have made a change, I do the
equivalent of:

      (1) -> )lisp (asdf:oos 'asdf:load-op :axisp)

In reality, I have this command associated with a key binding, to save
typing.  The end result is an Axiom, with all dependencies tracked and
loaded afresh, without having to restart the system.

Think about the consequences.  Already, there exists the basic
machinery to drag-and-drop a pamphlet file into a running system and
have it instantly available.  The connotations are far from being
limited to a simple convenience feature useful only to developers.


Another example, if you would bare with me.  The iterative process of
compilation does not jive well with a Lisp based system.  Consider the
algebra build, where we repeatedly invoke the Lisp system to compile
each and every file independently.  This is necessary for C, but not
for Lisp.  We could trivially define the dependencies in ASDF, and
build the algebra in one shot.  This is a simple minded application
which would reduce the build time, for fun, by 15 minutes+. You save,
at a minimum, the repeated autoloading of the code which implements
Axioms compiler.  Of course you could build a custom image which has
everything preloaded and save some time, but to me that is a gross
hack, and you loose the benefits which I alluded to above.
Furthermore, if you were to choose to do something similar from within
make you would be reimplementing a poor-mans ASDF, so why bother?
There are too many advantages to using ASDF directly.

I gave the above examples first as I feel they are the most `user
visible'.  Certainly others can extend on the theme. 

However, for the sake of completeness, one needs to consider the
design of ASDF itself -- what it means for developers.  This is Lisp
specific, so I wont go into deep details.  But understand that it is
defined via CLOS, the Common Lisp Object System.  The interface is
designed such that all entities over which the system operates are
objects (classes), and all functionality is exported as a method.
This is totally foreign to make and friends.

The system is intrinsically extensible, via subclassing and
specialization.  Thus, If you wanted to dynamically tangle and weave a
pamphlet file, you can do that with a minimum of effort.  No need to
grok make, shell scripts, sed regular expressions, M4 macros, etc,
etc.  You, among all people, should appreciate the benefits.  It is a
mostly environment neutral way of specifying such a process.  It is,
for any relative purpose, an instantly portable solution to an
exceedingly wide variety of problems.

> > >  And the goal is to develop tools such that given a working Lisp
> > > environment users and developers will be able to focus on the Algebra
> > > without worrying about the underlying tools.  If they MUST work with
> > > them, I would like them to be literate all the way down - no dark corners
> > > to get into trouble with.  But that's again just me.
> 
> That part I completely agree with but I fail to see why that requires
> doing the things that you and Stephen are proposing.

Its not a requirement.  There is nothing fundamental holding back
other approaches.  But I truly do feel that this is a reasonable and
pragmatic approach, even given the pie in the sky ideal we would all
like to see realized.

> > Your certainly not alone :)
> >
> 
> That's what I like about the web! ;-)

\start
Date: Sat, 30 Jun 2007 09:21:55 +0200
From: Ralf Hemmecke
To: Stephen Wilson
Subject: re: A modest proposal

BTW, has someone though about where we were now if NAG had given Axiom 
(including a autoconf build environment) to Tim?

We had something like BI but probably totally undocumented. Why cannot 
we take that position now. I am sure that if the tests work out fine, 
why shouldn't we quickly work with autoconf?

I wait for Gaby to submit a patch. I think that will be the better road 
than simply switch to wh-sandbox and make some people angry. We should 
stay together as a community. Please.

If Axiom is as well know as Linux then we may become much more 
restrictive which patches go into Axiom. Then it is time to really 
"force" people to submit LP patches. But now we should make Axiom 
attractive!!!

\start
Date: 30 Jun 2007 04:10:51 -0400
From: Stephen Wilson
To: Ralf Hemmecke
Subject: re: A modest proposal

Hi Ralph,

Ralf Hemmecke writes:

> BTW, has someone though about where we were now if NAG had given Axiom
> (including a autoconf build environment) to Tim?
> 
> We had something like BI but probably totally undocumented. Why cannot
> we take that position now. I am sure that if the tests work out fine,
> why shouldn't we quickly work with autoconf?

I really have no objection to the use of autoconf.  There is a huge
investment of knowledge encapsulated into that system which we would be
remiss to ignore.

I do not see a conflict between me advocating ASDF and autoconf, BTW.

> I wait for Gaby to submit a patch. I think that will be the better
> road than simply switch to wh-sandbox and make some people angry. We
> should stay together as a community. Please.

I totally agree.  All I hope for is that the patch is documented and
is in keeping with the clearly stated goals of the project.  I want to
be able to understand such a patch in detail, without having to second
guess the authors intent.  I am encouraged by Gaby's statements w.r.t
his willingness to expand on the details if something is not clear.
This is precisely the attitude we need if we hope to make documentation
a priority for the project.

> If Axiom is as well know as Linux then we may become much more
> restrictive which patches go into Axiom. Then it is time to really
> "force" people to submit LP patches. But now we should make Axiom
> attractive!!!

I believe we all have to agree that there exists a common goal.  I
dont think there is a fast path to an amicable result.  I have enough
people telling me that they want something done yesterday.  Axiom, I
hope, is an oasis from such expectations.

\start
Date: Sat, 30 Jun 2007 04:25:08 -0400
From: William Sit
To: Waldek Hebisch
Subject: Re: Fork time

Dear Waldek:

I feel sad that you have decided to "listen to Tim," but
precisely at the wrong time! I understand that your decision
has been provoked by Tim's message (A modest proposal). I
was surprised that Tim chose to communicate his convictions
in such a strong and provocative manner. I take full
responsibility for the consequences of my posting the
message to Tim that started all this. However, I did not
anticipate this turn of events and I apologize to the Axiom
community for sparking this chasm.

I applaud Gaby's restraint to stay in the project despite
similarly provoked. I, too, considered "listening to Tim"
and quit, but I found other reasons to continue to hang
around. I particularly find Gaby's willingness to work on a
megapatch to merge his build-improvements with the trunk and
his consideration for unity inspiring. He sets the best
example for us to follow.

At this stage of Axiom, forking is certainly not desirable.
Tim has taken the "rules" of open source to the extreme. I
think I understand Tim's reason for not merging his branch
to another. He does not want to set a precedent: where the
best "running code wins" even if the "running code" is not
the "runing, documented, code." Tim's version of best
"running code wins" is best "running, documented, code wins"
and perhaps he believes his work so far holds that title.
But if he WAS (he certainly IS) unwillingness to merge his
patches to wh-sandbox (for whatever reasons, one of them
seems to be wh-sandbox is not (yet) the best "running,
documented, code"), he should not have asked me to make my
email public, requested a vote, and said, "We will go with
the majority opinion." [Tim: you cannot both dictate and be
democratic.] For, to say "we will go with the majority
opinion" (which opinion is not yet clear and likely a tie)
implied his willingness in the event that there is a
majority opinion agreeing with the proposal. In my private
email to him, I had this as the first paragraph (removed in
the public message "A suggestion for Gold"):

"I am writing to you privately because I do not want to put
extra pressure on you. You can simply ignore this message if
you do not agree. If you feel you rather prefer this to be
made (or answer this in) public, please simply delete this
paragraph and quote the rest."

I believe somewhere along my private communication with Tim,
we had a misunderstanding. But that is not important. In
fact, it is not important *to the project* which of you, Tim
or Waldek, has to do the work of bringing the trunk
up-to-date and documented (I know, easy for me to say; but
you have both contributed greatly to the project and neither
of you are scared of work).  What is important is what Gaby
said, "move on *with* Axiom."

Please reconsider and continue your good work.

\start
Date: Sat, 30 Jun 2007 11:21:39 +0200
From: Ralf Hemmecke
To: Stephen Wilson
Subject: re: A modest proposal

>> I wait for Gaby to submit a patch. I think that will be the better 
>> road than simply switch to wh-sandbox and make some people angry.
>> We should stay together as a community. Please.
> 
> I totally agree.  All I hope for is that the patch is documented and 
> is in keeping with the clearly stated goals of the project.

It would be super good if the patch is properly documented, but that is
*not* my priority. Gaby is certainly willing to improve his autoconf
work with documentation when it is in trunk. How come that people seem
to think that Gaby is not committed to LP?

> I want to be able to understand such a patch in detail, without
> having to second guess the authors intent.

Do you know that we have a mailing list where you could simply ask?
The answer then should be used to improve the documentation. But see, 
for me it would be much worse to lose Gaby than to have a little 
imperfect documentation in trunk. We even have more imperfection all around.

Don't you see that probably all current developers are LP believers?
It is just a question how to arrive at an Axiom that is fully in an LP 
style. Some people think that we must from now on do everything in 
proper LP style. And some people rather like to work for a while in the 
usual programming paradigm and postpone proper documenation until we 
have autoconf, hyperdoc, windows port running. *Nobody* says that he 
will not eventually document in LP style.

I agree that it would be best that documentation gets done while the 
development happens, but that is *not* the main pressing part. It is 
much more important to make more people aware of Axiom and attract more 
developers. If we have 100 developer, then I totally agree that no patch 
should be admitted to trunk if it is not fully documented in a way Tim 
would like it. But until then let's just be a bit more relaxed.

With a handfull of developers we will *never* be able to document all 
the legacy algebra code. There is simply not enough time. Let's attract 
developers first and let's preach them some LP so that they know what 
will be the vision of Axiom.

Note, that is not a compromise to Tim's vision of having everything 
properly documented so that people can understand it. But what is the 
use of documentation where only 10 people in the world are willing to 
read it? Axiom will die without developers.

Look at Aldor. That's a super language, but all the other languages just 
take over the ideas of Aldor and Aldor will lose no matter how advanced 
it is. Without developers Aldor is dead. And with 10 developers also 
Axiom is dead.

> I believe we all have to agree that there exists a common goal.  I 
> dont think there is a fast path to an amicable result.  I have enough
> people telling me that they want something done yesterday.  Axiom, I
> hope, is an oasis from such expectations.

Of course there is no real time pressure. I press, because I want to see 
a well documented, well running Axiom during my lifetime. Only that 
presses to ask for more developers.

\start
Date: Sat, 30 Jun 2007 11:41:56 +0200
From: Ralf Hemmecke
To: Tim Daly
Subject: Re: Combinat

> I've been studying your combinatorial species project.

> Would it be reasonable to say that one could redefine (some of) the 
> data structures in axiom using a series of transformations and 
> combinations on sets?

I would say, yes. It would not be every data structure though. One could
define List as

List(L: LabelType): CombinatorialSpecies L ==
   Plus(EmptySetSpecies, Times(SingletonSpecies, List))(L) add {...}

the {...} is needed because the usual List has a few more exports.

But List is actually rather special and should be implemented in a more
efficient way.

But yes, species can be considered as a generic way to build data
structures. And one would get their generating series and a generation
of all structures of a certain size as a "side effect" that does not 
need any more effort than writing the "equation" as above for List.

> Would it be a set of pointers?

No. No pointers involved. Everything is fully and statically typed.

> So a species is a "builder function" that would build a given data
> structure, like a linked list, from a set of pointers?

Builder function is correct. Pointers is wrong. If you have the 
construction as above you would says

for l in structures set [1,2,3,4] repeat stdout << l << newline;

and it will print all the 4! different lists of with 4 elements.

(But you see List is rather special, I actually need it already to form 
the input of the "structures" function. But take

1 ==> EmptySetSpecies;
X ==> SingletonSpecies;
+ ==> Plus;
* ==> Times;
B(L: LabelType): CombinatorialSpecies L == (1+X*B*B)(L) add {...}

and the same "for" loop above with structures$B gives you all binary 
rooted trees with exactly 4 nodes.

\start
Date: 30 Jun 2007 06:33:05 -0400
From: Stephen Wilson
To: Ralf Hemmecke
Subject: re: A modest proposal

Ralf Hemmecke writes:

> >> I wait for Gaby to submit a patch. I think that will be the better
> >> road than simply switch to wh-sandbox and make some people angry.
> >> We should stay together as a community. Please.
> > I totally agree.  All I hope for is that the patch is documented and
> > is in keeping with the clearly stated goals of the project.
> 
> It would be super good if the patch is properly documented, but that is
> *not* my priority. Gaby is certainly willing to improve his autoconf
> work with documentation when it is in trunk. How come that people seem
> to think that Gaby is not committed to LP?

I dont think its an issue of lack of commitment.  I think it is a
divergence in process.  Regardless of how great and shiny and new
anyones patch is, I honestly do think its worth the time to document
it first.  The payoffs in the long run are worth it.

> > I want to be able to understand such a patch in detail, without
> > having to second guess the authors intent.
> 
> Do you know that we have a mailing list where you could simply ask?
> The answer then should be used to improve the documentation. But see,
> for me it would be much worse to lose Gaby than to have a little
> imperfect documentation in trunk. We even have more imperfection all
> around.

I really dont see it that way.  If I have a contribution, then I post
it to the list.  Give the community the chance to study it and
comment.  Such a post is almost certainly an initial release, save
trivial fixes.  It is an opertunity for everyone to contribute, to ask
questions, to engage themselves in the process.  One can propose a
patch with working code without it being literate from the start.
Nothing forbids that.  wh-sandbox and build-improvements dont
implicitly discount such a process.  Neither Gaby nor Waldek have ever
said `I dont care about suggestions regarding LP'.  The fundamental
problem, from my perspective, is that it is exceedingly rare for there
to be a public patch.  Something real that we can all comment on and
study, that we all have a vested interest in improving.

Fundamentally, what _is_ important is that when the code is ready to
go into silver, it is a documented, literate, work.  We do not need to
get that code in tommorow. This is a basic principle of the project.

> Don't you see that probably all current developers are LP believers?
> It is just a question how to arrive at an Axiom that is fully in an LP
> style.

Its not really a question.  Just write LP code for submission to
Silver.  Any steps one takes to get to that point is an individual
decision.

> Some people think that we must from now on do everything in
> proper LP style. And some people rather like to work for a while in
> the usual programming paradigm and postpone proper documenation until
> we have autoconf, hyperdoc, windows port running. *Nobody* says that
> he will not eventually document in LP style.

Its a totally classic scenario.  Write the code, and promise to
document it.  Almost invariably it turns out to be nonsense.  I would
not be surprised if the original developers of axiom entertained
exactly the same notions.  Look what that got us.

> I agree that it would be best that documentation gets done while the
> development happens, but that is *not* the main pressing part. It is
> much more important to make more people aware of Axiom and attract
> more developers. If we have 100 developer, then I totally agree that
> no patch should be admitted to trunk if it is not fully documented in
> a way Tim would like it. But until then let's just be a bit more
> relaxed.

Totally disagree.  If we cant convince the handfull of developers
currently involved, how on earth are we going to convince 100?

We need to stick to our guns and set an example.  It might even be
inspiring if we do.  Tim certainly inspired me, and thats why Im here.

> With a handfull of developers we will *never* be able to document all
> the legacy algebra code. There is simply not enough time. Let's
> attract developers first and let's preach them some LP so that they
> know what will be the vision of Axiom.

There is a huge difference between preaching and doing.

> Note, that is not a compromise to Tim's vision of having everything
> properly documented so that people can understand it. But what is the
> use of documentation where only 10 people in the world are willing to
> read it? Axiom will die without developers.

Axiom has developers, it will not die.  The hope is that effort and
patience will win out in the end.  That computational math becomes
both an art and a science.  That Axiom represents the very best of an
ever so young disipline, and one which will outlive us all.

> Look at Aldor. That's a super language, but all the other languages
> just take over the ideas of Aldor and Aldor will lose no matter how
> advanced it is. Without developers Aldor is dead. And with 10
> developers also Axiom is dead.

Aldor is dead because no one but a few privileged folk can read its
code, but even that is not entierly true.  I think Aldor has a lot of
good ideas behind it, and am trying to implement them myself.  Good
ideas always survive.

> > I believe we all have to agree that there exists a common goal.  I
> > dont think there is a fast path to an amicable result.  I have enough
> > people telling me that they want something done yesterday.  Axiom, I
> > hope, is an oasis from such expectations.
> 
> Of course there is no real time pressure. I press, because I want to
> see a well documented, well running Axiom during my lifetime. Only
> that presses to ask for more developers.

I share the same perspective. 

\start
Date: Sat, 30 Jun 2007 06:34:35 -0400
From: William Sit
To: Ralf Hemmecke
Subject: re: A modest proposal (PLEQN documentation)

Ralf Hemmecke wrote:
> [sniped]
> I don't quite know whether Tim wants to have both kinds of documentation
> in the Axiom project. If I understood correctly, that is the "facets of
> the crystal" view. Yes, Axiom should be a big monster which not only
> contains code.
> 
> It should be a collection of
> 1 code,
> 2 API descriptions (this is what the +++ comments are)
> 3 explanation of
>      motivations,
>      tricks that were used in the implementation,
>      things that are not used in the code (and the reason for it)
> 4 informal description of why the code is there
> 5 informal overall description of how some piece of code works
> 6 formal descriptions of the theory behind the code
> 7 proofs that the code fulfils its specification (its API)
> 8 test scripts that tests the code (we don't have automated
>    program verification yet)
> (This list is certainly not complete.)
> 
> William (I have not actually looked at your code so excuse me if I am
> wrong), what you contributed was/is in the code and API part and maybe
> in the test and formal description part (1,2,6,8). But what I think is
> very important is also the interconnection between all of this. Can you
> point me to some text in current Axiom that explains *why* (4) you have
> designed your contribution as it is now?

The code for PLEQN (parametric linear equations) was my
first Axiom code and I must admit that there are rooms for
improvement (even the variable names there weren't good).
But I did spend some time in designing the user interface
(or function interfaces for "psolve"). Bronstein complained
once that there were too many options (overloading psolve),
but he did not say which ones should be deleted. The code
was developed on and for an IBM main frame when memory was
at a premium (16MB). The code (even the algorithm) is not
efficient (even though it may be theoretically orders of
magnitude better than Gaussian elimination methods -- see
Section 9 of paper) and that is the reason for the options
to save partial computations to disk and this is possible
because the algorithm is by nature very parallel (which is
also the source of inefficiency; there is an efficiency
related open problem stated in the paper and so far I have
heard nothing new).

My paper has a long section on implementation issues,
(Section 7, although it is not Axiom specific, as required
by the journal referees) and SCRATCHPAD (former Axiom)
examples to use the code (Section 8). If you read these two
sections, you will find it is very close to the ideal of
literate programming (I didn't know what LP was at the
time). Interestingly, my submitted version interwined the
theory with the code but the referees wanted me to separate
them! Both the algorithm (and documentation) can be improved
to give better results (but not necessarily more efficient)
using another package QALGSET I developed about 6 years
later (1998). I have always wanted to rewrite the packages
but trying to do it taking in all the aspects (1 to 8) above
(of course I meant similar standards in different words) is
a big, big project, even for me. I fell behind when Axiom
changed to A# (former Aldor) and there are packages that
were dead code and I am even more behind currently. As a
researcher, my immediate concerns were (still are) to
produce new results (not necessarily related to Axiom), not
revisiting old code or even bringing them up to date
whenever the platform changes (Spad to A# to Aldor). But
actually, the days when I may refresh the packages is
getting closer because of applications to differential
equations.

> 
> I agree that some people are not interested in the code and in the
> description of the code, but for developers who maintain code it is very
> important to know about design issues. That is a different issue from
> the actual mathematical theory and it is important for maintainers of
> the code.
> 
> Axiom should have everything and it should be able to show to some
> person exactly the amount of detail s/he wants to see. If someone is
> only interested in the theory, extract something that doesn't show the
> implementation details. But some people would not only like to see the
> theory, but they want to see a "running theory", they want an
> interactive paper where they see the theory and can compute with the
> algorithms implemented by the paper. Other people like to see the actual
> algorithm in a specific programming language. Some people are not
> interested to be distracted by a lot of text and want to concentrate on
> more focused details of the implementation. Axiom should be able to
> extract all these different forms in nicely human readable formats. All
> that should be provided by a (or several) pamphlet(s).
> 
> The important thing is that the information is there. I am not so sure
> that we already have a good format of how a pamphlet should look like.

This is exactly my objections to the pamphlet format. It
would be easier from the author's viewpoint to create
different files for different uses, with cross-references
among them. It would be much harder to design one single
file that captures all possible views in a coherent way and
still be able to be unraveled as readable for various
separate views. To do the former you need a lot of "glue"
and the "glue" cannot be simply removed without
disconnecting the flow for individual views. To use a
compiler analogy, you need a lot of "ifdef"s and this
complicates the creative process as well as the logical flow
and reduces clarity because logical blocks may be dissected
into small chunks that spread across many pages.

> 
> I also agree that it is hard to actually write good LP documents. I made
> my experience with Aldor-Combinat. Look at it at
> http://www.risc.uni-linz.ac.at/people/hemmecke/AldorCombinat/ .
> It has a lot of documentation. But I myself would not say that it is a
> proper literate program. Try it out, read it. I guess, you will not be
> able to understand the overall project goals. I have not written that
> but still the program is working. Now, if I would require proper LP
> documentation, I would never be able to release this code at all. I try
> hard to add a lot of design decisions, but all that is still not enough.
> 
> And that Aldor-Combinat experience lets me think that it is better to
> release code even if it is not properly documented. So in this sense I
> do not fully agree with Tim. I find it better if I throw something at
> the public and have referees that tell me, hey there is something wrong,
> this and that is not understandable. So I have a chance to extend
> code+documentation at places where people complain. I am committed to
> LP, but I also have only limited time so it's better if there is really
> a community develepment. I am all for feedback. That should be our
> "quality assurance" way of makeing Axiom incrementally better.
> 

I just skipped through AldorCombinat and except for the
theory behind species, your documentation for the code and
usage is quite extensive. I am however overwhelmed by the
hundreds of chunks and occasionally the extra link
information can be distracting (of course they are useful
for debugging and code changes). Just one question: In
Section 8.1, just before the bottom ToDo, the two formulae
at the end of lines, do you mean $\cup_{U \subseteq L, U
finite} \{U\}$ (and similarly for F[U])?

We all have limited time and that is why the priority of the
Axiom project should be to increase user base. If there are
more users, Axiom will be used at more universities
(especially if a fully functioning Windows version is
available) and even commercial houses (but they don't
"count" in my books); we will have more students who can do
a lot of work such as documentation (writing pamphlets if
that is the standard) as undergraduate or master theses.
Doctoral students can develop better models, new and newer
algorithms for Axiom's foundation and implement them. 

\start
Date: Sat, 30 Jun 2007 05:31:15 -0700 (PDT)
From: Cliff Yapp
To: Bill Page, Stephen Wilson
Subject: re: A modest proposal

> Thanks for carrying my side of the conversation for me, Cliff. :-)

<turns red>.  Sorry, didn't mean to presume Bill - please forgive my
rudeness.  I just had a feeling I knew pretty well what that side of
the argument would be, and wanted to respond before I fell asleep ;-).

> I've had my mind on other things for the last few hours... Yes, you
> state very clearly and exactly my concerns.

OK, good.

> I have a very great respect for Lisp, but I wonder how you can look
> around the web and at the type and number of programs that have been
> written in the last 10 years and not think that Lisp is essentially
> already a ghetto (as you have so clearly and accurately defined it).

That's a fair question, and if you take the definition of "ghetto" as
laid out above I suppose it DOES satisfy that definition.  Which leaves
the question of why I don't think of Lisp as a ghetto even though it
might technically satisfy the definition.  

I would say my line of reasoning goes something like the following:

1.  Once I was able to understand the basics of how Lisp works, the
simplicity of it and the power it offers were worth the initial
learning effort.

2.  In the world of computer algebra specifically, Lisp is a staple and
has been for decades.  Far, far back in the depths of the Maxima
archives, before I knew what I was doing, I proposed rewriting Maxima
in a language with more popular support.  The archives no longer seem
to be online, but IIRC the response at some point was that learning
Lisp was a small effort compared to the effort required to properly
implement CAS abilities, and the benefits of using Lisp outweighed the
difficulties in this particular case.  I have since come to agree with
this.

3.  Lisp may not get the "popular interest" other languages do, but
much of the code written for it seems to be rather well written - it
solves problems well when it does solve them. 


> We might wish that that was not true but all the evidence is clearly
> there. Ask the people who teach computer science at university what
> they think of Lisp. Ask them what there students think of Lisp. Gaby
> for example has already said what the reaction of his colleagues was
> to the fact that he has been spending so much time on an "old Lisp"
> system like Axiom... When I mentioned Lisp to a room full of
> enthusiastic Sage developers you should have seen the "tolerant
> amusement" on the faces those under 25 in the crowd. Man, did that
> make me feel old... :-(

Lisp is still a working, functional language despite having its roots
in the Fortran days - that says something about the robustness of the
ideas behind it, IMHO.  In my opinion the question should be what does
the language bring to the table.  The only area I am aware of where
Lisp is seriously lacking compared to other languages is libraries
defining graphical tools.

Python has great library support for modern operating systems - I have
used it in the past because of this.  However, for the 30 year horizon
what is popular today is of somewhat less concern to me.  Who knows how
language trends will progress?  Something new may become the next
"star" language.  Lisp has been around for a very long time, and offers
a lot of power in exchange for being willing to think a little
differently.  To me that's worth the tradeoff.


> > >  And the goal is to develop tools such that given a working Lisp
> > > environment users and developers will be able to focus on the
> > > Algebra without worrying about the underlying tools.  If they
> > > MUST work with them, I would like them to be literate all the
> > > way down - no dark corners to get into trouble with.  But that's
> > > again just me.
> 
> That part I completely agree with but I fail to see why that requires
> doing the things that you and Stephen are proposing.

OK, ask these questions - is autoconf (not our configure file but GNU
autoconf) literate?  What about GCC?  If those programs are in the
critical dependency tree any problems that no one else takes care of we
have to deal with, because without them we would have no working
program.  noweb is at least literate but it also requires gcc.  GCL and
Clisp bootstrap off of GCC, true, but CMUCL and SBCL do not.  

Being able to maintain a working CAS means that everything required to
go from source code to finished binary is a potential issue for the
Axiom developers to deal with.  The easier it is to deal with any
potential issue at ANY point in the software stack, the better. 
Perhaps most of the time Axiom will be built and used with tools that
require external support, but (like Maxima) I would like Axiom to be
able AT NEED to get up and running with only tools that are fully
literate.  The less Axiom is at the mercy of ANY external requirements,
the more robust it will be for the 30 year horizon and beyond.  If
autoconf someday dies, if noweb becomes unmaintained someday, we would
still be able to build as long as an ANSI Lisp environment can be
bootstrapped.  That's robustness.

A consequence of this approach is that we rely less on mainstream
tools.  To me, the approach should be to have the option of using
mainstream tools if they do something better/faster, but be able to
fall back on Axiom itself if something goes haywire with the external
requirements.  Future proofing Axiom means that the work put into the
Algebra code will still be usable indefinitely, so long as the
supporting Lisp environment can run.  In some ways, it's the same
reason Java software is portable - it uses the virtual machine and
writes everything inside of it.  Java was designed from some people
familiar with Lisp - I have a feeling this idea came from there.  In
theory Lisp could provide many of the same benefits, if the work was
put into interfacing with the different graphics libraries properly.

"Mainstream" is a matter of definition, and the community defines it. 
We are part of the community, engaged in a major project with wide
ranging implications.  Rather than follow the trends, why don't we set
them?  Find the best tools for the task, use them, and make them
mainstream?

The Spad/Aldor languages are even more of a ghetto than Lisp, yet we
are putting effort into them because they provide enough benefits by
virture of their language constructs to be worth the effort.  I
personally like Lisp enough to consider it worth the extra effort
(which isn't really all that much, to be honest - I have a LOT of
basics to learn and that would be the same in any language) to make
ASDF capable of handling pamphlets and do some other work as well to
make it close to an ideal environment.  And I'm sure ASDF is a LOT
easier to make literate than autoconf, when the goal of "turtles all
the way down" with literate programming comes into play.

Anyway.  We'll see - it's an experiment.  All we can do is give it a
try.

\start
Date: Sat, 30 Jun 2007 14:46:17 +0200
From: Ralf Hemmecke
To: William Sit
Subject: re: A modest proposal (PLEQN documentation)

>> The important thing is that the information is there. I am not so sure
>> that we already have a good format of how a pamphlet should look like.

> This is exactly my objections to the pamphlet format. It
> would be easier from the author's viewpoint to create
> different files for different uses, with cross-references
> among them. It would be much harder to design one single
> file that captures all possible views in a coherent way and
> still be able to be unraveled as readable for various
> separate views.

I don't disagree with you. As you might know, I would call a collection 
of files that describe some idea/code/design issues by the name 
pamphlet. So a pamphlet would be a kind of zip file similar to what an 
open office file is. But I should rather chose another name in order not 
to confuse people with what is currently understood by pamphlet.

It is totally nontrivial to use the same information in different views. 
That is a burden for the author and I haven't yet seen a good tool that 
helps to break information into such information atoms.

> I just skipped through AldorCombinat and except for the
> theory behind species, your documentation for the code and
> usage is quite extensive. I am however overwhelmed by the
> hundreds of chunks and occasionally the extra link
> information can be distracting (of course they are useful
> for debugging and code changes).

Yep. I don't claim it is the best that can be done. LP for me is an 
experiment. The current form is quite helpful for development, but it is 
not linearly human readable. I agree. I try to figure out myself how LP 
should look like in the daily programming life. So any comment from 
outside is welcome.

> Just one question: In
> Section 8.1, just before the bottom ToDo, the two formulae
> at the end of lines, do you mean $\cup_{U \subseteq L, U
> finite} \{U\}$ (and similarly for F[U])?

Oh, yes. But as you can probably read there. I need a much better 
description. I'd like to formulate that in a categorial way, but I would 
need that a species is not a functor F: B->B but an L indexed something.
If you can think of a way how to incorporate the type L business into a 
categorial setting, I would be over grateful.

> We all have limited time and that is why the priority of the
> Axiom project should be to increase user base. If there are
> more users, Axiom will be used at more universities
> (especially if a fully functioning Windows version is
> available) and even commercial houses (but they don't
> "count" in my books); we will have more students who can do
> a lot of work such as documentation (writing pamphlets if
> that is the standard) as undergraduate or master theses.
> Doctoral students can develop better models, new and newer
> algorithms for Axiom's foundation and implement them. 

I support that view very much.

\start
Date: Sat, 30 Jun 2007 06:06:15 -0700 (PDT)
From: Cliff Yapp
To: William Sit, Waldek Hebisch
Subject: re: Fork time

I think one way to look at this fork (which as I think someone observed
is already in some ways a de-facto fork) is as a proving ground for
ideas which can eventually fold back into Axiom.

As I understand it right now, the motivations most in conflict with the
current direction of the project are the ones wishing to attract more
developers and get the system more fully functional quickly.  I can
certainly understand those motivations and even agree with them to some
extent, but I think a fork around wh-sandbox might be the most logical
place to pursue them.

Steve and I appear to have some ideas which will result in something of
a re-think of the interp structure, and we also seem to agree that the
fully "literate as we go" approach makes the most sense - hence the
focus on making this as easy as possible.  Personally I'm not so
concerned with having "something working" in the sense of the fully
working CAS - I am more concerned with having a system that offers
something new enough and unique enough to draw people.  I think the
only thing that stands a serious chance of doing this for the
mathematical community is a system that has a chance of producing
formal correctness proofs of any of its answers upon request.  For a
system to be trusted to that level, every part of it must be subject to
straightforward audit by as many eyes as possible.  That means making
understanding all parts of the system as simple as possible, AS A
DESIGN GOAL.

I don't dispute the enormous usefulness of Waldek's work or argue with
those who label it as the best currently running Axiom system.  Indeed,
I'll likely use it myself.  I am tempted to vote yes to the proposal
with the caveat that only files which are not already truly literate be
updated, as I don't think there is going to be much practical
difference in untangling non-literate files with Waldek's fixes and
non-literate files without them. However, I personally like best about
Axiom it's focus on "pie in the sky" goals that have the potential to
change the way people think about computational mathematics and its
role in the wider mathematical and scientific communities.  Sort of a
"QED Manifesto" type project for CAS.  This seems to collide with the
goal of getting a system "up and running" to attract developers, as the
mechanisms I envision being most attractive to developers involve what
are probably fairly major work even to get started.  Hence my
conclusion that at least a temporary fork to pursue the "gathering of
developers to the current Axiom CAS" goal is a good idea - I support
that goal but it's a bit orthogonal to some of the other directions I
personally would like to see pursued.

I would like to re-iterate again that I am very grateful to the effort
put in by ALL of the developers, and I personally at least feel no
hostility to ANYONE for putting their time and effort into such a
wonderful volunteer project.  Waldek has done amazing work and I am
very, very grateful to him for doing so - I have no doubt his efforts
will continue to be outstandingly successful.  What I don't want to see
is two different (and worthy) goals slugging it out endlessly to the
detriment of both.  I don't see it as a fragmenting of the community,
just the community working on different aspects of what is in the end
the same problem - a strongly typed, robust mathematical CAS.  If we
don't become too incompatible on the Algebra level, I don't think a
fragmentation needs to occur.  Waldek's fork can be to Axiom like
Ubuntu is to Debian.

\start
Date: Sat, 30 Jun 2007 16:12:16 +0200 (CEST)
From: Bertfried Fauser
To: Ralf Hemmecke
Subject: re: Combinat

On Sat, 30 Jun 2007, Ralf Hemmecke wrote:

Dear Ralf,

if we are here dealing already with a sort of pointers (or function
arrays) is there already in Aldor/Axiom a 'functor' domain?

I think of a Functor domain in the following sense, it should implement a
'categoy' (in the mathematical sense) of morphisms which opperate on
another (pair of) categor(y/ies). The functionality of such a category
would be to implement naturality of maps, coherence, composability of
morphisms, etc.

IFF such a thing would work, species would be an instance, as also lambda
rings and symmetric functions ;)


By the way, any templete category for symmetric functions in the oven?

Ciao
BF.

> > I've been studying your combinatorial species project.
>
> > Would it be reasonable to say that one could redefine (some of) the
> > data structures in axiom using a series of transformations and
> > combinations on sets?
>
> I would say, yes. It would not be every data structure though. One could
> define List as
>
> List(L: LabelType): CombinatorialSpecies L ==
>    Plus(EmptySetSpecies, Times(SingletonSpecies, List))(L) add {...}
>
> the {...} is needed because the usual List has a few more exports.
>
> But List is actually rather special and should be implemented in a more
> efficient way.
>
> But yes, species can be considered as a generic way to build data
> structures. And one would get their generating series and a generation
> of all structures of a certain size as a "side effect" that does not
> need any more effort than writing the "equation" as above for List.
>
> > Would it be a set of pointers?
>
> No. No pointers involved. Everything is fully and statically typed.
>
> > So a species is a "builder function" that would build a given data
> > structure, like a linked list, from a set of pointers?
>
> Builder function is correct. Pointers is wrong. If you have the
> construction as above you would says
>
> for l in structures set [1,2,3,4] repeat stdout << l << newline;
>
> and it will print all the 4! different lists of with 4 elements.
>
> (But you see List is rather special, I actually need it already to form
> the input of the "structures" function. But take
>
> 1 ==> EmptySetSpecies;
> X ==> SingletonSpecies;
> + ==> Plus;
> * ==> Times;
> B(L: LabelType): CombinatorialSpecies L == (1+X*B*B)(L) add {...}
>
> and the same "for" loop above with structures$B gives you all binary
> rooted trees with exactly 4 nodes.

\start
Date: Sat, 30 Jun 2007 12:03:45 -0400
From: Bill Page
To: Bertfried Fauser
Subject: re: Combinat

Bertfied,

On 6/30/07, you wrote:
>
> if we are here dealing already with a sort of pointers (or function
> arrays) is there already in Aldor/Axiom a 'functor' domain?
>
> I think of a Functor domain in the following sense, it should implement a
> 'categoy' (in the mathematical sense) of morphisms which opperate on
> another (pair of) categor(y/ies). The functionality of such a category
> would be to implement naturality of maps, coherence, composability of
> morphisms, etc.
>

You might be interested in this paper that deals at least in part with
these issues

Domains of data and domains of terms in AXIOM
by BROWN, R. & DRECKMANN, W

http://portal.axiom-developer.org/refs/articles/brown-free-c-g.pdf/file_view

from

http://www.informatics.bangor.ac.uk/public/math/research/preprints/95/algtop95.html

> IFF such a thing would work, species would be an instance, as also lambda
> rings and symmetric functions ;)
> ...

I think that is very interesting.

\start
Date: Sat, 30 Jun 2007 13:12:03 -0400
From: Alfredo Portes
To: Cliff Yapp
Subject: re: Fork time

On 6/30/07, Cliff Yapp wrote:

> fragmentation needs to occur.  Waldek's fork can be to Axiom like
> Ubuntu is to Debian.

This situation looks a lot more like Beryl/Compiz.
Hopefully, Waldek's is not too discouraged, and like William suggested,
he just forget about the comments that provoked this and continue the great
work he has been doing. Better days ahead...

\start
Date: Sat, 30 Jun 2007 15:42:46 -0500 (CDT)
From: Gabriel Dos Reis
To: list
Subject: Axiom and ANSI Lisp -- SBCL

  In a local tree, I've added a warpper to compile-file so that
it aborst build when the tertiary return value of compile-file (failure-p) is
true.  I consider that a minimum trust for sane build of Axiom -- which means
neither silver nor build-improvements is sane with respect to that 
notion.  When I do that I see lots of failures.  Did you try that?

\start
Date: Sat, 30 Jun 2007 22:42:51 +0200
From: Ralf Hemmecke
To: Bill Page
Subject: re: Combinat
Cc: Bertfried Fauser

>> if we are here dealing already with a sort of pointers (or function
>> arrays) is there already in Aldor/Axiom a 'functor' domain?

Not that I know.

>> I think of a Functor domain in the following sense, it should implement a
>> 'categoy' (in the mathematical sense) of morphisms which opperate on
>> another (pair of) categor(y/ies). The functionality of such a category
>> would be to implement naturality of maps, coherence, composability of
>> morphisms, etc.

> You might be interested in this paper that deals at least in part with
> these issues
> 
> Domains of data and domains of terms in AXIOM
> by BROWN, R. & DRECKMANN, W
> 
> http://portal.axiom-developer.org/refs/articles/brown-free-c-g.pdf/file_view 
> 
> from
> 
> http://www.informatics.bangor.ac.uk/public/math/research/preprints/95/algtop95.html 

I am quite disappointed from that paper. It is totally uninteresting 
from my species project point of view. Maybe the other way round, that 
species can be used to construct the directed graphs data structure. But 
that sounds a bit odd if I use functors (species) in order to implement 
categories.

In fact, it isn't. Axiom/Aldor cannot deal with categories and the 
keyword "Category" is a big misnomer. Aldor is better at describing 
universal algebras (or rather the multisorted case). And this is exactly 
what the above paper does. It describes a category by its algebraic 
properties. Unfortunately, all the categories from that paper have only 
finitely many objects. To me that is nothing really useful. For the 
species project I need the category of finite sets and bijections. 
Clearly, that category has infinitely many objects. It even has more 
than uncountably many objects. Take r any real. Then {r} is an object in 
that category.

I must say, I really doubt that any good implementation of a category is 
ever possible. Collecting all the arrows of a category explicitly, makes 
no sense for me. Same with the objects. If you want to compute in a 
category you probably have to do this, but then you are restricted to 
"finitely many".

As you can see in the ToDo of
http://www.risc.uni-linz.ac.at/people/hemmecke/AldorCombinat/combinatsu14.html#x27-320008.1
I did not yet take the time to work out the details of how the 
implementation of a species (i.e. a functor of a special kind) can be 
seen categorially. Note that I have a LabelType. That is a restriction 
that is imposed by the programming language Aldor. I cannot have a List 
of everything but only a List over objects of the same type. Same for a 
species. The labels must all be of the same type. Of course I could form 
unions, but again all objects/labels have to be of the same type.

There is no equivalent in the species theory. A species is a functor F 
that takes a finite set U and returns a finite set F[U]. There is no 
type attached.

>> IFF such a thing would work, species would be an instance, as also lambda
>> rings and symmetric functions ;)

Yes, yes, but don't forget, we have to deal with infinite things. I will 
not even be able to get the full category of natural numbers on my 
computer... ;-)

> I think that is very interesting.

Oh yes, I agree. But that would call for a workshop similar to the one 
we had on symmetric functions. Since I don't work so much with 
categories, it would be interesting to hear what people would like to do 
when the want categories/functors/natural transformations being 
implemented on a computer. To me that sounds much more complicated than 
the symmetric function business. Actually, categories are so simple as 
algebraic structures. But that is not everything.

\start
Date: 30 Jun 2007 18:06:49 -0400
From: Stephen Wilson
To: Camm Maguire
Subject: Re: 2.7.0 reports
Cc: Gabriel Dos Reis

A new problem now, unfortunately, unseen before latest commit.

Not pressing as I belive I have a workaround.

==----- test.lisp ----

(defun test (obj1 &optional (obj2 nil))
  (let ((obj2 (or obj2 t)))
    (cond
      ((and (null obj2)
            (stringp obj1)
            (pathname-type obj1))
       (values obj1))
      (t nil))))

==--------------------

Issue seems to be with optimization.  GCL knows OBJ2 above is
non-null.  The AND is transformed such that even if STRINGP returns
NIL, PATHNAME-TYPE is still executed, leading to a type error.

steve:tmp> gcl
GCL (GNU Common Lisp)  2.7.0 ANSI    Jun 30 2007 00:17:31
Source License: LGPL(gcl,gmp,pargcl), GPL(unexec,bfd,xgcl)
Binary License:  GPL due to GPL'ed components: (XGCL READLINE BFD UNEXEC)
Modifications of this banner must retain notice of a compatible license
Dedicated to the memory of W. Schelter

Use (help) to get some basic information on how to use GCL.

Temporary directory for compiler files set to /tmp/

>(si::use-fast-links nil)

NIL

>(compile-file "test.lisp")

;; Compiling test.lisp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling test.o.
#P"/home/steve/tmp/test.o"
NIL
NIL

>(load "test.o")

;; Loading test.o
 ;; start address -T 0xa33e50 ;; Finished loading test.o
84

>(test (list))

Error: 
Signalled by TEST.
Condition in TEST [or a callee]: INTERNAL-SIMPLE-TYPE-ERROR: NIL is not of type PATHNAME: 

Broken at TEST.  Type :H for Help.
 1 (Continue) Return to top level.
>>:bt

#0   TEST {obj1=nil,obj2=nil,loc2=nil,loc3=nil,loc4=nil,loc5=nil,loc6=nil} [ihs=3]
#1   EVAL {loc0=nil,loc1=nil,loc2=nil,loc3=#<compiled-function test>} [ihs=2]
>>:q

Top level.
>(disassemble 'test)

;; Compiling /tmp/gazonk_12078_0.lsp.
;; End of Pass 1.  
;; End of Pass 2.  
;; OPTIMIZE levels: Safety=0 (No runtime error checking), Space=0, Speed=3, (Debug quality ignored)
;; Finished compiling /tmp/gazonk_12078_0.o.

#include "gazonk_12078_0.h"
void init_code(){do_init((void *)VV);}
/*      local entry for function TEST   */

static object LI1(object V1,object first,...)
{
        va_list ap;
        int narg = VFUN_NARGS; VMB1 VMS1 VMV1
        {object V2;
        object V3;
        va_start(ap,first);
        V2= V1;
        narg -= 1;
        if (narg <= 0) goto T1;
        else {
        V3= first;}
        --narg; goto T2;
        goto T1;
T1:;
        V3= Cnil;
        goto T2;
T2:;
        goto TTL;
TTL:;
        {object V4;
        if(((V3))==Cnil){
        goto T6;}
        V4= (V3);
        goto T4;
        goto T6;
T6:;
        V4= Ct;
        goto T4;
T4:;
        (void)(type_of((V2))==t_string);
        base[0]= (V2);
        vs_top=(vs_base=base+0)+1;
        Lpathname_type();
        vs_top=sup;
        V5= ({register object _z=vs_base[0];_z;});
        if(!((V5)==(Cnil))){
        goto T12;}
        goto T10;
        goto T12;
T12:;
        goto T10;
T10:;
        {object V6 = Cnil;VMR1
        (V6);}}
        va_end(ap);
        base[0]=base[0];
        return Cnil;}
        }
#(#((%INIT
     . #((LET ((*DISABLE-RECOMPILE* T))
           (MFVFUN 'TEST 0 131073 0)
           (ADD-HASH 'TEST '((T *) NULL)
               '((PATHNAME-TYPE (T) T) (STRINGP (T) BOOLEAN))
COMMON-LISP-USER
LISPLAMBDA      !
                 OBJ1   ,&OPTIONA!
                                  OBJ,DECLA,OPTIMIZ,SAFETY      ,BLOCK
                                                                      TEST      ,LE.    ,OR.,T
,IF
,PATHNAME-TYPE,VALUES-
               '/tmp/gazonk_12078_0.lsp)
           (DEBUGGER 'TEST '(OBJ1 OBJ2)))
         (DO-RECOMPILE)))))
static object LI1(object,object,...);
#define VMB1 register object *base=vs_top; object  V5;
#define VMS1 register object *sup=vs_top+1;vs_top=sup;
#define VMV1 vs_check;
#define VMR1(VMT1) vs_top=base ; return(VMT1);
#define VM1 1
static void * VVi[1]={
#define Cdata VV[0]
(void *)(LI1)
};
#define VV (VVi)

/tmp/gazonk_12078_0.o:     file format elf32-i386

Disassembly of section .text:

00000000 <init_code>:
   0:   68 00 00 00 00          push   $0x0
   5:   e8 fc ff ff ff          call   6 <init_code+0x6>
   a:   58                      pop    %eax
   b:   c3                      ret    

0000000c <LI1>:
   c:   53                      push   %ebx
   d:   8b 1d 00 00 00 00       mov    0x0,%ebx
  13:   8d 43 04                lea    0x4(%ebx),%eax
  16:   3b 05 00 00 00 00       cmp    0x0,%eax
  1c:   a3 00 00 00 00          mov    %eax,0x0
  21:   72 05                   jb     28 <LI1+0x1c>
  23:   e8 fc ff ff ff          call   24 <LI1+0x18>
  28:   8b 44 24 08             mov    0x8(%esp),%eax
  2c:   89 03                   mov    %eax,(%ebx)
  2e:   8d 43 04                lea    0x4(%ebx),%eax
  31:   89 1d 00 00 00 00       mov    %ebx,0x0
  37:   a3 00 00 00 00          mov    %eax,0x0
  3c:   e8 fc ff ff ff          call   3d <LI1+0x31>
  41:   89 1d 00 00 00 00       mov    %ebx,0x0
  47:   b8 00 00 00 00          mov    $0x0,%eax
  4c:   5b                      pop    %ebx
  4d:   c3                      ret    
NIL


\start
Date: Sat, 30 Jun 2007 18:02:41 -0500 (CDT)
From: Gabriel Dos Reis
To: list
Subject: Fix thinko in src/interp/vmlisp.lisp

  This thinko while caugh while building build-improvements with
SBCL.  The error is that the value of abs(N) should not be part
of the arguments to error() and should be computed separately.
Fixed thusly.

Applied to build-improvements.
Will apply silver SF/SVN shortly.

-- Gaby
2007-06-30  Gabriel Dos Reis  Gabriel Dos Reis

	* vmlisp.lisp.pamphlet (MACRO-MISSINGARGS): Fix thinko.

*** vmlisp.lisp.pamphlet	(revision 22145)
--- vmlisp.lisp.pamphlet	(local)
*************** can be restored.
*** 1855,1867 ****
  (defun MACRO-MISSINGARGS (NAME ignore N)
    (declare (ignore ignore))
    (setq MACERRORCOUNT (+ 1 (eval 'MACERRORCOUNT)))
!   (error (concatenate 'string (symbol-name NAME) " requires "
!                        (if (minusp N) "at least " "exactly ")
!                        (setq N (abs N))
!                        (case N (0 "no") (1 "one") (2 "two") (3 "three")
!                              (4 "four") (5 "five") (6 "six")
!                              (t (princ-to-string N)))
!                        (if (eq n 1) " argument," " arguments,"))))
  
  (defun MACERR (MESSAGE &rest ignore)
    (declare (ignore ignore))
--- 1855,1867 ----
  (defun MACRO-MISSINGARGS (NAME ignore N)
    (declare (ignore ignore))
    (setq MACERRORCOUNT (+ 1 (eval 'MACERRORCOUNT)))
!   (let ((nargs (abs N)))
!     (error (concatenate 'string (symbol-name NAME) " requires "
! 			(if (minusp N) "at least " "exactly ")
! 			(case N (0 "no") (1 "one") (2 "two") (3 "three")
! 			      (4 "four") (5 "five") (6 "six")
! 			      (t (princ-to-string nargs)))
! 			(if (eq nargs 1) " argument," " arguments,")))))
  
  (defun MACERR (MESSAGE &rest ignore)
    (declare (ignore ignore))

\start
Date: 30 Jun 2007 19:54:19 -0400
From: Stephen Wilson
To: Gabriel Dos Reis
Subject: Re: Fix thinko in src/interp/vmlisp.lisp

Hi Gaby,

This is untested but I wanted to get it out before you commited.

Consider:

(defun macro-missingargs (name ignore n)
    (declare (ignore ignore))
    (setq macerrorcount (+ 1 (eval 'macerrorcount)))
    (let ((nargs (abs n)))
      (error "~A requires ~:[exactly~;at least~] ~D argument~P"
             (symbol-name name) (minusp n) nargs nargs)))

Note also your version still (I think) as a problem when N is
negative, as it will fall through the CASE and wind up printing -N,
which I dont think we want.

Gabriel Dos Reis writes:

> Hi,
> 
>   This thinko while caugh while building build-improvements with
> SBCL.  The error is that the value of abs(N) should not be part
> of the arguments to error() and should be computed separately.
> Fixed thusly.
> 
> Applied to build-improvements.
> Will apply silver SF/SVN shortly.
> 
> -- Gaby
> 2007-06-30  Gabriel Dos Reis  Gabriel Dos Reis
> 
> 	* vmlisp.lisp.pamphlet (MACRO-MISSINGARGS): Fix thinko.
> 
> *** vmlisp.lisp.pamphlet	(revision 22145)
> --- vmlisp.lisp.pamphlet	(local)
> *************** can be restored.
> *** 1855,1867 ****
>   (defun MACRO-MISSINGARGS (NAME ignore N)
>     (declare (ignore ignore))
>     (setq MACERRORCOUNT (+ 1 (eval 'MACERRORCOUNT)))
> !   (error (concatenate 'string (symbol-name NAME) " requires "
> !                        (if (minusp N) "at least " "exactly ")
> !                        (setq N (abs N))
> !                        (case N (0 "no") (1 "one") (2 "two") (3 "three")
> !                              (4 "four") (5 "five") (6 "six")
> !                              (t (princ-to-string N)))
> !                        (if (eq n 1) " argument," " arguments,"))))
>   
>   (defun MACERR (MESSAGE &rest ignore)
>     (declare (ignore ignore))
> --- 1855,1867 ----
>   (defun MACRO-MISSINGARGS (NAME ignore N)
>     (declare (ignore ignore))
>     (setq MACERRORCOUNT (+ 1 (eval 'MACERRORCOUNT)))
> !   (let ((nargs (abs N)))
> !     (error (concatenate 'string (symbol-name NAME) " requires "
> ! 			(if (minusp N) "at least " "exactly ")
> ! 			(case N (0 "no") (1 "one") (2 "two") (3 "three")
> ! 			      (4 "four") (5 "five") (6 "six")
> ! 			      (t (princ-to-string nargs)))
> ! 			(if (eq nargs 1) " argument," " arguments,")))))
>   
>   (defun MACERR (MESSAGE &rest ignore)
>     (declare (ignore ignore))

\start
Date: 30 Jun 2007 20:15:14 -0400
From: Stephen Wilson
To: list
Subject: Re: Fix thinko in src/interp/vmlisp.lisp
Cc: Gabriel Dos Reis

Hi Gaby,

Looks like I missed your commit.

MACERRORCOUNT appears unused and could be taken out as well.  No idea
what the (setq ... (.. (eval ..))) nonsense is about.  Any idea?

Thanks,
Steve


Stephen Wilson writes:

> Hi Gaby,
> 
> This is untested but I wanted to get it out before you commited.
> 
> Consider:
> 
> (defun macro-missingargs (name ignore n)
>     (declare (ignore ignore))
>     (setq macerrorcount (+ 1 (eval 'macerrorcount)))
>     (let ((nargs (abs n)))
>       (error "~A requires ~:[exactly~;at least~] ~D argument~P"
>              (symbol-name name) (minusp n) nargs nargs)))
> 
> Note also your version still (I think) as a problem when N is
> negative, as it will fall through the CASE and wind up printing -N,
> which I dont think we want.
> 
> Comments?
> 
> Thanks,
> Steve
> 
> 
> 
> Gabriel Dos Reis writes:
> 
> > Hi,
> > 
> >   This thinko while caugh while building build-improvements with
> > SBCL.  The error is that the value of abs(N) should not be part
> > of the arguments to error() and should be computed separately.
> > Fixed thusly.
> > 
> > Applied to build-improvements.
> > Will apply silver SF/SVN shortly.
> > 
> > -- Gaby
> > 2007-06-30  Gabriel Dos Reis  Gabriel Dos Reis
> > 
> > 	* vmlisp.lisp.pamphlet (MACRO-MISSINGARGS): Fix thinko.
> > 
> > *** vmlisp.lisp.pamphlet	(revision 22145)
> > --- vmlisp.lisp.pamphlet	(local)
> > *************** can be restored.
> > *** 1855,1867 ****
> >   (defun MACRO-MISSINGARGS (NAME ignore N)
> >     (declare (ignore ignore))
> >     (setq MACERRORCOUNT (+ 1 (eval 'MACERRORCOUNT)))
> > !   (error (concatenate 'string (symbol-name NAME) " requires "
> > !                        (if (minusp N) "at least " "exactly ")
> > !                        (setq N (abs N))
> > !                        (case N (0 "no") (1 "one") (2 "two") (3 "three")
> > !                              (4 "four") (5 "five") (6 "six")
> > !                              (t (princ-to-string N)))
> > !                        (if (eq n 1) " argument," " arguments,"))))
> >   
> >   (defun MACERR (MESSAGE &rest ignore)
> >     (declare (ignore ignore))
> > --- 1855,1867 ----
> >   (defun MACRO-MISSINGARGS (NAME ignore N)
> >     (declare (ignore ignore))
> >     (setq MACERRORCOUNT (+ 1 (eval 'MACERRORCOUNT)))
> > !   (let ((nargs (abs N)))
> > !     (error (concatenate 'string (symbol-name NAME) " requires "
> > ! 			(if (minusp N) "at least " "exactly ")
> > ! 			(case N (0 "no") (1 "one") (2 "two") (3 "three")
> > ! 			      (4 "four") (5 "five") (6 "six")
> > ! 			      (t (princ-to-string nargs)))
> > ! 			(if (eq nargs 1) " argument," " arguments,")))))
> >   
> >   (defun MACERR (MESSAGE &rest ignore)
> >     (declare (ignore ignore))
> > 
> > 
> > _______________________________________________
> > Axiom-developer mailing list
> > list
> > http://lists.nongnu.org/mailman/listinfo/axiom-developer
> 
> 
> 
> _______________________________________________
> Axiom-developer mailing list
> list
> http://lists.nongnu.org/mailman/listinfo/axiom-developer




\end{verbatim}
\eject
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cleardoublepage
%\phantomsection
\addcontentsline{toc}{chapter}{Bibliography}
\bibliographystyle{axiom}
\bibliography{axiom}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cleardoublepage
%\phantomsection
\addcontentsline{toc}{chapter}{Index}
\printindex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
