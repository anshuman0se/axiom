\documentclass{book}
%\newcommand{\VolumeName}{Volume 2: Axiom Users Guide}
%\input{bookheader.tex}
\pagenumbering{arabic}
\mainmatter
\setcounter{chapter}{0} % Chapter 1

\usepackage{makeidx}
\makeindex
\begin{document}
\begin{verbatim}
\start
Date: Sat, 1 Jun 2019 07:00:03 -0400
From: Tim Daly <axiomcas@gmail.com>
To: Jeremy Avigad <avigad@cmu.edu>, James Davenport <J.H.Davenport@bath.ac.uk>,
	axiom-dev <axiom-developer@nongnu.org>, axiomcas@gmail.com
Subject: [Axiom-developer] Competing on "features" is for game programmers,
 not mathematicians

I have an active discussion on Zulip / Lean (the general/syntax thread)

The issue is "long term stability".

Axiom code from the last century still compiles and gives the same answers.
Latex code from the last century still compiles and gives the same document.

I need to be able to write Definitions, Lemmas, and a Proof that will machine
check correctly at the "30 year horizon". It does me no good to use Lean to
prove Axiom's GCD algorithm if the proof fails next week.

Lisp had this problem and it was essentially solved with a standards effort
to create common lisp.

It does me no good to have a proof system where the tactics can change,
the syntax can change, and the kernel is unstable. I can't do long-term,
"30 year horizon" computational mathematics on that basis.

I think someone should raise the "common core proof standard effort"
so that all of the systems could import / export "raw" proofs (at a
minimum). Or at least a common core for systems using equivalent
logic rules.

It is reasonable to assume that a "proof" is a long-lived object and
that computational mathematical results are "stable".

Competing on "features" is for game programmers, not mathematicians.

Tim

\start
Date: Sat, 1 Jun 2019 15:36:47 -0400
From: Tim Daly <axiomcas@gmail.com>
To: James Davenport <masjhd@bath.ac.uk>
Subject: Re: [Axiom-developer] Competing on "features" is for game
Cc: Jeremy Avigad <avigad@cmu.edu>, axiom-dev <axiom-developer@nongnu.org>, 
	James Davenport <jhd@cs.bath.ac.uk>
 programmers, not mathematicians

Axiom has a "30 Year Horizon" project goal, looking to develop the
techniques and technology for reliable, proven computational
mathematics.

I'm trying to prove Axiom Sane (rational, judicious, sound, logical)
by constructing axioms and specifications for functions (actually,
only the GCD functions since I'm not gonna live long enough to do
much more :-) )

It is clearlly important to construct proofs that can be checked
at compile time, every time, to ensure that Axiom is still
mathematically sound despite changes.

Apparently this kind of "30 Year Horizon" stability isn't a project
goal for a lot of the systems.I find this suprising since Gentzen's
rules seem like a solid logic kernel you'd have to implement.

Robinson's resolution paper was in 1965 so proof technology is as
old as computer algebra (SAINT/SIN). After  50+ years, it seems
reasonable to think about standards.

Both of you have influence across both areas of computational
mathematics. Perhaps you can find consensus for at least the
beginnings of an effort to consider cooperation on a standard.

Tim



On 6/1/19, James Davenport <masjhd@bath.ac.uk> wrote:
> Especially "non-upwards-compatible" features. There was a discussion at Big
> Proof 2019 about the fragility of Big Proofs, and indeed it was asked
> whether the Classification of Finite Simple Groups was still proved. I THINK
> the question was slightl tongue-in-cheek, but nevertheless it's a good
> question.
>
>
> James Davenport
> Hebron & Medlock Professor of Information Technology, University of Bath
> National Teaching Fellow 2014
> OpenMath Content Dictionary Editor
> Former Fulbright CyberSecurity Scholar (at New York University)
> Vice-President and Academy Chair, British Computer Society
> ________________________________
> From: Tim Daly <axiomcas@gmail.com>
> Sent: 01 June 2019 12:00:03
> To: Jeremy Avigad; James Davenport; axiom-dev; axiomcas@gmail.com
> Subject: Competing on "features" is for game programmers, not
> mathematicians
>
> I have an active discussion on Zulip / Lean (the general/syntax thread)
>
> The issue is "long term stability".
>
> Axiom code from the last century still compiles and gives the same answers.
> Latex code from the last century still compiles and gives the same
> document.
>
> I need to be able to write Definitions, Lemmas, and a Proof that will
> machine
> check correctly at the "30 year horizon". It does me no good to use Lean to
> prove Axiom's GCD algorithm if the proof fails next week.
>
> Lisp had this problem and it was essentially solved with a standards effort
> to create common lisp.
>
> It does me no good to have a proof system where the tactics can change,
> the syntax can change, and the kernel is unstable. I can't do long-term,
> "30 year horizon" computational mathematics on that basis.
>
> I think someone should raise the "common core proof standard effort"
> so that all of the systems could import / export "raw" proofs (at a
> minimum). Or at least a common core for systems using equivalent
> logic rules.
>
> It is reasonable to assume that a "proof" is a long-lived object and
> that computational mathematical results are "stable".
>
> Competing on "features" is for game programmers, not mathematicians.
>
> Tim
>

\start
Date: Wed, 5 Jun 2019 11:38:27 -0400
From: Eugene Surowitz <surow@verizon.net>
To: Tim Daly <axiomcas@gmail.com>, Jeremy Avigad <avigad@cmu.edu>,
	James Davenport <J.H.Davenport@bath.ac.uk>,
	axiom-dev <axiom-developer@nongnu.org>
Subject: Re: [Axiom-developer] Competing on "features" is for game
 programmers, not mathematicians

An amusing anecdote about proofs can be found in
"My Brain Is Open" by Bruce Schechter; the subtitle is
'The Mathematical Journeys of Paul Erdos'.

At the bottom of p.20 Erdos asks Andrew Vazsonyi
how many proofs of the Pythagorean theorem did he know.
Vazsonyi's answer was that he only knew one.
Erdos claimed to know 37.

A proven theorem is an invariant object.

Long lived and stable are different notions
more applicable to computer programs and systems
as you rightly point out.

Cheers, Gene


On 6/1/2019 7:00 AM, Tim Daly wrote:
> I have an active discussion on Zulip / Lean (the general/syntax thread)
> 
> The issue is "long term stability".
> 
> Axiom code from the last century still compiles and gives the same answers.
> Latex code from the last century still compiles and gives the same document.
> 
> I need to be able to write Definitions, Lemmas, and a Proof that will machine
> check correctly at the "30 year horizon". It does me no good to use Lean to
> prove Axiom's GCD algorithm if the proof fails next week.
> 
> Lisp had this problem and it was essentially solved with a standards effort
> to create common lisp.
> 
> It does me no good to have a proof system where the tactics can change,
> the syntax can change, and the kernel is unstable. I can't do long-term,
> "30 year horizon" computational mathematics on that basis.
> 
> I think someone should raise the "common core proof standard effort"
> so that all of the systems could import / export "raw" proofs (at a
> minimum). Or at least a common core for systems using equivalent
> logic rules.
> 
> It is reasonable to assume that a "proof" is a long-lived object and
> that computational mathematical results are "stable".
> 
> Competing on "features" is for game programmers, not mathematicians.
> 
> Tim
> 

\start
Date: Fri, 7 Jun 2019 21:23:35 -0400
From: Tim Daly <axiomcas@gmail.com>
To: axiom-dev <axiom-developer@nongnu.org>, axiomdev <axiomdev@gmail.com>
Subject: [Axiom-developer] Program Synthesis and Computer Algebra

One interesting side-discussion of proving Axiom sane is that there
is a connection to the area of program synthesis.

At the moment, the program synthesis field is in a very early stage.
See, for instance [0] which generates algebra problems from specs
by using "similarity".

In the proof area of computational mathematics, some systems are
able to generate programs from the proof.

So in the computer algebra branch of computational mathematics
it is likely that interesting algorithms can be generated.

In particular, once it is possible to generate specifications from
Axiom's Category and Domain decorations, it should be possible
to construct specifications and then generate programs from these
specifications that are "Axiom compatible".

This will likely be a future research path as a direct spinoff of the
Axiom proof effort.

Tim


[0] Singh, Rohit, Gulwani, Sumit, and Rajamani, Sriram
"Automatically Generating Algebra Problems" AAAI'12 (2012)

\start
Date: Tue, 11 Jun 2019 06:58:42 -0400
From: Tim Daly <axiomcas@gmail.com>
To: axiom-dev <axiom-developer@nongnu.org>, axiomdev <axiomdev@gmail.com>
Subject: [Axiom-developer] The Coming Persistence Apocalypse

You are probably not old enough to remember 'core' memory.
It used to be the case that you could turn off a computer and
then, when you turned it on again, the memory image was
exactly remembered (in "magnetic core") and your program
would continue running exactly as though nothing happened.
Of course, a BIG memory machine had 8,192 bytes.

NVRAM (non-volitile RAM) is coming, in near terabyte sizes.
Unlike DRAM (dynamic RAM) it remembers everything even
though it has no power.

That changes everything we know about computing.
https://www.youtube.com/watch?v=kBXbump35dg
https://www.youtube.com/watch?v=X8nMsabFD2w

For example, data structures no longer needs a "disk
representation" since they never leave memory. On the
other hand, neither does a mangled data structure or a
memory leak.

Lisp is well suited for this environment. Lisp with a form of
persistent data structures (Okasaki)  would be even more
interesting.

This has interesting implications for the new "Sane" Axiom
compiler / interpreter. For example, an "input" file actually
resides in interpreter memory at all times.

If nothing else, these videos are an interesting glimpse of
near-future computing issues.

Tim

\start
Date: Tue, 11 Jun 2019 09:33:54 -0400
From: Tim Daly <axiomcas@gmail.com>
To: axiom-dev <axiom-developer@nongnu.org>, axiomdev <axiomdev@gmail.com>
Subject: [Axiom-developer] Compiling to Categories

Well, THIS is interesting. By compiling programs to categories it is
possible to do things like computing program derivatives. Watch
the video.
http://media.podcasts.ox.ac.uk/comlab/comsci/2017-09-04-ICFP2017/2017-09-04-ICFP2017-day2-pm-08.mp4

and the website:
http://conal.net/papers/compiling-to-categories/

This introduces an interesting wrinkle in computer algebra.

Tim

\start
Date: Tue, 11 Jun 2019 20:10:24 +0300
From: Henri Tuhola <henri.tuhola@gmail.com>
To: Tim Daly <axiomcas@gmail.com>
Subject: Re: [Axiom-developer] The Coming Persistence Apocalypse

I've been examining formal proving in linear logic for the reason that I am
tired of having my programs crash without a good way to plan the clean up.

I have an idea going about building a programming language around proof
presentation of programs. Eg. You'd encode addition with: (n && n (+);n).
The system would print it into a proof with semicolon replaced by a
horizontal line.

There seem to be few benefits from doing it like this. It helps in focusing
on what you prove with the program. You get more proof irrelevance and the
programming environment can therefore help more in writing the programs.

Did a little experiment with proving and modeling the hanoi puzzle on
paper. It ended up describing movement like this:

forall a, b, c:disc. forall i, j:peg,
(top(a, i), top(c, j), above(a, b), !(a<c)) -o (top(b, I), top(a, j),
above(a, c))

Next you'd compose this into itself to get more proofs and end up with an
induction scheme to move any stack anywhere. It also holds for pegs with no
items as empty is not above anything else.

Induction would be also used to describe the stacks of discs in the puzzle.
It'd be:

exists a:disc. stack(a) =3D
  (exists b:disc. above(a, b), !(a<b), stack(b)) | !(forall b:disc. b<a))

Eg. stack(=C3=B8) =3D !(forall a:disc. a<=C3=B8)

The type notation would be sort of like rewriting/space saving rules. I
haven't decided up on how types are represented yet. I think this recursion
scheme is not good but didn't figure a better out yet.

Some of these ideas do remind me from Axiom CAS. The types seem to bind
down the meaning here as well and actions seem to be conveniently defined
on types.

Also have ideas on logic programming env that interleaves on this and uses
the same system of logic. It could be used to do programs that only run if
they succeed to satisfy the goal.

It takes a bit of effort to make the programming env to test these ideas.
I've been working on this for a while now.

-- Henri Tuhola

ti 11. kes=C3=A4k. 2019 klo 15.06 Tim Daly <axiomcas@gmail.com> kirjoitti:

> You are probably not old enough to remember 'core' memory.
> It used to be the case that you could turn off a computer and
> then, when you turned it on again, the memory image was
> exactly remembered (in "magnetic core") and your program
> would continue running exactly as though nothing happened.
> Of course, a BIG memory machine had 8,192 bytes.
>
> NVRAM (non-volitile RAM) is coming, in near terabyte sizes.
> Unlike DRAM (dynamic RAM) it remembers everything even
> though it has no power.
>
> That changes everything we know about computing.
> https://www.youtube.com/watch?v=3DkBXbump35dg
> https://www.youtube.com/watch?v=3DX8nMsabFD2w
>
> For example, data structures no longer needs a "disk
> representation" since they never leave memory. On the
> other hand, neither does a mangled data structure or a
> memory leak.
>
> Lisp is well suited for this environment. Lisp with a form of
> persistent data structures (Okasaki)  would be even more
> interesting.
>
> This has interesting implications for the new "Sane" Axiom
> compiler / interpreter. For example, an "input" file actually
> resides in interpreter memory at all times.
>
> If nothing else, these videos are an interesting glimpse of
> near-future computing issues.
>
> Tim
>


\start
Date: Wed, 19 Jun 2019 07:18:31 -0400
From: Tim Daly <axiomcas@gmail.com>
To: axiom-dev <axiom-developer@nongnu.org>, Tim Daly <axiomcas@gmail.com>
Subject: [Axiom-developer] Axiom's Sane redesign musings

Sane: "rational, coherent, judicious, sound"

Axiom is computational mathematics, of course. The effort to
Prove Axiom Sane involves merging computer algebra and proof
technology so Axiom's algorithms have associated proofs.

The union of these two fields has made it obvious how far behind
Axiom has fallen. Mathematicians and some computer languages
(e.g. Haskell) have started to converge on some unifying ideas.

As a result, the new Sane compiler and interpreter needs to
consider the current environment that mathematicians expect.
This falls into several areas.

1) SYNTAX

It is clear that Axiom's syntax and user interface has not kept
up with the proof technology. A trivial example is a signature.
Axiom likes:

   foo : (a,b) -> c

whereas Lean / Coq / or even Haskell prefers

   foo: a -> b -> c

Given that many systems (e.g. Haskell) use the second syntax
we need to consider adopting this more widely accepted syntax.

2) PROOF and SPECIFICATIONS

And, obviously, Axiom does not support 'axiom', 'lemma',
'corollary', nor any specification language, or any language
for proof support (e.g. 'invariant').

Mathematicians have these tools readily available in many
systems today.

3) USER INTERFACE

Axiom's command line interface and hyperdoc were fine for its
time but Lean and Coq use a browser. For example, in Lean:

https://leanprover.github.io/tutorial/

or in Coq:

https://jscoq.github.io/

The combination of a browser, interactive development, and
"immediate documentation" merges a lot of Axiom's goals.

4) CATEGORY STRUCTURE

William Farmer and Jacques Carette (McMaster University)
have the notion of "tiny theories". The basic idea (in Axiom
speak) is that each Category should only introduce a single
signature or a single axiom (e.g. commutativity). It seems
possible to restructure the Category hierarchy to use this model
wilthout changing the end result.

5) BIFORM THEORIES

Farmer and Carette also have the notion of a 'biform theory'
which is a combination of code and proof. This is obviously
the same idea behind the Sane effort.

6) INTERACTIVITY

As mentioned in (3) above, the user interface needs to support
much more interactive program development. Error messages
ought to point at the suspected code. This involves rewriting
the compiler and interpreter to better interface with these tools.

Axiom already talks to a browser front end (Volume 11)
interactively but the newer combination of documentation
and interaction needs to be supported.

Sage provides interactivity for some things but does not
(as far as I know) support the Lean-style browser interface.

7) ALGORITHMS

Axiom's key strength and its key contribution is its collection
of algorithms. The proof systems strive for proofs but can't
do simple computations fast.

The proof systems also cannot trust "Oracle" systems, since
they remain unproven.

When Axiom's algorithms are proven, they provide the Oracle.

8) THE Sane EFFORT

Some of the changes above are cosmetic (e.g. syntax), some
are "additive" (e.g. lemma, corollary), some are just a restructure
(e.g. "tiny theory" categories).

Some of the changes are 'just programming', such as using
the browser to merge the command line and hyperdoc. This
involves changing the interpreter and compiler to deliver better
and more focused feedback All of that is "just a matter of
programming".

The fundamental changes like merging a specification
language and underlying proof machinery are a real challenge.
"Layering Axiom" onto a trusted core is a real challenge but
(glacial) progress is being made.

The proof systems are getting better. They lack long-term
stability (so far) and they lack Axiom's programming ability
(so far). But merging computer algebra and proof systems
seems to me to be possible with a focused effort.

Due to its design and structure, Axiom seems the perfect
platform for this merger.

Work on each of these areas is "in process" (albeit slowly).
The new Sane compiler is "on the path" to support all of these
goals.

9) THE "30 Year Horizion"

Axiom either converges with the future directions by becoming
a proven and trusted mathematical tool ... or it dies.

Axiom dies? ... As they say in the Navy "not on my watch".

Tim

\start
Date: Wed, 19 Jun 2019 16:29:31 +0100
From: Martin Baker <ax87438@martinb.com>
To: Tim Daly <axiomcas@gmail.com>, axiom-dev <axiom-developer@nongnu.org>
Subject: Re: [Axiom-developer] Axiom's Sane redesign musings

On 19/06/2019 12:18, Tim Daly wrote:
> The effort to
> Prove Axiom Sane involves merging computer algebra and proof
> technology so Axiom's algorithms have associated proofs.

Tim,

Are there some fundamental compromises that have to be made when 
combining computer algebra and proof technology?

For instance in proof assistants, like Coq, equations are types for 
instance:

x = x + 0

is a proposition which, by Curry-Howard, can be represented as a type. 
To prove the proposition we have to find an inhabitant of the type (Refl).

But in computer algebra I would have thought this equation would be an 
element of some Equation type (I'm skipping over a lot of details).

Do you think both of these approaches could be brought together in a 
consistent and elegant way?

Also my (limited) understanding is that Coq prevents inconsistencies 
which makes it not Turing complete and therefore cant do everything 
Axiom can do?

Martin

\start
Date: Wed, 19 Jun 2019 13:02:25 -0400
From: Tim Daly <axiomcas@gmail.com>
To: axiom-dev <axiom-developer@nongnu.org>, Tim Daly <axiomcas@gmail.com>
Subject: Re: [Axiom-developer] Axiom's Sane redesign musings

Martin,

> Are there some fundamental compromises that have to be made when combining computer > algebra and proof technology?

> For instance in proof assistants, like Coq, equations are types for instance:

> x = x + 0

> is a proposition which, by Curry-Howard, can be represented as a type. To prove the
> proposition we have to find an inhabitant of the type (Refl).

> But in computer algebra I would have thought this equation would be an element of
> some Equation type (I'm skipping over a lot of details).

> Do you think both of these approaches could be brought together in a
> consistent and elegant way?

> Also my (limited) understanding is that Coq prevents inconsistencies which
> makes it not Turing complete and therefore cant do everything Axiom can do?

Martin,

There are many problems with the marriage of logic and algebra. For instance,
the logic systems want proof of termination which is usually not
possible. Often,
though, a partial proof that does not guarantee termination is interesting and
sufficient. TLA provides some possible ideas in this direction.

Another problem is that in the generality of dependent types, full
type resolution
is undecidable (hence, a lot of the heuristics built into Axiom's interpreter).
Still there are interesting discussions of programs as proof objects ongoing at
the moment on the Lean discussion thread
https://leanprover.zulipchat.com/#

Still other problems arise in equational reasoning or probablistic algorithms.
I have looked at (and not really understood well) logics for these.

On the other hand, things like the Groebner Basis algorithm have been proven
in Coq. The technology, and the basic axioms, are gathering greater power.

In particular, since Axiom has a strong scaffolding of abstract algebra, it is
better suited for proofs than other systems. The fact that Axiom's compiler
insists on type information makes it somewhat more likely to be provable.

I have a very limited project goal of proving just the GCD algorithms in Axiom.

The idea is to create a "thin thread" through all of the issues so that they can
be attacked in more detail by later work. I've been gathering bits and pieces
of GCD related items from the literature. See Volume 13 for the current state
(mostly research notes and snippets to be reviewed)
https://github.com/daly/PDFS/blob/master/bookvol13.pdf

The idea is to decorate the categories with their respective axioms. Then to
decorate the domains with their axioms. Next to write specifications for the
function implementations. Then finding invariants, pre- and post-conditions,
etc. Finally, to generate a proof that can be automatically checked. So each
function has a deep pile of inheritated informaion to help the proof.

For example, a GCD algorithm in NonNegativeInteger already has the
ability to assume non-negative types. And it inherits all the axioms that
come with being a GCDDomain.

The fact that computer algebra really is a form of mathematics (as opposed
to, say proving a compiler) gives me hope that progress is possible, even if
difficult.

Do I know how to cross the "x=x+0" type vs equation form? No, but
this is research so I won't know until I know :-)

Tim

On 6/19/19, Tim Daly <axiomcas@gmail.com> wrote:
> Sane: "rational, coherent, judicious, sound"
>
> Axiom is computational mathematics, of course. The effort to
> Prove Axiom Sane involves merging computer algebra and proof
> technology so Axiom's algorithms have associated proofs.
>
> The union of these two fields has made it obvious how far behind
> Axiom has fallen. Mathematicians and some computer languages
> (e.g. Haskell) have started to converge on some unifying ideas.
>
> As a result, the new Sane compiler and interpreter needs to
> consider the current environment that mathematicians expect.
> This falls into several areas.
>
> 1) SYNTAX
>
> It is clear that Axiom's syntax and user interface has not kept
> up with the proof technology. A trivial example is a signature.
> Axiom likes:
>
>    foo : (a,b) -> c
>
> whereas Lean / Coq / or even Haskell prefers
>
>    foo: a -> b -> c
>
> Given that many systems (e.g. Haskell) use the second syntax
> we need to consider adopting this more widely accepted syntax.
>
> 2) PROOF and SPECIFICATIONS
>
> And, obviously, Axiom does not support 'axiom', 'lemma',
> 'corollary', nor any specification language, or any language
> for proof support (e.g. 'invariant').
>
> Mathematicians have these tools readily available in many
> systems today.
>
> 3) USER INTERFACE
>
> Axiom's command line interface and hyperdoc were fine for its
> time but Lean and Coq use a browser. For example, in Lean:
>
> https://leanprover.github.io/tutorial/
>
> or in Coq:
>
> https://jscoq.github.io/
>
> The combination of a browser, interactive development, and
> "immediate documentation" merges a lot of Axiom's goals.
>
> 4) CATEGORY STRUCTURE
>
> William Farmer and Jacques Carette (McMaster University)
> have the notion of "tiny theories". The basic idea (in Axiom
> speak) is that each Category should only introduce a single
> signature or a single axiom (e.g. commutativity). It seems
> possible to restructure the Category hierarchy to use this model
> wilthout changing the end result.
>
> 5) BIFORM THEORIES
>
> Farmer and Carette also have the notion of a 'biform theory'
> which is a combination of code and proof. This is obviously
> the same idea behind the Sane effort.
>
> 6) INTERACTIVITY
>
> As mentioned in (3) above, the user interface needs to support
> much more interactive program development. Error messages
> ought to point at the suspected code. This involves rewriting
> the compiler and interpreter to better interface with these tools.
>
> Axiom already talks to a browser front end (Volume 11)
> interactively but the newer combination of documentation
> and interaction needs to be supported.
>
> Sage provides interactivity for some things but does not
> (as far as I know) support the Lean-style browser interface.
>
> 7) ALGORITHMS
>
> Axiom's key strength and its key contribution is its collection
> of algorithms. The proof systems strive for proofs but can't
> do simple computations fast.
>
> The proof systems also cannot trust "Oracle" systems, since
> they remain unproven.
>
> When Axiom's algorithms are proven, they provide the Oracle.
>
> 8) THE Sane EFFORT
>
> Some of the changes above are cosmetic (e.g. syntax), some
> are "additive" (e.g. lemma, corollary), some are just a restructure
> (e.g. "tiny theory" categories).
>
> Some of the changes are 'just programming', such as using
> the browser to merge the command line and hyperdoc. This
> involves changing the interpreter and compiler to deliver better
> and more focused feedback All of that is "just a matter of
> programming".
>
> The fundamental changes like merging a specification
> language and underlying proof machinery are a real challenge.
> "Layering Axiom" onto a trusted core is a real challenge but
> (glacial) progress is being made.
>
> The proof systems are getting better. They lack long-term
> stability (so far) and they lack Axiom's programming ability
> (so far). But merging computer algebra and proof systems
> seems to me to be possible with a focused effort.
>
> Due to its design and structure, Axiom seems the perfect
> platform for this merger.
>
> Work on each of these areas is "in process" (albeit slowly).
> The new Sane compiler is "on the path" to support all of these
> goals.
>
> 9) THE "30 Year Horizion"
>
> Axiom either converges with the future directions by becoming
> a proven and trusted mathematical tool ... or it dies.
>
> Axiom dies? ... As they say in the Navy "not on my watch".
>
> Tim
>

\start
Date: Tue, 25 Jun 2019 17:44:03 +0000
From: William Sit <wsit@ccny.cuny.edu>
To: Tim Daly <axiomcas@gmail.com>, axiom-dev <axiom-developer@nongnu.org>
Subject: Re: [Axiom-developer] [EXTERNAL] Re: Axiom's Sane redesign musings

=0A=
Dear Martin and Tim:=0A=
=0A=
The expression  x =3D x + 0, whether treated as a type or an equation, can =
only make sense when x, =3D, + and 0 are clearly typed and defined. It make=
s little sense to me that this, as an equation, can be "proved" to be valid=
 universally (that is, without the definition of, say +). For example, if w=
e are in a domain where + is defined as max, or as min, or as the binary lo=
gic operator "and", then the expression is not an identity for all values x=
 in the domain. If + is the usual addition, or the logic operatior "or", th=
en the expression is a true identity and can be proved (more or less from d=
efinitions). In Axiom, if valid, these are simply stated as properties of t=
he domain or category as in "has ...".=0A=
=0A=
I assume this is well-known and perhaps that is what Martin meant by "(I'm =
skipping over a lot of details)". I am ignorant of type theory and often co=
nfused by terms like type, equation (equation type?), identity, and even pr=
oposition (like x =3D x + 0 is an identity) as used in proof theories. Plea=
se ignore this message if the first paragraph is irrelevant to this thread.=
=0A=
=0A=
William Sit=0A=
Professor Emeritus=0A=
Department of Mathematics=0A=
The City College of The City University of New York=0A=
New York, NY 10031=0A=
homepage: wsit.ccny.cuny.edu=0A=
=0A=
________________________________________=0A=
From: Axiom-developer <axiom-developer-bounces+wyscc=3Dsci.ccny.cuny.edu@no=
ngnu.org> on behalf of Tim Daly <axiomcas@gmail.com>=0A=
Sent: Wednesday, June 19, 2019 1:02 PM=0A=
To: axiom-dev; Tim Daly=0A=
Subject: [EXTERNAL] Re: [Axiom-developer] Axiom's Sane redesign musings=0A=
=0A=
Martin,=0A=
=0A=
> Are there some fundamental compromises that have to be made when combinin=
g computer > algebra and proof technology?=0A=
=0A=
> For instance in proof assistants, like Coq, equations are types for insta=
nce:=0A=
=0A=
> x =3D x + 0=0A=
=0A=
> is a proposition which, by Curry-Howard, can be represented as a type. To=
 prove the=0A=
> proposition we have to find an inhabitant of the type (Refl).=0A=
=0A=
> But in computer algebra I would have thought this equation would be an el=
ement of=0A=
> some Equation type (I'm skipping over a lot of details).=0A=
=0A=
> Do you think both of these approaches could be brought together in a=0A=
> consistent and elegant way?=0A=
=0A=
> Also my (limited) understanding is that Coq prevents inconsistencies whic=
h=0A=
> makes it not Turing complete and therefore cant do everything Axiom can d=
o?=0A=
=0A=
Martin,=0A=
=0A=
There are many problems with the marriage of logic and algebra. For instanc=
e,=0A=
the logic systems want proof of termination which is usually not=0A=
possible. Often,=0A=
though, a partial proof that does not guarantee termination is interesting =
and=0A=
sufficient. TLA provides some possible ideas in this direction.=0A=
=0A=
Another problem is that in the generality of dependent types, full=0A=
type resolution=0A=
is undecidable (hence, a lot of the heuristics built into Axiom's interpret=
er).=0A=
Still there are interesting discussions of programs as proof objects ongoin=
g at=0A=
the moment on the Lean discussion thread=0A=
https://urldefense.proofpoint.com/v2/url?u=3Dhttps-3A__leanprover.zulipchat=
.com_-23&d=3DDwIGaQ&c=3D4NmamNZG3KTnUCoC6InoLJ6KV1tbVKrkZXHRwtIMGmo&r=3DqW9=
SUYRDo6sWEVPpx7wwWYZ79PdSWMRxNZvTih0Bkxc&m=3DBh77WgNdFtJTZCN46189mNhezS-_JX=
cBwUWxnNPRF_8&s=3Du7sojPwgc1fuWoQpKPwsjxjH98p64z3RQNZlwxBTLPQ&e=3D=0A=
=0A=
Still other problems arise in equational reasoning or probablistic algorith=
ms.=0A=
I have looked at (and not really understood well) logics for these.=0A=
=0A=
On the other hand, things like the Groebner Basis algorithm have been prove=
n=0A=
in Coq. The technology, and the basic axioms, are gathering greater power.=
=0A=
=0A=
In particular, since Axiom has a strong scaffolding of abstract algebra, it=
 is=0A=
better suited for proofs than other systems. The fact that Axiom's compiler=
=0A=
insists on type information makes it somewhat more likely to be provable.=
=0A=
=0A=
I have a very limited project goal of proving just the GCD algorithms in Ax=
iom.=0A=
=0A=
The idea is to create a "thin thread" through all of the issues so that the=
y can=0A=
be attacked in more detail by later work. I've been gathering bits and piec=
es=0A=
of GCD related items from the literature. See Volume 13 for the current sta=
te=0A=
(mostly research notes and snippets to be reviewed)=0A=
https://urldefense.proofpoint.com/v2/url?u=3Dhttps-3A__github.com_daly_PDFS=
_blob_master_bookvol13.pdf&d=3DDwIGaQ&c=3D4NmamNZG3KTnUCoC6InoLJ6KV1tbVKrkZ=
XHRwtIMGmo&r=3DqW9SUYRDo6sWEVPpx7wwWYZ79PdSWMRxNZvTih0Bkxc&m=3DBh77WgNdFtJT=
ZCN46189mNhezS-_JXcBwUWxnNPRF_8&s=3DmaYsCHxZ4fjQEYua_1NfaxuO785JXAJlC4YRps-=
YFwQ&e=3D=0A=
=0A=
The idea is to decorate the categories with their respective axioms. Then t=
o=0A=
decorate the domains with their axioms. Next to write specifications for th=
e=0A=
function implementations. Then finding invariants, pre- and post-conditions=
,=0A=
etc. Finally, to generate a proof that can be automatically checked. So eac=
h=0A=
function has a deep pile of inheritated informaion to help the proof.=0A=
=0A=
For example, a GCD algorithm in NonNegativeInteger already has the=0A=
ability to assume non-negative types. And it inherits all the axioms that=
=0A=
come with being a GCDDomain.=0A=
=0A=
The fact that computer algebra really is a form of mathematics (as opposed=
=0A=
to, say proving a compiler) gives me hope that progress is possible, even i=
f=0A=
difficult.=0A=
=0A=
Do I know how to cross the "x=3Dx+0" type vs equation form? No, but=0A=
this is research so I won't know until I know :-)=0A=
=0A=
Tim=0A=
=0A=
On 6/19/19, Tim Daly <axiomcas@gmail.com> wrote:=0A=
> Sane: "rational, coherent, judicious, sound"=0A=
>=0A=
> Axiom is computational mathematics, of course. The effort to=0A=
> Prove Axiom Sane involves merging computer algebra and proof=0A=
> technology so Axiom's algorithms have associated proofs.=0A=
>=0A=
> The union of these two fields has made it obvious how far behind=0A=
> Axiom has fallen. Mathematicians and some computer languages=0A=
> (e.g. Haskell) have started to converge on some unifying ideas.=0A=
>=0A=
> As a result, the new Sane compiler and interpreter needs to=0A=
> consider the current environment that mathematicians expect.=0A=
> This falls into several areas.=0A=
>=0A=
> 1) SYNTAX=0A=
>=0A=
> It is clear that Axiom's syntax and user interface has not kept=0A=
> up with the proof technology. A trivial example is a signature.=0A=
> Axiom likes:=0A=
>=0A=
>    foo : (a,b) -> c=0A=
>=0A=
> whereas Lean / Coq / or even Haskell prefers=0A=
>=0A=
>    foo: a -> b -> c=0A=
>=0A=
> Given that many systems (e.g. Haskell) use the second syntax=0A=
> we need to consider adopting this more widely accepted syntax.=0A=
>=0A=
> 2) PROOF and SPECIFICATIONS=0A=
>=0A=
> And, obviously, Axiom does not support 'axiom', 'lemma',=0A=
> 'corollary', nor any specification language, or any language=0A=
> for proof support (e.g. 'invariant').=0A=
>=0A=
> Mathematicians have these tools readily available in many=0A=
> systems today.=0A=
>=0A=
> 3) USER INTERFACE=0A=
>=0A=
> Axiom's command line interface and hyperdoc were fine for its=0A=
> time but Lean and Coq use a browser. For example, in Lean:=0A=
>=0A=
> https://urldefense.proofpoint.com/v2/url?u=3Dhttps-3A__leanprover.github.=
io_tutorial_&d=3DDwIGaQ&c=3D4NmamNZG3KTnUCoC6InoLJ6KV1tbVKrkZXHRwtIMGmo&r=
=3DqW9SUYRDo6sWEVPpx7wwWYZ79PdSWMRxNZvTih0Bkxc&m=3DBh77WgNdFtJTZCN46189mNhe=
zS-_JXcBwUWxnNPRF_8&s=3DEM0zfm6XLk9cSYEzwVYO2vVnvmksn6UcM0KkUGyu_Og&e=3D=0A=
>=0A=
> or in Coq:=0A=
>=0A=
> https://urldefense.proofpoint.com/v2/url?u=3Dhttps-3A__jscoq.github.io_&d=
=3DDwIGaQ&c=3D4NmamNZG3KTnUCoC6InoLJ6KV1tbVKrkZXHRwtIMGmo&r=3DqW9SUYRDo6sWE=
VPpx7wwWYZ79PdSWMRxNZvTih0Bkxc&m=3DBh77WgNdFtJTZCN46189mNhezS-_JXcBwUWxnNPR=
F_8&s=3DvLHZcW4aiLGGw3-bGeVoO4TFa3CBy3qIAlOIbRSbwf8&e=3D=0A=
>=0A=
> The combination of a browser, interactive development, and=0A=
> "immediate documentation" merges a lot of Axiom's goals.=0A=
>=0A=
> 4) CATEGORY STRUCTURE=0A=
>=0A=
> William Farmer and Jacques Carette (McMaster University)=0A=
> have the notion of "tiny theories". The basic idea (in Axiom=0A=
> speak) is that each Category should only introduce a single=0A=
> signature or a single axiom (e.g. commutativity). It seems=0A=
> possible to restructure the Category hierarchy to use this model=0A=
> wilthout changing the end result.=0A=
>=0A=
> 5) BIFORM THEORIES=0A=
>=0A=
> Farmer and Carette also have the notion of a 'biform theory'=0A=
> which is a combination of code and proof. This is obviously=0A=
> the same idea behind the Sane effort.=0A=
>=0A=
> 6) INTERACTIVITY=0A=
>=0A=
> As mentioned in (3) above, the user interface needs to support=0A=
> much more interactive program development. Error messages=0A=
> ought to point at the suspected code. This involves rewriting=0A=
> the compiler and interpreter to better interface with these tools.=0A=
>=0A=
> Axiom already talks to a browser front end (Volume 11)=0A=
> interactively but the newer combination of documentation=0A=
> and interaction needs to be supported.=0A=
>=0A=
> Sage provides interactivity for some things but does not=0A=
> (as far as I know) support the Lean-style browser interface.=0A=
>=0A=
> 7) ALGORITHMS=0A=
>=0A=
> Axiom's key strength and its key contribution is its collection=0A=
> of algorithms. The proof systems strive for proofs but can't=0A=
> do simple computations fast.=0A=
>=0A=
> The proof systems also cannot trust "Oracle" systems, since=0A=
> they remain unproven.=0A=
>=0A=
> When Axiom's algorithms are proven, they provide the Oracle.=0A=
>=0A=
> 8) THE Sane EFFORT=0A=
>=0A=
> Some of the changes above are cosmetic (e.g. syntax), some=0A=
> are "additive" (e.g. lemma, corollary), some are just a restructure=0A=
> (e.g. "tiny theory" categories).=0A=
>=0A=
> Some of the changes are 'just programming', such as using=0A=
> the browser to merge the command line and hyperdoc. This=0A=
> involves changing the interpreter and compiler to deliver better=0A=
> and more focused feedback All of that is "just a matter of=0A=
> programming".=0A=
>=0A=
> The fundamental changes like merging a specification=0A=
> language and underlying proof machinery are a real challenge.=0A=
> "Layering Axiom" onto a trusted core is a real challenge but=0A=
> (glacial) progress is being made.=0A=
>=0A=
> The proof systems are getting better. They lack long-term=0A=
> stability (so far) and they lack Axiom's programming ability=0A=
> (so far). But merging computer algebra and proof systems=0A=
> seems to me to be possible with a focused effort.=0A=
>=0A=
> Due to its design and structure, Axiom seems the perfect=0A=
> platform for this merger.=0A=
>=0A=
> Work on each of these areas is "in process" (albeit slowly).=0A=
> The new Sane compiler is "on the path" to support all of these=0A=
> goals.=0A=
>=0A=
> 9) THE "30 Year Horizion"=0A=
>=0A=
> Axiom either converges with the future directions by becoming=0A=
> a proven and trusted mathematical tool ... or it dies.=0A=
>=0A=
> Axiom dies? ... As they say in the Navy "not on my watch".=0A=
>=0A=
> Tim=0A=
>=0A=
=0A=

\start
Date: Tue, 25 Jun 2019 14:28:22 -0400
From: Tim Daly <axiomcas@gmail.com>
To: William Sit <wsit@ccny.cuny.edu>, Martin Baker <ax87438@martinb.com>
Subject: Re: [Axiom-developer] [EXTERNAL] Re: Axiom's Sane redesign musings

It is all rather confusing. There are well over 100 "logics".

Equational logic, or equational reasoning, is a very restricted
logic having only equality as an operation.

An alternative interpretation would be a substitution-style
logic where equals can be substituted for equals as one of
the operations.

The expression x =3D x + 0 isn't meaningful in isolation. In
Axiom it would have surrounding axioms (in the coming
Sane version), one of which is that in some cases, the
zero is a unit.

Note that this is not an assignment operation but one whose
target type is a Boolean.

But "x =3D x + 0" has the type EQUATION(POLY(INT)), not
Boolean. Axiom says:

x =3D x + 0
               Type: Equation(Polynomial(Integer))
%::Boolean
   True
               Type: Boolean

The "elegant way" that Martin is questioning is the problem
of combining a certain kind of logic operation (refl aka
"reflection" where both sides are equal) with the notion of
a mathematical unit.

This particular issue is simple compared with the many other
issues. In Axiom, the question would be what is the type of
x, of 0, of +, and of the whole equation. If x is a matrix, for
example, the 0 is coerced to a matrix. And now the question
is "Is this equality true for matrix operations?"

Tim

On 6/25/19, William Sit <wsit@ccny.cuny.edu> wrote:
>
> Dear Martin and Tim:
>
> The expression  x =3D x + 0, whether treated as a type or an equation, ca=
n
> only make sense when x, =3D, + and 0 are clearly typed and defined. It ma=
kes
> little sense to me that this, as an equation, can be "proved" to be valid
> universally (that is, without the definition of, say +). For example, if =
we
> are in a domain where + is defined as max, or as min, or as the binary lo=
gic
> operator "and", then the expression is not an identity for all values x i=
n
> the domain. If + is the usual addition, or the logic operatior "or", then
> the expression is a true identity and can be proved (more or less from
> definitions). In Axiom, if valid, these are simply stated as properties o=
f
> the domain or category as in "has ...".
>
> I assume this is well-known and perhaps that is what Martin meant by "(I'=
m
> skipping over a lot of details)". I am ignorant of type theory and often
> confused by terms like type, equation (equation type?), identity, and eve=
n
> proposition (like x =3D x + 0 is an identity) as used in proof theories.
> Please ignore this message if the first paragraph is irrelevant to this
> thread.
>
> William Sit
> Professor Emeritus
> Department of Mathematics
> The City College of The City University of New York
> New York, NY 10031
> homepage: wsit.ccny.cuny.edu
>
> ________________________________________
> From: Axiom-developer
> <axiom-developer-bounces+wyscc=3Dsci.ccny.cuny.edu@nongnu.org> on behalf =
of
> Tim Daly <axiomcas@gmail.com>
> Sent: Wednesday, June 19, 2019 1:02 PM
> To: axiom-dev; Tim Daly
> Subject: [EXTERNAL] Re: [Axiom-developer] Axiom's Sane redesign musings
>
> Martin,
>
>> Are there some fundamental compromises that have to be made when combini=
ng
>> computer > algebra and proof technology?
>
>> For instance in proof assistants, like Coq, equations are types for
>> instance:
>
>> x =3D x + 0
>
>> is a proposition which, by Curry-Howard, can be represented as a type. T=
o
>> prove the
>> proposition we have to find an inhabitant of the type (Refl).
>
>> But in computer algebra I would have thought this equation would be an
>> element of
>> some Equation type (I'm skipping over a lot of details).
>
>> Do you think both of these approaches could be brought together in a
>> consistent and elegant way?
>
>> Also my (limited) understanding is that Coq prevents inconsistencies whi=
ch
>> makes it not Turing complete and therefore cant do everything Axiom can
>> do?
>
> Martin,
>
> There are many problems with the marriage of logic and algebra. For
> instance,
> the logic systems want proof of termination which is usually not
> possible. Often,
> though, a partial proof that does not guarantee termination is interestin=
g
> and
> sufficient. TLA provides some possible ideas in this direction.
>
> Another problem is that in the generality of dependent types, full
> type resolution
> is undecidable (hence, a lot of the heuristics built into Axiom's
> interpreter).
> Still there are interesting discussions of programs as proof objects ongo=
ing
> at
> the moment on the Lean discussion thread
> https://urldefense.proofpoint.com/v2/url?u=3Dhttps-3A__leanprover.zulipch=
at.com_-23&d=3DDwIGaQ&c=3D4NmamNZG3KTnUCoC6InoLJ6KV1tbVKrkZXHRwtIMGmo&r=3Dq=
W9SUYRDo6sWEVPpx7wwWYZ79PdSWMRxNZvTih0Bkxc&m=3DBh77WgNdFtJTZCN46189mNhezS-_=
JXcBwUWxnNPRF_8&s=3Du7sojPwgc1fuWoQpKPwsjxjH98p64z3RQNZlwxBTLPQ&e=3D
>
> Still other problems arise in equational reasoning or probablistic
> algorithms.
> I have looked at (and not really understood well) logics for these.
>
> On the other hand, things like the Groebner Basis algorithm have been pro=
ven
> in Coq. The technology, and the basic axioms, are gathering greater power=
.
>
> In particular, since Axiom has a strong scaffolding of abstract algebra, =
it
> is
> better suited for proofs than other systems. The fact that Axiom's compil=
er
> insists on type information makes it somewhat more likely to be provable.
>
> I have a very limited project goal of proving just the GCD algorithms in
> Axiom.
>
> The idea is to create a "thin thread" through all of the issues so that t=
hey
> can
> be attacked in more detail by later work. I've been gathering bits and
> pieces
> of GCD related items from the literature. See Volume 13 for the current
> state
> (mostly research notes and snippets to be reviewed)
> https://urldefense.proofpoint.com/v2/url?u=3Dhttps-3A__github.com_daly_PD=
FS_blob_master_bookvol13.pdf&d=3DDwIGaQ&c=3D4NmamNZG3KTnUCoC6InoLJ6KV1tbVKr=
kZXHRwtIMGmo&r=3DqW9SUYRDo6sWEVPpx7wwWYZ79PdSWMRxNZvTih0Bkxc&m=3DBh77WgNdFt=
JTZCN46189mNhezS-_JXcBwUWxnNPRF_8&s=3DmaYsCHxZ4fjQEYua_1NfaxuO785JXAJlC4YRp=
s-YFwQ&e=3D
>
> The idea is to decorate the categories with their respective axioms. Then=
 to
> decorate the domains with their axioms. Next to write specifications for =
the
> function implementations. Then finding invariants, pre- and post-conditio=
ns,
> etc. Finally, to generate a proof that can be automatically checked. So e=
ach
> function has a deep pile of inheritated informaion to help the proof.
>
> For example, a GCD algorithm in NonNegativeInteger already has the
> ability to assume non-negative types. And it inherits all the axioms that
> come with being a GCDDomain.
>
> The fact that computer algebra really is a form of mathematics (as oppose=
d
> to, say proving a compiler) gives me hope that progress is possible, even=
 if
> difficult.
>
> Do I know how to cross the "x=3Dx+0" type vs equation form? No, but
> this is research so I won't know until I know :-)
>
> Tim
>
> On 6/19/19, Tim Daly <axiomcas@gmail.com> wrote:
>> Sane: "rational, coherent, judicious, sound"
>>
>> Axiom is computational mathematics, of course. The effort to
>> Prove Axiom Sane involves merging computer algebra and proof
>> technology so Axiom's algorithms have associated proofs.
>>
>> The union of these two fields has made it obvious how far behind
>> Axiom has fallen. Mathematicians and some computer languages
>> (e.g. Haskell) have started to converge on some unifying ideas.
>>
>> As a result, the new Sane compiler and interpreter needs to
>> consider the current environment that mathematicians expect.
>> This falls into several areas.
>>
>> 1) SYNTAX
>>
>> It is clear that Axiom's syntax and user interface has not kept
>> up with the proof technology. A trivial example is a signature.
>> Axiom likes:
>>
>>    foo : (a,b) -> c
>>
>> whereas Lean / Coq / or even Haskell prefers
>>
>>    foo: a -> b -> c
>>
>> Given that many systems (e.g. Haskell) use the second syntax
>> we need to consider adopting this more widely accepted syntax.
>>
>> 2) PROOF and SPECIFICATIONS
>>
>> And, obviously, Axiom does not support 'axiom', 'lemma',
>> 'corollary', nor any specification language, or any language
>> for proof support (e.g. 'invariant').
>>
>> Mathematicians have these tools readily available in many
>> systems today.
>>
>> 3) USER INTERFACE
>>
>> Axiom's command line interface and hyperdoc were fine for its
>> time but Lean and Coq use a browser. For example, in Lean:
>>
>> https://urldefense.proofpoint.com/v2/url?u=3Dhttps-3A__leanprover.github=
.io_tutorial_&d=3DDwIGaQ&c=3D4NmamNZG3KTnUCoC6InoLJ6KV1tbVKrkZXHRwtIMGmo&r=
=3DqW9SUYRDo6sWEVPpx7wwWYZ79PdSWMRxNZvTih0Bkxc&m=3DBh77WgNdFtJTZCN46189mNhe=
zS-_JXcBwUWxnNPRF_8&s=3DEM0zfm6XLk9cSYEzwVYO2vVnvmksn6UcM0KkUGyu_Og&e=3D
>>
>> or in Coq:
>>
>> https://urldefense.proofpoint.com/v2/url?u=3Dhttps-3A__jscoq.github.io_&=
d=3DDwIGaQ&c=3D4NmamNZG3KTnUCoC6InoLJ6KV1tbVKrkZXHRwtIMGmo&r=3DqW9SUYRDo6sW=
EVPpx7wwWYZ79PdSWMRxNZvTih0Bkxc&m=3DBh77WgNdFtJTZCN46189mNhezS-_JXcBwUWxnNP=
RF_8&s=3DvLHZcW4aiLGGw3-bGeVoO4TFa3CBy3qIAlOIbRSbwf8&e=3D
>>
>> The combination of a browser, interactive development, and
>> "immediate documentation" merges a lot of Axiom's goals.
>>
>> 4) CATEGORY STRUCTURE
>>
>> William Farmer and Jacques Carette (McMaster University)
>> have the notion of "tiny theories". The basic idea (in Axiom
>> speak) is that each Category should only introduce a single
>> signature or a single axiom (e.g. commutativity). It seems
>> possible to restructure the Category hierarchy to use this model
>> wilthout changing the end result.
>>
>> 5) BIFORM THEORIES
>>
>> Farmer and Carette also have the notion of a 'biform theory'
>> which is a combination of code and proof. This is obviously
>> the same idea behind the Sane effort.
>>
>> 6) INTERACTIVITY
>>
>> As mentioned in (3) above, the user interface needs to support
>> much more interactive program development. Error messages
>> ought to point at the suspected code. This involves rewriting
>> the compiler and interpreter to better interface with these tools.
>>
>> Axiom already talks to a browser front end (Volume 11)
>> interactively but the newer combination of documentation
>> and interaction needs to be supported.
>>
>> Sage provides interactivity for some things but does not
>> (as far as I know) support the Lean-style browser interface.
>>
>> 7) ALGORITHMS
>>
>> Axiom's key strength and its key contribution is its collection
>> of algorithms. The proof systems strive for proofs but can't
>> do simple computations fast.
>>
>> The proof systems also cannot trust "Oracle" systems, since
>> they remain unproven.
>>
>> When Axiom's algorithms are proven, they provide the Oracle.
>>
>> 8) THE Sane EFFORT
>>
>> Some of the changes above are cosmetic (e.g. syntax), some
>> are "additive" (e.g. lemma, corollary), some are just a restructure
>> (e.g. "tiny theory" categories).
>>
>> Some of the changes are 'just programming', such as using
>> the browser to merge the command line and hyperdoc. This
>> involves changing the interpreter and compiler to deliver better
>> and more focused feedback All of that is "just a matter of
>> programming".
>>
>> The fundamental changes like merging a specification
>> language and underlying proof machinery are a real challenge.
>> "Layering Axiom" onto a trusted core is a real challenge but
>> (glacial) progress is being made.
>>
>> The proof systems are getting better. They lack long-term
>> stability (so far) and they lack Axiom's programming ability
>> (so far). But merging computer algebra and proof systems
>> seems to me to be possible with a focused effort.
>>
>> Due to its design and structure, Axiom seems the perfect
>> platform for this merger.
>>
>> Work on each of these areas is "in process" (albeit slowly).
>> The new Sane compiler is "on the path" to support all of these
>> goals.
>>
>> 9) THE "30 Year Horizion"
>>
>> Axiom either converges with the future directions by becoming
>> a proven and trusted mathematical tool ... or it dies.
>>
>> Axiom dies? ... As they say in the Navy "not on my watch".
>>
>> Tim
>>
>
> _______________________________________________
> Axiom-developer mailing list
> Axiom-developer@nongnu.org
> https://urldefense.proofpoint.com/v2/url?u=3Dhttps-3A__lists.nongnu.org_m=
ailman_listinfo_axiom-2Ddeveloper&d=3DDwIGaQ&c=3D4NmamNZG3KTnUCoC6InoLJ6KV1=
tbVKrkZXHRwtIMGmo&r=3DqW9SUYRDo6sWEVPpx7wwWYZ79PdSWMRxNZvTih0Bkxc&m=3DBh77W=
gNdFtJTZCN46189mNhezS-_JXcBwUWxnNPRF_8&s=3D071bx5Hfnags51BaZCergjN7ZxGQ0eQz=
cEsWvOJHG1s&e=3D

\start
Date: Tue, 25 Jun 2019 22:51:27 +0100
From: Martin Baker <ax87438@martinb.com>
To: Tim Daly <axiomcas@gmail.com>, William Sit <wsit@ccny.cuny.edu>,
Subject: Re: [Axiom-developer] [EXTERNAL] Re: Axiom's Sane redesign musings

On 6/25/19, William Sit<wsit@ccny.cuny.edu>  wrote:
 > The expression  x = x + 0, whether treated as a type or an equation,
 > can only make sense when x, =, + and 0 are clearly typed and defined.
 > It makes little sense to me that this, as an equation, can be "proved"
 > to be valid universally (that is, without the definition of, say +).

If x is a natural number defined like this in Coq:

Inductive nat : Set := O : nat | S : nat -> nat

then x = x + 0 is not an axiom but is derivable.
Of course this all depends on the structures and definitions, I didn't 
mean to imply that it is valid universally.

On 25/06/2019 19:28, Tim Daly wrote:
> The "elegant way" that Martin is questioning is the problem
> of combining a certain kind of logic operation (refl aka
> "reflection" where both sides are equal) with the notion of
> a mathematical unit.

I think that refl (short for "reflexivity" of = relation), is the usual 
abbreviation for the only constructor of an equality type in Martin-Lof 
type theory.

I get the impression that this theory is very powerful in proof 
assistants and I am questioning if you proposing to build this into 
Axiom and how?

Martin

\start
Date: Tue, 25 Jun 2019 20:16:12 -0400
From: Tim Daly <axiomcas@gmail.com>
To: Martin Baker <ax87438@martinb.com>
Subject: Re: [Axiom-developer] [EXTERNAL] Re: Axiom's Sane redesign musings

Martin,

My current "line of attack" on this research is to try to prove the
GCD algorithm in NonNegativeInteger.

While this seems trivial in proof systems it is expensive to
compute from the inductive definition. While this seems
trivial in computer algebra, the implementation code lacks
proof.

There are several steps I'm taking. I'm creating a new compiler
that handles Spad code with several new additions. The new
language (and the effort in general) is called "Sane".

One step is to make sure the new compiler generates code
that runs in Axiom. This is challenging as there is almost no
documentation about Axiom internals so it all has to be
reverse-engineered.

Next is the addition of "axioms" to the categories, such as
adding axioms for equality to BasicType, where equality is
defined to include reflexive and transitive properties.
(Equality, by the way, is probably THE most controversial
topics in logic, c.f. the univalence axiom in HoTT). These
axioms decorate the category signatures and are inherited.

Next is the addition of axioms to domains, also decorating
the signatures with axioms.

Next is the logical specification of properties of the data
type implementation of the domain, called the REP in
Axiom and the "carrier" in logic. For example, think of a
binary tree REP and what properties you can guarantee.

Next is adding a specification for the operations that
implement the signatures. These are specific to each
function that a domain implements.

Next is decorating code with pre- and post-conditions
as well as loop invariants and storage invariants.

Next the collection of all of the above is cast into a form
used by a proof system (currently Lean) that implements
dependent types (Calculus of Inductive Construction).

Next a proof is constructed. The resulting proof is attached
to the Axiom code. Proof checking is wildly cheaper than
proof construction and the new Sane compiler would
perform proof checking at compile time for each function.

So if there is a breaking change somewhere in the tower
the proof would fail.

Challenges along the way, besides reverse-engineering
the Spad compiler, include adding languages for stating
axioms, for stating REP properties, for stating function
specifications, for stating program properties, and for
stating proof certificates. The pieces all exist somewhere
but they are not necessarily compatible, nor well defined.

Is this all possible to do? Well, of course, as this is all
"just mathematics". Do *I* know how to do this? Well,
of course not, which is what makes this a research effort.

Ultimately I'm trying to build an instance of merging proof
and computer algebra at a very deep, proven level. Think
of it as a PhD thesis project without the degree incentive :-)

Tim

On 6/25/19, Martin Baker <ax87438@martinb.com> wrote:
> On 6/25/19, William Sit<wsit@ccny.cuny.edu>  wrote:
>  > The expression  x = x + 0, whether treated as a type or an equation,
>  > can only make sense when x, =, + and 0 are clearly typed and defined.
>  > It makes little sense to me that this, as an equation, can be "proved"
>  > to be valid universally (that is, without the definition of, say +).
>
> If x is a natural number defined like this in Coq:
>
> Inductive nat : Set := O : nat | S : nat -> nat
>
> then x = x + 0 is not an axiom but is derivable.
> Of course this all depends on the structures and definitions, I didn't
> mean to imply that it is valid universally.
>
> On 25/06/2019 19:28, Tim Daly wrote:
>> The "elegant way" that Martin is questioning is the problem
>> of combining a certain kind of logic operation (refl aka
>> "reflection" where both sides are equal) with the notion of
>> a mathematical unit.
>
> I think that refl (short for "reflexivity" of = relation), is the usual
> abbreviation for the only constructor of an equality type in Martin-Lof
> type theory.
>
> I get the impression that this theory is very powerful in proof
> assistants and I am questioning if you proposing to build this into
> Axiom and how?
>
> Martin
>

\start
Date: Wed, 26 Jun 2019 08:22:28 +0100
From: Martin Baker <ax87438@martinb.com>
To: Tim Daly <axiomcas@gmail.com>, axiom-dev <axiom-developer@nongnu.org>
Subject: Re: [Axiom-developer] [EXTERNAL] Re: Axiom's Sane redesign musings

Tim,

When I read this I am picking up a slightly different flavor than what I 
got from your first message in the thread.

You first message seemed to me to be about "merging computer algebra and 
proof technology" but this message seems to be about running the two in 
parallel.

I really like the idea of merging the two because Axiom has a steep 
learning curve and proof assistants have a steep learning curve. If they 
were merged the leaning curve would still be steep but at least there 
would only be one.

This seems to be more about:
* specifying axioms (and other identities?) in the category.
* decorating the domain with some denotational semantics stuff.
then checking it, at compile time, by running a separate proof assistant 
program.

Is this what you are suggesting.

Martin

On 26/06/2019 01:16, Tim Daly wrote:
> Martin,
> 
> My current "line of attack" on this research is to try to prove the
> GCD algorithm in NonNegativeInteger.
> 
> While this seems trivial in proof systems it is expensive to
> compute from the inductive definition. While this seems
> trivial in computer algebra, the implementation code lacks
> proof.
> 
> There are several steps I'm taking. I'm creating a new compiler
> that handles Spad code with several new additions. The new
> language (and the effort in general) is called "Sane".
> 
> One step is to make sure the new compiler generates code
> that runs in Axiom. This is challenging as there is almost no
> documentation about Axiom internals so it all has to be
> reverse-engineered.
> 
> Next is the addition of "axioms" to the categories, such as
> adding axioms for equality to BasicType, where equality is
> defined to include reflexive and transitive properties.
> (Equality, by the way, is probably THE most controversial
> topics in logic, c.f. the univalence axiom in HoTT). These
> axioms decorate the category signatures and are inherited.
> 
> Next is the addition of axioms to domains, also decorating
> the signatures with axioms.
> 
> Next is the logical specification of properties of the data
> type implementation of the domain, called the REP in
> Axiom and the "carrier" in logic. For example, think of a
> binary tree REP and what properties you can guarantee.
> 
> Next is adding a specification for the operations that
> implement the signatures. These are specific to each
> function that a domain implements.
> 
> Next is decorating code with pre- and post-conditions
> as well as loop invariants and storage invariants.
> 
> Next the collection of all of the above is cast into a form
> used by a proof system (currently Lean) that implements
> dependent types (Calculus of Inductive Construction).
> 
> Next a proof is constructed. The resulting proof is attached
> to the Axiom code. Proof checking is wildly cheaper than
> proof construction and the new Sane compiler would
> perform proof checking at compile time for each function.
> 
> So if there is a breaking change somewhere in the tower
> the proof would fail.
> 
> Challenges along the way, besides reverse-engineering
> the Spad compiler, include adding languages for stating
> axioms, for stating REP properties, for stating function
> specifications, for stating program properties, and for
> stating proof certificates. The pieces all exist somewhere
> but they are not necessarily compatible, nor well defined.
> 
> Is this all possible to do? Well, of course, as this is all
> "just mathematics". Do *I* know how to do this? Well,
> of course not, which is what makes this a research effort.
> 
> Ultimately I'm trying to build an instance of merging proof
> and computer algebra at a very deep, proven level. Think
> of it as a PhD thesis project without the degree incentive :-)
> 
> Tim
> 
> 
> On 6/25/19, Martin Baker <ax87438@martinb.com> wrote:
>> On 6/25/19, William Sit<wsit@ccny.cuny.edu>  wrote:
>>   > The expression  x = x + 0, whether treated as a type or an equation,
>>   > can only make sense when x, =, + and 0 are clearly typed and defined.
>>   > It makes little sense to me that this, as an equation, can be "proved"
>>   > to be valid universally (that is, without the definition of, say +).
>>
>> If x is a natural number defined like this in Coq:
>>
>> Inductive nat : Set := O : nat | S : nat -> nat
>>
>> then x = x + 0 is not an axiom but is derivable.
>> Of course this all depends on the structures and definitions, I didn't
>> mean to imply that it is valid universally.
>>
>> On 25/06/2019 19:28, Tim Daly wrote:
>>> The "elegant way" that Martin is questioning is the problem
>>> of combining a certain kind of logic operation (refl aka
>>> "reflection" where both sides are equal) with the notion of
>>> a mathematical unit.
>>
>> I think that refl (short for "reflexivity" of = relation), is the usual
>> abbreviation for the only constructor of an equality type in Martin-Lof
>> type theory.
>>
>> I get the impression that this theory is very powerful in proof
>> assistants and I am questioning if you proposing to build this into
>> Axiom and how?
>>
>> Martin
>>
> 

\start
Date: Wed, 26 Jun 2019 05:27:44 -0400
From: Tim Daly <axiomcas@gmail.com>
To: Martin Baker <ax87438@martinb.com>
Subject: Re: [Axiom-developer] [EXTERNAL] Re: Axiom's Sane redesign musings
Cc: axiom-dev <axiom-developer@nongnu.org>, William Sit <wsit@ccny.cuny.edu>, 
 James Davenport <J.H.Davenport@bath.ac.uk>, Jeremy Avigad <avigad@cmu.edu>

Yes, but even more than that.

The goal is to make Axiom a "trusted system" for the whole of
computational mathematics.

To do this, consider this (not entirely random) collection of systems
and facts:

1) Trusted systems are built using the de Bruijn principle. See, for example,
https://pdfs.semanticscholar.org/2498/8797cf3e98c3a4a7c3dc775f8c02ce252c33.pdf

The basic idea is to have a trusted kernel that is composed of
a small number of logic operations known to be correct. All other
operations get "compiled" into these trusted operations. This is
how the proof systems operate, by choosing a logic such as CIC
and then constructing a CIC kernel.

2) Axiom is really nothing more that a "Domain Specific Language"
on top of common lisp. For Axiom to be trusted, the lisp must be
trusted, which the whole of common lisp is not.

3) We would like a common lisp that is proven "down to the
metal". There is a lisp (not common lisp) kernel called Milawa
https://link.springer.com/article/10.1007/s10817-015-9324-6
that has this property. It starts with a proven kernel and builds
up layers (currently 11) towards ACL2, a common lisp theorem
prover.

4) There is a theorem prover called Matita which appears to be
of interest as another "intermediate step". See
http://matita.cs.unibo.it/index.shtml

5) There is also a newly forming Lean prover and I am trying
to follow along and get up to speed on it: See:
https://leanprover.github.io/

5) There is the mistaken belief that common lisp is a typeless
language. However, CLOS has defclass and every defclass
constructs a new type. So by careful design it is possible to
construct a "fully typed" domain specific language and compiler
in common lisp.

So what does this mean for a Sane Axiom system?

The game is to build the Sane compiler using CLOS so it is
strongly typed. The output of the compiler generates lisp code
that conforms to some (possibly higher, Axiom-specific) layer
of the Matita lisp. So compiler output would be in a provably
type-safe subset of lisp.

In addition, the Sane compiler is being constructed so that
the compiler itself can be proven correct. Everything in the
compiler is strongly typed as is its output.

Ultimately the goal is a proven Sane compiler that accepts
a provable Sane language for computer algebra which generates
proven computer algebra code running on a lisp that is
proven "down to the metal".

The end result is a trusted system for computational mathematics.

Like the blind philosophers, I can grab any part of this
elephantine system and describe it in great detail. My struggle
is to "envision the whole", make it sensible, and then construct
it in a provable way.

I've been at this for about 7 years now. I took 10 classes at
CMU. read several hundred papers (see the Axiom bibliography
volume, https://github.com/daly/PDFS/blob/master/bookvolbib.pdf)
and spent a few years "coming up to speed on the
proof theory" side of computational mathematics. Now I
finally have (poor) command of computer algebra, proof
theory, and provable programming. Having all the parts,
the question is "Can I construct the elephant?". I don't know.
But I am trying.

Tim


On 6/26/19, Martin Baker <ax87438@martinb.com> wrote:
> Tim,
>
> When I read this I am picking up a slightly different flavor than what I
> got from your first message in the thread.
>
> You first message seemed to me to be about "merging computer algebra and
> proof technology" but this message seems to be about running the two in
> parallel.
>
> I really like the idea of merging the two because Axiom has a steep
> learning curve and proof assistants have a steep learning curve. If they
> were merged the leaning curve would still be steep but at least there
> would only be one.
>
> This seems to be more about:
> * specifying axioms (and other identities?) in the category.
> * decorating the domain with some denotational semantics stuff.
> then checking it, at compile time, by running a separate proof assistant
> program.
>
> Is this what you are suggesting.
>
> Martin
>
> On 26/06/2019 01:16, Tim Daly wrote:
>> Martin,
>>
>> My current "line of attack" on this research is to try to prove the
>> GCD algorithm in NonNegativeInteger.
>>
>> While this seems trivial in proof systems it is expensive to
>> compute from the inductive definition. While this seems
>> trivial in computer algebra, the implementation code lacks
>> proof.
>>
>> There are several steps I'm taking. I'm creating a new compiler
>> that handles Spad code with several new additions. The new
>> language (and the effort in general) is called "Sane".
>>
>> One step is to make sure the new compiler generates code
>> that runs in Axiom. This is challenging as there is almost no
>> documentation about Axiom internals so it all has to be
>> reverse-engineered.
>>
>> Next is the addition of "axioms" to the categories, such as
>> adding axioms for equality to BasicType, where equality is
>> defined to include reflexive and transitive properties.
>> (Equality, by the way, is probably THE most controversial
>> topics in logic, c.f. the univalence axiom in HoTT). These
>> axioms decorate the category signatures and are inherited.
>>
>> Next is the addition of axioms to domains, also decorating
>> the signatures with axioms.
>>
>> Next is the logical specification of properties of the data
>> type implementation of the domain, called the REP in
>> Axiom and the "carrier" in logic. For example, think of a
>> binary tree REP and what properties you can guarantee.
>>
>> Next is adding a specification for the operations that
>> implement the signatures. These are specific to each
>> function that a domain implements.
>>
>> Next is decorating code with pre- and post-conditions
>> as well as loop invariants and storage invariants.
>>
>> Next the collection of all of the above is cast into a form
>> used by a proof system (currently Lean) that implements
>> dependent types (Calculus of Inductive Construction).
>>
>> Next a proof is constructed. The resulting proof is attached
>> to the Axiom code. Proof checking is wildly cheaper than
>> proof construction and the new Sane compiler would
>> perform proof checking at compile time for each function.
>>
>> So if there is a breaking change somewhere in the tower
>> the proof would fail.
>>
>> Challenges along the way, besides reverse-engineering
>> the Spad compiler, include adding languages for stating
>> axioms, for stating REP properties, for stating function
>> specifications, for stating program properties, and for
>> stating proof certificates. The pieces all exist somewhere
>> but they are not necessarily compatible, nor well defined.
>>
>> Is this all possible to do? Well, of course, as this is all
>> "just mathematics". Do *I* know how to do this? Well,
>> of course not, which is what makes this a research effort.
>>
>> Ultimately I'm trying to build an instance of merging proof
>> and computer algebra at a very deep, proven level. Think
>> of it as a PhD thesis project without the degree incentive :-)
>>
>> Tim
>>
>>
>> On 6/25/19, Martin Baker <ax87438@martinb.com> wrote:
>>> On 6/25/19, William Sit<wsit@ccny.cuny.edu>  wrote:
>>>   > The expression  x = x + 0, whether treated as a type or an equation,
>>>   > can only make sense when x, =, + and 0 are clearly typed and
>>> defined.
>>>   > It makes little sense to me that this, as an equation, can be
>>> "proved"
>>>   > to be valid universally (that is, without the definition of, say +).
>>>
>>> If x is a natural number defined like this in Coq:
>>>
>>> Inductive nat : Set := O : nat | S : nat -> nat
>>>
>>> then x = x + 0 is not an axiom but is derivable.
>>> Of course this all depends on the structures and definitions, I didn't
>>> mean to imply that it is valid universally.
>>>
>>> On 25/06/2019 19:28, Tim Daly wrote:
>>>> The "elegant way" that Martin is questioning is the problem
>>>> of combining a certain kind of logic operation (refl aka
>>>> "reflection" where both sides are equal) with the notion of
>>>> a mathematical unit.
>>>
>>> I think that refl (short for "reflexivity" of = relation), is the usual
>>> abbreviation for the only constructor of an equality type in Martin-Lof
>>> type theory.
>>>
>>> I get the impression that this theory is very powerful in proof
>>> assistants and I am questioning if you proposing to build this into
>>> Axiom and how?
>>>
>>> Martin

\start
Date: Thu, 27 Jun 2019 09:44:46 -0400
From: Tim Daly <axiomcas@gmail.com>
To: Martin Baker <ax87438@martinb.com>
Subject: Re: [Axiom-developer] [EXTERNAL] Re: Axiom's Sane redesign musings

Another thought....

There has been a "step change" in computer science in the last few years.

Guy Steele did a survey of the use of logic notation in conference papers.
More than 50% of the papers in some conferences use logic notation
(from one of the many logics).

CMU teaches their CS courses all based on and requiring the use of
logic and the associated notation. My college mathematics covered
the use of truth tables. The graduate course covered the use of
Karnaugh maps.

Reading current papers, I have found several papers with multiple
pages containing nothing but "judgements", pages of greek notation.
If you think Axiom's learning curve is steep, you should look at
Homotopy Type Theory (HoTT).

I taught a compiler course at Vassar in the previous century but
the Dragon book didn't cover CIC in any detail and I would not
have understood it if it did.

The original Axiom software predates most of the published logic
papers, at least as they applied to software. Haskell Curry wrote
from the logic side in 1934 and William Howard published in 1969
but I only heard of the Curry-Howard correspondence in 1998.

Writing a compiler these days requires the use of this approach.
In all, that's a good thing as it makes it clear how to handle types
and how to construct software that is marginally more correct.

The new Sane compiler is building on these logic foundations,
based on the Calculus of Inductive Construction and Dependent
Type theory. The compiler itself is strongly typed as is the
language it supports.

Since dependent types are not decidable there will always be
heuristics at runtime to try to disambiguate types, only now we
will have to write the code in greek :-)

Tim



On 6/26/19, Tim Daly <axiomcas@gmail.com> wrote:
> Yes, but even more than that.
>
> The goal is to make Axiom a "trusted system" for the whole of
> computational mathematics.
>
> To do this, consider this (not entirely random) collection of systems
> and facts:
>
> 1) Trusted systems are built using the de Bruijn principle. See, for
> example,
> https://pdfs.semanticscholar.org/2498/8797cf3e98c3a4a7c3dc775f8c02ce252c33.pdf
>
> The basic idea is to have a trusted kernel that is composed of
> a small number of logic operations known to be correct. All other
> operations get "compiled" into these trusted operations. This is
> how the proof systems operate, by choosing a logic such as CIC
> and then constructing a CIC kernel.
>
> 2) Axiom is really nothing more that a "Domain Specific Language"
> on top of common lisp. For Axiom to be trusted, the lisp must be
> trusted, which the whole of common lisp is not.
>
> 3) We would like a common lisp that is proven "down to the
> metal". There is a lisp (not common lisp) kernel called Milawa
> https://link.springer.com/article/10.1007/s10817-015-9324-6
> that has this property. It starts with a proven kernel and builds
> up layers (currently 11) towards ACL2, a common lisp theorem
> prover.
>
> 4) There is a theorem prover called Matita which appears to be
> of interest as another "intermediate step". See
> http://matita.cs.unibo.it/index.shtml
>
> 5) There is also a newly forming Lean prover and I am trying
> to follow along and get up to speed on it: See:
> https://leanprover.github.io/
>
> 5) There is the mistaken belief that common lisp is a typeless
> language. However, CLOS has defclass and every defclass
> constructs a new type. So by careful design it is possible to
> construct a "fully typed" domain specific language and compiler
> in common lisp.
>
> So what does this mean for a Sane Axiom system?
>
> The game is to build the Sane compiler using CLOS so it is
> strongly typed. The output of the compiler generates lisp code
> that conforms to some (possibly higher, Axiom-specific) layer
> of the Matita lisp. So compiler output would be in a provably
> type-safe subset of lisp.
>
> In addition, the Sane compiler is being constructed so that
> the compiler itself can be proven correct. Everything in the
> compiler is strongly typed as is its output.
>
> Ultimately the goal is a proven Sane compiler that accepts
> a provable Sane language for computer algebra which generates
> proven computer algebra code running on a lisp that is
> proven "down to the metal".
>
> The end result is a trusted system for computational mathematics.
>
> Like the blind philosophers, I can grab any part of this
> elephantine system and describe it in great detail. My struggle
> is to "envision the whole", make it sensible, and then construct
> it in a provable way.
>
> I've been at this for about 7 years now. I took 10 classes at
> CMU. read several hundred papers (see the Axiom bibliography
> volume, https://github.com/daly/PDFS/blob/master/bookvolbib.pdf)
> and spent a few years "coming up to speed on the
> proof theory" side of computational mathematics. Now I
> finally have (poor) command of computer algebra, proof
> theory, and provable programming. Having all the parts,
> the question is "Can I construct the elephant?". I don't know.
> But I am trying.
>
> Tim
>
>
> On 6/26/19, Martin Baker <ax87438@martinb.com> wrote:
>> Tim,
>>
>> When I read this I am picking up a slightly different flavor than what I
>> got from your first message in the thread.
>>
>> You first message seemed to me to be about "merging computer algebra and
>> proof technology" but this message seems to be about running the two in
>> parallel.
>>
>> I really like the idea of merging the two because Axiom has a steep
>> learning curve and proof assistants have a steep learning curve. If they
>> were merged the leaning curve would still be steep but at least there
>> would only be one.
>>
>> This seems to be more about:
>> * specifying axioms (and other identities?) in the category.
>> * decorating the domain with some denotational semantics stuff.
>> then checking it, at compile time, by running a separate proof assistant
>> program.
>>
>> Is this what you are suggesting.
>>
>> Martin
>>
>> On 26/06/2019 01:16, Tim Daly wrote:
>>> Martin,
>>>
>>> My current "line of attack" on this research is to try to prove the
>>> GCD algorithm in NonNegativeInteger.
>>>
>>> While this seems trivial in proof systems it is expensive to
>>> compute from the inductive definition. While this seems
>>> trivial in computer algebra, the implementation code lacks
>>> proof.
>>>
>>> There are several steps I'm taking. I'm creating a new compiler
>>> that handles Spad code with several new additions. The new
>>> language (and the effort in general) is called "Sane".
>>>
>>> One step is to make sure the new compiler generates code
>>> that runs in Axiom. This is challenging as there is almost no
>>> documentation about Axiom internals so it all has to be
>>> reverse-engineered.
>>>
>>> Next is the addition of "axioms" to the categories, such as
>>> adding axioms for equality to BasicType, where equality is
>>> defined to include reflexive and transitive properties.
>>> (Equality, by the way, is probably THE most controversial
>>> topics in logic, c.f. the univalence axiom in HoTT). These
>>> axioms decorate the category signatures and are inherited.
>>>
>>> Next is the addition of axioms to domains, also decorating
>>> the signatures with axioms.
>>>
>>> Next is the logical specification of properties of the data
>>> type implementation of the domain, called the REP in
>>> Axiom and the "carrier" in logic. For example, think of a
>>> binary tree REP and what properties you can guarantee.
>>>
>>> Next is adding a specification for the operations that
>>> implement the signatures. These are specific to each
>>> function that a domain implements.
>>>
>>> Next is decorating code with pre- and post-conditions
>>> as well as loop invariants and storage invariants.
>>>
>>> Next the collection of all of the above is cast into a form
>>> used by a proof system (currently Lean) that implements
>>> dependent types (Calculus of Inductive Construction).
>>>
>>> Next a proof is constructed. The resulting proof is attached
>>> to the Axiom code. Proof checking is wildly cheaper than
>>> proof construction and the new Sane compiler would
>>> perform proof checking at compile time for each function.
>>>
>>> So if there is a breaking change somewhere in the tower
>>> the proof would fail.
>>>
>>> Challenges along the way, besides reverse-engineering
>>> the Spad compiler, include adding languages for stating
>>> axioms, for stating REP properties, for stating function
>>> specifications, for stating program properties, and for
>>> stating proof certificates. The pieces all exist somewhere
>>> but they are not necessarily compatible, nor well defined.
>>>
>>> Is this all possible to do? Well, of course, as this is all
>>> "just mathematics". Do *I* know how to do this? Well,
>>> of course not, which is what makes this a research effort.
>>>
>>> Ultimately I'm trying to build an instance of merging proof
>>> and computer algebra at a very deep, proven level. Think
>>> of it as a PhD thesis project without the degree incentive :-)
>>>
>>> Tim
>>>
>>>
>>> On 6/25/19, Martin Baker <ax87438@martinb.com> wrote:
>>>> On 6/25/19, William Sit<wsit@ccny.cuny.edu>  wrote:
>>>>   > The expression  x = x + 0, whether treated as a type or an
>>>> equation,
>>>>   > can only make sense when x, =, + and 0 are clearly typed and
>>>> defined.
>>>>   > It makes little sense to me that this, as an equation, can be
>>>> "proved"
>>>>   > to be valid universally (that is, without the definition of, say
>>>> +).
>>>>
>>>> If x is a natural number defined like this in Coq:
>>>>
>>>> Inductive nat : Set := O : nat | S : nat -> nat
>>>>
>>>> then x = x + 0 is not an axiom but is derivable.
>>>> Of course this all depends on the structures and definitions, I didn't
>>>> mean to imply that it is valid universally.
>>>>
>>>> On 25/06/2019 19:28, Tim Daly wrote:
>>>>> The "elegant way" that Martin is questioning is the problem
>>>>> of combining a certain kind of logic operation (refl aka
>>>>> "reflection" where both sides are equal) with the notion of
>>>>> a mathematical unit.
>>>>
>>>> I think that refl (short for "reflexivity" of = relation), is the usual
>>>> abbreviation for the only constructor of an equality type in Martin-Lof
>>>> type theory.
>>>>
>>>> I get the impression that this theory is very powerful in proof
>>>> assistants and I am questioning if you proposing to build this into
>>>> Axiom and how?
>>>>
>>>> Martin

\start
Date: Sat, 29 Jun 2019 21:17:04 -0400
From: Tim Daly <axiomcas@gmail.com>
To: Martin Baker <ax87438@martinb.com>
Subject: Re: [Axiom-developer] [EXTERNAL] Re: Axiom's Sane redesign musings

One major Sane design decision is the use of CLOS,
the Common Lisp Object System.

First, since each CLOS object is a type it is possible to
create strong types everywhere. This helps with the ultimate
need to typecheck the compiler and the generated code.

Second, CLOS is an integral part of common lisp. One of
the Sane design goals is to make it possible to use Axiom's
domains in ordinary lisp programs. Since Axiom is nothing
more than a domain specific language on common lisp it
makes sense to construct it so users can freely intermix
polynomials with non-algebraic code.

Third, CLOS is designed for large program development,
hiding most of the implementation details and exposing
a well-defined API. This will make future maintenance and
documentation of Axiom easier, contributing to its longer
intended life.

So for a traditional Axiom user nothing seems to have
changed. But for future users it will be easy to compute
an integral in the middle of regular programs.

Tim

On 6/27/19, Tim Daly <axiomcas@gmail.com> wrote:
> Another thought....
>
> There has been a "step change" in computer science in the last few years.
>
> Guy Steele did a survey of the use of logic notation in conference papers.
> More than 50% of the papers in some conferences use logic notation
> (from one of the many logics).
>
> CMU teaches their CS courses all based on and requiring the use of
> logic and the associated notation. My college mathematics covered
> the use of truth tables. The graduate course covered the use of
> Karnaugh maps.
>
> Reading current papers, I have found several papers with multiple
> pages containing nothing but "judgements", pages of greek notation.
> If you think Axiom's learning curve is steep, you should look at
> Homotopy Type Theory (HoTT).
>
> I taught a compiler course at Vassar in the previous century but
> the Dragon book didn't cover CIC in any detail and I would not
> have understood it if it did.
>
> The original Axiom software predates most of the published logic
> papers, at least as they applied to software. Haskell Curry wrote
> from the logic side in 1934 and William Howard published in 1969
> but I only heard of the Curry-Howard correspondence in 1998.
>
> Writing a compiler these days requires the use of this approach.
> In all, that's a good thing as it makes it clear how to handle types
> and how to construct software that is marginally more correct.
>
> The new Sane compiler is building on these logic foundations,
> based on the Calculus of Inductive Construction and Dependent
> Type theory. The compiler itself is strongly typed as is the
> language it supports.
>
> Since dependent types are not decidable there will always be
> heuristics at runtime to try to disambiguate types, only now we
> will have to write the code in greek :-)
>
> Tim
>
>
>
> On 6/26/19, Tim Daly <axiomcas@gmail.com> wrote:
>> Yes, but even more than that.
>>
>> The goal is to make Axiom a "trusted system" for the whole of
>> computational mathematics.
>>
>> To do this, consider this (not entirely random) collection of systems
>> and facts:
>>
>> 1) Trusted systems are built using the de Bruijn principle. See, for
>> example,
>> https://pdfs.semanticscholar.org/2498/8797cf3e98c3a4a7c3dc775f8c02ce252c33.pdf
>>
>> The basic idea is to have a trusted kernel that is composed of
>> a small number of logic operations known to be correct. All other
>> operations get "compiled" into these trusted operations. This is
>> how the proof systems operate, by choosing a logic such as CIC
>> and then constructing a CIC kernel.
>>
>> 2) Axiom is really nothing more that a "Domain Specific Language"
>> on top of common lisp. For Axiom to be trusted, the lisp must be
>> trusted, which the whole of common lisp is not.
>>
>> 3) We would like a common lisp that is proven "down to the
>> metal". There is a lisp (not common lisp) kernel called Milawa
>> https://link.springer.com/article/10.1007/s10817-015-9324-6
>> that has this property. It starts with a proven kernel and builds
>> up layers (currently 11) towards ACL2, a common lisp theorem
>> prover.
>>
>> 4) There is a theorem prover called Matita which appears to be
>> of interest as another "intermediate step". See
>> http://matita.cs.unibo.it/index.shtml
>>
>> 5) There is also a newly forming Lean prover and I am trying
>> to follow along and get up to speed on it: See:
>> https://leanprover.github.io/
>>
>> 5) There is the mistaken belief that common lisp is a typeless
>> language. However, CLOS has defclass and every defclass
>> constructs a new type. So by careful design it is possible to
>> construct a "fully typed" domain specific language and compiler
>> in common lisp.
>>
>> So what does this mean for a Sane Axiom system?
>>
>> The game is to build the Sane compiler using CLOS so it is
>> strongly typed. The output of the compiler generates lisp code
>> that conforms to some (possibly higher, Axiom-specific) layer
>> of the Matita lisp. So compiler output would be in a provably
>> type-safe subset of lisp.
>>
>> In addition, the Sane compiler is being constructed so that
>> the compiler itself can be proven correct. Everything in the
>> compiler is strongly typed as is its output.
>>
>> Ultimately the goal is a proven Sane compiler that accepts
>> a provable Sane language for computer algebra which generates
>> proven computer algebra code running on a lisp that is
>> proven "down to the metal".
>>
>> The end result is a trusted system for computational mathematics.
>>
>> Like the blind philosophers, I can grab any part of this
>> elephantine system and describe it in great detail. My struggle
>> is to "envision the whole", make it sensible, and then construct
>> it in a provable way.
>>
>> I've been at this for about 7 years now. I took 10 classes at
>> CMU. read several hundred papers (see the Axiom bibliography
>> volume, https://github.com/daly/PDFS/blob/master/bookvolbib.pdf)
>> and spent a few years "coming up to speed on the
>> proof theory" side of computational mathematics. Now I
>> finally have (poor) command of computer algebra, proof
>> theory, and provable programming. Having all the parts,
>> the question is "Can I construct the elephant?". I don't know.
>> But I am trying.
>>
>> Tim
>>
>>
>> On 6/26/19, Martin Baker <ax87438@martinb.com> wrote:
>>> Tim,
>>>
>>> When I read this I am picking up a slightly different flavor than what I
>>> got from your first message in the thread.
>>>
>>> You first message seemed to me to be about "merging computer algebra and
>>> proof technology" but this message seems to be about running the two in
>>> parallel.
>>>
>>> I really like the idea of merging the two because Axiom has a steep
>>> learning curve and proof assistants have a steep learning curve. If they
>>> were merged the leaning curve would still be steep but at least there
>>> would only be one.
>>>
>>> This seems to be more about:
>>> * specifying axioms (and other identities?) in the category.
>>> * decorating the domain with some denotational semantics stuff.
>>> then checking it, at compile time, by running a separate proof assistant
>>> program.
>>>
>>> Is this what you are suggesting.
>>>
>>> Martin
>>>
>>> On 26/06/2019 01:16, Tim Daly wrote:
>>>> Martin,
>>>>
>>>> My current "line of attack" on this research is to try to prove the
>>>> GCD algorithm in NonNegativeInteger.
>>>>
>>>> While this seems trivial in proof systems it is expensive to
>>>> compute from the inductive definition. While this seems
>>>> trivial in computer algebra, the implementation code lacks
>>>> proof.
>>>>
>>>> There are several steps I'm taking. I'm creating a new compiler
>>>> that handles Spad code with several new additions. The new
>>>> language (and the effort in general) is called "Sane".
>>>>
>>>> One step is to make sure the new compiler generates code
>>>> that runs in Axiom. This is challenging as there is almost no
>>>> documentation about Axiom internals so it all has to be
>>>> reverse-engineered.
>>>>
>>>> Next is the addition of "axioms" to the categories, such as
>>>> adding axioms for equality to BasicType, where equality is
>>>> defined to include reflexive and transitive properties.
>>>> (Equality, by the way, is probably THE most controversial
>>>> topics in logic, c.f. the univalence axiom in HoTT). These
>>>> axioms decorate the category signatures and are inherited.
>>>>
>>>> Next is the addition of axioms to domains, also decorating
>>>> the signatures with axioms.
>>>>
>>>> Next is the logical specification of properties of the data
>>>> type implementation of the domain, called the REP in
>>>> Axiom and the "carrier" in logic. For example, think of a
>>>> binary tree REP and what properties you can guarantee.
>>>>
>>>> Next is adding a specification for the operations that
>>>> implement the signatures. These are specific to each
>>>> function that a domain implements.
>>>>
>>>> Next is decorating code with pre- and post-conditions
>>>> as well as loop invariants and storage invariants.
>>>>
>>>> Next the collection of all of the above is cast into a form
>>>> used by a proof system (currently Lean) that implements
>>>> dependent types (Calculus of Inductive Construction).
>>>>
>>>> Next a proof is constructed. The resulting proof is attached
>>>> to the Axiom code. Proof checking is wildly cheaper than
>>>> proof construction and the new Sane compiler would
>>>> perform proof checking at compile time for each function.
>>>>
>>>> So if there is a breaking change somewhere in the tower
>>>> the proof would fail.
>>>>
>>>> Challenges along the way, besides reverse-engineering
>>>> the Spad compiler, include adding languages for stating
>>>> axioms, for stating REP properties, for stating function
>>>> specifications, for stating program properties, and for
>>>> stating proof certificates. The pieces all exist somewhere
>>>> but they are not necessarily compatible, nor well defined.
>>>>
>>>> Is this all possible to do? Well, of course, as this is all
>>>> "just mathematics". Do *I* know how to do this? Well,
>>>> of course not, which is what makes this a research effort.
>>>>
>>>> Ultimately I'm trying to build an instance of merging proof
>>>> and computer algebra at a very deep, proven level. Think
>>>> of it as a PhD thesis project without the degree incentive :-)
>>>>
>>>> Tim
>>>>
>>>>
>>>> On 6/25/19, Martin Baker <ax87438@martinb.com> wrote:
>>>>> On 6/25/19, William Sit<wsit@ccny.cuny.edu>  wrote:
>>>>>   > The expression  x = x + 0, whether treated as a type or an
>>>>> equation,
>>>>>   > can only make sense when x, =, + and 0 are clearly typed and
>>>>> defined.
>>>>>   > It makes little sense to me that this, as an equation, can be
>>>>> "proved"
>>>>>   > to be valid universally (that is, without the definition of, say
>>>>> +).
>>>>>
>>>>> If x is a natural number defined like this in Coq:
>>>>>
>>>>> Inductive nat : Set := O : nat | S : nat -> nat
>>>>>
>>>>> then x = x + 0 is not an axiom but is derivable.
>>>>> Of course this all depends on the structures and definitions, I didn't
>>>>> mean to imply that it is valid universally.
>>>>>
>>>>> On 25/06/2019 19:28, Tim Daly wrote:
>>>>>> The "elegant way" that Martin is questioning is the problem
>>>>>> of combining a certain kind of logic operation (refl aka
>>>>>> "reflection" where both sides are equal) with the notion of
>>>>>> a mathematical unit.
>>>>>
>>>>> I think that refl (short for "reflexivity" of = relation), is the
>>>>> usual
>>>>> abbreviation for the only constructor of an equality type in
>>>>> Martin-Lof
>>>>> type theory.
>>>>>
>>>>> I get the impression that this theory is very powerful in proof
>>>>> assistants and I am questioning if you proposing to build this into
>>>>> Axiom and how?
>>>>>
>>>>> Martin

\start
Date: Sun, 30 Jun 2019 08:11:57 +0100
From: Martin Baker <ax87438@martinb.com>
To: Tim Daly <axiomcas@gmail.com>, axiom-dev <axiom-developer@nongnu.org>
Subject: Re: [Axiom-developer] [EXTERNAL] Re: Axiom's Sane redesign musings

Tim,

This all seems to be about the lisp layer, obviously thats what 
interests you.

It seems to me that if SPAD code is complicated and not aligned to type 
theory then, when SPAD is complied to Lisp, the List code will be 
complicated and hard to work with. Your previous remarks, about not 
seeing the whole elephant, suggest to me that you are drowning in 
complexity. Most languages, in their lifetime, acquire some messiness 
that needs to be cleared out occasionally.

Don't you think its time for SPAD 2.0 ?

Martin

On 30/06/2019 02:17, Tim Daly wrote:
> One major Sane design decision is the use of CLOS,
> the Common Lisp Object System.
> 
> First, since each CLOS object is a type it is possible to
> create strong types everywhere. This helps with the ultimate
> need to typecheck the compiler and the generated code.
> 
> Second, CLOS is an integral part of common lisp. One of
> the Sane design goals is to make it possible to use Axiom's
> domains in ordinary lisp programs. Since Axiom is nothing
> more than a domain specific language on common lisp it
> makes sense to construct it so users can freely intermix
> polynomials with non-algebraic code.
> 
> Third, CLOS is designed for large program development,
> hiding most of the implementation details and exposing
> a well-defined API. This will make future maintenance and
> documentation of Axiom easier, contributing to its longer
> intended life.
> 
> So for a traditional Axiom user nothing seems to have
> changed. But for future users it will be easy to compute
> an integral in the middle of regular programs.
> 
> Tim
> 
> On 6/27/19, Tim Daly <axiomcas@gmail.com> wrote:
>> Another thought....
>>
>> There has been a "step change" in computer science in the last few years.
>>
>> Guy Steele did a survey of the use of logic notation in conference papers.
>> More than 50% of the papers in some conferences use logic notation
>> (from one of the many logics).
>>
>> CMU teaches their CS courses all based on and requiring the use of
>> logic and the associated notation. My college mathematics covered
>> the use of truth tables. The graduate course covered the use of
>> Karnaugh maps.
>>
>> Reading current papers, I have found several papers with multiple
>> pages containing nothing but "judgements", pages of greek notation.
>> If you think Axiom's learning curve is steep, you should look at
>> Homotopy Type Theory (HoTT).
>>
>> I taught a compiler course at Vassar in the previous century but
>> the Dragon book didn't cover CIC in any detail and I would not
>> have understood it if it did.
>>
>> The original Axiom software predates most of the published logic
>> papers, at least as they applied to software. Haskell Curry wrote
>> from the logic side in 1934 and William Howard published in 1969
>> but I only heard of the Curry-Howard correspondence in 1998.
>>
>> Writing a compiler these days requires the use of this approach.
>> In all, that's a good thing as it makes it clear how to handle types
>> and how to construct software that is marginally more correct.
>>
>> The new Sane compiler is building on these logic foundations,
>> based on the Calculus of Inductive Construction and Dependent
>> Type theory. The compiler itself is strongly typed as is the
>> language it supports.
>>
>> Since dependent types are not decidable there will always be
>> heuristics at runtime to try to disambiguate types, only now we
>> will have to write the code in greek :-)
>>
>> Tim

\start
Date: Sun, 30 Jun 2019 11:40:21 -0400
From: Tim Daly <axiomcas@gmail.com>
To: Martin Baker <ax87438@martinb.com>
Subject: Re: [Axiom-developer] [EXTERNAL] Re: Axiom's Sane redesign musings

There are thousands of hours of expertise and thousands of
functions embedded in Spad code. An important design goal
is to ensure that code continues to function. The Sane compiler
will output code that runs in the interpreter. It is important that
"nothing breaks".

That said, the Sane compiler is "layered". The core of the design
is that Axiom categories, domains, and packages are represnted
as lisp classes and instances. This "core" is essentially what the
compiler people call an Abstract Syntax Tree (AST). But in this
case it is much more than syntax.

Given this "core" there are several tasks.

1) compile spad code to the core. The "front end" should
accept and understand current Spad code, unwinding it
into the core class structure.

2) compile core classes to Axiom data structures. Thi
"back end" generates current Axiom data structures from
the core data structures.

Now the compiler generates working code yet is in a state
to accept enhancements, essentially by extending the core
class objects.

3) In the interpreter, modify the getdatabase function to
extract data from the core rather than the databases. So
the databases go away but the interpreter continues to work.

So now the interpreter has been "lifted" onto the core classes
but continues to function.

4) enhance the core to support the axioms / specifications /
proofs /etc. This involves adding fields to the lisp classes.
This core work gives additional fields to hold information.

5) extend the Spad language (Spad 2.0?) to handle the
additional axioms / specifications / proofs / etc. This
involves adding syntax to the Spad language to support
the new fields.

6) build back-end targets to proof systems, spec systems,
etc. Compilers like GCC have multiple back ends. The Sane
compiler targets the interpreter, a specification checker, a
proof system, etc. as separate back ends, all from the same
core structures.

The Compiler Design

A separate but parallel design goal is to build the compiler so
it can be type-checked. Each function has typed input and
typed output and is, for the most part, purely functional. So,
for example, a "Filename" is an instance of a "File" object.
A "Line" is an instance of "String". The "FileReader" is

FileReader : Filename -> List Line

Careful design of the language used to construct hte compiler
(as opposed to the Spad language it accepts) makes it easier
to type check the compiler itself.

By REALLY careful design, the types are build on a layered
subset of lisp, like Milawa
https://www.cl.cam.ac.uk/~mom22/soundness.pdf
which is sound all the way down to the metal.

It all goes in stages. Build the new core class structure in a
strongly typed fashion. Accept the Spad language. Generate
Interpreter code. Enhance the core to support proofs / specs.
Enhance the language to support proofs / specs. Accept the
new language. Generate back ends to target the interpreter
and a proof / spec system. Build it all on a sound base so
the compiler can be checked.

To the initial end user, the Sane version is the same as the
current system. But in the long term all of the Axiom code
could be called from any Lisp function. The Sane version
can also be used as an "Oracle" for proof systems, since
the code has been proven correct.

This is a huge project but it can be done in small steps.
In particular, the goal is to build a "thin thread" all the way
through the system to handle only the GCD algorithms.
Once that proof happens "the real work begins".

Tim

\start
On 6/30/19, Martin Baker <ax87438@martinb.com> wrote:
> Tim,
>
> This all seems to be about the lisp layer, obviously thats what
> interests you.
>
> It seems to me that if SPAD code is complicated and not aligned to type
> theory then, when SPAD is complied to Lisp, the List code will be
> complicated and hard to work with. Your previous remarks, about not
> seeing the whole elephant, suggest to me that you are drowning in
> complexity. Most languages, in their lifetime, acquire some messiness
> that needs to be cleared out occasionally.
>
> Don't you think its time for SPAD 2.0 ?
>
> Martin
>
> On 30/06/2019 02:17, Tim Daly wrote:
>> One major Sane design decision is the use of CLOS,
>> the Common Lisp Object System.
>>
>> First, since each CLOS object is a type it is possible to
>> create strong types everywhere. This helps with the ultimate
>> need to typecheck the compiler and the generated code.
>>
>> Second, CLOS is an integral part of common lisp. One of
>> the Sane design goals is to make it possible to use Axiom's
>> domains in ordinary lisp programs. Since Axiom is nothing
>> more than a domain specific language on common lisp it
>> makes sense to construct it so users can freely intermix
>> polynomials with non-algebraic code.
>>
>> Third, CLOS is designed for large program development,
>> hiding most of the implementation details and exposing
>> a well-defined API. This will make future maintenance and
>> documentation of Axiom easier, contributing to its longer
>> intended life.
>>
>> So for a traditional Axiom user nothing seems to have
>> changed. But for future users it will be easy to compute
>> an integral in the middle of regular programs.
>>
>> Tim
>>
>> On 6/27/19, Tim Daly <axiomcas@gmail.com> wrote:
>>> Another thought....
>>>
>>> There has been a "step change" in computer science in the last few
>>> years.
>>>
>>> Guy Steele did a survey of the use of logic notation in conference
>>> papers.
>>> More than 50% of the papers in some conferences use logic notation
>>> (from one of the many logics).
>>>
>>> CMU teaches their CS courses all based on and requiring the use of
>>> logic and the associated notation. My college mathematics covered
>>> the use of truth tables. The graduate course covered the use of
>>> Karnaugh maps.
>>>
>>> Reading current papers, I have found several papers with multiple
>>> pages containing nothing but "judgements", pages of greek notation.
>>> If you think Axiom's learning curve is steep, you should look at
>>> Homotopy Type Theory (HoTT).
>>>
>>> I taught a compiler course at Vassar in the previous century but
>>> the Dragon book didn't cover CIC in any detail and I would not
>>> have understood it if it did.
>>>
>>> The original Axiom software predates most of the published logic
>>> papers, at least as they applied to software. Haskell Curry wrote
>>> from the logic side in 1934 and William Howard published in 1969
>>> but I only heard of the Curry-Howard correspondence in 1998.
>>>
>>> Writing a compiler these days requires the use of this approach.
>>> In all, that's a good thing as it makes it clear how to handle types
>>> and how to construct software that is marginally more correct.
>>>
>>> The new Sane compiler is building on these logic foundations,
>>> based on the Calculus of Inductive Construction and Dependent
>>> Type theory. The compiler itself is strongly typed as is the
>>> language it supports.
>>>
>>> Since dependent types are not decidable there will always be
>>> heuristics at runtime to try to disambiguate types, only now we
>>> will have to write the code in greek :-)
>>>
>>> Tim
>

\start
Date: Sun, 30 Jun 2019 15:18:29 -0400
From: Clifford Yapp <cliffyapp@gmail.com>
To: axiom-dev <axiom-developer@nongnu.org>
Subject: Re: [Axiom-developer] [EXTERNAL] Re: Axiom's Sane redesign musings

On Sun, Jun 30, 2019 at 11:40 AM Tim Daly <axiomcas@gmail.com> wrote:

>
> By REALLY careful design, the types are build on a layered
> subset of lisp, like Milawa
> https://www.cl.cam.ac.uk/~mom22/soundness.pdf
> which is sound all the way down to the metal.
>

Milawa and Jitawa... Wow.  That is a really interesting development.

Tim, I'm nowhere near current on recent developments so apologies if I'm
not interpreting this correctly, but will the Sane core be able to identify
any existing bugs in the Spad code?  I.e., will any successful compilation
of existing Spad code on the Sane stack indicate verified correctness of
the Spad algorithm?  Or (almost as useful for applied problems) will it
instead mean that for any particular application of a Sane-compiled Spad
algorithm to a specific numerical problem, the system will be able to
generate a specific proof for the correctness of that answer that is in
turn tractably verifiable by simple proof checkers?

(Either way, what I'm hoping is that whether or not proof techniques are
powerful enough to verify general properties of symbolic expressions, this
approach will allow an applied user (say a physicist) to at the end of the
day be very confident that the computer-algebra-system-supplied answer for
any specific problem is correct...)

Cheers,
CY


\end{verbatim}
\eject
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cleardoublepage
%\phantomsection
\addcontentsline{toc}{chapter}{Bibliography}
\bibliographystyle{axiom}
\bibliography{axiom}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cleardoublepage
%\phantomsection
\addcontentsline{toc}{chapter}{Index}
\printindex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
